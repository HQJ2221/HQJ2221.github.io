<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>è®¡ç®—æœºç½‘ç»œ</title>
    <url>/2024/09/09/Computer-Networks/</url>
    <content><![CDATA[<h1 id="Chapter-1-Introduction"><a href="#Chapter-1-Introduction" class="headerlink" title="Chapter 1. Introduction"></a>Chapter 1. Introduction</h1><HR style="FILTER: alpha(opacity=0, finishopacity=100,style=1)" width="100%" color="black" size="2">

<center><font face="STXinwei" size="5">Layout</font></center>

<p><strong>1.1</strong> what is the Internet?</p>
<p><strong>1.2</strong> network edge</p>
<ul>
<li>end systems, access networks, links</li>
</ul>
<p><strong>1.3</strong> network core</p>
<ul>
<li>packet switching, circuit switching, network, structure</li>
</ul>
<p><strong>1.4</strong> delay, loss, throughput in networks</p>
<p><strong>1.5</strong> protocol layers, service models</p>
<p><strong>1.6</strong> networks under attack: security</p>
<HR style="FILTER: alpha(opacity=0,finishopacity=100,style=1)" width="100%" color="black" size="2">



<blockquote>
<p>Learning top-down, we have 5 layer about computer network</p>
</blockquote>
<ul>
<li>Application: supporting network applications<ul>
<li>IMAP, SMTP, HTTP</li>
</ul>
</li>
<li>Transport: process-process data transfer<ul>
<li>TCP, UDP</li>
</ul>
</li>
<li>Network: routing of datagrams from source to destination<ul>
<li>IP, routing protocols</li>
</ul>
</li>
<li>Link: data transfer between neighboring  network elements<ul>
<li>Ethernet, 802.11 (WiFi), P2P</li>
</ul>
</li>
<li>Physical: bits â€œon the wireâ€</li>
</ul>
<h2 id="1-1-Structure-of-Internet"><a href="#1-1-Structure-of-Internet" class="headerlink" title="1.1. Structure of Internet"></a>1.1. Structure of Internet</h2><table>
<tr>
<td><img src="/2024/09/09/Computer-Networks/cn1.png" style="zoom:60%"></td>
<td><img src="/2024/09/09/Computer-Networks/cn2.png" style="zoom:60%"></td>
</tr>
</table>



<h2 id="1-2-Network-edge"><a href="#1-2-Network-edge" class="headerlink" title="1.2. Network edge"></a>1.2. Network edge</h2><ul>
<li>end systems (hosts):<ul>
<li>run application programs</li>
<li>e.g. Web, email</li>
<li>at â€œedge of networkâ€</li>
</ul>
</li>
<li>client/server model<ul>
<li>client host requests, receives service from always-on server</li>
<li>e.g., Web browser/server; email </li>
</ul>
</li>
<li>client/server<ul>
<li>peer-peer model:</li>
<li>minimal (or no) use of dedicated servers</li>
<li>e.g. Skype,  BitTorrent</li>
</ul>
</li>
</ul>
<p><strong>Hosts: sends packets of data</strong></p>
<p>Host sending function:</p>
<ul>
<li>takes application message</li>
<li>breaks into smaller chunks, known as packets, of length $L$ bits</li>
<li>transmits packet into access network at transmission rate $R$<ul>
<li>aka link capacity, bandwidth (å³é“¾è·¯å®¹é‡æˆ–å¸¦å®½)</li>
</ul>
</li>
</ul>
<p><img src="/2024/09/09/Computer-Networks/cn3.png" style="zoom:80%"></p>
<blockquote class="blockquote-center">
<p>$<br>\text{packet transmission delay}=\frac{L\text{(bits)}}{R\text{(bits/sec)}}<br>$</p>

</blockquote>
<h2 id="Plus-Access-Networks-æ¥å…¥ç½‘"><a href="#Plus-Access-Networks-æ¥å…¥ç½‘" class="headerlink" title="Plus: Access Networks(æ¥å…¥ç½‘)"></a>Plus: Access Networks(æ¥å…¥ç½‘)</h2><p><strong>Def.</strong> The network that physically connects an <font color="red">end system</font> to the <font color="red">first router (edge router)</font> on a path from the end system to any other distant end system.</p>
<p>Different kinds of access networks:</p>
<ul>
<li>Cable network</li>
<li>Digital subscriber line (DSL)</li>
<li>Home network</li>
<li>Wireless access network</li>
<li>Enterprise access network</li>
</ul>
<p><strong>Cable network</strong></p>
<p><img src="/2024/09/09/Computer-Networks/cn4.png" style="zoom:60%"></p>
<ul>
<li>Cable Internet access makes use of the cable television companyâ€™s existing <font color="blue">cable television infrastructure</font>.</li>
<li>Shared broadcast medium<ul>
<li>Shared downstream and upstream</li>
<li>Distributed multiple access control: avoid collision (åˆ†é¢‘æ®µæ§åˆ¶)</li>
</ul>
</li>
<li>Applying Frequency division multiplexing (é¢‘åˆ†å¤ç”¨)</li>
<li>Hybrid fiber coax (HFC): fiber + coaxial cable (å…‰çº¤+åŒè½´ç”µç¼†)<ul>
<li>asymmetric: up to 30 Mbps downstream transmission rate(ä¸‹è¡Œä¼ è¾“æ•ˆç‡), 2 Mbps upstream transmission rate</li>
</ul>
</li>
<li>network of cable, fiber attaches homes to ISP router<ul>
<li>homes share access network to cable headend(å¤šå®¶åº­ç½‘ç»œæ¥å…¥åŒä¸€ç”µç¼†å¤´éƒ¨)</li>
</ul>
</li>
</ul>
<p><strong>DSL(digital subscriber line)</strong></p>
<ul>
<li>Digital subscriber line (DSL) makes use of the its wired local phone(æœ‰çº¿æœ¬åœ°ç”µè¯) access of local telephone company (telco).</li>
<li>Use existing telephone line to central office DSLAM<ul>
<li>data over DSL phone line goes to Internet</li>
<li>voice over DSL phone line goes to telephone net</li>
</ul>
</li>
<li>&lt; 2.5 Mbps upstream transmission rate (typically &lt; 1 Mbps)</li>
<li>&lt; 24 Mbps downstream transmission rate (typically &lt; 10 Mbps)</li>
</ul>
<p><strong>Wireless Access Network</strong></p>
<ul>
<li>Shared wireless access network connects end systems to router<ul>
<li>via base station aka â€œaccess pointâ€</li>
</ul>
</li>
<li>Wireless LANs(WLAN):<ul>
<li>within building (100 ft)</li>
<li>802.11b/g/n/ac (WiFi): 11, 54, 800, 1733 Mbps transmission rate</li>
</ul>
</li>
<li>Wide-area wireless access<ul>
<li>provide by telco (cellular) operator</li>
<li>10 Mbps, 100Mbps, 10Gbps </li>
<li>3G, 4G, 5G</li>
</ul>
</li>
</ul>
<blockquote>
<p>è¡¥å……ï¼šä¿¡å·ä¼ è¾“ç‰©ç†ä»‹è´¨</p>
<ul>
<li>å•ä½ï¼šbit</li>
<li>æœ‰å‘ä»‹è´¨<ul>
<li>å›ºä½“ä»‹è´¨å¦‚é“œï¼Œå…‰çº¤å’ŒåŒè½´ç¼†çº¿</li>
</ul>
</li>
<li>æ— å‘ä»‹è´¨<ul>
<li>æ— çº¿ç”µ</li>
</ul>
</li>
</ul>
</blockquote>
<h2 id="1-3-Network-Core-ç½‘ç»œæ ¸å¿ƒ"><a href="#1-3-Network-Core-ç½‘ç»œæ ¸å¿ƒ" class="headerlink" title="1.3. Network Core(ç½‘ç»œæ ¸å¿ƒ)"></a>1.3. Network Core(ç½‘ç»œæ ¸å¿ƒ)</h2><p><strong>Def.</strong>  The mesh(é“¾è·¯ç½‘æ ¼) of packet switches and links that interconnects the Internetâ€™s end systems.</p>
<h4 id="Packet-switching-vs-Circuit-switching"><a href="#Packet-switching-vs-Circuit-switching" class="headerlink" title="Packet switching vs. Circuit switching"></a>Packet switching vs. Circuit switching</h4><p><strong>Packet Switching</strong></p>
<p>Basic thought: Hosts break long messages into packets and each packet is forwarded independently.</p>
<p><img src="/2024/09/09/Computer-Networks/cn5.png" style="zoom:60%"></p>
<ul>
<li><font color="red">store-and-forward</font></li>
<li>each packet is transmitted at <font color="red">full link capacity</font></li>
<li><font color="red">not reserved</font> â†’ queueing delay and packet loss<ul>
<li>queuing delay: packets will queue, wait to be transmitted on link</li>
<li>packet loss(ä¸¢åŒ…): packets can be dropped (lost) if memory (buffer) fills up</li>
</ul>
</li>
</ul>
<blockquote>
<p>Make it clear: whatâ€™s routing ? whatâ€™s forwarding ?</p>
<p><font color="red">Routing</font> is global actions: determine source-destination paths taken by packets, and need routing algorithm</p>
<p><font color="red">Forwarding</font> is local actions (inside 1 router): move arriving packets from routerâ€™s input link to appropriate router output link</p>
</blockquote>
<p><strong>Circuit Switching: FDM vs. TDM</strong></p>
<p>Basic thought: Determine path before the message being transmitted (called).</p>
<ul>
<li>Advantage: Guaranteed constant rate</li>
<li>Reserved (dedicated resources): buffer, link</li>
<li>Limitation: Circuit idleï¼ˆç©ºé—²ï¼‰if not used by call (no sharing)</li>
</ul>
<ul>
<li>About <strong>FDM</strong>(é¢‘åˆ†å¤ç”¨) and <strong>TDM</strong>(æ—¶åˆ†å¤ç”¨)<ul>
<li>FDM divides frequencies into (narrow) frequency bands â†’ bandwidth<ul>
<li>transmit at max rate of that narrow band</li>
</ul>
</li>
<li>TDM divides time into slots<ul>
<li>at maximum rate of (wider) frequency band, but only during its time slot(s)</li>
<li>have T virtual links in each frame (graph below)</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="/2024/09/09/Computer-Networks/cn6.png" style="zoom:60%"></p>
<p>An example to calculate delay in <strong>Circuit Switching</strong>: </p>
<p><img src="/2024/09/09/Computer-Networks/cn7.png" style="zoom:60%"></p>
<p align="center">----- COMPARISON -----</p>

<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">Packet Switching</th>
<th style="text-align:center">Circuit Switching</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">not reserved</td>
<td style="text-align:center">reserved (dedicated resources):<br>buffer, link, transmission rate</td>
</tr>
<tr>
<td style="text-align:center">packet forwarded independently(æ¯æ­¥ç‹¬ç«‹)</td>
<td style="text-align:center">establish an end-to-end link</td>
</tr>
<tr>
<td style="text-align:center">at full link capacity</td>
<td style="text-align:center">a fraction of each linkâ€™s capacity</td>
</tr>
<tr>
<td style="text-align:center">queuing delay</td>
<td style="text-align:center">guaranteed constant rate</td>
</tr>
<tr>
<td style="text-align:center">packet loss</td>
<td style="text-align:center">circuit segment idle</td>
</tr>
</tbody>
</table>
</div>
<blockquote>
<p>Therefore, Packet Switching is more used in network(more users but have low prob to online at the same time), Circuit Switching is more used in telephone call(assuring rate and connection).</p>
</blockquote>
<h4 id="Network-Structure"><a href="#Network-Structure" class="headerlink" title="Network Structure"></a>Network Structure</h4><p><img src="/2024/09/09/Computer-Networks/cn8.png" style="zoom:60%"></p>
<ul>
<li>Different ISPs from different business</li>
<li><font color="red">Internet exchange point(IXP)</font> as a connection between ISPs, or direct linking by <font color="red">peering links</font></li>
<li>Regional network may arise to connect access nets to ISPs</li>
<li><font color="red">Content provider networks</font>(e.g. Google, Microsoft) may run their own network, to bring services, content close to end users.</li>
</ul>
<h2 id="1-4-Performance-Metric"><a href="#1-4-Performance-Metric" class="headerlink" title="1.4. Performance Metric"></a>1.4. Performance Metric</h2><ul>
<li>Delay<ul>
<li>Nodal delay &amp; end-to-end delay</li>
</ul>
</li>
<li>Packet Loss</li>
<li>Throughput<ul>
<li>the amount of data per second that can be transferred between end systems</li>
</ul>
</li>
</ul>
<font color="green">Recall: Packet Switching would make packets queuing at each router(delay), if a router is full, the new packet would be dropped(loss).</font>



<h3 id="Delay-Nodal-vs-End-to-end"><a href="#Delay-Nodal-vs-End-to-end" class="headerlink" title="Delay: Nodal vs. End-to-end"></a>Delay: Nodal vs. End-to-end</h3><p><strong>Nodal Delay</strong></p>
<blockquote class="blockquote-center">
<p>$<br>d_{\text{nodal}}=d_{\text{proc}}+d_{\text{queue}}+d_{\text{trans}}+d_{\text{prop}}<br>$</p>

</blockquote>
<ul>
<li>$d_{\text{proc}}$ : nodal processing<ul>
<li>check bit errors</li>
<li>determine output link</li>
<li>typically &lt; 1 msec</li>
</ul>
</li>
<li>$d_{\text{queue}}$ : <ul>
<li>time waiting at output link for transmission </li>
<li>depends on congestion(æ‹¥å µ) level of router</li>
</ul>
</li>
<li>$d_{\text{trans}}$ : ä¼ è¾“æ—¶å»¶<ul>
<li>$L$: packet length (bits) </li>
<li>$R$: transmission rate (bps)</li>
<li>$d_{\text{trans}} = L/R$</li>
</ul>
</li>
<li>$d_{\text{prop}}$ : ä¼ æ’­æ—¶å»¶<ul>
<li>$d$: length of physical link</li>
<li>$s$: propagation speed in medium (~2x108 m/sec)</li>
<li>$d_{\text{prop}} = d/s$</li>
</ul>
</li>
</ul>
<blockquote>
<p>Easy way to understand $d_{\text{trans}}$ and $d_{\text{prop}}$</p>
<p>Assume that a ten-car caravan(packets) is moving through tollbooth (end/routers). Think of a car as a bit data.<br>Suppose that the Tollbooth takes 12 sec to service one car (transmission time) and cars runs at a speed of 100 km/hr (propagation speed).</p>
<font color="red">Q: How long does it take the <b>last car</b> to arrive at the 2nd tollbooth?</font>

<p>Now the time to â€œpushâ€ entire caravan through tollbooth onto highway = 12 * 10 = 120 sec, known as <font color="blue">Transmission Delay</font>;</p>
<p>The time for last car to propagate from 1st to 2nd tollbooth: 100km / (100km/hr) = 1 hr, known as <font color="blue">Propagation Delay</font>.</p>
<font color="green">A: 62 mins</font>



</blockquote>
<ul>
<li>Special: Queuing Delay â€” Vary from packet to packet<ul>
<li>When characterizing queuing delay, statistical measures:<ul>
<li>average queuing delay</li>
<li>variance of queuing delay</li>
<li>the probability that the queuing delay exceeds some specified value</li>
</ul>
</li>
<li>Use Traffic intensity $=\lambda L / R$ to measure avg queuing delay.<ul>
<li>$\lambda$ : average packet arrival rate (packets per sec)</li>
<li>$\lambda L / R \to 0$: avg. queueing delay small</li>
<li>$\lambda L / R \to 1$: avg. queueing delay $\to \infty$ (queuing theory)</li>
<li>$\lambda L / R \lt 1$: more â€œworkâ€ arriving than can be serviced, average delay infinite!</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>End-to-end Delay</strong></p>
<blockquote class="blockquote-center">
<p>$<br>d_{\text{end-end}}=N(d_{\text{proc}}+d_{\text{trans}}+d_{\text{prop}})<br>$</p>

</blockquote>
<p align="center">What do "real" Internet delay & loss look like?</p>

<blockquote>
<p>Refer to Lab 1</p>
</blockquote>
<h3 id="Throughput-ååé‡"><a href="#Throughput-ååé‡" class="headerlink" title="Throughput(ååé‡)"></a>Throughput(ååé‡)</h3><p><strong>Def.</strong> rate (bits/time unit) at which bits transferred between sender/receiver.</p>
<blockquote>
<p>Throughput is decided by the pipe with minimum fluid-carry-rate.</p>
</blockquote>
<ul>
<li>More complex condition: 10 connections (fairly) share backbone bottleneck link R bits/sec<ul>
<li>Per-connection end-end throughput: $\min{\{R_c, R_s, R/10\}}$</li>
<li>In practice: $R_c$ or $R_s$ is often bottleneck</li>
</ul>
</li>
</ul>
<p><img src="/2024/09/09/Computer-Networks/cn9.png" style="zoom:40%"></p>
<h2 id="1-5-Protocol-layers-amp-Service-models"><a href="#1-5-Protocol-layers-amp-Service-models" class="headerlink" title="1.5. Protocol layers &amp; Service models"></a>1.5. Protocol layers &amp; Service models</h2><blockquote>
<font color="red">Q: Why layering?</font>

<p>To deal with complex systems: </p>
<ul>
<li>Explicit structure allows identification, relationship of complex systemâ€™s pieces</li>
<li>modularization eases maintenance, updating of system</li>
</ul>
<font color="red">Q: Any drawbacks?</font>

<ul>
<li>One layer may duplicate lower layer functionality</li>
<li>Functionality at one layer may need information that is present only in another layer</li>
</ul>
</blockquote>
<ul>
<li>An easy model to describe how networks layering:</li>
</ul>
<p><img src="/2024/09/09/Computer-Networks/cn10.png" style="zoom:60%"></p>
<ul>
<li>Layers: Each layer provide services to the layer above<ul>
<li>via its own internal-layer actions</li>
<li>relying on services provided by layer below</li>
</ul>
</li>
</ul>
<p><strong>Encapsulation</strong></p>
<ul>
<li>Used to keep content of data safe and assure the layer below to acquire enough info to transmit.</li>
</ul>
<p><img src="/2024/09/09/Computer-Networks/cn11.png" style="zoom:40%"></p>
<h2 id="1-6-Security"><a href="#1-6-Security" class="headerlink" title="1.6. Security"></a>1.6. Security</h2><p><strong>Attack Type</strong></p>
<ol>
<li>Malware(æ¶æ„è½¯ä»¶) into hosts via Internet<ul>
<li>virus</li>
<li>worm</li>
</ul>
</li>
<li>Attack server: Denial of Service(DoS), make resources(server, bandwidth) unavailable to legitimate(åˆæ³•çš„) traffic by overwhelming resource with bogus(ä¼ªé€ çš„) traffic.<ul>
<li>aka. æ›´æ”¹ domain åœ°å€</li>
</ul>
</li>
<li>Sniff packets(æ‹†åŒ…ï¼Œæ‹¦æˆª):<ul>
<li>broadcast media</li>
<li>read all packets passing by</li>
</ul>
</li>
<li>Use fake addresses:<ul>
<li>send packet with false source address</li>
</ul>
</li>
</ol>
<p><strong>Defense Lines</strong></p>
<ul>
<li>authentication</li>
<li>confidentiality(å¯†ä¿): via encryption</li>
<li>integrity checks(å¤šé‡æ£€æµ‹)</li>
<li>access restrictions</li>
<li>firewalls: <ul>
<li>off-by-default: filter packets</li>
<li>detecting / reacting to DoS attacks</li>
</ul>
</li>
</ul>
<h1 id="Chapter-2-Application-Layer"><a href="#Chapter-2-Application-Layer" class="headerlink" title="Chapter 2. Application Layer"></a>Chapter 2. Application Layer</h1><HR style="FILTER: alpha(opacity=0, finishopacity=100,style=1)" width="100%" color="black" size="2">

<center><font face="STXinwei" size="5">Layout</font></center>

<p><strong>2.1</strong> principles of network applications</p>
<p><strong>2.2</strong> Web and HTTP</p>
<p><strong>2.3</strong> Electronic mail</p>
<ul>
<li>SMTP, POP3, IMAP</li>
</ul>
<p><strong>2.4</strong> DNS</p>
<p><strong>2.5</strong> P2P applications</p>
<p><strong>2.6</strong> video streaming and content distribution networks</p>
<p><strong>2.7</strong> socket programming with UDP and TCP</p>
<HR style="FILTER: alpha(opacity=0, finishopacity=100,style=1)" width="100%" color="black" size="2">

<blockquote>
<p>Learning Goals: </p>
<p>æœ‰å…³ç½‘ç»œåº”ç”¨åè®®çš„æ¦‚å¿µä¸å®ç°ï¼šåŒ…æ‹¬ç”¨æˆ·-æœåŠ¡ç«¯æ¶æ„ï¼Œpeer-to-peer æ¶æ„å’Œä¼ è¾“å±‚æœåŠ¡æ¨¡å‹</p>
<p>å­¦ä¹ ä¸€äº›å¹¿æ³›ä½¿ç”¨çš„åº”ç”¨å±‚åè®®ï¼šå¦‚HTTPï¼ŒPOP3ï¼ŒDNSç­‰</p>
<p>å­¦ä¹ å¦‚ä½•æ­å»ºç®€å•ç½‘ç»œåº”ç”¨ï¼šassignment 1 ç›¸å…³ï¼Œç”¨ python å»ºç«‹ç”¨æˆ·-æœåŠ¡ç«¯ä¹‹é—´çš„ç›¸äº’é€šä¿¡</p>
</blockquote>
<h2 id="2-1-Principles-of-network-applications"><a href="#2-1-Principles-of-network-applications" class="headerlink" title="2.1. Principles of network applications"></a>2.1. Principles of network applications</h2><ul>
<li>Consider building a network application :<ul>
<li><font color="red">Q1: Which architecture?</font> client-server or peer-to-peer?</li>
<li><font color="red">Q2: Which transport layer protocol to choose?</font> TCP? UDP?</li>
<li><font color="red">Q3: Which protocol to follow?</font> HTTP for Web? SMTP for email? Customized?</li>
</ul>
</li>
</ul>
<h3 id="Architecture-of-network"><a href="#Architecture-of-network" class="headerlink" title="Architecture of network"></a>Architecture of network</h3><p><strong>Client-Server Architecture</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">Server</th>
<th style="text-align:center">Client</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">always-on host</td>
<td style="text-align:center">communicate with server(can shutdown)</td>
</tr>
<tr>
<td style="text-align:center">permanent(fixed, well-known) IP address</td>
<td style="text-align:center">may have dynamic IP addresses</td>
</tr>
<tr>
<td style="text-align:center">data centers for scaling</td>
<td style="text-align:center">no direct communication with each other</td>
</tr>
</tbody>
</table>
</div>
<p><strong>P2P Architecture</strong></p>
<ul>
<li><em>no</em> always-in server, directly communicate</li>
<li>peers <em>request</em> service from other peers, <em>provide</em> service in return to otehr peers<ul>
<li><font color="red">self scalability:</font> new peers bring new service capacity and new service demands</li>
</ul>
</li>
</ul>
<blockquote>
<p>Hybrid arch: client-server + P2P</p>
</blockquote>
<h3 id="Transport-layer-protocol"><a href="#Transport-layer-protocol" class="headerlink" title="Transport layer protocol"></a>Transport layer protocol</h3><blockquote>
<p>Q: How do apps (at end systems) exchange messages? (E.g. how does a browser exchange message with a server?)</p>
<p>A: Split to 2 questions:</p>
<ul>
<li><font color="red">Who send/recv msg to/from network?</font> <font color="green">Process(è¿›ç¨‹)</font></li>
<li><font color="red">Where does process send/recv msg to/from?</font> <font color="green">Sockets(å¥—æ¥å­—)</font>

</li>
</ul>
</blockquote>
<p>Comparison:</p>
<ol>
<li><ul>
<li>Processes within same host communicate using  <font color="red">inter-process communication</font> (defined by OS)<ul>
<li>Processes in different hosts communicate by exchanging messages across the <font color="red">computer network</font></li>
</ul>
</li>
</ul>
</li>
<li><ul>
<li><strong>client process:</strong> process that initiates communication (å‘é€æ–¹è½®è¯¢)<ul>
<li><strong>server process:</strong> process that waits to be contacted (æ¥æ”¶æ–¹é˜»å¡)</li>
</ul>
</li>
</ul>
</li>
<li>(2) is compatible in :<ul>
<li>Client-server architecture</li>
<li>P2P architectures having client processes &amp; server processes</li>
</ul>
</li>
</ol>
<h4 id="Interface-between-Process-and-Computer-Networks-Sockets"><a href="#Interface-between-Process-and-Computer-Networks-Sockets" class="headerlink" title="Interface between Process and Computer Networks: Sockets"></a>Interface between Process and Computer Networks: Sockets</h4><p><img src="/2024/09/09/Computer-Networks/cn12.png"></p>
<ul>
<li><p>Process sends/receives messages to/from the network through socket</p>
<ul>
<li><font color="blue">sending process</font> shoves(æ¨é€) message <strong>â€œout doorâ€</strong></li>
<li><font color="blue">sending process</font> relies on transport infrastructure (on other side of door) to deliver message to socket at <font color="blue">receiving process</font>
</li>
</ul>
</li>
<li><p>To receive messages, sockets must be identified by</p>
<ul>
<li>The address of the host: <font color="red">IP address</font></li>
<li>An identifier that specifies the receiving process/socket: <font color="red">port numbers</font> (æ ‡è¯†è¿›ç¨‹)</li>
<li>Some default port number:<ul>
<li>HTTP server: 80</li>
<li>HTTPS server: 433</li>
<li>mail server: 25</li>
</ul>
</li>
</ul>
</li>
</ul>
<blockquote>
<font color="red">Q: How to choose transport service?</font>

<font color="green">A: choose one of the available transport-layer protocols (e.g., UDP, TCP)</font>

</blockquote>
<ul>
<li>Measurements for transport service choosing:<ul>
<li>Throughput</li>
<li>Timing</li>
<li>Security</li>
</ul>
</li>
</ul>
<p><img src="/2024/09/09/Computer-Networks/cn13.png"></p>
<ul>
<li>ä»¥ä¸Šæ˜¯éƒ¨åˆ†åº”ç”¨çš„éœ€æ±‚ï¼Œä¸‹é¢æˆ‘ä»¬å¯ä»¥çœ‹åˆ°è¿™äº›åº”ç”¨é€‰æ‹©äº†å“ªé¡¹ä¼ è¾“æœåŠ¡ã€‚</li>
</ul>
<h4 id="Brief-looking-on-transport-protocols"><a href="#Brief-looking-on-transport-protocols" class="headerlink" title="Brief looking on transport protocols"></a>Brief looking on transport protocols</h4><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">TCP Service</th>
<th style="text-align:center">UDP Service</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><font color="red">connection-oriented:</font> setup required between client and server processes (TCP connection/full-duplex)</td>
<td style="text-align:center"><font color="red">connectionless</font></td>
</tr>
<tr>
<td style="text-align:center"><font color="red">reliable transport</font> between sending and receiving process</td>
<td style="text-align:center"><font color="red">unreliable data transfer</font> between sending and receiving process</td>
</tr>
<tr>
<td style="text-align:center"><font color="red">congestion(æ‹¥å µ) control</font>: throttle(é˜»æ–­) sender when network overloaded</td>
<td style="text-align:center">-</td>
</tr>
<tr>
<td style="text-align:center"><font color="red">no provide</font>: timing, minimum throughput guarantee, security</td>
<td style="text-align:center"><font color="red">no provide</font>: reliability, congestion control, timing, throughput guarantee, security, or connection setup</td>
</tr>
</tbody>
</table>
</div>
<blockquote>
<p>æ³¨æ„ï¼TCP å’Œ UDP éƒ½ä¸ç›´æ¥ä¿è¯å®‰å…¨æ€§ã€‚TCP ä¿è¯è¿æ¥ç¨³å®šï¼ŒUDP ä¿è¯ä¼ è¾“æ•ˆç‡ã€‚</p>
<p>UDP é€‚ç”¨äºæ—¶é—´æ•æ„Ÿçš„é€šä¿¡ä¸­ã€‚å½“é‡åˆ°ä¸¢åŒ…æ¯”å»¶è¿Ÿè¦å¥½çš„æƒ…å†µæ—¶ï¼Œå°±ä½¿ç”¨ UDP ä¼ è¾“ã€‚</p>
</blockquote>
<p><img src="/2024/09/09/Computer-Networks/cn14.png"></p>
<h3 id="Application-level-protocols-Brief"><a href="#Application-level-protocols-Brief" class="headerlink" title="Application-level protocols (Brief)"></a>Application-level protocols (Brief)</h3><ul>
<li>App-layer protocol defines<ul>
<li><font color="red">types of messages exchanged</font><ul>
<li>e.g., request, response </li>
</ul>
</li>
<li><font color="red">message syntax (è¯­æ³•)</font><ul>
<li>what fields in messages &amp; how fields are delineated</li>
</ul>
</li>
<li><font color="red">message semantics (è¯­ä¹‰)</font> <ul>
<li>meaning of information in fields</li>
</ul>
</li>
<li><font color="red">rules</font> for when and how processes send &amp; respond to messages</li>
</ul>
</li>
</ul>
<blockquote>
<p>åº”ç”¨å±‚åè®®åªæ˜¯åº”ç”¨çš„ä¸€éƒ¨åˆ†ï¼š</p>
<p>ä»¥ Web ä¸ºä¾‹ï¼šWeb æ˜¯ä¸€ä¸ªæœåŠ¡ç«¯-å®¢æˆ·ç«¯åº”ç”¨ï¼Œå…è®¸ç”¨æˆ·ä» Web æœåŠ¡å™¨è·å–æ–‡æ¡£ï¼Œå…¶ç»„æˆæœ‰</p>
<ul>
<li>ä¸€ä¸ªæ–‡æ¡£æ ‡å‡†æ ¼å¼ï¼ˆHTMLï¼‰</li>
<li>Web æµè§ˆå™¨ï¼ˆBrowsersï¼‰</li>
<li>Web æœåŠ¡å™¨</li>
<li>åº”ç”¨å±‚åè®®</li>
</ul>
</blockquote>
<h2 id="2-2-Web-and-HTTP"><a href="#2-2-Web-and-HTTP" class="headerlink" title="2.2. Web and HTTP"></a>2.2. Web and HTTP</h2><ul>
<li><font color="red">Web page</font> consists of <font color="red">base HTML-file</font> which includes <font color="red">several referenced objects</font></li>
<li>each object is addressable by a <font color="red">URL</font></li>
</ul>
<p><img src="/2024/09/09/Computer-Networks/cn15.png"></p>
<ul>
<li>Web<ul>
<li>client-server architecture</li>
<li>use HTTP as its application layer protocol</li>
</ul>
</li>
<li>HTTP (hypertext transfer protocol) defines <ul>
<li>HTTP request: how <font colo="red">Web clients request</font> Web pages from Web servers</li>
<li>HTTP response: how <font color="red">servers transfer</font> Web pages to clients</li>
</ul>
</li>
</ul>
<table>
    <tr>
        <td><p>Client-server architecture:</p><p><font color="red">client</font>: browser that requests, receives, (using HTTP protocol) and â€œdisplaysâ€ Web objects</p><p><font color="red">server</font>: Web server sends (using HTTP protocol) objects in response to  requests</p></td>
        <td><img src="/2024/09/09/Computer-Networks/cn16.png"></td>
    </tr>
</table>

<h3 id="HTTP"><a href="#HTTP" class="headerlink" title="HTTP"></a>HTTP</h3><p><strong>Outline</strong></p>
<ul>
<li>HTTP Overview<ul>
<li>HTTP runs over TCP</li>
<li>HTTP is stateless</li>
<li>Persistent and non-persistent connection</li>
</ul>
</li>
<li>Request and response messages</li>
<li>Cookies</li>
<li>Web caching</li>
</ul>
<h4 id="HTTP-overview-TCP"><a href="#HTTP-overview-TCP" class="headerlink" title="HTTP overview: TCP"></a>HTTP overview: TCP</h4><ul>
<li>client initiates TCP connection (creates socket) to server,  port 80</li>
<li>server accepts TCP connection from client</li>
<li>HTTP messages (application-layer protocol messages) exchanged between browser (HTTP client) and Web server (HTTP server)</li>
<li>TCP connection closed</li>
</ul>
<p><img src="/2024/09/09/Computer-Networks/cn17.png"></p>
<p><b><font color="red">HTTP is â€œstatelessâ€ !</font></b></p>
<ul>
<li>Server maintains no information about past client requests.</li>
<li>If a client asks for the same object twice, the server resends the object.</li>
</ul>
<p><b><font color="red">Persistent &amp; non-persistent connection</font></b></p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">persistent HTTP</th>
<th style="text-align:center">non-persistent HTTP</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">multiple objects can be sent over single TCP connection between client and server</td>
<td style="text-align:center">at most one object sent over TCP connection, then connection closed</td>
</tr>
<tr>
<td style="text-align:center">server leaves connection open after sending response;<br>server closes a connection when it isnâ€™t used <font color="red">for a certain time</font></td>
<td style="text-align:center">OS overhead (TCP buffer, variables) for each TCP connection</td>
</tr>
<tr>
<td style="text-align:center">client sends requests <font color="red">as soon as</font> it encounters a referenced object</td>
<td style="text-align:center">browsers often open <font color="red">parallel TCP connections</font> to fetch referenced objects</td>
</tr>
</tbody>
</table>
</div>
<center>-----        Calculation        -----</center>

<blockquote>
<p><strong>Conception.</strong> RTT(round-trip-time) is time for a small packet to travel from client to server and back (ä¸€ä¸ªæ¥å›)</p>
</blockquote>
<ul>
<li>For persistent HTTP, time from init TCP conn to, e.g., $n$ files received is : <blockquote class="blockquote-center">
<p>$<br>\text{Time}=1\text{RTT}+n\times\text{RTT}<br>$</p>

</blockquote></li>
<li>For non-persistent HTTP, is :<blockquote class="blockquote-center">
<p>$<br>\text{Time} = 2\times \text{RTT}<br>$</p>

</blockquote>
</li>
</ul>
<h4 id="Messages"><a href="#Messages" class="headerlink" title="Messages"></a>Messages</h4><ol>
<li>HTTP request messages</li>
</ol>
<table><tr>
    <td><img src="/2024/09/09/Computer-Networks/cn18.png"></td>
    <td><img src="/2024/09/09/Computer-Networks/cn19.png"></td>
</tr><tr>
    <td>Particular case</td>
    <td>General cases</td>
</tr></table>

<ol>
<li>HTTP response messages</li>
</ol>
<table><tr>
    <td><img src="/2024/09/09/Computer-Networks/cn20.png"></td>
    <td><img src="/2024/09/09/Computer-Networks/cn21.png"></td>
</tr><tr>
    <td>Particular case</td>
    <td>General cases</td>
</tr></table>

<p><strong>Status Code</strong></p>
<ul>
<li><code>200 OK</code></li>
<li><code>301 Moved Permanently</code></li>
<li><code>400 Bad Request</code></li>
<li><code>404 Not Found</code></li>
<li><code>505 HTTP Version Not Supported</code></li>
</ul>
<h4 id="Cookies"><a href="#Cookies" class="headerlink" title="Cookies"></a>Cookies</h4><blockquote>
<p>å› ä¸º HTTP æ˜¯æ— çŠ¶æ€çš„ï¼Œä½†æ˜¯ Web åº”ç”¨æœ‰ä¿å­˜ç”¨æˆ·çŠ¶æ€çš„éœ€æ±‚ï¼Œæ‰€ä»¥éœ€è¦ä¸€ä¸ªæœºåˆ¶è¯†åˆ«ç”¨æˆ·</p>
</blockquote>
<p><img src="/2024/09/09/Computer-Networks/cn22.png"></p>
<blockquote>
<p>Cookies çš„å·¥ä½œåŸç†</p>
</blockquote>
<p><img src="/2024/09/09/Computer-Networks/cn23.png"></p>
<ul>
<li>Cookies are associated with <font color="red">web browser</font><ul>
<li>E.g. Suppose â€œBobâ€ register for Amazon server, then he get a cookie for himself (user-level), but â€œSusanâ€ have no cookie for Amazon. If she also register(even in same host), the web browser will store a cookie for her.</li>
</ul>
</li>
<li>Cookies and privacy:<ul>
<li>cookies permit sites to learn a lot about you</li>
<li>you may supply name and e-mail to sites</li>
</ul>
</li>
</ul>
<h4 id="Web-caches-proxy-ä»£ç†-server"><a href="#Web-caches-proxy-ä»£ç†-server" class="headerlink" title="Web caches: proxy(ä»£ç†) server"></a>Web caches: proxy(ä»£ç†) server</h4><blockquote>
<p>ç›®çš„ï¼šç”¨æˆ·æ— éœ€è®¿é—®åŸå§‹æœåŠ¡å™¨æ¥è·å–èµ„æº</p>
</blockquote>
<p><img src="/2024/09/09/Computer-Networks/cn24.png"></p>
<ul>
<li>Cache (Proxy server) acts as both client and server<ul>
<li>server for original requesting client</li>
<li>client to origin server</li>
</ul>
</li>
<li>typically cache is <font color="red">installed by ISP</font> (university, company, residential ISP)</li>
<li><font color="red">Why Web caching?</font>
  - <font color="green">reduce <u>response time</u> for client request (bottleneck bandwidth)</font>
  - <font color="green"><u>reduce traffic</u> on an institutionâ€™s access link</font>
  - <font color="green">Internet dense with caches: enables â€œpoorâ€ content providers to <u>effectively deliver content</u> (so does P2P file sharing)</font>



</li>
</ul>
<center>-----        Calculation        -----</center>

<ul>
<li>Assume that<ul>
<li>avg object size: $1M$ bits</li>
<li>avg request rate from browsers to origin servers: $15$ requests/sec</li>
<li>avg data rate to all browsers: $15 Mbps$</li>
<li>RTT from router A to any origin server: 2 sec (Internet delay)</li>
<li>access link rate: $15.4 Mbps$</li>
</ul>
</li>
<li>Consequences:<ul>
<li>LAN utilization: $15Mbps/100Mbps=0.15$</li>
<li>access link utilization: $15/15.4=0.974$</li>
<li>total delay = Internet delay + access delay + LAN delay = $2sec+\text{minutes} + \text{milliseconds}$</li>
</ul>
</li>
</ul>
<table><tr>
    <td><img src="/2024/09/09/Computer-Networks/cn25.png"></td>
    <td><img src="/2024/09/09/Computer-Networks/cn26.png"></td>
</tr><tr>
    <td><center>Large access link</center></td>
    <td><center>Cache server</center></td>
</tr></table>

<ul>
<li>Assume that<ul>
<li>access link rate: 150 Mbps (p1)</li>
</ul>
</li>
<li>Therefore:<ul>
<li>access link utilization: $15/150=0.1$</li>
<li>total delay = $2sec + \text{milliseconds} + \text{milliseconds}$</li>
</ul>
</li>
</ul>
<ul>
<li>Now we have cache server ! (p2)<ul>
<li>suppose cachee hit rate is 0.4 (40% at cache, 60% at origin)</li>
</ul>
</li>
<li>Therefore:<ul>
<li>(avg) data rate to browsers over access link $=0.6\times 15 Mbps=9Mbps$</li>
<li>(avg) access link utilization $=9/15.4=0.58$</li>
<li>avg delay $=0.6\times \text{(delay from origin servers)}+0.4\times \text{(delay when satisfied at  cache)}=0.6\times 2.01 +0.4\times (~msecs) = ~1.2secs$</li>
<li>Conclusion: faster than with 150 Mbps link and cheaper!</li>
</ul>
</li>
</ul>
<center>-----        Calculation End        -----</center>

<blockquote>
<p>Q: ç”¨æˆ·å‘ä»£ç†æœåŠ¡å™¨è¯·æ±‚å†…å®¹ï¼Œå¦‚æœåˆå§‹æœåŠ¡å™¨çš„å†…å®¹æ›´æ”¹ï¼Œè€Œä»£ç†æœåŠ¡å™¨çš„å†…å®¹æœªæ›´æ–°ï¼Œå¦‚ä½•è§£å†³ï¼Ÿ</p>
<p>A: Conditional <code>GET</code> â†’ <code>GET</code> method + <code>If-Modified-Since</code></p>
</blockquote>
<ul>
<li>Proxy cache: specify date of cached copy in HTTP request: <code>If-modified-since: &lt;date&gt;</code></li>
<li>Server: response contains no object if cached copy is up-to-date: <code>HTTP/1.0 304 Not Modified</code> or <code>HTTP /1.0 200 OK</code> if modified</li>
</ul>
<p><img src="/2024/09/09/Computer-Networks/cn27.png"></p>
<h2 id="2-3-Electronic-Mail"><a href="#2-3-Electronic-Mail" class="headerlink" title="2.3. Electronic Mail"></a>2.3. Electronic Mail</h2><ul>
<li>Overview<ul>
<li>Main components</li>
<li>Alice sends an email to Bob</li>
</ul>
</li>
<li>SMTP</li>
<li>Mail Message Format</li>
<li>Mail Access Protocol<ul>
<li>POP3</li>
<li>IMAP</li>
<li>HTTP: Web-based Email</li>
</ul>
</li>
</ul>
<h3 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h3><p><img src="/2024/09/09/Computer-Networks/cn28.png"></p>
<p>3 major components:</p>
<ul>
<li>User agents<ul>
<li>Allow users to read, reply to, forward, save and compose messages</li>
<li>e.g. Outlook, iPhone mail client</li>
</ul>
</li>
<li>Mail servers<ul>
<li>Always-on hosts</li>
<li><font color="red">User mailbox</font> contains outgoing, incoming messages</li>
<li><font color="red">Message queue</font> of outgoing (to be sent) mail messages</li>
<li><font color="red">Simple Mail Transfer Protocol (SMTP)</font> between mail servers to send email messages (è§ä¸Šå›¾)</li>
<li>Both client and server sides of SMTP run on mail server.<ul>
<li>client process: sending mail server</li>
<li>server  process: receiving mail server</li>
</ul>
</li>
</ul>
</li>
<li><font color="red">simple mail transfer protocol</font> (SMTP): use TCP</li>
</ul>
<p><strong>Learning by scenario: Alice sends message to Bob</strong></p>
<p><img src="/2024/09/09/Computer-Networks/cn29.png"></p>
<ol>
<li>Alice uses user agent to compose message â€œtoâ€ <code>bob@hamburger.edu</code></li>
<li>Aliceâ€™s user agent sends message to her mail server; message placed in message queue</li>
<li>client side of SMTP opens TCP connection with Bobâ€™s mail server</li>
<li>SMTP client sends Aliceâ€™s message over the TCP connection</li>
<li>Bobâ€™s mail server places the message in Bobâ€™s mailbox</li>
<li>Bob invokes his user agent to read message</li>
</ol>
<h3 id="Simple-Mail-Transfer-Protocol-SMTP"><a href="#Simple-Mail-Transfer-Protocol-SMTP" class="headerlink" title="Simple Mail Transfer Protocol(SMTP)"></a>Simple Mail Transfer Protocol(SMTP)</h3><table><tr>
    <td><ul><li>Uses TCP to reliably transfer email message from client to server, port 25</li><li>Direct transfer: sending server to receiving server (no intermediate server)</li><li>Three phases of transfer</li><ul><li>handshaking (greeting): indicate email address</li><li>transfer of messages: persistent connection</li><li>closure</li></ul><li>Two types of messages (like HTTP)</li><ul><li>commands: text</li><li>response: status code and phrase</li></ul></ul></td>
    <td><img src="/2024/09/09/Computer-Networks/cn30.png"></td>
</tr></table>



<font color="red">Properties of SMTP :</font>


<ul>
<li>SMTP uses persistent connections</li>
<li>SMTP requires message (header &amp; body) to be in  ASCII</li>
<li>SMTP server uses <font color="red">CRLF</font>(å›è½¦æ¢è¡Œç¬¦) to determine end of message</li>
</ul>
<p>Comparison with HTTP :</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">HTTP</th>
<th style="text-align:center">SMTP</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">pull</td>
<td style="text-align:center">push //TODO</td>
</tr>
<tr>
<td style="text-align:center">ASCII in header</td>
<td style="text-align:center">ASCII in header and body</td>
</tr>
<tr>
<td style="text-align:center">each object encapsulated in its own response message</td>
<td style="text-align:center">multiple objects sent in one message</td>
</tr>
</tbody>
</table>
</div>
<p><img src="/2024/09/09/Computer-Networks/cn31.png"></p>
<blockquote>
<font color="red">Q: Why not having mail servers directly on userâ€™s local PC?</font>

<font color="green">A: Mail server manages mailboxes and runs the client and server sides of SMTP. (Bob's PC have to remain always on in order to receive new mail)</font>

</blockquote>
<p><img src="/2024/09/09/Computer-Networks/cn32.png"></p>
<blockquote>
<font color="red">Q: Why not letting Alice send to Bobâ€™s mail server directly?</font>

<p><font color="green">A: Bobâ€™s mail server may fail; need to repeatedly send the message until success.</font> // TODO</p>
</blockquote>
<h3 id="Mail-Message-Format"><a href="#Mail-Message-Format" class="headerlink" title="Mail Message Format"></a>Mail Message Format</h3><blockquote>
<p>How do you write an e-mail â€¦</p>
<p>Header lines, e.g., <code>To:</code>, <code>From:</code>, <code>Subject:</code>, etc.<br>Body, the messages</p>
</blockquote>
<h3 id="Mail-Access-Protocol"><a href="#Mail-Access-Protocol" class="headerlink" title="Mail Access Protocol"></a>Mail Access Protocol</h3><blockquote>
<p>Well, <code>SMTP</code> is used to delivery mail to receiverâ€™s server (a push operation), but how does Bob obtain the mail ?</p>
</blockquote>
<p><img src="/2024/09/09/Computer-Networks/cn33.png"></p>
<ul>
<li><strong>POP3</strong>: Post Office Protocol 3: authorization, download <ul>
<li><font color="blue">TCP, port 110(æœªåŠ å¯†) or 995(åŠ å¯†)</font></li>
</ul>
</li>
<li><strong>IMAP</strong>: Internet Mail Access Protocol: more features, including maintain folders, keep user state</li>
<li><strong>HTTP</strong>: gmail, Hotmail, Yahoo! Mail, etc. [Web-based Email]</li>
</ul>
<ul>
<li>More about <code>POP3</code> â€”â€”</li>
<li>Authorization phase<ul>
<li>client commands: <ul>
<li><code>user</code>: declare username</li>
<li><code>pass</code>: password</li>
</ul>
</li>
<li>server responses<ul>
<li><code>+OK</code></li>
<li><code>-ERR</code></li>
</ul>
</li>
</ul>
</li>
<li>Transaction phase<ul>
<li>client:<ul>
<li><code>list</code>: list message numbers</li>
<li><code>retr</code>: retrieve message by number</li>
<li><code>dele</code>: delete</li>
<li><code>quit</code></li>
</ul>
</li>
</ul>
</li>
<li><p>Update phase (After <code>Quit</code>, the mail server deletes the messages marked as deletion)</p>
</li>
<li><p>æ¯”è¾ƒ POP3 å’Œ IMAP</p>
</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">POP3</th>
<th style="text-align:center">IMAP</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">é‚®ä»¶ä¸‹è½½åˆ°æœ¬åœ°è®¾å¤‡ï¼Œé€šå¸¸åœ¨ä¸‹è½½åä¼šä»æœåŠ¡å™¨ä¸Šåˆ é™¤</td>
<td style="text-align:center">é‚®ä»¶ä¿ç•™åœ¨æœåŠ¡å™¨ä¸Šï¼Œç”¨æˆ·å¯ä»¥åœ¨å¤šä¸ªè®¾å¤‡ä¸Šè®¿é—®åŒä¸€å°é‚®ä»¶</td>
</tr>
<tr>
<td style="text-align:center">ä¸æ”¯æŒåœ¨å¤šä¸ªè®¾å¤‡ä¹‹é—´åŒæ­¥é‚®ä»¶</td>
<td style="text-align:center">èƒ½å¤Ÿä¿æŒæ‰€æœ‰è®¾å¤‡ä¹‹é—´çš„é‚®ä»¶ï¼ˆçŠ¶æ€ï¼‰ä¸€è‡´æ€§</td>
</tr>
<tr>
<td style="text-align:center">é€šå¸¸ä¸æ”¯æŒæ–‡ä»¶å¤¹ç®¡ç†</td>
<td style="text-align:center">æ”¯æŒæ–‡ä»¶å¤¹ç®¡ç†</td>
</tr>
<tr>
<td style="text-align:center">ä¸‹è½½åå¯ä»¥åœ¨æ²¡æœ‰äº’è”ç½‘çš„æƒ…å†µä¸‹æŸ¥çœ‹é‚®ä»¶</td>
<td style="text-align:center">è®¾è®¡ç”¨äºåœ¨çº¿è®¿é—®ï¼ŒåŒ…æ‹¬æœç´¢ã€æ ‡è®°ç­‰æ“ä½œ</td>
</tr>
</tbody>
</table>
</div>
<h2 id="2-4-Domain-Name-System-DNS-é‡ç‚¹"><a href="#2-4-Domain-Name-System-DNS-é‡ç‚¹" class="headerlink" title="2.4. Domain Name System(DNS) [é‡ç‚¹!]"></a>2.4. Domain Name System(DNS) [é‡ç‚¹!]</h2><ul>
<li>DNS Services</li>
<li>DNS Structure<ul>
<li>Hierarchical structure</li>
<li>Iterated and recursive query</li>
</ul>
</li>
<li>DNS protocol<ul>
<li>DNS Records</li>
<li>Query and reply messages</li>
</ul>
</li>
<li>Inserting records into DNS</li>
</ul>
<h3 id="DNS-Services"><a href="#DNS-Services" class="headerlink" title="DNS Services"></a>DNS Services</h3><p><strong>Def.</strong> hostname to IP address translation</p>
<ul>
<li>Host aliasing<ul>
<li><code>www.ibm.com</code> (alias) is really <code>servereast.backup2.ibm.com</code> (canonical æœ¬å)</li>
</ul>
</li>
<li>load distribution<ul>
<li>replicated Web servers: many IP addresses correspond to one name (å¤šä¸ª IP å…±äº«ä¸€ä¸ªåå­—)</li>
<li>rotation distributes the traffic (ä½œç”¨æ˜¯å‡è½»è´Ÿæ‹…)</li>
</ul>
</li>
</ul>
<blockquote>
<p>How does APPs invoke DNS Service?</p>
</blockquote>
<ol>
<li>An application invokes the client side of DNS<ul>
<li>specifying the hostname that needs to be translated</li>
</ul>
</li>
<li>DNS in the userâ€™s host takes over, sending a query message into the network. <ul>
<li>DNS query and reply messages </li>
<li><font color="blue">UDP datagrams to port 53.</font> (faster)</li>
</ul>
</li>
<li>After a delay, ranging from milliseconds to seconds, DNS in the userâ€™s host receives a DNS reply message that provides the desired mapping.</li>
<li>The <font color="red">mapping (hostname - IP)</font> is then passed to the invoking application.</li>
</ol>
<h3 id="DNS-Structure"><a href="#DNS-Structure" class="headerlink" title="DNS Structure"></a>DNS Structure</h3><blockquote>
<p>ä¸ºä½•åˆ†å±‚çº§ï¼Ÿ</p>
<p>è€ƒè™‘åˆ°å®¹é”™ç‡ï¼ˆå•ç‚¹æŠ¥é”™ï¼‰ï¼Œé€Ÿåº¦æˆ–åœ°åŒºè®¿é—®å·®å¼‚ç­‰ã€‚</p>
</blockquote>
<p><img src="/2024/09/09/Computer-Networks/cn34.png"></p>
<p><strong>Properties.</strong> DNS is a distributed, hierarchical database.</p>
<ul>
<li><font color="red">Root DNS Servers:</font>  find IP address of the <code>.com</code> <font color="red">TLD DNS server</font> (ç½‘å€è¶Šé åçš„éƒ¨åˆ†è¶Šåœ¨é¡¶å±‚)<ul>
<li>Provide the IP addresses of the TLD servers</li>
</ul>
</li>
<li><font color="red">Top-Level Domain (TLD) DNS:</font> client queries <code>.com</code> DNS server to get <code>google.com</code> <font color="red">authoritative DNS server</font><ul>
<li>Top-level domains: com, org, net, edu, aero, jobs, museums; </li>
<li>Top-level country domains: uk, fr, cn, jp;</li>
</ul>
</li>
<li>Authoritative <font color="red">DNS servers:</font> client queries  <code>google.com</code>  DNS server to get  IP address for  <code>www.google.com / scholar.google.com</code><ul>
<li>organizationâ€™s own DNS server(s), providing authoritative hostname to IP mappings for organizationâ€™s named hosts </li>
<li>can be maintained by <font color="blue">organization</font> or <font color="blue">service provider</font></li>
</ul>
</li>
</ul>
<blockquote>
<p>Local DNS Server</p>
<ul>
<li>Does not strictly belong to hierarchy</li>
<li>Each ISP (residential ISP, company, university) has one<ul>
<li>also called â€œdefault name serverâ€</li>
</ul>
</li>
</ul>
<p>When a host connects to an ISP, the ISP provides the <font color="red">IP addresses</font> of one or more of local DNS servers</p>
<p>When host makes DNS query, query is sent to <font color="red">local DNS server</font></p>
<ul>
<li>acts as <font color="blue">proxy</font>, forwards query into hierarchy</li>
<li>has <font color="blue">local cache</font> of recent name-to-address translation pairs (but may be out of date!)</li>
</ul>
</blockquote>
<table>
    <tr>
    <td><img src="/2024/09/09/Computer-Networks/cn35.png"></td>
    <td><img src="/2024/09/09/Computer-Networks/cn36.png"></td>
    </tr><tr>
    <td><center>Iterated query</center></td>
    <td><center>Recursive query</center></td>
    </tr>
</table>

<blockquote>
<p>è¡¥å……ï¼šå…³äºå¦‚ä½•è§£å†³æœ¬åœ° DNS ç¼“å­˜è¿‡æœŸçš„é—®é¢˜ï¼Œç›®å‰ä¸»æµçš„æ–¹æ³•æ˜¯é€šè¿‡è®¾ç½®åˆç†çš„ TTL (Time to live) å€¼ã€‚æ—¶é—´åˆ°äº†å°±ä¼šé‡æ–°æŸ¥è¯¢ä¸Šæ¸¸ DNS æœåŠ¡å™¨ã€‚</p>
</blockquote>
<h3 id="DNS-Protocol"><a href="#DNS-Protocol" class="headerlink" title="DNS Protocol"></a>DNS Protocol</h3><p><strong>Properties.</strong> DNS is a distributed database storing <font color="red">resource records</font> (RR).</p>
<blockquote class="blockquote-center">
<p>$<br>\text{RR format}=\text{(name, value, type, TTL)}<br>$</p>

</blockquote>
<ul>
<li><font color="red">type = A</font><ul>
<li><code>name</code> is hostname</li>
<li><code>value</code> is IP address</li>
</ul>
</li>
<li><font color="red">type = NS</font><ul>
<li><code>name</code> is domain (e.g., <code>foo.com</code>)</li>
<li><code>value</code> is hostname of authoritative server for this domain (e.g., <code>dns.foo.com</code>)</li>
</ul>
</li>
<li>type = CNAME<ul>
<li><code>name</code> is alias name for some â€œcanonicalâ€ (the real) name</li>
<li><code>www.ibm.com</code> is really <code>servereast.backup2.ibm.com</code></li>
<li><code>value</code> is canonical name</li>
</ul>
</li>
<li><p>type = MX</p>
<ul>
<li><code>value</code> is canonical name(çœŸå) of the mailserver with <code>name</code> (alias name)</li>
</ul>
</li>
<li><p>If a DNS server is <font color="red">authoritative</font> for a particular hostname</p>
<ul>
<li>the DNS server will contain a <u>Type A record</u> for the hostname</li>
<li>(Even if the DNS server is not authoritative, it may contain a Type A record in its cache.) </li>
</ul>
</li>
<li>If a server is <font color="red">not authoritative</font> for a hostname<ul>
<li>the server will contain a <u>Type NS record</u> for the domain that includes the hostname</li>
<li>it will also contain a <u>Type A record</u> that provides the IP address of the DNS server in the <code>value</code> field of the NS record.</li>
</ul>
</li>
<li>Example: an <code>.edu</code> TLD server is not authoritative for <code>gaia.cs.umass.edu</code><ul>
<li><code>(umass.edu, dns.umass.edu, NS)  // NS record</code></li>
<li><code>(dns.umass.edu, 128.119.40.111, A)  // A record</code></li>
</ul>
</li>
</ul>
<blockquote>
<p>DNS åè®®æ”¯æŒæŸ¥è¯¢ï¼ˆQueryï¼‰å’Œå›å¤ï¼ˆReplyï¼‰ä¸¤ç§æ“ä½œï¼Œä¸”æ¶ˆæ¯çš„æ ¼å¼ç›¸åŒã€‚</p>
</blockquote>
<p><img src="/2024/09/09/Computer-Networks/cn37.png"></p>
<p><img src="/2024/09/09/Computer-Networks/cn38.png"></p>
<ul>
<li><p>Example: a reply to an MX query</p>
</li>
<li><p><u>Answer section</u>: Type MX</p>
<ul>
<li>an RR providing the canonical hostname (at <code>value</code>) of a mail server. </li>
</ul>
</li>
<li><u>Additional section</u>: Type A<ul>
<li>the IP address (at <code>value</code>) for the canonical hostname (at <code>name</code>) of the mail server.</li>
</ul>
</li>
</ul>
<h3 id="Inserting-records-into-DNS"><a href="#Inserting-records-into-DNS" class="headerlink" title="Inserting records into DNS"></a>Inserting records into DNS</h3><p><strong>Example</strong></p>
<ul>
<li>New startup â€œNetwork Utopiaâ€</li>
<li>Register name <code>networkuptopia.com</code> at <font color="red">DNS register</font> (e.g., Network Solutions)<ul>
<li>provide <font color="red">names, IP addresses</font> of authoritative DNS server (primary and secondary)</li>
<li>registrar inserts two RRs into <code>.com</code> TLD server :<ul>
<li><code>(networkutopia.com, dns1.networkutopia.com, NS)</code></li>
<li><code>(dns1.networkutopia.com, 212.212.212.1, A)</code></li>
</ul>
</li>
</ul>
</li>
<li>Then users can access by recursive query in the ways shown ğŸ‘‡</li>
</ul>
<p><img src="/2024/09/09/Computer-Networks/cn39.png"></p>
<blockquote>
<p>Attack DNS (ç•¥)</p>
</blockquote>
<h2 id="2-5-P2P-applications"><a href="#2-5-P2P-applications" class="headerlink" title="2.5. P2P applications"></a>2.5. P2P applications</h2><ul>
<li>Properties<ul>
<li>no always-on server</li>
<li>arbitrary end systems directly communicate</li>
<li>peers are intermittently connected and change IP addresses (IP å¯å˜)</li>
</ul>
</li>
<li>Example<ul>
<li>file distribution (BitTorrent)</li>
<li>Streaming (KanKan)</li>
<li>VoIP (Skype)</li>
</ul>
</li>
</ul>
<h3 id="P2P-vs-Client-Server"><a href="#P2P-vs-Client-Server" class="headerlink" title="P2P vs. Client-Server"></a>P2P vs. Client-Server</h3><p>Question: How much time to distribute file (size F) from one server to N peers?</p>
<ul>
<li>Suppose $u_s$ is server upload capacity, $d_i$ is download capacity of peer $i$</li>
<li>Time to distribute file to all peers $D_{C-S}$ is :</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>D_{C-S}\ge \max{NF/u_s, F/d_{\text{min}}}<br>$</p>

</blockquote>
<ul>
<li>So the $D$ increases linearly in $N$</li>
</ul>
<p><img src="/2024/09/09/Computer-Networks/cn40.png"></p>
<ul>
<li>As each host provide $u_i$ for uploading capacity</li>
<li>Server must upload at least one copy ($F/u_s$)</li>
<li>time $D_{P2P}$ is :</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>D_{P2P}\ge \max{F/d_{min}, F/u_s, NF/(u_s+\sum{u_i})}<br>$</p>

</blockquote>
<h3 id="P2P-file-distribution-BitTorrent"><a href="#P2P-file-distribution-BitTorrent" class="headerlink" title="P2P file distribution: BitTorrent"></a>P2P file distribution: BitTorrent</h3><blockquote>
<p>How P2P works ğŸ‘‡</p>
</blockquote>
<p><img src="/2024/09/09/Computer-Networks/cn41.png"></p>
<ul>
<li>Some points:<ul>
<li><font color="red">TCP connection</font> with other peers</li>
<li>Once get entire file, one will leave or remain in BitTorrent</li>
</ul>
</li>
</ul>
<center>Machanism about BitTorrent</center>

<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><font color="red">requesting</font> chunks</th>
<th style="text-align:center"><font color="red">sending</font> chunks: tit-for-tat</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">at any time, different peers have different subsets of file chunks</td>
<td style="text-align:center">maintain a priority list of top-N peers</td>
</tr>
<tr>
<td style="text-align:center">periodically, asks each â€œneighborâ€ for list of chunks</td>
<td style="text-align:center">periodically, select one additional peer(â€œoptimistically unchokeâ€) to start sending chunks, and chokes others</td>
</tr>
<tr>
<td style="text-align:center">request missing chunks, rarest first</td>
<td style="text-align:center">sends chunks to those who sending me chunks at highest rate</td>
</tr>
</tbody>
</table>
</div>
<blockquote>
<p>é€šä¿—è§£é‡Šï¼šè¯·æ±‚å‘åŒ…ä¼˜å…ˆæ‰¾è¯·æ±‚å¾—æœ€å°‘çš„ï¼Œå‘åŒ…ä¼˜å…ˆå‘è¯·æ±‚æœ€å¤šçš„ã€‚(ç¬¦åˆå¸¸ç†)</p>
</blockquote>
<p><strong>tit-for-tat</strong></p>
<ul>
<li>(1) Alice â€œoptimistically unchokesâ€ Bob</li>
<li>(2) Alice becomes one of Bobâ€™s top-four providers; Bob reciprocates</li>
<li>(3) Bob becomes one of Aliceâ€™s top-four providers</li>
</ul>
<h2 id="2-6-video-streaming-and-content-distribution-networks"><a href="#2-6-video-streaming-and-content-distribution-networks" class="headerlink" title="2.6. video streaming and content distribution networks"></a>2.6. video streaming and content distribution networks</h2><ul>
<li>Challenge<ul>
<li>scale â€”â€” how to reach ~1B users?</li>
<li>heterogeneity (å¼‚è´¨æ€§) â€”â€” different users have different capabilities</li>
<li>video traffic (è§†é¢‘æµé‡) â€”â€” major consumer of Internet bandwidth</li>
</ul>
</li>
<li>Solution<ul>
<li>distributed, application-level infrastructure</li>
</ul>
</li>
</ul>
<blockquote>
<p>Video has demand of multiple images per sec (e.g. 60 FPS needs 60 img/sec)</p>
<p>Use redundancy within and between images to decrease # bits used to encode image (å‰åå¸§å›¾åƒåˆ†å—ï¼ŒåŒè‰²çš„å—ä¸å†ä¼ è¾“)</p>
<p>A more efficient way below ğŸ‘‡</p>
</blockquote>
<h3 id="Streaming-multimedia-DASH"><a href="#Streaming-multimedia-DASH" class="headerlink" title="Streaming multimedia: DASH"></a>Streaming multimedia: DASH</h3><ul>
<li>DASH: Dynamic, Adaptive Streaming over HTTP</li>
<li>Server:<ul>
<li>divides video file into <font color="red">multiple chunks</font></li>
<li>each chunk stored, encoded at different rates </li>
<li>manifest file: provides URLs for different chunks encoded at different rates </li>
</ul>
</li>
<li>Client:<ul>
<li>periodically measures server-to-client bandwidth</li>
<li>consulting manifest, requests one chunk at a time <ul>
<li>chooses maximum coding rate sustainable given current bandwidth</li>
<li>can choose different coding rates at different points in time (depending on available bandwidth at time)</li>
</ul>
</li>
</ul>
</li>
</ul>
<blockquote>
<p>åœ¨è¿™é‡Œ client æ˜¯è‡ªç”±çš„ã€‚ä½•æ—¶è¯·æ±‚æ•°æ®å—ï¼Œç”¨å“ªç§ç¼–ç é€Ÿç‡ï¼Œå‘å“ªä¸ªåœ°å€è¯·æ±‚æ•°æ®å—ï¼Œéƒ½ç”± client è‡ªå·±å†³å®šã€‚</p>
</blockquote>
<h3 id="Content-Distribution-Network-CDN"><a href="#Content-Distribution-Network-CDN" class="headerlink" title="Content Distribution Network(CDN)"></a>Content Distribution Network(CDN)</h3><blockquote>
<p>Why not using â€œmega-serverâ€ ?</p>
<p>å•ç‚¹é”™è¯¯ï¼ˆå®¹é”™ç‡ä½ï¼‰ï¼Œå·¨å¤§è´Ÿè½½ï¼Œå¯¹è¿œè·ç¦»ç”¨æˆ·ä¸å‹å¥½ç­‰</p>
</blockquote>
<p><img src="/2024/09/09/Computer-Networks/cn42.png"></p>
<p><strong>Solution.</strong> CDN store/serve multiple copies of videos at multiple geographically distributed sites</p>
<ul>
<li>In practice, push CDN servers deep into many access networks; (inside ISPs)</li>
<li>Or smaller number (10â€™s) of larger clusters in Internet Exchange Point (IXP); (outside ISPs)</li>
</ul>
<p><strong>E.g.</strong> See how Bob request video by CDN : </p>
<p><img src="/2024/09/09/Computer-Networks/cn43.png"></p>
<blockquote>
<p>ç”¨æˆ·æŸ¥æ‰¾â€œæœ€è¿‘â€ CDN æœåŠ¡å™¨çš„ä¸¤ç§ç­–ç•¥ï¼šåœ°ç†è·ç¦»æœ€çŸ­æˆ–å®æ—¶è®¡ç®—æœ€çŸ­å»¶è¿Ÿ</p>
</blockquote>
<h2 id="2-7-Socket-programming-with-UDP-and-TCP"><a href="#2-7-Socket-programming-with-UDP-and-TCP" class="headerlink" title="2.7. Socket programming with UDP and TCP"></a>2.7. Socket programming with UDP and TCP</h2><p><strong>Goal:</strong> learn how to build client/server applications that communicate using sockets.</p>
<p><strong>Socket:</strong> door between application process and end-end-transport protocol</p>
<h3 id="Socket-programming-with-UDP"><a href="#Socket-programming-with-UDP" class="headerlink" title="Socket programming with UDP"></a>Socket programming with UDP</h3><ul>
<li>No â€œconnectionsâ€</li>
<li>Transmitted data may be lost or received out-of-order</li>
</ul>
<p><img src="/2024/09/09/Computer-Networks/cn44.png"></p>
<ul>
<li>Implementation ã€serverã€‘</li>
</ul>
<figure class="highlight python"><figcaption><span>server.py</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> socket <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line">serverPort = <span class="number">12000</span></span><br><span class="line">serverSocket = socket(AF_INET, SOCK_DGRAM)  <span class="comment"># create socket</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;UDP socket is identified by destination IP address and port number&#x27;&#x27;&#x27;</span></span><br><span class="line">serverSocket.bind((<span class="string">&#x27;&#x27;</span>, serverPort))</span><br><span class="line"><span class="built_in">print</span> (â€œThe server <span class="keyword">is</span> ready to receiveâ€)</span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;clientAddress = IP + port&#x27;&#x27;&#x27;</span></span><br><span class="line">    message, clientAddress = serverSocket.recvfrom(<span class="number">2048</span>)</span><br><span class="line">    modifiedMessage = message.decode().upper()  <span class="comment"># what server do</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;response to client&#x27;&#x27;&#x27;</span></span><br><span class="line">    serverSocket.sendto(modifiedMessage.encode(), clientAddress)</span><br></pre></td></tr></table></figure>
<ul>
<li>Implemetation ã€clientã€‘</li>
</ul>
<figure class="highlight python"><figcaption><span>client.py</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;Client do not need to specify port-num&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">from</span> socket <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line">serverName = <span class="string">&#x27;hostname&#x27;</span>  <span class="comment"># either IP address or hostname</span></span><br><span class="line">serverPort = <span class="number">12000</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;AF_INET -&gt; IPv4, SOCK_DGRAM -&gt; UDP&#x27;&#x27;&#x27;</span></span><br><span class="line">clientSocket = socket(AF_INET, SOCK_DGRAM)</span><br><span class="line">message = raw_input(<span class="string">&#x27;Input lowercase sentence:&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;Direct send, no connection&#x27;&#x27;&#x27;</span></span><br><span class="line">clientSocket.sendto(message.encode(), (serverName, serverPort))</span><br><span class="line">modifiedMessage, serverAddress = clientSocket.recvfrom(<span class="number">2048</span>)</span><br><span class="line"><span class="built_in">print</span>(modifiedMessage.decode())</span><br><span class="line">clientSocket.close()  <span class="comment"># client leave</span></span><br></pre></td></tr></table></figure>
<h3 id="Socket-programming-with-TCP"><a href="#Socket-programming-with-TCP" class="headerlink" title="Socket programming with TCP"></a>Socket programming with TCP</h3><ul>
<li>Client must contact server<ul>
<li>server process must first be running</li>
<li>server must have created socket (door) that welcomes clientâ€™s contact (<font color="blue">welcome socket</font>)</li>
</ul>
</li>
<li>Client contacts server by: <ul>
<li>Creating TCP socket, specifying IP address, port number of server process</li>
<li>Client TCP establishes connection to server TCP</li>
<li>when contacted by client, <font color="red">server TCP creates new socket</font> for server process to communicate with that particular client (å…è®¸æœåŠ¡ç«¯ä¸å¤šä¸ªå®¢æˆ·è¿æ¥)</li>
</ul>
</li>
</ul>
<blockquote>
<p>Identifications difference between UDP and TCP socket (å¯¹åº”åˆ°åŒä¸€ä¸ªå¥—æ¥å­—æ‰€éœ€å‚æ•°): </p>
<p>UDP = dst.IP + dst.port</p>
<p>TCP = dst.IP + dst.port + src.IP + src.port</p>
</blockquote>
<p><img src="/2024/09/09/Computer-Networks/cn45.png"></p>
<ul>
<li>Implementation ã€serverã€‘</li>
</ul>
<figure class="highlight python"><figcaption><span>server.py</span></figcaption><table><tr><td class="code"><pre><span class="line">serverPort = <span class="number">12000</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;SOCK_STREAM -&gt; TCP&#x27;&#x27;&#x27;</span></span><br><span class="line">serverSocket = socket(AF_INET,SOCK_STREAM)</span><br><span class="line">serverSocket.bind((<span class="string">&#x27;&#x27;</span>,serverPort))</span><br><span class="line">serverSocket.listen(<span class="number">1</span>)  <span class="comment"># Times to listening, must before client</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;The server is ready to receive&#x27;</span>)</span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    connectionSocket, addr = serverSocket.accept()</span><br><span class="line">     </span><br><span class="line">    sentence = connectionSocket.recv(<span class="number">1024</span>).decode()</span><br><span class="line">    capitalizedSentence = sentence.upper()  <span class="comment"># what server do</span></span><br><span class="line">    connectionSocket.send(capitalizedSentence.encode())</span><br><span class="line">    connectionSocket.close()</span><br></pre></td></tr></table></figure>
<ul>
<li>Implementation ã€clientã€‘</li>
</ul>
<figure class="highlight python"><figcaption><span>client.py</span></figcaption><table><tr><td class="code"><pre><span class="line">serverName = <span class="string">&#x27;servername&#x27;</span></span><br><span class="line">serverPort = <span class="number">12000</span></span><br><span class="line">clientSocket = socket(AF_INET, SOCK_STREAM)</span><br><span class="line">clientSocket.connect((serverName,serverPort))  <span class="comment"># set up connection(SYN)</span></span><br><span class="line">sentence = raw_input(<span class="string">&#x27;Input lowercase sentence:&#x27;</span>)</span><br><span class="line">clientSocket.send(sentence.encode())  <span class="comment"># &quot;3rd hand-shaking&quot;</span></span><br><span class="line">modifiedSentence = clientSocket.recv(<span class="number">1024</span>)</span><br><span class="line"><span class="built_in">print</span> (â€˜From Server:â€™, modifiedSentence.decode())</span><br><span class="line">clientSocket.close()  <span class="comment"># client leave first</span></span><br></pre></td></tr></table></figure>
<h1 id="Chapter-3-Transport-Layer"><a href="#Chapter-3-Transport-Layer" class="headerlink" title="Chapter 3. Transport Layer"></a>Chapter 3. Transport Layer</h1><HR style="FILTER: alpha(opacity=0, finishopacity=100,style=1)" width="100%" color="black" size="2">

<center><font face="STXinwei" size="5">Layout</font></center>

<p><strong>3.1</strong> transport-layer services</p>
<p><strong>3.2</strong> multiplexing and demultiplexing</p>
<p><strong>3.3</strong> connectionless transport: UDP</p>
<p><strong>3.4</strong> principles of reliable data transfer</p>
<p><strong>3.5</strong> connection-oriented transport: TCP</p>
<ul>
<li>segment structure</li>
<li>reliable data transfer</li>
<li>flow control</li>
<li>connection management</li>
</ul>
<p><strong>3.6</strong> principles of congestion control</p>
<p><strong>3.7</strong> TCP congestion control</p>
<HR style="FILTER: alpha(opacity=0, finishopacity=100,style=1)" width="100%" color="black" size="2">

<h2 id="3-1-Transport-Layer-Services"><a href="#3-1-Transport-Layer-Services" class="headerlink" title="3.1. Transport Layer Services"></a>3.1. Transport Layer Services</h2><ul>
<li><strong>Transport vs. App</strong><ul>
<li>logical communication between <font color="blue">app processes</font> running on different <font color="red">hosts</font></li>
<li>Transport protocols run in <font color="red">end systems</font><ul>
<li>send side: breaks app messages into segments, passes to network layer</li>
<li>rcv side: reassembles segments into messages, passes to app layer (<font color="green">Recall encapsulations</font>)</li>
</ul>
</li>
</ul>
</li>
<li><strong>Transport vs. Network</strong></li>
</ul>
<p><img src="/2024/09/09/Computer-Networks/cn46.png"></p>
<ul>
<li>hosts = houses</li>
<li>processes = kids</li>
<li>app messages = letters in envelopes</li>
<li><font color="red">transport protocol = Ann and Bill</font></li>
<li><font color="red">network-layer protocol = postal service</font>

</li>
</ul>
<blockquote>
<p>å¤§éƒ¨åˆ†ä¼ è¾“å±‚çš„æœåŠ¡åŒ…å«åœ¨ç½‘ç»œå±‚ä¸­ï¼ˆå¦‚ç¡®ä¿å»¶è¿Ÿæ—¶é—´å’Œå¸¦å®½çš„æœåŠ¡ï¼Œå› æ­¤ UDP å’Œ TCP éƒ½ä¸åŒ…å«æ­¤æœåŠ¡ï¼‰ï¼Œä½†ä»æœ‰ä¸€äº›æ˜¯ç½‘ç»œå±‚ä¸æä¾›çš„ï¼ˆå¦‚å®‰å…¨ä¿éšœï¼Œrdtç­‰ï¼‰ã€‚</p>
</blockquote>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">TCP</th>
<th style="text-align:center">UDP</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">reliable, in-order delivery</td>
<td style="text-align:center">unreliable, unordered delivery</td>
</tr>
<tr>
<td style="text-align:center">connection setup</td>
<td style="text-align:center">no-frills(ç®€æ´çš„) extension</td>
</tr>
<tr>
<td style="text-align:center">congestion control and flow control</td>
<td style="text-align:center">process-to-process data delivery and error checking</td>
</tr>
</tbody>
</table>
</div>
<h2 id="3-2-Multiplexing-Demultiplexing"><a href="#3-2-Multiplexing-Demultiplexing" class="headerlink" title="3.2. Multiplexing / Demultiplexing"></a>3.2. Multiplexing / Demultiplexing</h2><p><strong>Def.</strong> extending the host-to-host delivery service to a process-to-process delivery service for applications running on the hosts.</p>
<p><img src="/2024/09/09/Computer-Networks/cn47.png"></p>
<blockquote>
<p>åœ¨ Ann and Bill çš„ä¾‹å­é‡Œï¼Œè¿™å°±åƒæ¯ä¸ªå°æœ‹å‹ï¼ˆè¿›ç¨‹ï¼‰éƒ½æœ‰å¯¹åº”çš„åå­—å’Œ IDï¼Œé€šè¿‡å¯¹æ­¤è¿›è¡Œæ ‡è¯†ï¼Œå¯ä»¥è®©é€šä¿¡åŒæ–¹çš„ Socket çŸ¥é“å¦‚ä½•è¿›è¡Œä¸‹ä¸€æ­¥ä¼ è¾“ã€‚</p>
</blockquote>
<ul>
<li>Sending hostï¼š Host uses <font color="red">IP addresses &amp; port numbers</font> to direct segment to appropriate socket</li>
<li>Receiving hostï¼šHost receives IP datagrams from network layer<ul>
<li>each datagram has source IP address, destination IP address</li>
<li>each datagram carries one transport-layer segment</li>
</ul>
</li>
</ul>
<h3 id="UDP-Connectionless-demux"><a href="#UDP-Connectionless-demux" class="headerlink" title="UDP: Connectionless demux"></a>UDP: Connectionless demux</h3><p><img src="/2024/09/09/Computer-Networks/cn48.png"></p>
<ul>
<li>IP datagrams with same <code>dst.port</code> #, but <font color="red">different source IP addresses</font> and/or source port numbers will be directed to <font color="red">same</font> socket at destination.</li>
</ul>
<h3 id="TCP-Connection-oriented-demux"><a href="#TCP-Connection-oriented-demux" class="headerlink" title="TCP: Connection-oriented demux"></a>TCP: Connection-oriented demux</h3><p><img src="/2024/09/09/Computer-Networks/cn49.png"></p>
<blockquote>
<p>å›¾ä¸­çš„ Socket ä¸å†å¯¹åº”äºè¿›ç¨‹ï¼Œè€Œæ˜¯å¯¹åº”çº¿ç¨‹</p>
</blockquote>
<ul>
<li>Web servers have different sockets for each connecting client<ul>
<li>Both the initial connection-establishment segments and the segments carrying HTTP requests will have destination <strong>port 80</strong>.</li>
<li>non-persistent HTTP will have different socket for each request</li>
</ul>
</li>
</ul>
<h2 id="3-3-Connectionless-transport-UDP"><a href="#3-3-Connectionless-transport-UDP" class="headerlink" title="3.3. Connectionless transport: UDP"></a>3.3. Connectionless transport: UDP</h2><ul>
<li>UDP is used in:<ul>
<li>streaming multimedia apps (loss tolerant, rate sensitive)</li>
<li>DNS</li>
</ul>
</li>
<li>reliable transfer over UDP: (éƒ½æ˜¯åœ¨å…¶ä»–å±‚è§£å†³çš„ï¼Œæ‰€ä»¥è¯´ UDP æ˜¯ä¸å¯é çš„ä¼ è¾“)<ul>
<li>add reliability at application layer</li>
<li>application-specific error recovery!</li>
</ul>
</li>
</ul>
<h3 id="UDP-Checksum"><a href="#UDP-Checksum" class="headerlink" title="UDP Checksum"></a>UDP Checksum</h3><p><strong>Goal:</strong> detect â€œerrorsâ€ (e.g., flipped bits) in transmitted segment (from source to destination)</p>
<ul>
<li>Q: Why UDP using checksum?</li>
<li>A: <ul>
<li>no guarantee that all the links provide error checking</li>
<li>bit errors could be introduced when segments are in memory</li>
<li>Lower cost comparing to checking in app-level.</li>
</ul>
</li>
</ul>
<p><img src="/2024/09/09/Computer-Networks/cn50.png"></p>
<ul>
<li>Sender:<ul>
<li>treat segment contents, including header fields,  as sequence of 16-bit integers</li>
<li>checksum: 1s complement of the sum of segment contents</li>
<li>sender puts checksum value into UDP checksum field</li>
</ul>
</li>
<li>Receiver:<ul>
<li>check the sum of the segment<ul>
<li>All bits are equal to 1 - no error detected. But maybe errors nonetheless? More laterâ€¦</li>
<li>Otherwise: error detected</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>Example</strong></p>
<p><img src="/2024/09/09/Computer-Networks/cn51.png" style="zoom:60%"></p>
<p><img src="/2024/09/09/Computer-Networks/cn52.png" style="zoom:60%"></p>
<blockquote>
<p>ä¸€ä¸ªæ›´ç®€å•çš„è¯æ˜ä¾‹å­ï¼š</p>
<p>è®¾ä¸‰ä¸ªåŠ æ•°ä¸º <code>0101</code>, <code>1101</code>, <code>1011</code></p>
<p>$0101+1101=10010 \rightarrow +1011=11101$ ï¼Œè¡¥ä½å¾— <code>1110</code>ï¼Œå–åå¾— <code>0001</code></p>
<p>æ¥æ”¶æ–¹è®¡ç®—ï¼š$0101+1101=10010 \rightarrow +1011=11101 \rightarrow + 0001=11110$ï¼Œè¡¥ä½å¾— <code>1111</code></p>
<p>å…¨ 1 ç¬¦åˆæ¡ä»¶ï¼Œæš‚æ—¶æ£€æµ‹ä¸å‡ºé”™è¯¯ã€‚</p>
</blockquote>
<h2 id="3-4-Principles-of-Reliable-Data-Transfer-rdt"><a href="#3-4-Principles-of-Reliable-Data-Transfer-rdt" class="headerlink" title="3.4. Principles of Reliable Data Transfer (rdt)"></a>3.4. Principles of Reliable Data Transfer (rdt)</h2><h3 id="Overview-1"><a href="#Overview-1" class="headerlink" title="Overview"></a>Overview</h3><p><img src="/2024/09/09/Computer-Networks/cn53.png"></p>
<blockquote>
<p>We mainly use FSM to describe rdt clearly. Template as pic above.</p>
</blockquote>
<ul>
<li>Perfectly reliable channel: <code>rdt1.0</code></li>
<li>Channel with bit error: <ul>
<li>bit error in packet: <code>rdt 2.0</code></li>
<li>bit error in ACK: <code>2.1</code></li>
<li>NAK-free: <code>2.2</code></li>
</ul>
</li>
<li>Lossy channel: <code>rdt 3.0</code></li>
</ul>
<h3 id="rdt-1-0"><a href="#rdt-1-0" class="headerlink" title="rdt 1.0"></a>rdt 1.0</h3><ul>
<li>Underlying channel â€œperfectly reliableâ€<ul>
<li>no bit error</li>
<li>no loss of packet</li>
</ul>
</li>
<li>Therefore, no control for feedback</li>
</ul>
<p><img src="/2024/09/09/Computer-Networks/cn54.png" style="zoom:50%"></p>
<h3 id="rdt-2-0"><a href="#rdt-2-0" class="headerlink" title="rdt 2.0"></a>rdt 2.0</h3><ul>
<li>Underlying channel may <font color="blue">flip bits</font> (0 â†’ 1) in packet</li>
<li><font color="red">Q: how to recover from errors?</font><ul>
<li>acknowledgements (ACKs): receiver explicitly tells sender that pkt received OK</li>
<li>negative acknowledgements (NAKs): receiver explicitly tells sender that pkt had errors</li>
<li>sender retransmits pkt on receipt of NAK</li>
</ul>
</li>
</ul>
<ul>
<li>New Machanism in <code>rdt 2.0</code><ul>
<li>Error detection: checksum</li>
<li>Receiver feedback: control msgs (ACK,NAK) <code>rcvr-&gt;sender</code></li>
<li>Retransmission</li>
</ul>
</li>
</ul>
<p><img src="/2024/09/09/Computer-Networks/cn55.png" style="zoom:50%"></p>
<ul>
<li><code>rdt 2.0</code> has a <font color="red">fatal flaw</font> !</li>
<li><font color="red">What if ACK / NAK packet is corrupted?</font></li>
<li>Handling corrupted ACKs or NAKs:<ul>
<li>Op1. Keep asking until get answer ( foolish ! )</li>
<li>Op2. add enough checksum to recover</li>
<li>Op3. when garbled ACK or NAK, retransmit (ğŸ‘ˆseems better, but still some probs)</li>
</ul>
</li>
</ul>
<h3 id="rdt-2-1"><a href="#rdt-2-1" class="headerlink" title="rdt 2.1"></a>rdt 2.1</h3><p><img src="/2024/09/09/Computer-Networks/cn56.png" style="zoom:50%"></p>
<p><img src="/2024/09/09/Computer-Networks/cn57.png" style="zoom:50%"></p>
<ul>
<li>Recv maintain seq # as Sender do (æ­£å¸¸æƒ…å†µä¸‹æŒæœ‰ç›¸åŒçŠ¶æ€å€¼)</li>
<li>Sender check if received ACK/NAK corrupted</li>
<li>Recv check if received packet is duplicate</li>
</ul>
<blockquote>
<p>ä¾‹ï¼šsender åœ¨çŠ¶æ€ 0ï¼Œreceiver åœ¨çŠ¶æ€ 0</p>
<p>æ­¤æ—¶ sender å‘é€ä¸€ä¸ª seq0 çš„åŒ…ï¼Œrecv æ­£å¸¸æ”¶åˆ°ï¼Œè§£åŒ…å¹¶å‘é€ ACKï¼Œç„¶åè½¬å‘çŠ¶æ€ 1ã€‚</p>
<p>ä½†æ˜¯ sender æ²¡æ”¶åˆ° ACKï¼Œé‡å‘ seq0ã€‚recv åˆ™ä¼šå†å‘ ACKï¼ˆæ ¹æ® FSMï¼‰ï¼Œå¦‚æ­¤åˆ° sender æ”¶åˆ° ACKï¼Œç„¶åè½¬å‘çŠ¶æ€ 1ã€‚ç„¶å sender å‘é€ seq1 çš„åŒ…ã€‚å¦‚æ­¤å¾ªç¯ã€‚</p>
</blockquote>
<h3 id="rdt-2-2"><a href="#rdt-2-2" class="headerlink" title="rdt 2.2"></a>rdt 2.2</h3><p><img src="/2024/09/09/Computer-Networks/cn58.png" style="zoom:50%"></p>
<ul>
<li>Optimization<ul>
<li>using ACKs only (sends ACK for last pkt received OK)</li>
<li>must send ACK with seq #</li>
</ul>
</li>
</ul>
<h3 id="rdt-3-0"><a href="#rdt-3-0" class="headerlink" title="rdt 3.0"></a>rdt 3.0</h3><ul>
<li><font color="red">New Assumption:</font> underlying channel can also lose packets (data, ACKs)</li>
<li>Approach: sender waits â€œreasonableâ€ amount of time for ACK </li>
<li>retransmits if no ACK received in this time</li>
<li>if pkt (or ACK) just delayed (not lost):<ul>
<li>retransmission will be duplicate, but seq. #â€™s already handles this</li>
<li>receiver must specify seq # of pkt being ACKed</li>
</ul>
</li>
<li>requires countdown timer<ul>
<li>start timer, timer interrupt, stop timer</li>
</ul>
</li>
</ul>
<ul>
<li>Sender in <code>rdt 3.0</code></li>
</ul>
<p><img src="/2024/09/09/Computer-Networks/cn59.png" style="zoom:50%"></p>
<h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><p><strong>Key techniques</strong></p>
<ul>
<li>Checksum (2.0)</li>
<li>ACK packet (2.0)</li>
<li>Retransmission (2.0)</li>
<li>Sequence number (2.1)</li>
<li>Timeout (3.0)</li>
</ul>
<h1 id="Labs"><a href="#Labs" class="headerlink" title="Labs"></a>Labs</h1><h2 id="Week-1"><a href="#Week-1" class="headerlink" title="Week 1"></a>Week 1</h2><blockquote>
<p>Introduce to Lab 01:</p>
<p>åº”ç”¨å±‚ï¼ˆApplicationï¼‰</p>
<ul>
<li><code>ipconfig</code></li>
<li><code>nslookup</code></li>
</ul>
<p>ç½‘ç»œå±‚ï¼ˆNetworkï¼‰</p>
<ul>
<li><code>ping</code></li>
<li><code>tracert</code></li>
<li><code>netstat</code></li>
</ul>
<p>é“¾è·¯å±‚ï¼ˆLinkï¼‰</p>
<ul>
<li><code>arp</code></li>
</ul>
</blockquote>
<ul>
<li>Protocol layering (TCP/IP)<ul>
<li>Application: HTTP, HTTPS, SMTP, POP3, FTP, DNS, DHCP, etc.</li>
<li>Transport: TCP, UDP</li>
<li>Network: IPv4, IPv6, ICMP, IGMP, ARP</li>
<li>Link</li>
<li>Physical</li>
</ul>
</li>
</ul>
<ul>
<li>Domain name(App Layer)<ul>
<li>www.sustech.edu.cn</li>
<li>www.baidu.com</li>
</ul>
</li>
<li>IP address(Network Layer)<ul>
<li>IPv4 (ç‚¹åˆ†åè¿›åˆ¶)<ul>
<li>32 bits, dotted decimal notation</li>
<li>e.g. 192.168.1.1</li>
</ul>
</li>
<li>IPv6<ul>
<li>128 bits, hecadecimal notation</li>
<li>e.g. 2002::4ab8:7b76</li>
</ul>
</li>
</ul>
</li>
<li>Physical/MAC address(Link Layer)<ul>
<li>48 bits, hexadecimal notation</li>
<li>e.g. 8a-69-0c-51-98-66</li>
</ul>
</li>
</ul>
<ul>
<li>Use <code>ipconfig</code> to check your PCâ€™s network configurations (Wins)<ul>
<li>use <code>ifconfig</code> in MacOS</li>
<li>IP Address = {Network Number, Host Number}</li>
<li>Subnet Mask (å­ç½‘æ©ç ): n â€˜1â€™ + m â€˜0â€™ (totally 32 bits)<ul>
<li>e.g. 255.255.252.0 (22 â€˜1â€™ and 10 â€˜0â€™)</li>
</ul>
</li>
<li>Network Number = Subnet Mask &amp; IP Address<ul>
<li>e.g. if IP Address is <code>129.168.1.1</code> and Subnet Mask is <code>255.255.252.0</code>, then Network Number is <code>129.168.0.0</code> and Host Number is <code>0.0.1.1</code></li>
</ul>
</li>
</ul>
</li>
<li>Try <code>ipconfig -release</code> (haha~)<ul>
<li>find your network shutdown! (DHCP disabled)</li>
<li>use <code>ipconfig -renew</code> to apply for a new one.</li>
</ul>
</li>
</ul>
<p><strong>DNS Server</strong></p>
<ul>
<li>Try <code>ipconfig -displaydns</code>: looking for info about network(DNS) cache</li>
<li>Use <code>ipconfig -flushdns</code> to clear and refresh the DNS cache</li>
</ul>
<p><strong>ARP (åœ°å€è§£æåè®®)</strong></p>
<ul>
<li><code>arp -a</code><ul>
<li>Display all ARP information, that is, the corresponding relationship between all activated IP addresses and physical<br>addresses</li>
</ul>
</li>
<li><code>arp -d</code><ul>
<li>Delete all ARP cache contents. </li>
<li>If the IP address is specified in the command, only the ARP cache information of the IP address is deleted.</li>
</ul>
</li>
<li><code>arp -s</code><ul>
<li>Adding the corresponding relationship between IP address and physical address to ARP cache</li>
<li>e.g. <code>arp -s 172.16.0.19 00-10-5C-BE-11-CC</code></li>
</ul>
</li>
</ul>
<ul>
<li><code>nslookup</code> to find the corresponding IP through the host name, or find the corresponding host by specifying the IP.<ul>
<li>e.g. <code>nslookup www.baidu.com</code> or <code>nslookup 140.207.198.6</code></li>
</ul>
</li>
</ul>
<p><strong>Ping</strong></p>
<ul>
<li>Use <code>ping</code> to check network connectivity<ul>
<li><code>ping /?</code> : look up usage</li>
<li><code>ping -t</code> : ping the specific host â€˜til stopped</li>
<li><code>ping -i</code> : Time to live(TTL)</li>
<li><code>ping -n &lt;count&gt;</code> : set echo requests number</li>
</ul>
</li>
</ul>
<p><strong>Tracert: trace route</strong></p>
<ul>
<li>Use <code>tracert</code> to track the routing to check the connectivity of the network.</li>
<li>An example of this(address is fake):</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">C:\Users\xxx&gt; tracert www.baidu.com</span><br><span class="line"></span><br><span class="line">Tracing route to www.a.shifen.com [240e:ff:e020:966:0:ff:b042:f296]</span><br><span class="line">over a maximum of 30 hops:</span><br><span class="line"></span><br><span class="line">  1    14 ms    31 ms    14 ms  3010:dc5:207e:1107::6</span><br><span class="line">  2     7 ms     3 ms     3 ms  3010:dc5:207e:1:1::2</span><br><span class="line">  3     2 ms     2 ms     3 ms  3010:dc5:207e:1::1:1</span><br><span class="line">  4     4 ms     6 ms     3 ms  3010:250:3c02::d:1</span><br><span class="line">  5     2 ms     7 ms     2 ms  cernet2.net [3010:dc5:a2:4400::1101]</span><br><span class="line">  6     4 ms     4 ms     3 ms  3010:dc5:2:121::1</span><br><span class="line">  7     7 ms     7 ms     6 ms  3010:dc5:2:18::1</span><br><span class="line">  8     *        8 ms     6 ms  3010:dc5:2:704::2</span><br><span class="line">  9     9 ms     *        *     240e::e:3:2008:402</span><br><span class="line"> 10     6 ms     7 ms     7 ms  240e::c:3:5200:902</span><br><span class="line"> 11     8 ms     6 ms     7 ms  240e:1f:5000:64::3</span><br><span class="line"> 12   171 ms     *      150 ms  240e:1f:5800:35::3</span><br><span class="line"> 13     9 ms    10 ms     8 ms  240e:ff:e020:8ff::73</span><br><span class="line"> 14    44 ms    44 ms    44 ms  240c:4001:3170::ec2:eb2:3</span><br><span class="line"> 15    42 ms    44 ms    43 ms  240c:4001:3170::eb1:eb2:2</span><br><span class="line"> 16    44 ms    43 ms    43 ms  240c:4051:1317:2eb:1eaf:4:eb01:2</span><br><span class="line"> 17    46 ms    45 ms    44 ms  240c:4051:1317:205:1eaf:4:1b05:5</span><br><span class="line"> 18     8 ms     8 ms     8 ms  240e:ff:e020:966:0:ff:b042:f296</span><br><span class="line"></span><br><span class="line">Trace complete.</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>Traceroute program:</strong> provides delay measurement from source to router along end-end Internet path towards destination. For $i$ in $N$ node($N-1$ routers and 1 end):<ul>
<li>sends three packets (as probes) with a time-to-live (TTL) of $i$; will reach router $i$ on path towards destination</li>
<li>router $i$ will return packets to sender</li>
<li>sender times interval between transmission and reply.</li>
</ul>
</li>
</ul>
<h2 id="Week-2"><a href="#Week-2" class="headerlink" title="Week 2"></a>Week 2</h2><h3 id="Wireshark-ä½¿ç”¨"><a href="#Wireshark-ä½¿ç”¨" class="headerlink" title="Wireshark ä½¿ç”¨"></a>Wireshark ä½¿ç”¨</h3><h1 id="Appendix"><a href="#Appendix" class="headerlink" title="Appendix"></a>Appendix</h1><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">ç¼©å†™</th>
<th style="text-align:center">é‡Šä¹‰</th>
<th style="text-align:center">ç¼©å†™</th>
<th style="text-align:center">é‡Šä¹‰</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">DSL</td>
<td style="text-align:center">æ•°å­—ç”¨æˆ·çº¿</td>
<td style="text-align:center">LAN</td>
<td style="text-align:center">å±€åŸŸç½‘</td>
</tr>
<tr>
<td style="text-align:center">DSLAM</td>
<td style="text-align:center">æ•°å­—ç”¨æˆ·çº¿æ¥å…¥å¤ç”¨å™¨</td>
<td style="text-align:center">WLAN</td>
<td style="text-align:center">æ— çº¿å±€åŸŸç½‘</td>
</tr>
<tr>
<td style="text-align:center">HFC(Hybrid fiber coax)</td>
<td style="text-align:center">æ··åˆå…‰çº¤åŒè½´ç”µç¼†</td>
<td style="text-align:center">WAN</td>
<td style="text-align:center">å¹¿åŸŸç½‘(æ— çº¿æ¥å…¥ç½‘)</td>
</tr>
<tr>
<td style="text-align:center">ISP</td>
<td style="text-align:center">ç½‘ç»œæœåŠ¡æä¾›å•†</td>
<td style="text-align:center">ARP</td>
<td style="text-align:center">åœ°å€è§£æåè®®</td>
</tr>
<tr>
<td style="text-align:center">HTML</td>
<td style="text-align:center">è¶…æ–‡æœ¬æ ‡è®°è¯­è¨€</td>
<td style="text-align:center">HTTP(S)</td>
<td style="text-align:center">è¶…æ–‡æœ¬ä¼ è¾“ï¼ˆå®‰å…¨ï¼‰åè®®</td>
</tr>
<tr>
<td style="text-align:center">DNS</td>
<td style="text-align:center">åŸŸåç³»ç»Ÿ</td>
<td style="text-align:center">CDN</td>
<td style="text-align:center">å†…å®¹åˆ†å‘ç½‘ç»œ</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
</tbody>
</table>
</div>
</HR></HR></HR></HR></HR></HR>]]></content>
      <categories>
        <category>2024 Fall</category>
      </categories>
      <tags>
        <tag>CSE Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>æ“ä½œç³»ç»Ÿ</title>
    <url>/2024/09/13/Operation-System/</url>
    <content><![CDATA[<h1 id="About"><a href="#About" class="headerlink" title="About"></a>About</h1>]]></content>
      <categories>
        <category>2024 Fall</category>
      </categories>
      <tags>
        <tag>CSE Learning</tag>
        <tag>Rust</tag>
      </tags>
  </entry>
  <entry>
    <title>å¤§æ•°æ®å¯¼è®ºä¸å®è·µï¼ˆä¸‰ï¼‰</title>
    <url>/2024/08/29/Big-Data-3/</url>
    <content><![CDATA[<h1 id="Big-Data-III"><a href="#Big-Data-III" class="headerlink" title="Big Data (III)"></a>Big Data (III)</h1><h2 id="VI-Ensemble-Methods-é›†æˆæ–¹æ³•"><a href="#VI-Ensemble-Methods-é›†æˆæ–¹æ³•" class="headerlink" title="VI. Ensemble Methods (é›†æˆæ–¹æ³•)"></a>VI. Ensemble Methods (é›†æˆæ–¹æ³•)</h2><ul>
<li>Two commonly used ensemble methods<ul>
<li><strong>Bagging</strong><ul>
<li>Random sampling : generating independent models, and averaging for regressions (making majority vote for classifications) [éšæœºé‡‡æ ·è¿›è¡Œå»ºæ¨¡]</li>
<li><font color="red">Reducing variances(æ–¹å·®)</font></li>
<li>E.g. <em>Random Forest</em></li>
</ul>
</li>
<li><strong>Boosting</strong><ul>
<li>Sequential training : training the subsequent models based on the errors of previous models <font color="grey">[å¤ç›˜â€œé”™è¯¯â€]</font></li>
<li><font color="red">Reducing bias(è¯¯å·®)</font></li>
<li>E.g. AdaBoost and GBDT</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Bagging"><a href="#Bagging" class="headerlink" title="Bagging"></a>Bagging</h3><p><strong>Algorithm</strong></p>
<ul>
<li>Input : training set $D = \{(x_1, y_1), â€¦,(x_N, y_N)\}$</li>
<li>Output : additive model $\hat{f}_\text{bag} (x)$</li>
</ul>
<ol>
<li>For $m = 1$ to $M$ :<ol>
<li>Sample from $D$ with replacement to obtain $D_m$</li>
<li><font color="red">Train a model</font> $\hat f_m(x)$ from the dataset $D_m$ : for <font color="#4a4aff">classification</font>, $\hat f_m(x)$ returns a $K$-class 0-1 vector $e_k$ ; for <font color="#4a4aff">regression</font>, it is just a value</li>
</ol>
</li>
<li>Compute <strong>bagging estimate</strong> $\hat{f}_\text{bag} (x)=\frac{1}{M} \sum_{m=1}^{M} \hat f_m(x) $<ol>
<li>for <font color="#4a4aff">classification</font>, make majority vote $\hat{G}_\text{bag}(x)=\arg\max_k \hat f_k(x)$</li>
<li>for <font color="#4a4aff">regression</font>,  just return <font color="red">the average value</font></li>
</ol>
</li>
</ol>
<p><strong>Variance Reduction</strong></p>
<ul>
<li>In bagging, we use the same model to train different sample set in each iteration ; assume the models $\{\hat f_m(x)\}_{m=1}^{M}$ have the <font color="red">same variance</font> $\sigma^2 (x)$, while the <font color="red">correlation</font> of each pair is $\rho(x)$ </li>
<li>Then the variance of the final model is :</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{l}<br>\text{Var}(\hat{f}_{bag}(x)) &amp;= \frac{1}{M^2}\left(\sum_{m=1}^{M}\text{Var}(\hat{f}_m(x)) + \sum_{t\neq m}\text{Cov}(\hat{f}_t(x)\hat{f}_m(x))\right) \\ &amp;= \rho(x)\sigma^2(x) + \frac{1-\rho(x)}{M}\sigma^2(x)<br>\end{array}<br>$</p>

</blockquote>
<ul>
<li>As $M\to\infty$ , $\text{Var}(\hat f_{bag}(x))\to \rho(x)\sigma^2(x)$ . This usually <font color="red">reduces the variance</font>.</li>
<li>If $\rho(x)=0$ , the variance approach zero.</li>
<li>The <font color="red">random sampling</font> in bagging is to reduce the correlation $Ï(x)$, i.e., make the sub-predictors as independent as possible</li>
</ul>
<h4>Random Forest</h4>

<ul>
<li>More randomness on <strong>Decision Tree</strong> : avoid local optimal<ul>
<li>Sampling on the <font color="blue">training data</font> with replacement</li>
<li>Select <font color="blue">features</font> at random</li>
</ul>
</li>
<li>Example : RF consisting of $3$ independent trees, each with an error rate of $40\%$. Then the probability that more than one tree misclassify the samples is $0.4^3 + 3 <em> 0.4^2 </em> (1 âˆ’ 0.4) = 0.352$</li>
<li><strong>Algorithm</strong><ul>
<li>Input : training set $D =\{(x_1,y_1),(x_2,y_2),â€¦,(x_N,y_N)\}$</li>
<li>Output : additive model $\hat{f}_{\text{rf}}(x)$</li>
</ul>
<ol>
<li>For $m = 1$ to $M$ :<ol>
<li>Sample from $D$ with replacement to obtain $D_m$</li>
<li>Grow a random-forest tree $T_m$ to the dataset $D_m$ : by recursively repeating the following steps for each terminal node of the tree, until the minimum node size $n_{min}$ is reached<ul>
<li>Select $q$ features at <font color="red">random</font> from the $p$ features</li>
<li>Pick the best feature/split-point among the $q$</li>
<li>Split the node into two daughter nodes</li>
</ul>
</li>
</ol>
</li>
<li>Output the ensemble of trees $\{T_m\}_{m=1}^M$ : for <font color="blue">regression</font>, $\hat{f}_rf(x) = \frac{1}{M} \sum_{m=1}^M T_m(x)$; for <font color="blue">classification</font>, make majority vote</li>
</ol>
</li>
<li><font color="red">Small value</font> of $q$ increases the <font color="red">independency</font> of trees;  empirically, $q = \log_2 p + 1$</li>
</ul>
<h4>Model Evaluation</h4>

<ul>
<li><strong>Out-of-bag (OOB)</strong> errors : The observation is called out-of-bag sample to some trees if it is <font color="red">not sampled</font> for those trees. Denote the training set in the m-th sampling by $D_m$. <em>OOB error</em> is computed as :<ol>
<li>For each observation $(x_i, y_i)$, find the trees which treat it as OOB sample : <br>$\{\hat T_m(\textbf{x}) : (\textbf{x}_i, y_i) \notin D_m \}$</li>
<li>Use those trees to classify this observation and make majority vote as the label of this observation :<br>$\hat{f}_\text{oob}(\textbf{x}_i)=\arg\underset{y\in\mathcal Y}\max \sum_{m=1}^{M} I(\hat{f}_{m}(\textbf{x}_{i})=y)I(\textbf{x}_{i} \notin D_{m})$</li>
<li>Compute the number of misclassified samples, and take the ratio of this number to the total number of samples as OOB error : <br>$Err_{oob}=\frac{1}{N} \sum_{m=1}^{M} I(\hat{f}_{oob}(\textbf{x}_i) \not = y_i)$</li>
</ol>
</li>
</ul>
<blockquote>
<p>Q: OOB æ•°æ®æ˜¯å¦æŒ‡æ‰€æœ‰ç”Ÿæˆçš„æ ‘éƒ½æ²¡æœ‰é€‰æ‹©åˆ°çš„æ•°æ®ï¼Ÿ</p>
<p>Q: ç¬¬äºŒæ­¥ä¸ºä»€ä¹ˆä¸æ˜¯ $I(\hat f_m(\textbf{x}_i)=y \wedge \textbf{x}_i\notin D_m)$ ?</p>
</blockquote>
<ul>
<li><strong>Pros</strong><ul>
<li>Bagging or random forest (RF) work for models with high variance but low bias (<font color="red">deal with overfitting</font>)</li>
<li>Better for <font color="red">nonlinear</font> estimators</li>
<li>RF works for very <font color="red">high-dimensional data</font>, and no need to do feature selection as RF gives the feature importance</li>
<li>Easy to do <font color="red">parallel computing</font></li>
</ul>
</li>
<li><strong>Cons</strong><ul>
<li>Overfitting when the samples are large-sized with <font color="blue">great noise</font>, or when the dimension of data is low</li>
<li>Slow computing performance comparing to single tree</li>
<li><font color="red">Hard to interpret</font>

</li>
</ul>
</li>
</ul>
<hr>
<h3 id="Boosting-amp-AdaBoost"><a href="#Boosting-amp-AdaBoost" class="headerlink" title="Boosting &amp; AdaBoost"></a>Boosting &amp; AdaBoost</h3><blockquote>
<p>Principle : Combines the outputs of many <font color="blue">â€œweakâ€ classifiers</font> to produce a powerful â€œcommitteeâ€</p>
<p><font color="blue">Weak classifiers</font> : error rate $&lt; 0.5$ (random guessing)</p>
</blockquote>
<table>
    <tr><td><img align="left" src="/2024/08/29/Big-Data-3/bd36.png" style="zoom:100%"></td>
        <td><font color="red">Sequentially</font> apply the weak classifiers to the repeatedly modified data, emphasizing the misclassified samples<br><br>
        Combine weak classifiers through a weighted majority vote or averaging to produce the final prediction</td></tr>
</table>



<font size="4">Boosting fits an additive model</font>

<ul>
<li>Additive Model : $f(x)=\sum_{m=1}^{M}\beta_m b(x;\gamma_m)$  where $\gamma$ is the parameter of basic function, $\beta$ is the coefficient.</li>
<li>Possible choices for <font color="blue">basis function</font> $b(x;\gamma_m)$<ul>
<li>Neural Network : $\sigma(\gamma_0+\gamma_1^T x)$ , where $\sigma(t)=1/(1+e^{-t})$</li>
<li>Wavelets</li>
<li>Cubic Spline Basis</li>
<li>Trees</li>
<li>Eigenfunctions in reproducing kernel Hilbert space (RKHS)</li>
</ul>
</li>
<li><strong>Parameter fitting</strong> : $\underset{\{ \beta_m,\gamma_m\}} \min \sum_{i=1}^{N} L(y_i,\sum_{m=1}^{M}\beta_m b(x_i;\gamma_m))$</li>
<li>Loss function : <font color="red">squared error $L(y, f (x)) = (y âˆ’ f (x))^2$</font> or likelihood-based loss</li>
</ul>
<p><b><font size="4">Forward <font color="red">Stagewise</font> Additive Model&lt;/font&gt;</font></b></p>
<blockquote>
<p>Difference between â€œForward Stepwiseâ€ and â€œForward Stagewiseâ€</p>
<ul>
<li>Stepwise regression initialize model with all predictors(forward) or no predictors(backward), and then iteratively <font color="red">adds or removes</font> variables based on a defined criterion(e.g. AIC and BIC)</li>
<li><strong>Stagewise</strong> regression initialize model with all predictors, and then in each iteration, it <font color="red">adjusts the coefficients</font> of the predictors by a small amount in the direction that improves the modelâ€™s performance.</li>
</ul>
<p><strong>Stagewise</strong> regression is designed to be more robust to multicollinearity and can produce more stable and interpretable models compared to stepwise regression.<br>Useful when there are many potential predictors, and the goal is to identify the most important ones while maintaining model stability.</p>
</blockquote>
<p><strong>Algorithm</strong></p>
<ul>
<li>Input : training set $D =\{(x_1,y_1),(x_2,y_2),â€¦,(x_N,y_N)\}$</li>
<li>Output : additive model $f_M(x)$</li>
</ul>
<ol>
<li>Initialize $f_0(x)=0$</li>
<li>For $m=1$ to $M$ :<br> 2.1. Compute $(\beta_m,\gamma_m)=\underset{\beta ,\gamma}{\arg\min} \sum_{i=1}^{N} L(y_i,f_{m-1}(x_i)+\beta b(x_i;\gamma))$<br> 2.2. Update $f_m(x)=f_{m-1}(x)+\beta_m b(x_i;\gamma_m)$</li>
</ol>
<p>Squared error loss in step 2.1:</p>
<blockquote class="blockquote-center">
<p>$<br>L(y_i,f_{m-1}(x_i)+\beta b(x_i;\gamma))=\underbrace{(y_i-f_{m-1}(x_i))}_{\text{residual}}-\beta b(x_i;\gamma)^2<br>$</p>

</blockquote>
<blockquote>
<p>What if we use Exponential loss in step 2.1 ?</p>
</blockquote>
<ul>
<li>Exponential loss : $L(y,f(x))=\exp(-yf(x))$</li>
<li><font color="blue">Classifier</font> as basis function : $b(x; \gamma) = G(x) \in \{âˆ’1, 1\}$</li>
<li>Let $w_i^{(m)}=\exp(-y_i f_{m-1}(x_i))$ , then step 2.1 turn to be :</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\begin{align}{l}<br>(\beta_m, G_m) &amp;= \arg \min_{\beta, G} \sum_{i=1}^{n} w_i^{(m)} \exp(-\beta y_i G(x_i))\\<br>&amp;=\arg \min_{\beta, G} \left[ \sum_{y_i \neq G(x_i)} w_i^{(m)} (e^{\beta} - e^{-\beta}) + e^{-\beta} \sum_{i=1}^{n} w_i^{(m)} \right]<br>\end {align}<br>$</p>

</blockquote>
<ul>
<li>We get $\beta_m$ and $G_m$ separately :</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\begin{align}{l}<br>G_m &amp;= \arg \min_G \sum_{i=1}^{n} w_i^{(m)} I(y_i \neq G(x_i)) \\<br>\beta_m &amp;= \arg \min_{\beta} \left[ \epsilon_m (e^{\beta} - e^{-\beta}) + e^{-\beta} \right] = \frac{1}{2} \log \frac{1-\epsilon_m}{\epsilon_m} \\<br>\epsilon_m &amp;= \left(\left(\sum_{i=1}^{n} w_i^{(m)} I(y_i \neq G(x_i))\right) \left/\right. \sum_{i=1}^{n} w_i^{(m)}\right)<br>\end{align}<br>$</p>

</blockquote>
<p>where $\epsilon_m$ is weighted error rate.</p>
<h4>AdaBoost Algorithm</h4>

<table><tr>
<td><img align="center" src="/2024/08/29/Big-Data-3/bd37.png" style="zoom:50%"></td>
<td><img align="center" src="/2024/08/29/Big-Data-3/bd38.png" style="zoom:90%"></td>
</tr></table>

<h5>Loss Functions</h5>

<ul>
<li>For classification, exponential loss and binomial negative log-likelihood (deviance) loss $\log(1 + \exp(âˆ’2yf))$ share the same population minimizer ; thus it is equivalent to MLE rule</li>
<li>For classification, squared error loss is not good (not monotonically decreasing) ; the exponential loss is good and binomial deviance is better (less penalty for large $âˆ’yf$)</li>
</ul>
<hr>
<h3 id="Gradient-Boosting-Decision-Tree-GBDT"><a href="#Gradient-Boosting-Decision-Tree-GBDT" class="headerlink" title="Gradient Boosting Decision Tree (GBDT)"></a>Gradient Boosting Decision Tree (GBDT)</h3><center><h4>Boosting Tree</h4></center>

<ul>
<li>Using classification trees or regression trees as <font color="blue">base learners</font></li>
<li>$f_M(x) = \sum_{m=1}^{M} T(x; \Theta_m)$ where $T(x; \Theta) = \sum_{j=1}^{J} \gamma_j I(x \in R_j)$ <font color="grey">[æ ‘çš„è¡¨ç¤ºæ–¹æ³•ï¼šä»£è¡¨å°†è¾“å…¥ç©ºé—´åˆ’åˆ†ä¸º$J$ä¸ªäº’ä¸ç›¸äº¤çš„åŒºåŸŸ$R_1,\cdots,R_J$ï¼Œå¹¶åœ¨æ¯ä¸ªåŒºåŸŸä¸Šç¡®å®šè¾“å‡ºçš„å¸¸é‡$\gamma_j$ã€‚æ‰€ä»¥$J$ä»£è¡¨æ ‘çš„å¤æ‚åº¦å³å¶èŠ‚ç‚¹ä¸ªæ•° ]</font></li>
<li>Parameter set $\Theta = \{R_j, \gamma_j\}_{j=1}^{J}$ </li>
<li>Parameter finding : minimizing the empirical risk </li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{rl}<br>&amp;\hat{\Theta} = \arg \min_{\Theta} \sum_{j=1}^{J} \sum_{x_i \in R_j} L(y_i, \gamma_j) \qquad &amp;\text{Combinatorial optimization}<br>\end{array}<br>$</p>

</blockquote>
<ul>
<li>Approximate suboptimal solutions : <ol>
<li>Finding $\gamma_j$ given $R_j$ : $\gamma_j = \bar{y}_j = \frac{1}{|R_j|} \sum_{y_i \in R_j} y_i$   for $L^2$ loss ; and  $\gamma_j =$ modal class in $R_j$   for misclassification loss </li>
<li>Finding $R_j$ given $\gamma_j$ : Difficult, need to estimate $\gamma_j$ as well ;<br>greedy, top-down recursive partitioning algorithm</li>
</ol>
</li>
</ul>
<center><h4>Boosting Tree as Forward Stagewise Algorithm</h4></center>

<ul>
<li>$\hat{\Theta}_m = \arg \min_{\Theta_m} \sum_{i=1}^{N} L(y_i, f_{m-1}(x_i) + T(x_i; \Theta_m))$<ol>
<li>$\hat{\gamma}_{jm} = \arg \min_{\gamma_{jm}} \sum_{x_i \in R_{jm}} L(y_i, f_{m-1}(x_i) + \gamma_{jm})$</li>
<li>Finding $R_{jm}$ is more difficult than for a single tree in general.</li>
</ol>
</li>
<li>Squared-error loss : fit a tree to the residual<br> $L(y_i, f_{m-1}(x_i) + T(x_i; \Theta_m)) = (y_i - f_{m-1}(x_i) - T(x_i; \Theta_m))^2$</li>
<li>Two-class classification and exponential loss : AdaBoost for trees, <ul>
<li>$\hat{\Theta}_m = \arg \min_{\Theta_m} \sum_{i=1}^{N} w_i^{(m)} \exp[-y_i T(x_i; \Theta_m)]$</li>
</ul>
</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\hat{\gamma}_{jm} = \log \Large\frac{\sum_{x_i \in R_{jm}} w_i^{(m)} l(y_i = 1)}{\sum_{x_i \in R_{jm}} w_i^{(m)} l(y_i = -1)}<br>$</p>

</blockquote>
<ul>
<li>Absolute error or the Huber loss : robust but slow</li>
</ul>
<center><h4>Gradient Descent for General Loss</h4></center>

<ul>
<li>Supervised learning is equivalent to the optimization problem</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\min_{f}L(f)=\min_{f}\sum_{i=1}^{N}L(y_i,f(x_i))<br>$</p>

</blockquote>
<ul>
<li>Numberical optimization : $\hat{\textbf{f}}=\arg\min_{\textbf{f}}L(\textbf{f})$  where  $\textbf{f}=\{f(x_1),f(x_2),\cdots,f(x_N)\}$ </li>
<li>Appriximate $\hat{\textbf{f}}$ by $\textbf{f}_M=\sum_{m=0}^{M} \textbf{h}_m$ , where $\textbf{f}_0=\textbf{h}_0$ is <font color="red">the initial guess</font>.</li>
<li>Gradient Descent method : $\textbf{f}_m=\textbf{f}_{m-1}-\rho_m \textbf{g}_m$  , where $g_{im}=\left[\frac{\partial L(y_i,f(x_i))}{\partial f(x_i)} \right]_{f(x_i)=f_{m-1}(x_i)}$  , and $\textbf{h}_m=-\rho_m\textbf{g}_m$ .</li>
<li>Here $\color{red}\rho_m$ is the learning rate, and $\color{red}\textbf{g}_m$ is the <font color="red">gradient of the target function</font> $\color{red}L(f)$ at the point $f(x_i)$ . So $\rho_m$ decides the <font color="blue">step length</font> of the gradient.</li>
</ul>
<blockquote>
<p>Usage of Gradient Descent on <strong>Decision Tree</strong></p>
<ul>
<li>Find a Tree $T(x;\Theta_m)$ by minimization problem :</li>
</ul>
</blockquote>
<blockquote class="blockquote-center">
<p>$<br>\tilde{\Theta}_m=\arg\min_{\Theta_m}\sum_{i=1}^{N}(-g_{im}-T(x_i;\Theta_m))^2<br>$</p>

</blockquote>
<blockquote>
<p>In general, $\tilde{R}_{jm}\not=R_{jm}$ </p>
</blockquote>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">Setting</th>
<th style="text-align:center">Loss Function</th>
<th style="text-align:center">$-\partial L(y_i,f(x_i))/\partial f(x_i)$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Regression</td>
<td style="text-align:center">$\frac{1}{2}\left[y_i-f(x_i) \right]^2$</td>
<td style="text-align:center">$y_i-f(x_i)$</td>
</tr>
<tr>
<td style="text-align:center">Regression</td>
<td style="text-align:center">$\lvert y_i-f(x_i)\rvert$</td>
<td style="text-align:center">$\text{sign}\left[y_i-f(x_i) \right]$</td>
</tr>
<tr>
<td style="text-align:center">Regression</td>
<td style="text-align:center">Huber</td>
<td style="text-align:center">$y_i-f(x_i)$  for $\lvert y_i-f(x_i)\rvert \le \delta_m$<br>$\delta_m\text{sign}\left[y_i-f(x_i) \right]$  for $\lvert y_i-f(x_i)\rvert \gt \delta_m$ <br>where $\delta_m=\alpha^{\text{th}}$-quantile $\{\lvert y_i-f(x_i)\rvert \}$</td>
</tr>
<tr>
<td style="text-align:center">Classification</td>
<td style="text-align:center">Deviance</td>
<td style="text-align:center">$k^{th}$ component: $I(y_i=\mathcal G_k)-p_k(x_i)$</td>
</tr>
</tbody>
</table>
</div>
<center><h4>GBDT Algorithm</h4></center>

<ul>
<li>Input : training set $D = \{(x_1, y_1), \ldots, (x_N, y_N)\}$, loss function $L(y, f(x))$</li>
<li>Output : boosting tree $\hat{f}(x)$</li>
</ul>
<ol>
<li>Initialize $f_0(x) = \arg\min_\gamma \sum_{i=1}^{N} L(y_i, \gamma)$</li>
<li>For $m = 1$ to $M$ : <ol>
<li>For $i = 1, 2, \ldots, N$ compute $r_{im} = \bigg[\frac{\partial L(y_i,f(x_i))}{\partial f(x_i)}\bigg]_{f=f_{m-1}}$</li>
<li>Fit a regression tree to the target residual $r_{im}$, giving terminal regions $R_{jm}$ (è¡¨ç¤ºç¬¬ j ä¸ªæ ·æœ¬åœ¨ç¬¬ m ä¸ªåŸºæ¨¡å‹ä¸Šçš„æ®‹å·®) , $j = 1, \ldots, J_m$ </li>
<li>For $j = 1, \ldots, J_m$, compute $\gamma_{jm} = \arg\min_\gamma \sum_{x_i \in R_{jm}} L(y_i, f_{m-1}(x_i) + \gamma)$</li>
<li>Update $f_m(x) = f_{m-1}(x) + \sum_{j=1}^{J_m} \gamma_{jm}I(x_i \in R_{jm})$</li>
</ol>
</li>
<li>$\hat{f}(x) = f_M(x)$</li>
</ol>
<p><strong>Regularization</strong></p>
<ul>
<li><p><font color="red">Shrinkage</font> : the step 2.4 is modified as $f_m(x) = f_{m-1}(x) + \nu \sum_{j=1}^{J_m} \gamma_{jm}I(x_i \in R_{jm})$</p>
</li>
<li><p><font color="red">Subsampling</font> : at each iteration, sample a fraction $\eta$ of the training set and grow the next tree using the subsample</p>
</li>
<li><p>Shrinkage + subsampling : best performance</p>
</li>
</ul>
<p><strong>Feature importance and Partial Dependence Plots</strong></p>
<ul>
<li>Feature importance<ul>
<li>When fitting a single tree $T$, at each node $t$, one feature $X_{v(t)}$ and one separate value $X_{v(t)} = c_{v(t)}$ are chosen to improve a certain quantity of criterion (e.g. GINI, entropy, squared error, etc.)</li>
<li>Sum all these improvements $i_t$ brought by each feature $X_k$ over all internal nodes: $I_k(T) = \sum_{t=1}^{J-1} i_t I(v(t) = k)$</li>
<li>Average the improvements of all trees $\Rightarrow$ importance of that feature: $I_k=\frac{1}{M} \sum_{m=1}^{M} I_k(T_m)$</li>
</ul>
</li>
<li>Partial Dependence Plots<ul>
<li>Partial dependence of $f(X)$ on $X_S$ : $f_S(X_S) = E_{X_C}f(X_S, X_C)$</li>
<li>Estimate by empirical mean : $\hat{f}_S(X_S) = \frac{1}{N} \sum_{i=1}^{N} f(X_S, X_{iC})$</li>
</ul>
</li>
</ul>
<hr>
<h2 id="VII-Clustering"><a href="#VII-Clustering" class="headerlink" title="VII. Clustering"></a>VII. Clustering</h2><ul>
<li>Different from classification : it is <font color="red">unsupervised learning</font> ; no outputs or labels</li>
<li>Central goal : Optimize the similarity (or dissimilarity) between the individual objects being clustered :<ul>
<li>Obtain <font color="blue">great similarity</font> of samples <font color="blue">within</font> cluster</li>
<li>Obtain <font color="#c4c400">small similarity</font> of samples <font color="#c4c400">between</font> clusters</li>
</ul>
</li>
<li>Cost functions : not related to the outputs, but related to the similarity</li>
<li>Two kinds of input data :<ul>
<li>$n Ã— n$ similarity (dissimilarity) matrix $D$ : only depends on the distances between pairs of samples ; may lose some information on data</li>
<li>Original data with features $X \in R^{nÃ—d}$</li>
</ul>
</li>
</ul>
<h3 id="K-Mean-Clustering"><a href="#K-Mean-Clustering" class="headerlink" title="K-Mean Clustering"></a>K-Mean Clustering</h3><center><font size="5">Idea</font></center>

<ul>
<li>Data set $\{x_i\}_{i=1}^n$, $x_i \in \mathbb{R}^d$</li>
<li>Representatives : Mass center of $k$th-cluster $C_k$ is $c_k$, $k = 1, \ldots, K$</li>
<li>Sample $x_i$ belongs to cluster $k$ if $d(x_i, c_k) &lt; d(x_i, c_m)$ for $m \neq k$, where $d(x_i, x_j)$ is dissimilarity function</li>
<li>Make the mass centers well-located so that the average distance between each sample to its cluster center is as small as possible</li>
</ul>
<center><img src="/2024/08/29/Big-Data-3/bd39.png" style="zoom:90%"></center>



<center><font size="5">Optimization Problem</font></center>

<ul>
<li>Let $C : \{1, \ldots, n\} \rightarrow \{1, \ldots, k\}$ be the assignment from the data indices to the cluster indices. $C(i) = k$ means $x_i \in C_k$</li>
<li>Total point scatter : <ul>
<li>$T = \frac{1}{2} \sum_{i=1}^{n} \sum_{j=1}^{n} d(x_i, x_j) =\frac{1}{2} \sum_{k=1}^{K} \sum_{C(i)=k}\left( \sum_{C(j)=k} d_{ij} + \sum_{C(j)\neq k} d_{ij}\right) = W(C) + B(C)$</li>
</ul>
</li>
<li>Loss function ($d$ is the distance) :<ul>
<li>within-cluster point scatter $W(C) = \frac{1}{2} \sum_{k=1}^{K} \sum_{C(i)=k} \sum_{C(j)=k} d_{ij}$ ; </li>
<li>between-cluster point scatter $B(C) = \frac{1}{2} \sum_{k=1}^{K} \sum_{C(i)=k} \sum_{C(j)\neq k} d_{ij}$</li>
</ul>
</li>
<li>Minimize $W(C)$ is equivalent to maximize $B(C)$</li>
</ul>
<h4 id="Hierarchical-Clustering"><a href="#Hierarchical-Clustering" class="headerlink" title="Hierarchical Clustering"></a>Hierarchical Clustering</h4><ul>
<li>Clustering in different hierarchies, generating tree structure </li>
<li>Two approaches : <ul>
<li><font color="blue">Agglomerate clustering : bottom-up</font></li>
<li><font color="blue">Divisive clustering : top-down</font> </li>
</ul>
</li>
<li>Limitation : once merged or divided, the operation cannot be modified</li>
</ul>
<h5>Agglomerate Clustering</h5>

<ul>
<li><p>Given n samples and proximity matrix, do the following steps : </p>
<ol>
<li>Let every observation represent a singleton cluster </li>
<li>Merge the two closest clusters into one single cluster </li>
<li>Calculate the new proximity matrix (dissimilarity between two clusters) </li>
<li>Repeat step 2 and 3, until all samples are merged into one cluster </li>
</ol>
</li>
<li><p>Three methods for computing intergroup dissimilarity : </p>
<ul>
<li>Single linkage (SL) </li>
<li>Complete linkage (CL) </li>
<li>Average linkage (AL)</li>
</ul>
</li>
</ul>
<h5>Generalized Agglomerative Scheme</h5>

<p>()</p>
<h3 id="DBSCAN"><a href="#DBSCAN" class="headerlink" title="DBSCAN"></a>DBSCAN</h3><center><font size="5">Concept</font></center>

<ul>
<li>Three type of points :<ul>
<li><strong>Core point</strong> : # of samples in its $\epsilon$-neighborhood $&gt; \text{MinPts}$</li>
<li><strong>Boundary point</strong> : it lies in the $\epsilon$-neighborhood of some core point, # of samples in its $\epsilon$-neighborhood $&lt; \text{MinPts}$ </li>
<li><strong>Noise point</strong> : neither core point nor boundary point, it lies in the sparse region</li>
</ul>
</li>
</ul>
<center><img src="/2024/08/29/Big-Data-3/bd40.png" style="zoom:70%"></center>





<h3 id="Model-Assessment"><a href="#Model-Assessment" class="headerlink" title="Model Assessment"></a>Model Assessment</h3><center><font size="5">Purity</font></center>

<p><strong>Def.</strong> Total purity defined as </p>
<blockquote class="blockquote-center">
<p>$<br>\text{Purity}\triangleq \sum_i \frac{n_i}{n}p_i=\sum_i\frac{n_i}{n}(\max_j p_{ij})<br>$</p>

</blockquote>
<p>E.g. $\text{purity}=\frac{6}{17}\cdot \frac{4}{6}+\frac{6}{17}\cdot\frac{5}{6}+\frac{5}{17}\cdot\frac{3}{5}=0.71$ </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">|-------|-------|--------|</span><br><span class="line">| A B B | A A A |  A  A  |</span><br><span class="line">|       |       |        |</span><br><span class="line">| B B C | A A B | C C C  |</span><br><span class="line">|-------|-------|--------|</span><br></pre></td></tr></table></figure>
<center><font size="5">Confusion Matrix</font></center>

<div>
<img src="/2024/08/29/Big-Data-3/bd41.png" style="zoom:70%">
</div>
]]></content>
      <categories>
        <category>2024 Spring</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>CSE Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>MA234 å¤§æ•°æ®å¯¼è®ºä¸å®è·µï¼ˆäºŒï¼‰</title>
    <url>/2024/06/24/Big-Data-2/</url>
    <content><![CDATA[<h1 id="Big-Data-II"><a href="#Big-Data-II" class="headerlink" title="Big Data (II)"></a>Big Data (II)</h1><h2 id="IV-Classification"><a href="#IV-Classification" class="headerlink" title="IV. Classification"></a>IV. Classification</h2><blockquote>
<p>æœ¬ç« å†…å®¹è¾ƒå¤šï¼Œå…ˆå†™ä¸‹æœ¬ç« ä¸»è¦å†…å®¹ï¼š</p>
<p>æœ¬ç« æ¶‰åŠåˆ†ç±»ç®—æ³•ï¼Œä¸»è¦ä¼šæåŠ KNN ç®—æ³•ï¼Œå†³ç­–æ ‘ç®—æ³•å’Œæœ´ç´ è´å¶æ–¯ç®—æ³•ï¼ˆæ˜¯åˆ†ç±»ç®—æ³•ä¸­æœ€åŸºç¡€çš„å‡ ç§ï¼‰<br>å…¶ä¸­ï¼Œæ¯ç§ç®—æ³•çš„åº”ç”¨é‡Œæ¶µç›–äº†ä¸€äº›å¤šç”¨æ¦‚å¿µï¼Œå¦‚å‰ªææ“ä½œã€ä¼¼ç„¶å‡½æ•°è®¡ç®—ç­‰ã€‚</p>
<p>ä»‹ç»ä¸‰ç§åŸºæœ¬ç®—æ³•åï¼Œæœ¬ç« è¿˜æ¶‰åŠæ¨¡å‹è¯„ä¼°ï¼Œè®²è§£å¦‚ä½•é€šè¿‡ä¸åŒé—®é¢˜ä½¿ç”¨ä¸åŒçš„ç®—æ³•ä»¥å¾—åˆ°æœ€ä¼˜çš„ç»“æœ</p>
<p>æ³¨ï¼šæœ¬ç« å«æœ‰ä¸äºšäºæ•°æ®é¢„å¤„ç†ç« èŠ‚çš„æ•°å­¦å…¬å¼ï¼Œè¦æ±‚ç†è§£å…¬å¼åŸºæœ¬å†…æ¶µã€‚</p>
</blockquote>
<h3 id="K-Nearest-Neighbor-KNN"><a href="#K-Nearest-Neighbor-KNN" class="headerlink" title="K-Nearest Neighbor (KNN)"></a>K-Nearest Neighbor (KNN)</h3><blockquote>
<p>Supervised learning method, especially useful when prior knowledge on the data is very limited.</p>
<p><font color="red">Low bias, high variance</font> : <font color="blue">just for small</font> <code>k</code> </p>
<p><strong>Advantages</strong> : not sensitive to outliers (å¼‚å¸¸å€¼è·ç¦»ä¸€èˆ¬è¾ƒè¿œ) , easy to implement and parallelize, good for large training set</p>
<p><strong>Drawbacks</strong> : need to tune (è°ƒèŠ‚) $k$, take large storage, computationally intensive (è®¡ç®—ç¼“æ…¢ï¼Œç®—åŠ›è¦æ±‚é«˜)</p>
</blockquote>
<font size="4"><b>Algorithm</b></font>

<ul>
<li>Input : training set $D_{train} = \{(x_1, y_1),\cdots,(x_N, y_N)\}$,  a test sample $x$ without label $y$, $k$ and distance metric $d(x, y)$</li>
<li>Output : predicted label $y_{pred}$ for $x$ </li>
</ul>
<ol>
<li>Compute $d(x, x_j)$ for each $(x_j , y_j) \in D_{train}$</li>
<li>Sort the distances in an <font color="Red">ascending</font> order, choose the ï¬rst $k$ samples $(x_{(1)}, y_{(1)}),\cdots,(x_{(k)} , y_{(k)})$ </li>
<li>Make majority vote $y_{pred} = \text{Mode}(y_{(1)},\cdots, y_{(k)})$ </li>
</ol>
<p>Time Complexity : $O(mndK)$ where $n$ is the number of training samples, $m$ is the number of test samples, $d$ is the dimension, and $K$ is the number of nearest neighbors</p>
<div align="center"><img src="/2024/06/24/Big-Data-2/bd8.png" alt="bd8" style="zoom:50%"></div>



<p><strong>Similarity and Divergence</strong></p>
<ul>
<li><a href="/2024/06/22/Big-Data-1/index.html#cosine distance">Cosine similarity</a></li>
<li><a href="/2024/06/22/Big-Data-1/index.html#Jaccard">Jaccard similarity</a> for sets $A$ and $B$ : $Jaccard(A,B)=\Large{\frac{|A\cap B|}{|A\cup B|}}$ </li>
<li>Kullback-Leibler(KL) divergence : $d_{KL}(P||Q) = E_P log \large{\frac{P(x)}{Q(x)}}$ , measures the distance between two probability <font color="red">distributions</font> $P$ and $Q$ ; in discrete case, $d_{KL}(p||q) = \sum^m_{i=1} p_i log \large{\frac{p_i}{q_i}}$ (CDF of $P$ and $Q$)</li>
</ul>
<p><strong>Tuning <code>k</code></strong> </p>
<ul>
<li>Different <code>k</code> value can lead to totally different results. ( model overfit the data when <code>k = 1</code>, bad for generalization )</li>
<li><strong>M-fold Cross-validation (CV)</strong> to tune <code>k</code> : <ul>
<li>partition the dataset into M parts ( M = 5 or 10 ) , let $\kappa : \{1,\cdots, N\} \to \{1,\cdots, M\}$ be <em>randomized partition index map</em> (éšæœºåˆ†å¸ƒç´¢å¼•æ˜ å°„) . The <em>CV estimate of prediction error</em> (é¢„æµ‹è¯¯å·®çš„CVä¼°è®¡) is<br> $CV(\hat f,k)=\large{\frac{1}{N}} \sum_{n=1}^{N}L(y_i,\hat f^{-\kappa(i)}(x_i,k))$</li>
</ul>
</li>
</ul>
<p><img src="/2024/06/24/Big-Data-2/bd9.png" alt="bd9"></p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">kâ€™s value</th>
<th style="text-align:center">$k=1$ (complex model)</th>
<th style="text-align:center">$k=\infty$ (simplier model)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Bias</td>
<td style="text-align:center">decrease</td>
<td style="text-align:center">increase</td>
</tr>
<tr>
<td style="text-align:center">Variance</td>
<td style="text-align:center">increase</td>
<td style="text-align:center">$0$</td>
</tr>
<tr>
<td style="text-align:center">Generalization</td>
<td style="text-align:center">overfitting (train-set friendly)</td>
<td style="text-align:center">underfitting (test-set friendly)</td>
</tr>
</tbody>
</table>
</div>
<p><a name="Bayes"><b>Bayes Classifier (Oracle Classifier)</b></a></p>
<ul>
<li>Assume $Y \in \mathcal{Y} = \{1, 2, . . . , C\}$, the classiï¬er $f : \mathcal X â†’ \mathcal Y$ is a piecewise (åˆ†æ®µ) constant function</li>
<li>For <a href="/2024/06/22/Big-Data-1/index.html#0-1 loss">0-1 loss</a> $L(y, f )$, the learning problem is to minimize</li>
</ul>
<script type="math/tex; mode=display">
\begin{align}
\mathcal E(f)&=E_{P(X,Y)}[L(Y,f(X))]=1-P(Y=f(X))\\
&=1-\int_{\mathcal X}P(Y=f(X)|X=x)p_X(x)\text dx
\end{align}</script><ul>
<li>Bayes rule : $f^{âˆ—} (x) = \arg \max_c P(Y = c|X = x)$ , <font color="grey">â€œthe most probable label under the conditional probability on xâ€</font></li>
<li>Bayes Error Rate (è´å¶æ–¯è¯¯å·®) : $\text{inf}_{f}\varepsilon (f)=$ $\color{red}\mathcal E(f^{\ast})$ $=1-P(Y=f^{\ast}(X))$</li>
<li><strong>Bayes Decision Boundary</strong> (è´å¶æ–¯å†³ç­–è¾¹ç•Œ) : the boundary separating the <strong>K partition</strong> domains in $\mathcal X$ on each of which $f^{ âˆ— }(x) \in Y$ is constant. For binary classiï¬cation, it is the level set on which $P(Y=1|X=x)=P(Y=0|X=x)=0.5$<ul>
<li><font color="green">Recall : Decision boundary of 15NN is smoother than that of 1NN</font> 



</li>
</ul>
</li>
</ul>
<font color="red">Analysis of 1NN</font>

<ul>
<li>1NN error rate is twice the Bayes error rate<ul>
<li>Bayes error $=1-p_{c^\ast}(x)$ where $c^\ast=\arg\max_{c}p_c(x)$</li>
<li>Assume the samples are i.i.d. (ç‹¬ç«‹åŒåˆ†å¸ƒ) , for any test sample $x$ and small $\delta$, there is always a training sample $z \in B(x, \delta)$ (the label of $x$ is the same as that of $z$), then 1NN error is</li>
</ul>
</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\begin{align}<br>\epsilon=\sum_{c=1}^{C}p_c(x)(1-p_c(z))\overset{\delta\to 0}{\longrightarrow}&amp;1-\sum_{c=1}^{C}p_{c}^{2}(x) \\<br>\le\ &amp;1-p_{c^\ast}^{2}(x) \\<br>\le\ &amp;2(1-p_{c^\ast}(x))<br>\end{align}<br>$</p>

</blockquote>
<ul>
<li><ul>
<li><font color="green">Remark : In fact,</font> $\color{green}\epsilon\le 2(1-p_{c^\ast}^{2}(x))-\frac{C}{C-1}(1-p_{c^\ast}^{2}(x))^2$</li>
</ul>
</li>
</ul>
<font color="blue">Case : Use kNN to diagnose breast cancer (cookdata) </font>

<ul>
<li>We have to consider its radius, texture (è´¨åœ°) , perimeter, area, smoothness, etc. (n-dimension)</li>
<li>Data scaling : 0-1 scaling or z-score scaling</li>
<li>Use code to assist</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line">KNeighborsClassifier(n_neighbors = <span class="number">10</span>, metric = <span class="string">&#x27;minkowski&#x27;</span>, p = <span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="Decision-Tree"><a href="#Decision-Tree" class="headerlink" title="Decision Tree"></a>Decision Tree</h3><ul>
<li>Tree structure : internal nodes indicate features, while leaf nodes represent classes.</li>
<li>Start from root, choose a suitable feature $x_i$ and its split point $c_i$ at each internal node, split the node to two child nodes depending on whether $x_i \le c_i$ , until the child nodes are pure.</li>
<li>Equivalent to rectangular partition of the region.</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th><img src="/2024/06/24/Big-Data-2/bd11.png" width="60%"></th>
<th><img src="/2024/06/24/Big-Data-2/bd12.png" width="60%"></th>
</tr>
</thead>
<tbody>
<tr>
<td><p align="center"><a name="tree">Tree structure</a></p></td>
<td><p align="center">Rectangular partition</p></td>
</tr>
</tbody>
</table>
</div>
<ul>
<li>How to choose <font color="red">features</font> and <font color="red">split points</font> ?<ul>
<li>Impurity : choose the feature and split point so that after each slit the impurity should decrease the most</li>
<li>Impurity(M0)-Impurity(M12) &gt; Impurity(M0)-Impurity(M34), choose A as split node ; otherwise choose B</li>
</ul>
</li>
</ul>
<div align="center"><img src="/2024/06/24/Big-Data-2/bd13.png" alt="bd13" style="zoom:80%"></div>

<ul>
<li>Impurity Measures<ol>
<li>GINI Index<ul>
<li>Gini index of node $t$ : $Gini(t)=1-\sum_{c=1}^C (p(c|t))^2$ where $p(c|t)$ is the proportion of class-c data in node $t$</li>
<li>Gini index of a split : $Gini_{split}=\sum_{k=1}^{K}\frac{n_k}{n}Gini(k)$ where $n_k$ is the number of samples in the child node $k$, $n=\sum_{k=1}^{K} n_k$ </li>
<li>Choose the split so that $Gini(t) âˆ’ Gini_{split}$ is maximized</li>
</ul>
</li>
<li>Information Gain<ul>
<li>Entropy at $t$ : $H(t) = âˆ’\sum_{c=1}^{C}p(c|t)\log_2 p(c|t)$ , </li>
<li>where $t$ is the node and $\color{blue}c$ <font color="blue">represents that this node is chosen</font>.</li>
<li>Maximum at $log_2 C$, when $p(c|t)=\frac{1}{C}$</li>
<li>Minimum at $0$, when $p(c|t)=1$ for some $c$</li>
</ul>
</li>
<li>Misclassiï¬cation Error<ul>
<li>Misclassiï¬cation error at t : $\text{Error}(t) = 1 âˆ’ \max_c p(c|t)$  (use majority vote)</li>
<li>Maximum at $1âˆ’\frac{1}{C}$, when $p(c|t) = \frac{1}{C}$</li>
<li>Minimum at $0$, when $p(c|t)=1$ for some $c$</li>
</ul>
</li>
</ol>
</li>
<li>Compare Three Measure<ul>
<li>Gini index and information gain should be used when growing the tree</li>
<li>In pruning, all three can be used (typically misclassiï¬cation error)</li>
</ul>
</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">Algorithm</th>
<th style="text-align:center">Type</th>
<th style="text-align:center">Impurity Measure</th>
<th style="text-align:center">Child Nodes</th>
<th style="text-align:center">Target Type</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">ID3</td>
<td style="text-align:center">Discrete</td>
<td style="text-align:center">Info Gain</td>
<td style="text-align:center">$k\ge 2$</td>
<td style="text-align:center">Discrete</td>
</tr>
<tr>
<td style="text-align:center">C4.5</td>
<td style="text-align:center">Discrete, Continuous</td>
<td style="text-align:center">Info Gain</td>
<td style="text-align:center">$k\ge 2$</td>
<td style="text-align:center">Discrete</td>
</tr>
<tr>
<td style="text-align:center">C5.0</td>
<td style="text-align:center">Discrete, Continuous</td>
<td style="text-align:center">Info Gain</td>
<td style="text-align:center">$k\ge 2$</td>
<td style="text-align:center">Discrete</td>
</tr>
<tr>
<td style="text-align:center">CART</td>
<td style="text-align:center">Discrete, Continuous</td>
<td style="text-align:center">Gini Index</td>
<td style="text-align:center">$k=2$</td>
<td style="text-align:center">Discrete, Continuous</td>
</tr>
</tbody>
</table>
</div>
<ul>
<li>Tree Pruning (å‰ªæ)<ul>
<li>Too complex tree structure easily leads to <font color="red">overï¬tting</font> (åˆ†ç±»å¤ªç»†ï¼Œæ¨¡å‹å¤ªå¤æ‚)</li>
<li>Prepruning : set threshold <font color="grey">(é˜ˆå€¼)</font> $\delta$ for impurity decrease <font color="grey">(å‰”é™¤æ‚è´¨)</font> in splitting a node ; if $\Delta \text{Impurity}_{split} \gt \delta$, do slitting, otherwise stop</li>
<li>Postpruning : based on <u>cost function</u> (provided  $|T|$ and $\alpha$)<ul>
<li>$\color{red}\text{Cost}_{ \alpha}(T)=\sum_{t=1}^{|T|}n_t\ \text{Impurity}(t)+\alpha|T|$</li>
<li>Input: a complete tree $T$, $\alpha$</li>
<li>Output: postpruning tree $\text{T}_{\alpha}$ </li>
</ul>
<ol>
<li>Compute $\text{Impurity}(t)$ for $\forall t$</li>
<li>Iteratively merge child nodes <strong>bottom-up</strong> : Suppose $\text{T}_{A}$ and $\text{T}_{B}$ are the trees before and after merging, do merging if $\text{Cost}_{ \alpha}(\text{T}_{A}) \ge \text{Cost}_{ \alpha}(\text{T}_{B})$   <font color="grey">(å‰ªæå‰æŸå¤±æ›´å¤§)</font></li>
</ol>
</li>
</ul>
</li>
</ul>
<ul>
<li>Pros and Cons<ul>
<li>Advantage<ul>
<li>Easy to interpret and visualize : widely used in ï¬nance, medical health, biology, etc.</li>
<li>Easy to deal with missing values (treat as new data type)</li>
<li>Could be extended to regression</li>
</ul>
</li>
<li>Disadvantage<ul>
<li>Easy to be trapped at local minimum because of greedy algorithm (è´ªå¿ƒ)</li>
<li>Simple decision boundary : parallel lines to the axes (Recall <a href="#tree">Pic above</a>)</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<h3 id="Naive-Bayes-æœ´ç´ è´å¶æ–¯"><a href="#Naive-Bayes-æœ´ç´ è´å¶æ–¯" class="headerlink" title="Naive Bayes (æœ´ç´ è´å¶æ–¯)"></a>Naive Bayes (æœ´ç´ è´å¶æ–¯)</h3><ul>
<li>Based on <strong>Bayes Theorem</strong> and conditional independency assumption on features (Recall <a href="#Bayes">Bayes Classifier</a>)</li>
<li>Bayes Theorem : $\Large{P(Y|X)=\frac{P(X|Y)P(Y)}{P(X)}}$<ul>
<li>$P(Y)$ is prior prob. distribution (å…ˆéªŒæ¦‚ç‡åˆ†å¸ƒ) , $P(X|Y )$ is likelihood function (ä¼¼ç„¶å‡½æ•°) , $P(X)$ is evidence (è¾¹é™…æ¦‚ç‡) , $P(Y |X)$ is posterior prob. distribution (åéªŒæ¦‚ç‡åˆ†å¸ƒ).</li>
</ul>
</li>
<li>The <font color="red">core problem</font> of machine learning is to estimate $P(Y |X)$ </li>
</ul>
<ol>
<li>Let $X = \{X_1, . . . , X_d \}$, for ï¬xed sample $X = x$, $P(X = x)$ is independent of  $Y$ , by Bayes Theorem, $P(Y|X=x)\propto P(X=x|Y)P(Y)$</li>
<li>Assume conditional independency of $X_1, \cdots, X_d$ given $Y = c$ : $P(X=x|Y=c)=\prod_{i=1}^{d}P(X_i=x_i|Y=c)$</li>
<li><font color="red">Naive Bayes Model :</font>

</li>
</ol>
<blockquote class="blockquote-center">
<p>$<br>\color{red}\hat y =\arg \max_c P(Y=c)\prod_{i=1}^{d}P(X_i=x_i|Y=c)<br>$</p>

</blockquote>
<p><strong>Maximum Likelihood Estimate (MLE)</strong></p>
<ul>
<li>Estimate $P(Y = c)$ and $P(X_i = x_i |Y = c)$ from the dataset $D = \{(\textbf{x}_1, y_1), \cdots ,(\textbf{x}_n, y_n)\}$<ol>
<li><strong>MLE</strong> for $P(Y = c)$ : $P(Y = c) =\Large{\frac{ \sum_{i=1}^{n} I(y_i=c)}{n}}$</li>
<li>When $X_i$ is discrete variable with range $\{v_1, \cdots , v_K\}$, <strong>MLE</strong> for $P(X_i = v_k |Y = c) =\Large{\frac{ \sum_{i=1}^{n} I(x_i = v_k |y_i = c)}{ \sum_{i=1}^{n} I(y_i = c)}}$ <br> ( if $X_i$ is continuous, just do discretization on it and use this formula )</li>
</ol>
</li>
</ul>
<hr>
<h3 id="Model-Assessment"><a href="#Model-Assessment" class="headerlink" title="Model Assessment"></a>Model Assessment</h3><p><strong>Confusion Matrix</strong></p>
<div align="center"><img src="/2024/06/24/Big-Data-2/bd14.png" alt="bd14" style="zoom:100%"></div>



<ul>
<li>Representation<ul>
<li>T &amp; F : represents truth of label (æ ‡ç­¾æ˜¯å¦çœŸå®)</li>
<li>P &amp; N : represents aspect of label (æ ‡ç­¾çš„ä¸¤é¢)</li>
</ul>
</li>
<li><p>Two-class classification: </p>
<ul>
<li>$\text{Accuracy} =\large{\frac{\text{TP+TN}}{\text{TN+FN+FP+TP}}}$, not a good index when samples are <font color="red">imbalanced</font></li>
<li>$\text{Precision}=\large{\frac{\text{TP}}{\text{TP+FP}}}$ </li>
<li>TPR : $\text{Recall} = \large{\frac{\text{TP}}{\text{TP+FN}}}$ ; important in medical diagnosis (å›æ”¶)</li>
<li>F score : $F_{\beta} = \large{\frac{(1+\beta^2)\text{Precision}\times\text{Recall}}{\beta^2 \times \text{Precision}+\text{Recall}}}$ , e.g. $F_1$ score for $\beta=1$</li>
<li>FPR : $\text{Specifity} = \large{\frac{\text{TN}}{\text{TN+FP}}}$ ; recall for negative samples</li>
</ul>
</li>
<li><p>Receiver Operating Characteristic (ROC, å—è¯•è€…å·¥ä½œç‰¹å¾) and Area Under ROC (AUC)</p>
<ul>
<li>Aim to solve class distribution <font color="red">imbalance problem</font></li>
<li>Set different threshold (é˜ˆå€¼) $t$ for continuous predicted values.</li>
<li>Compute <strong>TPR</strong> vs. <strong>FPR</strong> for all $t$ and plot ROC curve</li>
</ul>
</li>
</ul>
<div align="center"><img src="/2024/06/24/Big-Data-2/bd15.png" style="zoom:120%"></div>

<ul>
<li>Beware: Donâ€™t view the â€œcurveâ€ as a function, but as a <strong>continuous set of points</strong>.<ul>
<li>Higher ROC implies better performance (How to measure ? AUC)</li>
</ul>
</li>
<li>AUC: compute the area under ROC curve. The larger the better. Model is good for test set if $AUC \gt 0.75$</li>
</ul>
<p><strong>Cohenâ€™s Kappa Coefficient</strong></p>
<blockquote>
<p>Since ROC and AUC is complex to be quantified, we need a <code>coe</code> to indicate it.</p>
<p>We use an example to explain how to quantified it.</p>
</blockquote>
<blockquote class="blockquote-center">
<p>$<br>\begin{align}<br>&amp;\text{Cohenâ€™s Kappa Coefficient: }&amp; &amp;\kappa=\frac{p_o-p_e}{1-p_e}=1-\frac{1-p_o}{1-p_e} \\<br>&amp;&amp; &amp;p_e=\sum_{c=1}^{C}\frac{n_c^{pred}}{N}\frac{n_c^{true}}{N}<br>\end{align}<br>$</p>

</blockquote>
<ul>
<li>$p_o$ is the accuracy</li>
<li>$p_e$ is the hypothetical probability of chance agreement</li>
</ul>
<div align="center"><img src="/2024/06/24/Big-Data-2/bd16.png" alt="bd16" style="zoom:100%"></div>

<p>E.g.  $\large{p_o=\frac{20+15}{50}=0.7}$, $\large{p_e=\frac{25}{50}\times\frac{20}{50}+\frac{25}{50}=0.5}$, then $\large{\kappa=0.4}$</p>
<ul>
<li>$\kappa \in [-1,1]$, $\kappa\ge 0.75$ for good performance and $\kappa\lt 0.4$ for bad one.</li>
</ul>
<hr>
<h2 id="V-Regression"><a href="#V-Regression" class="headerlink" title="V. Regression"></a>V. Regression</h2><h3 id="Linear-Model"><a href="#Linear-Model" class="headerlink" title="Linear Model"></a>Linear Model</h3><p><strong>Linear model</strong> : </p>
<ul>
<li>For <strong>Univariate</strong> linear model,  $y = w_0 + w_1x + \epsilon$, where $w_0$ and $w_1$ are regression coeï¬ƒcients, $\epsilon$ is the error or noise</li>
</ul>
<p>Assume $\epsilon âˆ¼ \mathcal N (0, \sigma^2)$, where $Ïƒ^2$ is a ï¬xed but unknown variance; then $y|x âˆ¼ \mathcal N (w_0 + w_1x, Ïƒ^2)$</p>
<script type="math/tex; mode=display">
(\hat{w}_0,\hat{w}_1)= \arg \min_{w_0,w_1}\sum_{i=1}^{n}(y_i-w_0-w_1x_i)^2</script><p>which means $L(\hat w_0,\hat w_1)$ is minimized (æ®‹å·®æœ€å°).</p>
<ul>
<li>For <strong>multivariate</strong> linear model, $y=f(\textbf{x})=w_0+w_1x_1+w_2x_2+\cdots+w_px_p + \epsilon$ <ul>
<li>where $w_0, w_1,\cdots, w_p$ are <font color="red">regression coefficients</font>, $\textbf{x} = (x_1,\cdots, x_p)^T$ is the input vector whose components are independent variables or attribute values, $\epsilon \thicksim \mathcal N(0, Ïƒ^2)$ is the noise.</li>
<li>For the size n samples $\{(\textbf{x}_i, y_i)\}$, let $\textbf{y} = (y_1, \cdots , y_n)^T$ be the response or dependent variables, $\textbf{w} = (w_0, w_1, \cdots, w_p)^T$,  we construct a matrix $\textbf{X}=[\textbf{1}_n, (\textbf{x}_1, \cdots,\textbf{x}_n)^T]\in \mathbb R^{n \times(p+1)}$ , and $\textbf{\varepsilon}=(\epsilon_1,\cdots,\epsilon_n)^T \thicksim \mathcal N(\textbf{0},\sigma^2\textbf{l}_n)$ </li>
</ul>
</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\begin{align}<br>&amp;\textbf{y}=\textbf{X}\textbf{w} + \varepsilon\\ \\<br>&amp;\textbf{X}=<br>\begin{pmatrix}<br>1 &amp; x_{11} &amp; \cdots &amp; x_{1p} \\<br>1 &amp; x_{21} &amp; \cdots &amp; x_{2p} \\<br>\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\<br>1 &amp; x_{n1} &amp; \cdots &amp; x_{np}<br>\end{pmatrix}<br>\end{align}<br>$</p>

</blockquote>
<p><strong>Least Square (LS)</strong> <font color="grey" size="3">æœ€å°äºŒä¹˜æ³•</font></p>
<div><img src="/2024/06/24/Big-Data-2/bd17.png" style="zoom:60%"></div>

<ul>
<li>From geometry aspect, we should <strong>minimize the residual sum-of-square (æ®‹å·®å¹³æ–¹å’Œ)</strong>: <br>$\text{RSS}(\textbf{w})=\sum_{i=1}^{n} (y_i-w_0-w_1x_1-\cdots-w_px_p)^2=|\textbf{y} - \textbf{X} \textbf{w}|_{2}^2$<ul>
<li>When $\textbf{X}^T\textbf{X}$ is invertible, the <strong>minimizer</strong> $\hat{\textbf{w}}$ satisfy :  ï¼ˆå¯è¯æ˜ $\hat w$ æ˜¯æ— åä¼°è®¡ï¼‰</li>
</ul>
</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\nabla_{\textbf{w}}\text{RSS}(\hat{\textbf{w}})=0 \Rightarrow \hat{\textbf{w}}=(\textbf{X}^T \textbf{X})^{-1}\textbf{X}^T \textbf{y}<br>$</p>

</blockquote>
<ul>
<li><ul>
<li>Then prediction $\hat{\textbf{y}}=\textbf{X}(\textbf{X}^T \textbf{X})^{-1}\textbf{X}^T \textbf{y}= \textbf{P} \textbf{y}$ is a projection of $\textbf{y}$ onto the linear space spanned by the column vectors of $\textbf{X}$; (As Pic 15 show)<ul>
<li>$\textbf{P}=\textbf{X}(\textbf{X}^T \textbf{X})^{-1}\textbf{X}^T$ is the projection matrix satisfying $\textbf{P}^2 = \textbf{P}$ <font color="green">(Recall: Linear Algebra)</font></li>
</ul>
</li>
</ul>
</li>
</ul>
<blockquote>
<p>Optimal Method: Ordinary least square (<strong>OLS</strong>)</p>
<ol>
<li>Get mean values from sample set: $\bar y=\frac{1}{n}\sum_{i=1}^{n}y_i$ , $\bar{\textbf{x}}=\frac{1}{n}\sum_{i=1}^{n}{ \textbf{x}_i}$</li>
<li>Centralize data (minus by $\bar y$ and $\bar{\textbf{x}}$) and calculate $RSS(\tilde{\textbf{w}})$ </li>
<li>Prediction $\hat{\textbf{y}}= \textbf{P} \textbf{y}$ is the projection (æŠ•å½±) of $\textbf{y}$ on the <em>linear space spanned</em> by the columns of $\textbf{X}$. <br>$\mathcal X= \text{Span} \{ \textbf{x}_{\cdot ,0}, \textbf{x}_{\cdot ,1},\cdots,  \textbf{x}_{\cdot ,p}\}$ , recall that $ \textbf{x}_{\cdot ,0}= \textbf{1}_n$</li>
<li>If $\{ \textbf{x}_{\cdot ,0}, \textbf{x}_{\cdot ,1},\cdots,  \textbf{x}_{\cdot ,p}\}$ forms a set of orthonormal basis (æ ‡å‡†æ­£äº¤åŸº) , then $\hat{\textbf{y}}=\sum_{i=0}^{p}&lt;\textbf{y}, \textbf{x}_{\cdot ,i}&gt; \textbf{x}_{\cdot ,i}$</li>
<li>If not, do orthogonalization by Gram-Schmidt procedure for the set $\{ \textbf{x}_{\cdot ,0}, \textbf{x}_{\cdot ,1},\cdots,  \textbf{x}_{\cdot ,p}\}$ </li>
</ol>
</blockquote>
<ul>
<li>From mathemetic aspect, itâ€™s about <strong>MLE</strong> (Result the same)<ol>
<li>Likelihood function: $L((\textbf{w},\textbf{X}),\textbf{y})=P(\textbf{y}|(\textbf{X}, \textbf{w}))=\prod_{i=1}^{n}P(y_i|(\textbf{x}_i, \textbf{w}))$ </li>
<li>Find <strong>MLE</strong>: $\hat{\textbf{w}}=\arg \max_{\textbf{w}} L(\textbf{w} ; \textbf{X}, \textbf{y})$ (E.g. For $P(y_i|(\textbf{x}_i, \textbf{w}))=\frac{1}{\sqrt{2\pi}\sigma} \Large{e^{-\frac{(y_i-w_0-w_1x_{i1}-\cdots-w_px_{ip})^2}{2\sigma^{2}}}}$)</li>
<li><font color="blue">(2.) is equivalent to its log-function:</font><br> E.g.  $l(\textbf{w} ; \textbf{X}, \textbf{y})= \log{L(\textbf{w} ; \textbf{X}, \textbf{y})}=-n\log(\sqrt{2\pi}\sigma)-\frac{1}{2\sigma^{2}} \sum_{i=1}^{n} (y_i-w_0-w_1x_{i1}-\cdots-w_px_{ip})^2$ </li>
<li>Then get the same minimizer as <strong>LS</strong> : $\hat{\textbf{w}}=(\textbf{X}^T \textbf{X})^{-1}\textbf{X}^T \textbf{y}$</li>
</ol>
</li>
</ul>
<p><strong>Shortcomings of Fitting Nonlinear Data</strong> (ä¸Šè¿°æ–¹æ³•ä»…é€‚åˆçº¿æ€§å›å½’)</p>
<ul>
<li>Evaluating the model by Coefficient of Determination $R^2$<ul>
<li>$R^2 := 1-\frac{ \text{SS}_{res}}{ \text{SS}_{tot}}$ ($=\frac{ \text{SS}_{reg}}{ \text{SS}_{tot}}$ only for linear regression), where<ul>
<li>$ \text{SS}_{tot} = \sum_{i=1}^{n} (y_i-\bar y)^2$ is the total sum of squares</li>
<li>$ \text{SS}_{reg} = \sum_{i=1}^{n} (\hat y_i-\bar y)^2$ is the regression sum of squares</li>
<li>$ \text{SS}_{res} = \sum_{i=1}^{n} (y_i-\hat y_i)^2$ is the residual sum of squares.</li>
</ul>
</li>
<li>The larger the $R^2$, the better the model !</li>
</ul>
</li>
<li><strong>Multicolinearity</strong> [å¤šé‡å…±çº¿æ€§]<ul>
<li>If the columns of $\textbf{X}$ are almost linearly dependent (multicolinearity), then $\det(\textbf{X}^{T}\textbf{X})\approx 0$, the diagonal entries in $(\textbf{X}^{T}\textbf{X})^{-1}$ is quite large, leading to a large variances of $\hat{\textbf{w}}$ (inaccurate).</li>
<li>Remedies (è¡¥æ•‘æªæ–½): ridge regression (å²­å›å½’), principal component regression (ä¸»å±æ€§å›å½’), partial least squares regression (éƒ¨åˆ†æœ€å°äºŒä¹˜å›å½’), etc.</li>
</ul>
</li>
<li>Overfitting<ul>
<li>Linear regression easily to be overfitted when introducing more variables.</li>
<li>Solution: <a href="#regul">Regularization</a></li>
</ul>
</li>
</ul>
<p><strong>Bias-Variance Decomposition</strong></p>
<ul>
<li>Bias (åå·®): $\text{Bias}(\hat f(\textbf{x}))=\text{E}_\text{train}\hat f(\textbf{x})-f(\textbf{x})$ , average <strong>accuracy</strong> of prediction for the model (deviation from the truth)</li>
<li>Variance (æ–¹å·®): $\text{Var}(\hat f(\textbf{x}))=\text{E}_\text{train}(\hat f(\textbf{x})-\text{E}_\text{train}\hat f(\textbf{x}))^2$ , <strong>variability</strong> of the model prediction due to different data set (stability)</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\color{red}<br>\text{E}_\text{train}\text{R}_\text{exp}(\hat f(\textbf{x}))=\text{E}_\text{train}\text{E}_\text{P}[(y-\hat f(\textbf{x}))^2|\textbf{x}] = \underbrace{\text{Var}(\hat f(\textbf{x}))}_{\text{variance}}+\underbrace{\text{Bias}^2(\hat f(\textbf{x}))}_{\text{bias}}+\underbrace{\sigma^2}_{\text{noise}}<br>$</p>

</blockquote>
<div><img src="/2024/06/24/Big-Data-2/bd19.png" style="zoom:80%"></div>

<ul>
<li>The more complicated the model, the lower the bias, but the higher the variance.</li>
</ul>
<div><img src="/2024/06/24/Big-Data-2/bd18.png" style="zoom:90%"></div>

<ul>
<li>kNN Regression<ul>
<li>kNN can be used to do regression if the mode (majority vote) is replaced by mean : $\hat f(x)=\frac{1}{k} \sum_{ x_{(i)} \in N_{k}(x)} y_{(i)}$</li>
<li>Generalization error of kNN regression is</li>
</ul>
</li>
</ul>
<div><img src="/2024/06/24/Big-Data-2/bd20.png" style="zoom:80%"></div>

<p>where we have used the fact that $E_{ \text{train}} y_{i} = f(\textbf{x}_{i})$ and $\text{Var}(y_i)=\sigma^2$</p>
<ul>
<li>For small $k$, overfitting, bias â†“, variance â†‘</li>
<li>For large $k$, underfitting, bias â†‘, variance â†“</li>
</ul>
<hr>
<h3 id="Regularization-æ­£åˆ™åŒ–"><a href="#Regularization-æ­£åˆ™åŒ–" class="headerlink" title="Regularization (æ­£åˆ™åŒ–)"></a><a name="regul">Regularization</a> (æ­£åˆ™åŒ–)</h3><blockquote>
<p>Why we need Regularization ?</p>
<ul>
<li>In <strong>high dimensions</strong>, the more the input attributes, the larger the <strong>variance</strong></li>
<li>Shrinking some coefficients or setting them to zero can reduce the <strong>overfitting</strong></li>
<li>Using less input variables also help interpretation with the most important variables</li>
<li>Subset selectionÂµretaining only a subset of the variables, while eliminating the rest variables from the model</li>
</ul>
</blockquote>
<h4>Best-Subset Selection</h4>

<ul>
<li>find for each $k âˆˆ \{0, 1, \cdots , p\}$ the subset $S_k \subset \{1,\cdots, p\}$ of size $k$ that gives the smallest $\text{RSS}(\textbf{w}) = \sum_{i=1}^n (y_i âˆ’ w_0 âˆ’ \sum_{j\in S_k} w_j x_{ij})^2$ </li>
<li>Noted that the best subset of size $k + 1$ may not include the the variables in the best subset of size $k$</li>
<li>Choose $k$ based on <strong>bias-variance tradeoff</strong>, usually by <strong>AIC</strong> and <strong>BIC</strong>(è´å¶æ–¯ä¿¡æ¯é‡), or practically by <strong>cross-validation</strong></li>
</ul>
<h5>Forward-stepwise selection</h5>

<ul>
<li>Start with the intercept (æˆªè·?) $\bar y$ , then sequentially add into the model the variables that improve the fit most (reduce RSS most)</li>
<li><font color="red">QR factorization</font> helps search the candidate variables to add </li>
<li><font color="red">Greedy algorithm</font> : the solution could be sub-optimal</li>
</ul>
<h5>Backward-stepwise selection</h5>

<ul>
<li>Start with the <font color="red">full model</font>, then sequentially delete from the model the variables that has the least impact on the fit most </li>
<li>The candidate for dropping is the variable with the smallest <a href="/2024/06/22/Big-Data-1/index.html#z-score">Z-score</a> </li>
<li>Can only be used when $n &gt; p$ in order to fit the full model by <strong>OLS</strong></li>
</ul>
<h5><font color="red">Regularization by Penalties</font></h5>

<ul>
<li>Add a penalty term, in general $l_q$ - norm</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\sum_{i=1}^{n}(y_i-w_0-w_1x_1-\cdots-w_px_p)^2+\lambda |\textbf{w}|^q_q=|\textbf{y}-\textbf{X}\textbf{w}|^2+\lambda |\textbf{w}|^q_q<br>$</p>

</blockquote>
<ul>
<li>By arranging $\lambda$ , we can correct the overfitting (bias inc. &amp; var dec.)</li>
<li><code>q = 2</code> for Ridge Regression &amp; <code>q = 1</code> for LASSO Regression</li>
</ul>
<div align="center"><img src="/2024/06/24/Big-Data-2/bd26.png" style="zoom:60%"></div>



<h4>Ridge Regression</h4>

<font color="#ff44ff">$\hat w=\arg \underset{w}\min {\|y-Xw\|_2^2}+\lambda\|w\|_2^2$</font> 

<div align="center"><img src="/2024/06/24/Big-Data-2/bd21.png" style="zoom:50%"></div>

<blockquote>
<p>Solving Ridge Regression</p>
</blockquote>
<div align="center"><img src="/2024/06/24/Big-Data-2/bd22.png" style="zoom:50%"></div>



<blockquote>
<p>Bayesian Viewpoint of Ridge Regression</p>
</blockquote>
<div align="center"><img src="/2024/06/24/Big-Data-2/bd23.png" style="zoom:60%"></div>

<hr>
<h4>LASSO Regression</h4>

<blockquote>
<p>Can be used to estimate the coefficients and select the important variables simultaneously</p>
<p>Reduce the model complexity, avoid overfitting, and improve the generalization ability</p>
</blockquote>
<font color="#ff44ff">$\hat w=\arg \underset{w}\min {\|y-Xw\|_2^2}+\lambda\|w\|_1$</font> 

<p>Two Rpoperties : </p>
<ul>
<li>Shrinkage (å°†æ‰€æœ‰ç‚¹æ”¶ç¼©)</li>
<li>Selection (å°†è¿‘ç‚¹å½’é›¶ï¼Œè¿œç‚¹æ”¶ç¼©)</li>
</ul>
<table>
    <tr>
        <td><img align="center" src="/2024/06/24/Big-Data-2/bd24.png" style="zoom:50%"></td>
        <td><img align="center" src="/2024/06/24/Big-Data-2/bd25.png" style="zoom:50%"></td>
    </tr>
    <tr>
        <td colspan="2"><center><font size="2">LASSO Regression</font></center></td>
    </tr>
</table>

<blockquote class="blockquote-center">
<p>$<br>\hat w_i^{\text{lasso}} = (|\hat w^{OLS}_i| âˆ’ \lambda)+\text{sign}(\hat w^{OLS}_i)<br>$</p>

</blockquote>
<ul>
<li>Solving LASSO by <strong>LARS</strong> (æœ€å°è§’å›å½’ç®—æ³•)<ol>
<li>Start with all coefficients $w_i$ equal to zero</li>
<li>Find the predictor $x_i$ most correlated with $y$ (ä¸€èˆ¬è®¤ä¸ºå¤¹è§’æœ€å°çš„å³æ˜¯)</li>
<li>Increase the coefficient $w_i$ in the direction of the sign of its correlation with $y$. Take residuals $r = y âˆ’ \hat y$ along the way. Stop when some other predictor $x_k$ has as much correlation with $r$ as $x_i$ has (è°ƒæ•´å‚æ•° $w$ ç›´è‡³ä¸‹ä¸€ä¸ªåˆ†é‡å¤¹è§’æœ€å°)</li>
<li>Increase $(w_i, w_k)$ in their joint <strong>least squares direction</strong>, until some other predictor $x_m$ has as much correlation with the residual $r$</li>
<li>Continue until all predictors are in the model</li>
</ol>
</li>
</ul>
<center><img src="/2024/06/24/Big-Data-2/bd27.png" style="zoom:70%"><font size="2">Pic 19. LARS</font></center>



<blockquote>
<p>Optional: Maximum A Posteriori (<strong>MAP</strong>) Estimation</p>
<ul>
<li><p>Given $\theta$ , the conditional distribution of $\textbf{y}$ is $P(\textbf{y}|\theta)$</p>
</li>
<li><p><strong>MAP</strong> choose the point of maximal posterior probability :</p>
<p> $\hat{\theta}^{MAP}=\arg \underset{\theta}\max{(\log P(\textbf{y}|\theta)+\log P(\theta))}$</p>
</li>
<li><p>If $\theta=\textbf{w}$, and we choose the log-prior <font color="grey">[å¯¹æ•°å…ˆéªŒ]</font> (i.e. normal prior  $\mathcal N(0, \frac{\sigma^2}{\lambda} \textbf{I})$ ) , we revocer the ridge regression.</p>
</li>
<li><p><font color="#ff7575">Different log-prior lead to different penalties</font> (Not general case. Some penalties may not be the logarithms[å¯¹æ•°] of probability distributions, some other penalties depend on the data)</p>
</li>
</ul>
<p>Related Regularization Models</p>
<ul>
<li>Elastic net (æ··åˆå›å½’) : $\hat{\textbf{w}}=\arg\min_w|y-Xw|_2^2+\lambda_1|\textbf{w}|^2_2+\lambda_2|\textbf{w}|_1$ </li>
<li>Group LASSO (å¯¹ä¸åŒåˆ†ç»„è¿›è¡Œå›å½’) : $\hat{\textbf{w}}=\arg\min_w|y-Xw|_2^2+\sum_{g=1}^{G}\lambda_{g}|\textbf{w}_{g}|_2$ , where $\textbf{w}=(w_1,\cdots,w_G)$ is the <strong>group partition</strong> of $\textbf{w}$. </li>
<li>Dantzig Selector : â€¦</li>
<li>Smoothly clipped absolute deviation (<strong>SCAD</strong>) penalty</li>
<li>Adaptive LASSO</li>
</ul>
</blockquote>
<h4>ADMM Used in LASSO Problem</h4>

<p><strong>Altinating Direction Method of Multipliers (ADMM)</strong></p>
<ul>
<li>ADMM [äº¤æ›¿æ–¹å‘ä¹˜å­æ³•] often used to solve problems with two optimized variables which only has equality constraint. </li>
<li><p>Normal Form as below :</p>
<script type="math/tex; mode=display">
\min_{x,z} f(x)+g(z)\\ s.t.\ Ax+Bz=c</script></li>
<li><p>where $x\in R^{n}$ and $z\in R^{m}$ are optimized variables, and in the equality constraint, $A\in R^{p\times n}$ , $B\in R^{p\times m}$ , $c\in R^{p}$ , and $f$ and $g$ are <font color="red">convex functions (å‡¸å‡½æ•°)</font></p>
</li>
</ul>
<center>------ Solution ------</center>

<ol>
<li>Define Augmented Lagrangian (å¢å¹¿æ‹‰æ ¼æœ—æ—¥å‡½æ•°)</li>
</ol>
<script type="math/tex; mode=display">
L_{\rho}(x,z,u)=f(x)+g(z)+u^{T}(Ax+Bz-c)+\frac{\rho}{2}\|Ax+Bz-c\|^2</script><ul>
<li>If we let $w=\frac{u}{\rho}$ , then we can get simplified form of Augmented Lagrangian</li>
</ul>
<script type="math/tex; mode=display">
L_{\rho}(x,z,u)=f(x)+g(z)+\frac{\rho}{2}\|Ax+Bz-c+w\|_2^2-\frac{\rho}{2}\|w\|_2^2</script><ol>
<li>Algorithm : fixed other variables and update only one of them (Here $\rho\gt 0$ is a penalty parameter)</li>
</ol>
<script type="math/tex; mode=display">
\begin{align}
&\text{for }k=1,2,3,...\\
&\text{step 1: } x^{(k)}=\arg\min_{x}L_{\rho}(x,z^{(k-1)},w^{(k-1)})=\arg\min_{x} f(x)+\frac{\rho}{2}\|Ax+Bz^{(k-1)}-c+w^{(k-1)}\|_2^2 \\
&\text{step 2: } z^{(k)}=\arg\min_{z}L_{\rho}(x^{(k)},z,w^{(k-1)})=\arg\min_{z} g(z)+\frac{\rho}{2}\|Ax^{(k)}+Bz-c+w^{(k-1)}\|_2^2 \\
&\text{step 3: } w^{(k)}=w^{(k-1)}+Ax^{(k)}+Bz^{(k)}-c
\end{align}</script><ol>
<li><strong>Consider LASSO Problem</strong> <ul>
<li>To find $\min_{w} \frac{1}{2}|y-Xw|^2_2+\lambda|w|_1$ </li>
<li>Let $w=\beta$ (the constraint : $w-\beta=0$) and rewrite the Augmented Lagrangian : $L_{\rho}(w,\beta,u)=\frac{1}{2}|y-Xw|^2_2+\lambda|\beta|_1+u^T(w-\beta)+\frac{\rho}{2}|w-\beta|_2^2$</li>
</ul>
</li>
</ol>
<h3 id="Model-Assessment-1"><a href="#Model-Assessment-1" class="headerlink" title="Model Assessment"></a>Model Assessment</h3><ul>
<li>Mean absolute error (MAE) : $MAE =\frac{1}{n} \sum_{i=1}^{n} |y_i - \hat y_i|$</li>
<li>Mean square error (MSE) : $MSE =\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat y_i)^2$ </li>
<li>Root mean square error (RMSE) : $RMSE = \sqrt{\frac{1}{n} (y_i - \hat y_i)^2}$</li>
<li><p>Coefficient of Determination [å†³å®šç³»æ•°] <font color="green">(Recall)</font> : $R^2:=1-\frac{\text{SS}_{\text{res}}}{\text{SS}_{\text{tot}}}$ , <br>where $\text{SS}_{\text{tot}}=\sum_{i=1}^n (y_i-\bar y_i)^2$  and  $\text{SS}_{\text{res}}=\sum_{i=1}^n (y_i-\hat y_i)^2$ </p>
<ul>
<li>Normally $R^2\in[0,1]$ , but it can be negative (a wrong model making residual too large). </li>
<li><font color="red">The larger the $R^2$ , the better the model.</font>
</li>
</ul>
</li>
<li><p>Adjusted Coefficient of Determination</p>
</li>
</ul>
<script type="math/tex; mode=display">
R_{\text{adj}}^2=1-\frac{(1-R^2)(n-1)}{n-p-1}</script><ul>
<li>$n$ is  the number of samples, $p$ is the dimensionality (or the number of attributes)</li>
<li><font color="red">The larger the $\text{R}_{\text{adj}}^2$ value, the better performance the model</font></li>
<li>When adding important variables into the model, $\text{R}_{\text{adj}}^2$ gets larger and $\text{SS}_{\text{res}}$ is reduced</li>
</ul>
<hr>
<h2 id="VI-Classification-II"><a href="#VI-Classification-II" class="headerlink" title="VI. Classification II"></a>VI. Classification II</h2><blockquote>
<p>Why talk about Regression first ?</p>
<ul>
<li>Naive Bayes uses Probability and Mathemetic methods, which is the core of Regression</li>
<li>Regression all apply <strong>MLE</strong>, which is connected with Bayes rules.</li>
</ul>
</blockquote>
<h3 id="Logistic-Regression"><a href="#Logistic-Regression" class="headerlink" title="Logistic Regression"></a>Logistic Regression</h3><blockquote>
<p>é€»è¾‘å›å½’æ˜¯ä¸€ç§åˆ†ç±»æ–¹æ³•ï¼ˆä¸æ˜¯å›å½’ï¼‰</p>
</blockquote>
<font color="green">Recall: Linear Regression</font>

<ul>
<li>$E(y|x)=P(y=1|x)=w_0+w_1x$ , but $w_0+w_1x$ may be not probability</li>
<li>Use <strong>Sigmoid function</strong> to map it to $\left[0,1\right]$ : $g(z)=\frac{1}{1+e^{-z}}$ , where $z=w_0+w_1x_1+\cdots+w_dx_d$</li>
<li><font color="red">Equivalently</font>, $\log{\frac{P(y=1|x)}{1-P(y=1|x)}}=w_0+w_1x_1+\cdots+w_dx_d$</li>
</ul>
<script type="math/tex; mode=display">
\text{logit}(z)=\log\frac{z}{1-z}</script><p><strong>MLE for Logistic Regression</strong></p>
<ul>
<li>The prob. distribution for two-class logistic regression model is <ul>
<li>$Pr(y=1|X=x)=\frac{\exp(\textbf{w}^T \textbf{x})}{1+\exp(\textbf{w}^T \textbf{x})}$</li>
<li>$Pr(y=0|X=x)=\frac{1}{1+\exp(\textbf{w}^T \textbf{x})}$</li>
</ul>
</li>
<li>Let $P(y=k|X=x)=p_k(\textbf{x};\textbf{w})$, $k=0,1$. The <font color="red">likelihood function</font> is $L(\textbf{w})=\prod_{i=1}^{n} p_{y_i}(\textbf{x}_i;\textbf{w})$</li>
<li>MLE of $\textbf{w}$ : $\hat{\textbf{w}}=\arg \underset{\textbf{w}}\max L(\textbf{w})$</li>
<li>Solve $\color{red}\nabla_{\textbf{w}}\log L(\textbf{w})=0$ by Newton-Raphson method</li>
</ul>
<blockquote>
<p>ç”¨ MLE è®¡ç®— $\hat{\textbf{w}}$ ï¼Œéœ€è¦æå‰çŸ¥é“ $x$ çš„åˆ†å¸ƒï¼Œæ‰€ä»¥é€»è¾‘å›å½’æ˜¯ä¸€ç§åˆ†ç±»ç®—æ³•ã€‚</p>
</blockquote>
<h3 id="Linear-Discriminant-Analysis-LDA"><a href="#Linear-Discriminant-Analysis-LDA" class="headerlink" title="Linear Discriminant Analysis (LDA)"></a>Linear Discriminant Analysis (LDA)</h3><blockquote>
<p>çº¿æ€§åˆ¤åˆ«åˆ†æï¼Œæ˜¯ä¸€ç§ç›‘ç£å­¦ä¹ çš„é™ç»´æ–¹æ³•ï¼ˆæ— ç›‘ç£å­¦ä¹ ä¸€èˆ¬ç”¨<strong>PCA</strong>ï¼Œä¸»æˆåˆ†åˆ†ææ¥é™ç»´ï¼‰</p>
</blockquote>
<font color="green">Recall: Naive Bayes</font>

<ul>
<li>By <strong>Bayes Theorem</strong>: $P(Y|X=x)\propto f_k(\textbf{x})\pi_{k}$ , where $f_k(\textbf{x})=P(\textbf{X}=\textbf{x}|Y=k)$ is be the <font color="red">density function</font> of samples in each class $Y=k$, $\pi_k=P(Y=k)$ is the <font color="red">prior probability</font>.</li>
<li>Assume $f_k (\textbf{x})$ is multivariate Gaussian (å¤šå…ƒé«˜æ–¯åˆ†å¸ƒ) : $f_k(x)=\large{\frac{1}{(2\pi)^{p/2} |\Sigma_k}^{1/2}|e^{\frac{1}{2}(x-\mu_k)^T\Sigma_k^{-1}(x-\mu_k)}}$ , with a common covariance matrix (åæ–¹å·®çŸ©é˜µ) $\Sigma_k$ <font color="grey">(æ³¨ï¼šå¤šå…ƒé«˜æ–¯å¯ä»¥è¡¨ç¤ºä¸ºå‘é‡å’ŒçŸ©é˜µä¹˜ç§¯çš„å½¢å¼ï¼Œå¦‚ä¸Š)</font></li>
<li>For the decision boundary between class $k$ and $l$, the <strong>log-ratio</strong> of their posteriors (åéªŒ) $P(Y|X)$ is</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\log{\frac{P(Y=k|\textbf{X}=\textbf{x})}{P(Y=l|\textbf{X}=\textbf{x})}}=\log{\frac{\pi_k}{\pi_l}}-\frac{1}{2}(\mu_k+\mu_l)^T\Sigma_k^{-1}(\mu_k-\mu_l)+\textbf{x}^T \Sigma^{-1}(\mu_k-\mu_l)<br>$</p>

</blockquote>
<ol>
<li><p>From log-ratio, we can get <font color="red">Linear discriminant functions</font>(e.g. for class $k$) : $\delta_k(\textbf{x})=\textbf{x}^T\Sigma^{-1}\mu_k-\frac{1}{2}\mu_k^T\Sigma^{-1}\mu_k+\log\pi_k$ </p>
</li>
<li><p>Then the log-ratio become : $\log{\frac{P(Y=k|\textbf{X}=\textbf{x})}{P(Y=l|\textbf{X}=\textbf{x})}}=\delta_k(\textbf{x})-\delta_l(\textbf{x})$ </p>
<blockquote>
<p>ç›¸å‡ç»“æœæ˜¯ä¸€ä¸ªä¸€æ¬¡æ–¹ç¨‹ï¼ˆçº¿æ€§ï¼‰</p>
</blockquote>
</li>
<li><p>Decision Rule(åˆ†ç±»ä¾æ®) : $k^{\ast}=\arg\max_k \delta_k(\textbf{x})$</p>
</li>
</ol>
<p><strong>Two-class LDA</strong></p>
<ul>
<li>LDA rule classifies to <strong>class 2</strong> if</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>(\textbf{x}-\frac{\hat\mu_1+\hat\mu_2}{2})^T \Sigma^{-1}(\hat\mu_2-\hat\mu_1)+\log{\frac{\hat\pi_2}{\hat\pi_1}}\gt 0<br>$</p>

</blockquote>
<ul>
<li>Discriminant direction : $\beta=\Sigma^{-1}(\hat\mu_2-\hat\mu_1)$ </li>
</ul>
<center><img src="/2024/06/24/Big-Data-2/bd28.png" style="zoom:50%"><font size="2">Pic 20. Two-class LDA</font></center>

<blockquote>
<p>$\hat\mu$ çœ‹ä½œå›¾ä¸­æ¤­åœ†çš„ä¸­å¿ƒï¼Œå›¾ä¸­çš„ $w$ ä¸ºæŠ•å½±æ–¹å‘ã€‚ç”±ä¸Šè¿°å…¬å¼è®¡ç®—å¯å¾—åˆ°æ ·æœ¬åœ¨æŠ•å½±åŸºå‘é‡ä¸Šçš„æ–¹å‘ï¼Œä»è€Œåˆ¤æ–­å…¶ç±»åˆ«</p>
<p>ä»å®šæ€§ä¸Šçœ‹ï¼ŒæŠ•å½±çš„ä½œç”¨æ˜¯é™ç»´ï¼Œé€‰æ‹©çš„æŠ•å½±ç©ºé—´åº”å½“æ˜¯èƒ½å°†ä¸åŒç±»æ•°æ®ç‚¹åœ¨æ˜ å°„åå°½å¯èƒ½åˆ†å¼€ï¼ˆæˆ–åŒç±»çš„ç‚¹å°½å¯èƒ½ç´§å‡‘ï¼‰ã€‚</p>
</blockquote>
<h3 id="Neural-Network"><a href="#Neural-Network" class="headerlink" title="Neural Network"></a>Neural Network</h3><center><img src="/2024/06/24/Big-Data-2/bd29.png" style="zoom:70%"><font size="2">Pic 21. NN</font></center>

<script type="math/tex; mode=display">
\hat y=g(w_0+\sum_{i=1}^{m} x_iw_i)</script><ul>
<li>$\hat y$ is Output</li>
<li>$g$ is a <font color="red">Non-linear activation function</font> (éçº¿æ€§æ¿€æ´»å‡½æ•°)</li>
<li>$w_0$ is the Bias</li>
</ul>
<center><img src="/2024/06/24/Big-Data-2/bd30.png" style="zoom:70%"><font size="2">Pic 22. Common Activation Functions</font></center>

<ul>
<li><strong>Single Hidden Layer Neural Network</strong><ul>
<li><font color="red">$z_i=w_{0,i}^{(1)}+\sum_{j=1}^{m}x_jw_{j,i}^{(1)}$</font> </li>
<li><font color="red">$\hat y_i=w_{0,i}^{(2)}+\sum_{j=1}^{d_1}g(z_j)w_{j,i}^{(2)}$</font></li>
<li>$x_i\to z_k\to y_j$ , where $z_k$ is the hidden layer</li>
<li>Hidden Layer can be <font color="red">multiple</font> </li>
</ul>
</li>
</ul>
<center><img src="/2024/06/24/Big-Data-2/bd31.png" style="zoom:50%"></center>



<ul>
<li><strong>Thm: Universal Approximation Theorem</strong> â€”â€” Any function can be approximated by a <font color="blue">three-layer</font> neural network within sufficiently high accuracy.<ul>
<li>Why not effective ?</li>
<li>The <strong>width</strong> of each layer may be too much (Large calculation !!)</li>
<li><font color="green">Now weâ€™re trying to replace <b>width</b> with <b>depth</b> and find the same Theorem</font> <font color="grey">(å³å¢åŠ å±‚æ•°ï¼Œå‡å°‘æ¯å±‚çš„ç¥ç»å…ƒ)</font>



</li>
</ul>
</li>
</ul>
<h4>Loss Optimization</h4>

<blockquote>
<p>Find $\textbf{W}=\{w^{(0)},w^{(1)},â€¦,w^{(n)}\}$ with lowest loss function</p>
</blockquote>
<blockquote class="blockquote-center">
<p>$<br>\textbf{W}^{\ast}=\underset{\textbf{W}} {\arg\min} \frac{1}{n}\sum_{i=1}^{n}L(f(x^{(i)};\textbf{W}),y^{(i)})=\underset{\textbf{W}} {\arg\min}\ C(\textbf{W})<br>$</p>

</blockquote>
<ul>
<li>But for most cases, we should calculate <font color="red">gradient</font> to find $\textbf{W}^{\ast}$ </li>
<li><font color="red">Use <b>gradient decent</b> to solve:</font> $\frac{\partial{C}}{\partial{\textbf{W}}}$</li>
</ul>
<blockquote>
<p>How to calculate ? (More detail)</p>
</blockquote>
<center><img src="/2024/06/24/Big-Data-2/bd33.png" style="zoom:60%"></center>

<ul>
<li>$w_{jk}^{l}$ is the weight for the connection from the $k^{th}$ neuron in the $(l âˆ’ 1)^{th}$ layer to the $j^{th}$ neuron in the $l^{th}$ layer.</li>
<li>More briefly, <font color="red">$b_{j}^{l}=w_{j0}^l$</font> is the <font color="red">bias</font> of the $j^{th}$ neuron in the $l^{th}$ layer.</li>
<li><p>$a^l_j$ for the <font color="red">activation</font> of the $j^{th}$ neuron in the $l^{th}$ layer $z_j^l$  : <font color="red">$a^l_j=g(z^l_j)=g(\sum_k w_{jk}^{l}a_k^{l-1} + b_j^l)$</font> </p>
</li>
<li><p>We have define $C(\textbf{W})=\frac{1}{n}\sum_{i=1}^{n}L(f(x^{(i)};\textbf{W}),y^{(i)})$ </p>
</li>
</ul>
<center><img src="/2024/06/24/Big-Data-2/bd32.png" style="zoom:40%"></center>

<blockquote>
<p>Proof (æš‚ç•¥)</p>
</blockquote>
<h4>Gradient Descent</h4>

<p><strong>Algorithm</strong> :</p>
<ol>
<li>Initialize weights randomly  $\thicksim\mathcal N(0, \sigma^{2})$ </li>
<li>Loop until convergence : <ol>
<li>Pick single data point $i$</li>
<li>Compute <strong>gradient</strong>  $\frac{\partial J_i(\textbf{W})}{\partial \textbf{W}}$ </li>
<li>Update weights, $\textbf{W} \leftarrow (\textbf{W}-\eta \frac{\partial J(\textbf{W})}{\partial \textbf{W}})$ </li>
</ol>
</li>
<li>Return weights</li>
</ol>
<ul>
<li>Mini-batches lead to fast training ! (need not to calculate all gradient for trainset $x$)</li>
<li>Can parallelize computation + achieve significant speed increases on GPUs.</li>
</ul>
<h3 id="Support-Vector-Machine-SVM"><a href="#Support-Vector-Machine-SVM" class="headerlink" title="Support Vector Machine (SVM)"></a>Support Vector Machine (SVM)</h3><p><strong>About SVM</strong></p>
<ul>
<li>Use <strong>hyperplane</strong> [è¶…å¹³é¢] to separate data : maximize <strong>margin</strong></li>
<li>Can deal with <font color="red">low-dimensional data</font> that are not linearly separated by using kernel functions</li>
<li>Decision boundary only depends on some samples (support vectors)</li>
</ul>
<p><strong>How to train</strong></p>
<ul>
<li>Training data: $\{(\textbf{x}_1,y_1),(\textbf{x}_2,y_2),â€¦,(\textbf{x}_n, y_n) \}, y_i\in \{-1, 1\}$</li>
<li>Hyperplane: $S=\textbf{w}^T\textbf{x} + b$ ;     Decision function: $f(\textbf{x})=\text{sign}(\textbf{w}^T\textbf{x} + b)$</li>
<li>Geometric <strong>margin</strong> between a point and hyperplane : $\large{r_i=\frac{y_i(\textbf{w}^T\textbf{x} + b)}{|\textbf{w}|_2}}$</li>
<li>Margin between dataset and hyperplane : $\underset{i}\min r_i$</li>
<li>Maximize margin : $\underset{\textbf{w}, b}\max \underset{i}\min r_i$</li>
</ul>
<p><strong>Optimization</strong></p>
<ul>
<li>Without loss of generality, let $\underset{i}\min y_i(\textbf{w}^T\textbf{x} + b)=1$</li>
<li>Maximize margin is equivalent to $\underset{\textbf{w}, b}\max \frac{1}{|\textbf{w}|_2}$  ,  $s.t.\ y_i(\textbf{w}^T\textbf{x} + b)\ge 1,\ i=1,â€¦,n$</li>
<li>Further reduce to $\underset{\textbf{w}, b} \min \frac{1}{2}|\textbf{w}|_2^2$  ,  $s.t.\ y_i(\textbf{w}^T\textbf{x} + b)\ge 1,\ i=1,â€¦,n$</li>
<li>This is <strong>primal problem</strong> : quadratical programming with linear constraints, computational complexity is $O(p^3)$ where $p$ is dimension</li>
</ul>
<blockquote>
<p>But we use <strong>Dual problem optimization</strong>(å¯¹å¶é—®é¢˜ä¼˜åŒ–) most.</p>
</blockquote>
<ul>
<li>When slater condition is satisfied, $\min \max â‡” \max \min$</li>
<li>Dual problem : $\underset{\alpha}\max \underset{\textbf{w}, b}\min L(\textbf{w},b,\alpha)$ â€”â€” $L$ is Lagrange function(æ‹‰æ ¼æœ—æ—¥å‡½æ•°)</li>
<li><p>Solve for inner minimization problem : </p>
<ul>
<li>$\nabla_{\textbf{w}}L=0 \Longrightarrow \textbf{w}^\ast=\sum_i \alpha_iy_i \textbf{x}_i$</li>
<li>$\frac{\partial L}{\partial b}=0 \Longrightarrow \sum_i\alpha_iy_i=0$</li>
</ul>
</li>
<li><p>Plug into $L$: $L(\textbf{w}^\ast,b^\ast,\alpha)=\sum_i\alpha_i-\frac{1}{2}\sum_i\sum_j\alpha_i\alpha_jy_iy_j(\textbf{x}_i^T \textbf{x}_j)$ </p>
</li>
<li><font color="red">Dual Optimization: </font>

</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\begin{align}<br>&amp;\min_\alpha\frac{1}{2}\sum_i\sum_j\alpha_i\alpha_jy_iy_j(\textbf{x}_i^T \textbf{x}_j)-\sum_i\alpha_i, \\<br>&amp;\text{s.t. }\alpha_i\ge0,\ i=1,â€¦,n,\ \sum_i\alpha_iy_i=0<br>\end{align}<br>$</p>

</blockquote>
<p><strong>KKT Condition</strong></p>
<ul>
<li>Three more conditions from the equivalence of primal and minimax problems</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\left\{ \begin{array}{l}<br>\alpha_i^{\ast}\ge 0\\<br>y_i((\textbf{w}^{\ast})^T \textbf{x}_i+b^{\ast})-1 \ge 0\\<br>\alpha_i^{\ast}[y_i((\textbf{w}^{\ast})^T \textbf{x}_i+b^{\ast})-1]=0<br>\end{array}\right.<br>$</p>

</blockquote>
<ul>
<li>These together with two zero derivative conditions form KKT conditions</li>
<li>$\alpha_i^{\ast}\gt 0 \Rightarrow y_i((\textbf{w}^{\ast})^T \textbf{x}_i+b^{\ast})=1$</li>
<li>Index set of <font color="red">support vectors</font> : $S=\{i|\ \alpha_i \gt 0\}$</li>
<li>$b=y_s-\textbf{w}^T\textbf{x}_s=y_s-\sum_{i\in S}\alpha_i y_i \textbf{x}^T_i\textbf{x}_s$</li>
<li>More stable solution : </li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\color{red} b=\frac{1}{|S|}\sum_{s\in S}\left(y_s-\sum_{i\in S}\alpha_i y_i \textbf{x}^T_i\textbf{x}_s\right)<br>$</p>

</blockquote>
<p><strong>Soft Margin</strong></p>
<ul>
<li>When data are not linear separable, introduce slack variables (tolerance control of fault) $\xi_i \gt 0$</li>
<li>Relax constraint to $y_i(\textbf{w}^T\textbf{x} + b) \ge 1-\xi_i$ </li>
<li>Primal problem :</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\begin{align}<br>&amp;\underset{\textbf{w}, b} \min \frac{1}{2}|\textbf{w}|_2^2+C\sum_{i=1}^{n}\xi_i\\<br>&amp;\text{s.t. }y_i(\textbf{w}^T\textbf{x} + b)\ge 1-\xi_i,\ \xi_i \ge 0,\ i=1,â€¦,n<br>\end{align}<br>$</p>

</blockquote>
<ul>
<li>Similar derivation to dual problem : (Difference: add the error coe $C$ as a bound)</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\begin{align}<br>&amp;\min_{\alpha}\frac{1}{2}\sum_i \sum_j \alpha_i \alpha_j y_i y_j (\textbf{x}_i^T \textbf{x}_j)-\sum_i \alpha_i \\<br>&amp;\text{s.t. }0\le \alpha_i \le C,\ i=1,â€¦,n,\ \sum_i\alpha_iy_i=0<br>\end{align}<br>$</p>

</blockquote>
<h4 id="Nonlinear-SVM"><a href="#Nonlinear-SVM" class="headerlink" title="Nonlinear SVM"></a>Nonlinear SVM</h4><ul>
<li>Nonlinear decision boundary could be mapped to linear boundary in <font color="red">high-dimensional space</font></li>
</ul>
<center><img src="/2024/06/24/Big-Data-2/bd34.png" style="zoom:60%"></center>

<ul>
<li>Modify objective function in dual problem : $\color{red}\frac{1}{2}\sum_i \sum_j \alpha_i \alpha_j y_i y_j (\phi(\textbf{x}_i)^T \phi(\textbf{x}_j))-\sum_i \alpha_i$</li>
<li>Kernel function as inner product : $K(\textbf{x}_i, \textbf{x}_j)=\phi(\textbf{x}_i)^T \phi(\textbf{x}_j)$</li>
<li><font color="grey">Q: How to choose <b>Kernel Functions</b> ?</font>      <font color="green">A: Arbitrary</font>

</li>
</ul>
<center><img src="/2024/06/24/Big-Data-2/bd35.png" style="zoom:50%"></center>

<hr>
]]></content>
      <categories>
        <category>2024 Spring</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>CSE Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>Linear Algebra</title>
    <url>/2024/08/25/Linear-Algebra/</url>
    <content><![CDATA[<h1 id="About"><a href="#About" class="headerlink" title="About"></a>About</h1><p>ç”±äºç¯‡ä»…ç”¨äºæŸäº›è®¡ç®—æœºç›¸å…³è¯¾ç¨‹çš„å¤ä¹ ï¼Œæ‰€ä»¥æŸäº›â€œä¸å¤ªé‡è¦â€çš„çŸ¥è¯†ç‚¹è¦ä¹ˆé»˜è®¤å·²çŸ¥ï¼Œè¦ä¹ˆä¸ä¼šæåŠï¼ˆå¦‚è½¬ç½®çš„æ¦‚å¿µå’ŒäºŒçº§ç»“è®ºï¼Œè¡Œåˆ—å¼çš„æ¦‚å¿µç­‰ï¼‰ã€‚</p>
<p>ç”±äºæ•™æä¸åŒæˆ–ç‰ˆæœ¬åŸå› ï¼Œå¯¹äºä¸€äº›ç¬¦å·å¯èƒ½æœ‰å·®å¼‚ï¼ˆå¦‚è¡¨ç¤ºå•ä½æ–¹é˜µæœ‰ $I/E$ï¼Œä»¥ä¸‹ç»Ÿä¸€ä½¿ç”¨æœ¬äººå­¦ä¹ çš„æ•™ææ‰€ç”¨ç¬¦å·ï¼‰</p>
<h1 id="ç¬¬ä¸€ç« -çŸ©é˜µï¼ˆå…¥é—¨ï¼‰"><a href="#ç¬¬ä¸€ç« -çŸ©é˜µï¼ˆå…¥é—¨ï¼‰" class="headerlink" title="ç¬¬ä¸€ç«  çŸ©é˜µï¼ˆå…¥é—¨ï¼‰"></a>ç¬¬ä¸€ç«  çŸ©é˜µï¼ˆå…¥é—¨ï¼‰</h1><h2 id="çŸ©é˜µçš„é€†"><a href="#çŸ©é˜µçš„é€†" class="headerlink" title="çŸ©é˜µçš„é€†"></a>çŸ©é˜µçš„é€†</h2><p>å®šä¹‰ï¼š$AC=CA=I\Longleftrightarrow$ $C$ æ˜¯ $A$ çš„é€†ï¼Œè®°ä½œ $A^{-1}$ã€‚</p>
<blockquote>
<p>ä¸æ˜¯æ‰€æœ‰æ–¹é˜µéƒ½æœ‰é€†ï¼Œä¸å¯é€†<font color="red">æ–¹é˜µ</font>ç§°ä¸º<font color="red">å¥‡å¼‚çŸ©é˜µ</font>ã€‚</p>
</blockquote>
<h2 id="çŸ©é˜µçš„-LDU-åˆ†è§£"><a href="#çŸ©é˜µçš„-LDU-åˆ†è§£" class="headerlink" title="çŸ©é˜µçš„ LDU åˆ†è§£"></a>çŸ©é˜µçš„ LDU åˆ†è§£</h2><p>å®šä¹‰ï¼š$\color{red}PA=LDU$ï¼Œå…¶ä¸­ $L$ æ˜¯ä¸‹ä¸‰è§’çŸ©é˜µï¼Œ$D$ æ˜¯å¯¹è§’çŸ©é˜µï¼Œ$U$ æ˜¯ä¸»å¯¹è§’å…ƒä¸º 1 çš„ä¸Šä¸‰è§’çŸ©é˜µã€‚($P$ ä»…ç”¨ä½œè¡Œäº¤æ¢)</p>
<h1 id="ç¬¬äºŒç« -å‘é‡ç©ºé—´"><a href="#ç¬¬äºŒç« -å‘é‡ç©ºé—´" class="headerlink" title="ç¬¬äºŒç«  å‘é‡ç©ºé—´"></a>ç¬¬äºŒç«  å‘é‡ç©ºé—´</h1><h2 id="åŸºçš„ç›¸å…³å®šç†"><a href="#åŸºçš„ç›¸å…³å®šç†" class="headerlink" title="åŸºçš„ç›¸å…³å®šç†"></a>åŸºçš„ç›¸å…³å®šç†</h2><p><strong>ä¸€ã€åæ ‡ï¼š</strong> ä»¤ $A=\{v_1,v_2,\cdots,v_n\}$ æ˜¯ $\mathbb{V}^n$ çš„ä¸€ç»„åŸºï¼Œ$\forall w\in\mathbb{V}^n$ ï¼Œæœ‰å”¯ä¸€æ•°ç»„ $\{a_1,a_2,\cdots,a_n\}$ ä½¿ $w=a_1v_1+a_2v_2+\cdots +a_nv_n$ ï¼Œåˆ™è¯¥æ•°ç»„æ˜¯ $\mathbb{A}$ï¼ˆå‘é‡ç©ºé—´çš„ä¸€ç»„åŸºï¼‰ä¸­ $w$ çš„åæ ‡ï¼Œè®°ä¸º $[w]_A$ ã€‚</p>
<p><strong>äºŒã€æ»¡ç§©ï¼š</strong> å¯¹äºä¸€ä¸ª $m*n$ çŸ©é˜µ $A$ï¼Œè‹¥ $rank(A)=m$ï¼Œåˆ™ç§° $A$ è¡Œæ»¡ç§©ï¼Œè‹¥ $rank(A)=n$ï¼Œåˆ™ç§° $A$ åˆ—æ»¡ç§©ã€‚</p>
<ul>
<li>è‹¥ $A_{m\times n}$ è¡Œæ»¡ç§©ï¼ˆå¯æ¨å‡º $m\le n$ï¼‰ï¼Œä¸”å‰ $m$ åˆ—çº¿æ€§ç‹¬ç«‹ï¼Œä»¤ $A=\left[A_0|X\right]$ ï¼Œåˆ™å³é€† $C=\left[\begin{array}{c}A_0^{-1} \\ 0\end{array}\right]$ ï¼›</li>
<li>è‹¥ $A_{m\times n}$ åˆ—æ»¡ç§©ï¼ˆå¯æ¨å‡º $m\ge n$ï¼‰ï¼Œä¸”å‰ $n$ è¡Œçº¿æ€§ç‹¬ç«‹ï¼Œä»¤ $A=\left[\begin{array}{c}A_0 \\ Y\end{array}\right]$ ï¼Œåˆ™å·¦é€† $B=\left[A_0^{-1}|\ 0\right]$ ã€‚</li>
</ul>
<p><strong>ä¸‰ã€çº¿æ€§å˜æ¢ï¼š</strong></p>
<ul>
<li>æ±‚è§£å˜æ¢çŸ©é˜µçš„æ–¹æ³•ï¼š<ul>
<li>1ï¼‰è‡ªç„¶åŸºå˜æ¢æ±‚è§£</li>
<li>2ï¼‰éè‡ªç„¶åŸºå˜æ¢æ±‚è§£ï¼šåˆ©ç”¨çŸ©é˜µé€†è¿ç®—</li>
</ul>
</li>
</ul>
<h1 id="ç¬¬ä¸‰ç« -æ­£äº¤æ€§"><a href="#ç¬¬ä¸‰ç« -æ­£äº¤æ€§" class="headerlink" title="ç¬¬ä¸‰ç«  æ­£äº¤æ€§"></a>ç¬¬ä¸‰ç«  æ­£äº¤æ€§</h1><p><strong>æ­£äº¤è¡¥</strong></p>
<p>å¯¹äºå­ç©ºé—´ $V \subseteq \mathbb{R}^n$ï¼Œæ‰€æœ‰ä¸ $V$ æ­£äº¤çš„å‘é‡é›†åˆç»„æˆçš„ç©ºé—´ç§°ä¸ºæ­£äº¤è¡¥ï¼Œå†™ä½œ $W=V^{\bot}$ã€‚</p>
<p><strong>æŠ•å½±</strong></p>
<p>å‘é‡ $b$ åœ¨å‘é‡ $a$ ä¸Šçš„æŠ•å½±è¡¨ç¤ºä¸ºï¼š$proj_a:b\mapsto p=\hat xa$</p>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{l}<br>&amp;0=a^T(b-\hat{x}a)\Rightarrow \hat{x}=\frac{a^Tb}{a^T a} \\<br>\therefore &amp;proj_a(b)=\frac{aa^T}{a^Ta}\cdot b<br>\end{array}<br>$</p>

</blockquote>
<p>æ‰€ä»¥ï¼ŒæŠ•å½±çŸ©é˜µä¸º $P=\frac{aa^T}{|a|^2}$</p>
<h2 id="æœ€å°äºŒä¹˜"><a href="#æœ€å°äºŒä¹˜" class="headerlink" title="æœ€å°äºŒä¹˜"></a>æœ€å°äºŒä¹˜</h2><p>è‹¥ç³»ç»Ÿ $Ax=b$ æ— è§£ï¼Œåˆ™å…¶æœ€å°äºŒä¹˜è§£ï¼ˆæ®‹å·®æœ€å°ï¼‰ä¸º $\hat{x}=(A^TA)^{-1}A^T b$ï¼Œå…¶æŠ•å½± $p=A\hat{x}=A(A^TA)^{-1}A^T b$ã€‚</p>
<h2 id="æ­£äº¤åŸºï¼ˆé‡ç‚¹ï¼‰"><a href="#æ­£äº¤åŸºï¼ˆé‡ç‚¹ï¼‰" class="headerlink" title="æ­£äº¤åŸºï¼ˆé‡ç‚¹ï¼‰"></a>æ­£äº¤åŸºï¼ˆé‡ç‚¹ï¼‰</h2><p>æ­£äº¤çŸ©é˜µ $Q$ æ»¡è¶³ $Q^TQ=I$ï¼Œå³ $Q$ çš„æ¯ä¸€åˆ—ï¼ˆå‘é‡ï¼‰ç»„æˆäº† $\mathbb{R}^n$ çš„æ ‡å‡†æ­£äº¤åŸºã€‚</p>
<h2 id="Gram-Schmidt-æ­£äº¤åŒ–"><a href="#Gram-Schmidt-æ­£äº¤åŒ–" class="headerlink" title="Gram-Schmidt æ­£äº¤åŒ–"></a>Gram-Schmidt æ­£äº¤åŒ–</h2><ul>
<li>åŸºæœ¬æ€æƒ³ï¼šä»æ¯ä¸€ä¸ªæ–°å‘é‡ä¸­æ‰£é™¤å…¶åœ¨å·²çŸ¥æ–¹å‘ä¸Šçš„æŠ•å½±åˆ†é‡</li>
<li>æ­¥éª¤ï¼š<ol>
<li>æ±‚æŠ•å½±ï¼ˆæ­£äº¤åŒ–ï¼‰</li>
<li>æ±‚æ ‡å‡†åŸºï¼ˆå•ä½åŒ–ï¼‰</li>
</ol>
</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{l}<br>&amp;A_j=a_j-(q_1^T a_j)q_1-(q_2^T a_j)q_2â€”\cdots -(q_{j-1}^T a_j)q_{j-1} \\<br>&amp;q_j=\frac{A_j}{|A_j|}<br>\end{array}<br>$</p>

</blockquote>
<h2 id="QR-åˆ†è§£ï¼ˆé‡ç‚¹ï¼‰"><a href="#QR-åˆ†è§£ï¼ˆé‡ç‚¹ï¼‰" class="headerlink" title="QR åˆ†è§£ï¼ˆé‡ç‚¹ï¼‰"></a>QR åˆ†è§£ï¼ˆé‡ç‚¹ï¼‰</h2><p>$A=QR$</p>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{l}<br>A= \left[\begin{array}{c} a&amp;b&amp;c \end{array}\right]=\left[\begin{array}{c} q_1 &amp; q_2 &amp; q_3 \end{array}\right]\left[\begin{array}{c} q_1^Ta &amp; q_1^Tb &amp; q_1^Tc \\ &amp; q_2^Tb &amp; q_2^Tc \\ &amp;&amp; q_3^Tc \end{array}\right]=QR<br>\end{array}<br>$</p>

</blockquote>
<blockquote>
<p>$Q$ å¯é€šè¿‡ Gram-Schmidt è¿‡ç¨‹æ±‚å¾—ï¼Œ$R$ é€šè¿‡ $R=Q^TA$ æ±‚å¾—ã€‚</p>
</blockquote>
<h1 id="ç¬¬å››ç« -è¡Œåˆ—å¼"><a href="#ç¬¬å››ç« -è¡Œåˆ—å¼" class="headerlink" title="ç¬¬å››ç«  è¡Œåˆ—å¼"></a>ç¬¬å››ç«  è¡Œåˆ—å¼</h1><p>ç•¥ã€‚</p>
<h1 id="ç¬¬äº”ç« -ç‰¹å¾å€¼ä¸ç‰¹å¾å‘é‡"><a href="#ç¬¬äº”ç« -ç‰¹å¾å€¼ä¸ç‰¹å¾å‘é‡" class="headerlink" title="ç¬¬äº”ç«  ç‰¹å¾å€¼ä¸ç‰¹å¾å‘é‡"></a>ç¬¬äº”ç«  ç‰¹å¾å€¼ä¸ç‰¹å¾å‘é‡</h1><h2 id="ä»‹ç»"><a href="#ä»‹ç»" class="headerlink" title="ä»‹ç»"></a>ä»‹ç»</h2><p>å®šä¹‰ï¼šè®¾ $A$ ä¸º $n$ é˜¶çŸ©é˜µã€‚è‹¥å­˜åœ¨ä¸€ä¸ªéé›¶å‘é‡ $x$ å’Œæ ‡é‡ $\lambda$ æ»¡è¶³ $Ax=\lambda x$ ï¼Œåˆ™ç§° $\lambda$ ä¸º $A$ çš„ä¸€ä¸ªç‰¹å¾å€¼ï¼Œ$x$ ä¸º $\lambda$ å¯¹åº”çš„ç‰¹å¾å‘é‡ã€‚</p>
<p>å®šä¹‰ï¼šè®¾ $A=[a_{ij}]_{n\times n}$ ä¸º $n$ é˜¶æ–¹é˜µï¼š</p>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{l}<br>f(\lambda)=|A-\lambda I|=\left|\begin{array}{c} a_{11}-\lambda &amp; a_{12} &amp; \cdots &amp; a_{1n} \\ a_{21} &amp; a_{22}-\lambda &amp; \cdots &amp; a_{2n} \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ a_{n1} &amp; a_{n2} &amp; \cdots &amp; a_{nn}-\lambda \end{array}\right|<br>\end{array}<br>$</p>

</blockquote>
<p>ä¸º $A$ çš„ç‰¹å¾å¤šé¡¹å¼ã€‚</p>
<ul>
<li>æ±‚ç‰¹å¾å€¼å’Œç‰¹å¾å‘é‡çš„æ–¹æ³•ï¼š<ul>
<li>è®¡ç®— A çš„ç‰¹å¾å¤šé¡¹å¼</li>
<li>æ±‚å‡ºå…¨éƒ¨æ ¹ï¼ˆç‰¹å¾å€¼ï¼‰</li>
<li>å¸¦å…¥ç‰¹å¾æ–¹ç¨‹æ±‚å‡ºç‰¹å¾å‘é‡</li>
</ul>
</li>
<li>ç‰¹å¾å€¼çš„æ€§è´¨ï¼šä»¥çŸ©é˜µ $A$ çš„æ‰€æœ‰ç‰¹å¾å€¼ä¸ºä¾‹<ul>
<li>ç‰¹å¾å€¼ä¹‹ç§¯ï¼š$\prod_{i}\lambda_i=|A|$</li>
<li>ç‰¹å¾å€¼ä¹‹å’Œï¼š$\sum_{i}\lambda_i=trace(A)$ï¼Œç§°ä¸º $A$ çš„è¿¹</li>
</ul>
</li>
</ul>
<h2 id="çŸ©é˜µå¯¹è§’åŒ–"><a href="#çŸ©é˜µå¯¹è§’åŒ–" class="headerlink" title="çŸ©é˜µå¯¹è§’åŒ–"></a>çŸ©é˜µå¯¹è§’åŒ–</h2><p>å®šä¹‰ï¼š$\exists S,\ S^{-1}AS=\Lambda\Rightarrow$ çŸ©é˜µ $A$ å¯å¯¹è§’åŒ–ï¼ˆ$\Lambda$ æ˜¯å¯¹è§’çŸ©é˜µï¼Œå¯¹è§’å…ƒä¸º $A$ çš„ç‰¹å¾å€¼ï¼‰</p>
<p>æ¦‚å¿µï¼š</p>
<ul>
<li>ä»£æ•°é‡æ•°ï¼šç‰¹å¾å€¼ $\lambda_i$ çš„æœ€å¤§é‡å¤æ•°</li>
<li>å‡ ä½•é‡æ•°ï¼š$\lambda_i$ å¯¹åº”çš„ç‰¹å¾å­ç©ºé—´ï¼ˆå³ $A-\lambda_i I$ çš„é›¶ç©ºé—´ï¼‰çš„ç»´æ•°</li>
</ul>
<p>å®šç†ï¼š</p>
<ul>
<li>å½“ä¸”ä»…å½“å¯¹äº $A$ çš„æ¯ä¸ªç‰¹å¾å€¼ $\lambda_i$ï¼Œå‡ ä½•é‡æ•°ç­‰äºï¼ˆä¸€èˆ¬æ˜¯å°äºç­‰äºï¼‰ä»£æ•°é‡æ•°æ—¶ï¼ŒçŸ©é˜µ $A$ å¯å¯¹è§’åŒ–</li>
<li>å®šä¹‰ä¸­ $S$ çš„ç¬¬ $j$ åˆ—æ˜¯ $A$ çš„ç¬¬ $j$ ä¸ªç‰¹å¾å€¼æ‰€å¯¹åº”çš„ç‰¹å¾å‘é‡</li>
<li>è®¾ $A$ï¼Œ$B$ ä¸ºåŒé˜¶å¯å¯¹è§’åŒ–çŸ©é˜µï¼Œå½“ä¸”ä»…å½“ $AB=BA$ æ—¶ï¼Œå®ƒä»¬æœ‰ç›¸åŒçš„ç‰¹å¾å‘é‡ã€‚</li>
</ul>
<h2 id="å¤çŸ©é˜µ"><a href="#å¤çŸ©é˜µ" class="headerlink" title="å¤çŸ©é˜µ"></a>å¤çŸ©é˜µ</h2><p>æ¦‚å¿µï¼š</p>
<ul>
<li>å…±è½­ï¼š$z=a+ib \to \bar{z}=a-ib$</li>
<li>æåæ ‡ï¼š$\begin{array}{l} &amp;a+ib=r(\cos{\theta}+i\sin{\theta})=re^{i\theta} \\ &amp;a-ib=r(\cos{\theta}-i\sin{\theta})=re^{-i\theta} \end{array}$</li>
</ul>
<p>æåæ ‡ç®€åŒ–è¿ç®—ï¼š$(a+bi)\times (c+di)=re^{i\theta}\times Re^{i\alpha} \to$ æ¨¡é•¿ä¸º $rR$ï¼Œè§’åº¦ä¸º $\theta +\alpha$</p>
<p><strong>å„ç±³ç‰¹çŸ©é˜µ (Hermitian Matrix)</strong></p>
<p>å®šä¹‰1ï¼šå¯¹äºä¸€å¤æ•°çŸ©é˜µ $A$ï¼Œå…¶è½¬ç½®ä¸º $\bar{A}^T$ï¼Œç§°ä¸º $A$ çš„å„ç±³ç‰¹çŸ©é˜µï¼Œè®°ä¸º $A^H$ ã€‚</p>
<p>å®šä¹‰2ï¼šè‹¥çŸ©é˜µ $A$ æ»¡è¶³ $A^H=A$ï¼Œåˆ™ç§° $A$ æ˜¯å„ç±³ç‰¹çŸ©é˜µã€‚</p>
<h2 id="ä¸‰ç§å¯¹è§’åŒ–åˆ†è§£"><a href="#ä¸‰ç§å¯¹è§’åŒ–åˆ†è§£" class="headerlink" title="ä¸‰ç§å¯¹è§’åŒ–åˆ†è§£"></a>ä¸‰ç§å¯¹è§’åŒ–åˆ†è§£</h2><ul>
<li><font color="red">å¯å¯¹è§’åŒ–çŸ©é˜µ</font>å¯ä»¥ç”¨<font color="blue">å¯é€†çŸ©é˜µ</font>è¿›è¡Œå¯¹è§’åŒ–ï¼š$A=S\Lambda S^{-1}$</li>
<li><font color="red">å®å¯¹ç§°çŸ©é˜µ</font>å¯ä»¥ç”¨<font color="blue">æ­£äº¤çŸ©é˜µ</font>è¿›è¡Œå¯¹è§’åŒ–ï¼š$A=Q\Lambda Q^T$</li>
<li><font color="red">å„ç±³ç‰¹çŸ©é˜µ</font>å¯ä»¥ç”¨<font color="blue">é…‰çŸ©é˜µ</font>è¿›è¡Œå¯¹è§’åŒ–ï¼š$A=U\Lambda U^H$<ul>
<li>é…‰çŸ©é˜µæ˜¯æ»¡è¶³ $U^H=U^{-1}$ çš„çŸ©é˜µ</li>
</ul>
</li>
</ul>
<h2 id="ç›¸ä¼¼çŸ©é˜µ"><a href="#ç›¸ä¼¼çŸ©é˜µ" class="headerlink" title="ç›¸ä¼¼çŸ©é˜µ"></a>ç›¸ä¼¼çŸ©é˜µ</h2><p>å®šä¹‰ï¼šè‹¥çŸ©é˜µ $A$ï¼Œ$B$ æ»¡è¶³ $B=MAM^{-1}$ï¼ˆå…¶ä¸­ï¼Œ$M$ æ˜¯å¯é€†çŸ©é˜µï¼‰ï¼Œåˆ™ç§° $A$ ä¸ $B$ ç›¸ä¼¼ï¼Œè®°ä¸º $A\sim B$ã€‚</p>
<p>å®šç†ï¼š</p>
<ol>
<li>$A$ å’Œ $B$ æœ‰ç›¸åŒçš„ç‰¹å¾å€¼ã€‚</li>
<li>å½“ä¸”ä»…å½“ $M^{-1}v$ æ˜¯ $B$ çš„ä¸€ä¸ªç‰¹å¾å‘é‡æ—¶ï¼Œ$v$ æ˜¯ $A$ çš„ç‰¹å¾å‘é‡ã€‚</li>
<li>$A$ å’Œ $B$ æœ‰ç›¸åŒçš„è¡Œåˆ—å¼ã€ç§©å’Œè¿¹ã€‚</li>
</ol>
<p><strong>ç›¸ä¼¼å˜æ¢</strong></p>
<p>å®šç†ï¼šåŒä¸€ä¸ªçº¿æ€§å˜æ¢åœ¨ä¸¤ç»„åŸºä¸‹çš„è¡¨ç¤ºçŸ©é˜µ $A$ å’Œ $B$ æ˜¯ç›¸ä¼¼çš„</p>
<p>è¯æ˜ï¼šä»¤ $V=\mathbb{R}^2$ ï¼Œ$T$ ä¸º $V$ çš„ä¸€ä¸ªçº¿æ€§å˜æ¢ï¼›åˆè®¾å¦ä¸€ç»„åŸº $\{w_1,w_2\}$ï¼Œè¯æ˜å¦‚ä¸‹</p>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{l}<br>&amp;T(v_1)=a_{11}v_1+a_{12}v_2\ \ \ \ T(v_2)=a_{21}v_1+a_{22}v_2 \\<br>\therefore &amp;\left[\begin{array}{c}Tv_1&amp;Tv_2\end{array}\right]=\left[\begin{array}{c}v_1&amp;v_2\end{array}\right]\left[\begin{array}{c}a_{11}&amp;a_{21} \\ a_{12}&amp;a_{22}\end{array}\right]=\left[\begin{array}{c}v_1&amp;v_2\end{array}\right]A \\<br>\because &amp;\left\{\begin{array}{l}&amp;w_1=m_{11}v_1+m_{12}v_2 \\ &amp;w_2=m_{21}v_1+m_{22}v_2 \end{array}\right. \\<br>\therefore &amp;\left[\begin{array}{c}w_1&amp;w_2\end{array}\right]=\left[\begin{array}{c}v_1&amp;v_2\end{array}\right]M \\<br>&amp;\left[\begin{array}{c}Tw_1&amp;Tw_2\end{array}\right]=\left[\begin{array}{c}Tv_1&amp;Tv_2\end{array}\right]M \\<br>\text{also }\because &amp;\left[\begin{array}{c}Tw_1&amp;Tw_2\end{array}\right]=\left[\begin{array}{c}w_1&amp;w_2\end{array}\right]B \\<br>\therefore &amp;MB=AM \Rightarrow B=M^{-1}AM\text{(ç›¸ä¼¼)}<br>\end{array}<br>$</p>

</blockquote>
<h2 id="èˆ’å°”å®šç†"><a href="#èˆ’å°”å®šç†" class="headerlink" title="èˆ’å°”å®šç†"></a>èˆ’å°”å®šç†</h2><p>å¯¹ä¸€ä¸ª $n$ é˜¶æ–¹é˜µ $A$ï¼Œæ€»æœ‰ä¸€ä¸ªé…‰çŸ©é˜µ $U$ï¼Œä»¤ $U^{-1}AU=T$ï¼Œ$T$ ä¸ºä¸ $A$ ç›¸ä¼¼çš„ä¸‰è§’çŸ©é˜µï¼Œä¸”å¯¹è§’çº¿ä¸Šçš„å€¼æ˜¯ $A$ çš„ç‰¹å¾å€¼</p>
<p>æ¨è®ºï¼šå½“ $A$ ä¸ºå„ç±³ç‰¹çŸ©é˜µæ—¶ï¼Œ$T^H=(U^{-1}AU)^H=U^{-1}A^H U=T$ã€‚$T$ æ˜¯å¯¹è§’çŸ©é˜µï¼ˆè¯æ˜äº†è°±å®šå¾‹ï¼š$A=A^H \Rightarrow A$ æ˜¯å¯å¯¹è§’åŒ–çš„ï¼‰</p>
<h1 id="ç¬¬å…­ç« -æ­£å®šçŸ©é˜µ"><a href="#ç¬¬å…­ç« -æ­£å®šçŸ©é˜µ" class="headerlink" title="ç¬¬å…­ç«  æ­£å®šçŸ©é˜µ"></a>ç¬¬å…­ç«  æ­£å®šçŸ©é˜µ</h1><h2 id="äºŒæ¬¡å‹"><a href="#äºŒæ¬¡å‹" class="headerlink" title="äºŒæ¬¡å‹"></a>äºŒæ¬¡å‹</h2><blockquote class="blockquote-center">
<p>$<br>f(x,y)=ax^2+2bxy+cy^2<br>$</p>

</blockquote>
<ul>
<li>å½“ä¸”ä»…å½“ $ac\gt b^2$ ä¸” $a\gt 0(a\lt 0)$ æ—¶ï¼Œ$f(x,y)$ ä¸ºæ­£å®šï¼ˆè´Ÿå®šï¼‰ï¼Œå­˜åœ¨å”¯ä¸€æœ€å°ï¼ˆæœ€å¤§ï¼‰å€¼ã€å®šç‚¹ã€‘</li>
<li>è‹¥ $ac=b^2$ï¼Œåˆ™æ ¹æ® $a$ çš„å€¼ç§°ä¸ºåŠæ­£å®š/åŠè´Ÿå®šï¼Œå­˜åœ¨ä¸å”¯ä¸€æœ€å°ï¼ˆæœ€å¤§ï¼‰å€¼</li>
<li>å½“ $ac\lt b^2$ï¼Œç§°äºŒæ¬¡å‹ $f$ ä¸å®šï¼Œæ­¤æ—¶äºŒæ¬¡å‹æ‰€è¿‡å®šç‚¹éæœ€å¤§ä¹Ÿéæœ€å°ï¼Œç§°ä¸º<font color="red">éç‚¹</font></li>
</ul>
<p>äºŒæ¬¡å‹çš„å¦ä¸€ç§è¡¨ç¤ºï¼š($A$ æ˜¯å®å¯¹ç§°çŸ©é˜µ)</p>
<blockquote class="blockquote-center">
<p>$<br>ax^2+2bxy+cy^2=\left[\begin{array}{c}x&amp;y\end{array}\right]\left[\begin{array}{c}a&amp;b \\ b&amp;c\end{array}\right]\left[\begin{array}{c}x \\ y\end{array}\right]=x^TAx<br>$</p>

</blockquote>
<blockquote>
<p>æ­£å®šäºŒæ¬¡å‹æ‰€å¯¹åº”çŸ©é˜µ $A$ ä¸ºæ­£å®šçŸ©é˜µ </p>
</blockquote>
<h2 id="ä¸»è½´å®šç†ï¼ˆé‡ç‚¹ï¼‰"><a href="#ä¸»è½´å®šç†ï¼ˆé‡ç‚¹ï¼‰" class="headerlink" title="ä¸»è½´å®šç†ï¼ˆé‡ç‚¹ï¼‰"></a>ä¸»è½´å®šç†ï¼ˆé‡ç‚¹ï¼‰</h2><p>å®šä¹‰ï¼š</p>
<p>è®¾ $A_{n\times n}$ ä¸ºå®å¯¹ç§°çŸ©é˜µåˆ™æœ‰ä¸€ä¸ªå˜æ¢ $x=Qy$ï¼ˆ ä¸ºæ­£äº¤çŸ©é˜µï¼‰ï¼Œå°†äºŒæ¬¡å‹ $x^T Ax$ è½¬å˜ä¸º $y^T\Lambda y$ï¼ˆä¸å«äº¤å‰ä¹˜ç§¯é¡¹ï¼‰ï¼Œé€šè¿‡è¿™ç§å˜æ¢ï¼Œå¯ä»¥å¾—åˆ°ä¸€ä¸ªæ ‡å‡†äºŒæ¬¡å‹ $y^T\Lambda y=\lambda_1y_1^2+\lambda_2y_2^2+\cdots +\lambda_n y_n^2$ã€‚</p>
<p>ä¾‹ï¼šè®¾ $A=\left[\begin{array}{c}5&amp;-2 \\ -2&amp;5\end{array}\right]$ ï¼Œå³ $x^T Ax=5x_1^2-4x_1x_2+5x_2^2$ ã€‚å¯æ±‚å¾— $A$ çš„ç‰¹å¾å€¼æ˜¯ $3$ å’Œ $7$ï¼Œå¯¹åº”çš„ç‰¹å¾å‘é‡ä¸º $u_1=\left[\begin{array}{c}1/\sqrt{2} \\ 1/\sqrt{2}\end{array}\right]$ å’Œ $u_2=\left[\begin{array}{c}-1/\sqrt{2} \\ 1/\sqrt{2}\end{array}\right]$ã€‚</p>
<p>ä»¤ $Q=\left[\begin{array}{c}u_1&amp;u_2\end{array}\right]=\left[\begin{array}{c}1/\sqrt{2}&amp;-1/\sqrt{2} \\ 1/\sqrt{2}&amp;1/\sqrt{2}\end{array}\right]$ï¼Œç”± $x=Qy$ å¾—ï¼š$y^T\Lambda y=3y_1^2+7y_2^2$ã€‚</p>
<blockquote>
<p>ç”¨æ³•ï¼šå°†å®å¯¹ç§°çŸ©é˜µ $A$ æ­£äº¤å¯¹è§’åŒ–ï¼š$A=Q\Lambda Q^T$ã€‚å†é€šè¿‡ $y=Q^T x$ å¾—åˆ° $y$ã€‚</p>
</blockquote>
<h2 id="åˆåŒå˜æ¢æ³•"><a href="#åˆåŒå˜æ¢æ³•" class="headerlink" title="åˆåŒå˜æ¢æ³•"></a>åˆåŒå˜æ¢æ³•</h2><p>æ€è·¯ï¼šä»»æ„ n é˜¶å®å¯¹ç§°çŸ©é˜µ Aï¼Œéƒ½å­˜åœ¨å¯é€†çŸ©é˜µ Cï¼Œä½¿å¾— $C^TAC=diag(d_1,d_2,\cdots,d_n)$ã€‚é€šè¿‡å¯¹çŸ©é˜µ $A$ çš„åˆç­‰è¡Œ/åˆ—å˜æ¢ï¼Œå¯ä»¥å¾—åˆ°åˆåŒå˜æ¢çŸ©é˜µ $C$ å’Œå˜æ¢åçš„çŸ©é˜µ $D=C^TAC$</p>
<blockquote class="blockquote-center">
<p>$<br>\left[\begin{array}{c}C^T&amp;0 \\ 0&amp;I\end{array}\right]\left[\begin{array}{c}A \\ I\end{array}\right]C=\left[\begin{array}{c}C^TAC \\ C\end{array}\right]=\left[\begin{array}{c}D \\ C\end{array}\right]<br>$</p>

</blockquote>
<p>ç”±æ­¤å¯è§ï¼Œç”¨æ­£äº¤å˜æ¢æ³•å¾—åˆ°çš„æ ‡å‡†å‹å¹¶ä¸å”¯ä¸€ï¼ˆå‚è€ƒä¸»è½´å®šç†ï¼‰ã€‚æ ‡å‡†å‹ä¸å”¯ä¸€ï¼Œä½†æ˜¯æ ‡å‡†å‹çš„æ­£è´Ÿå·ä¸ªæ•°ä¸å˜ã€‚</p>
<h2 id="å¥‡å¼‚å€¼åˆ†è§£ï¼ˆé‡ç‚¹ï¼‰"><a href="#å¥‡å¼‚å€¼åˆ†è§£ï¼ˆé‡ç‚¹ï¼‰" class="headerlink" title="å¥‡å¼‚å€¼åˆ†è§£ï¼ˆé‡ç‚¹ï¼‰"></a>å¥‡å¼‚å€¼åˆ†è§£ï¼ˆé‡ç‚¹ï¼‰</h2><p>æ€è·¯ï¼šå½“çŸ©é˜µéæ–¹é˜µæ—¶ï¼Œä¸å¯è¿›è¡Œç‰¹å¾å€¼åˆ†è§£ï¼ˆæ­£äº¤å¯¹è§’åŒ–ï¼‰ã€‚æ­¤æ—¶å¯ä»¥è¿›è¡Œå¥‡å¼‚å€¼åˆ†è§£ã€‚</p>
<p>å®šä¹‰ï¼šå¯å¯¹ä»»æ„çŸ©é˜µè¿›è¡Œå¥‡å¼‚å€¼åˆ†è§£ï¼ˆSVDï¼‰ï¼š</p>
<blockquote class="blockquote-center">
<p>$<br>A=U\Sigma V^T<br>$</p>

</blockquote>
<p>å…¶ä¸­ï¼Œ$\Sigma$ ä¸º $m\times n$ å¯¹è§’é˜µï¼ˆéæ–¹é˜µï¼‰ï¼Œå…¶å¯¹è§’çº¿å¤„éé›¶å…ƒç´ è®°ä¸º $\sigma_1,\sigma_2.\cdots,\sigma_r$ ï¼Œè¿™äº›å…ƒç´ ç§°ä¸º $A$ çš„å¥‡å¼‚å€¼ï¼Œä¹Ÿæ˜¯ $AA^T$ çš„ç‰¹å¾å€¼çš„å¹³æ–¹æ ¹ã€‚</p>
<ul>
<li>æ­£äº¤çŸ©é˜µ $U$ï¼š$m$ è¡Œ $n$ åˆ—ï¼Œæ¯ä¸ªå‘é‡æ˜¯ $AA^T$ çš„ç‰¹å¾å‘é‡ï¼›</li>
<li>æ­£äº¤çŸ©é˜µ $V$ï¼š$n$ è¡Œ $n$ åˆ—ï¼Œæ¯ä¸ªå‘é‡æ˜¯ $A^TA$ çš„ç‰¹å¾å‘é‡ã€‚</li>
</ul>
]]></content>
      <categories>
        <category>2022 Fall</category>
      </categories>
      <tags>
        <tag>Maths</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¦‚ç‡è®ºä¸æ•°ç†ç»Ÿè®¡</title>
    <url>/2024/08/19/Probability-Theory-and-Mathematical-Statistics/</url>
    <content><![CDATA[<h1 id="ç¬¬ä¸€ç« -æ¦‚ç‡"><a href="#ç¬¬ä¸€ç« -æ¦‚ç‡" class="headerlink" title="ç¬¬ä¸€ç«  æ¦‚ç‡"></a>ç¬¬ä¸€ç«  æ¦‚ç‡</h1><h2 id="è®°æ•°æ–¹æ³•"><a href="#è®°æ•°æ–¹æ³•" class="headerlink" title="è®°æ•°æ–¹æ³•"></a>è®°æ•°æ–¹æ³•</h2><ul>
<li>å¤å…¸æ¦‚å‹<ul>
<li>$\Omega$ åªå«æœ‰é™ä¸ªæ ·æœ¬ç‚¹</li>
<li>æ¯ä¸ªæ ·æœ¬ç‚¹å‡ºç°æ˜¯ç­‰å¯èƒ½çš„</li>
</ul>
</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>P(A)=\frac{A \text{çš„æœ‰åˆ©åœºåˆæ•°}}{\text{æ ·æœ¬ç‚¹æ€»æ•°}}=\frac{k}{n}<br>$</p>

</blockquote>
<ul>
<li>å‡ ä½•æ¦‚å‹<ul>
<li>å¯¹æ¯”å¤å…¸æ¦‚å‹æœ‰æ— é™ä¸ªæ ·æœ¬ç‚¹</li>
</ul>
</li>
</ul>
<h2 id="å…¨æ¦‚ç‡å®šå¾‹"><a href="#å…¨æ¦‚ç‡å®šå¾‹" class="headerlink" title="å…¨æ¦‚ç‡å®šå¾‹"></a>å…¨æ¦‚ç‡å®šå¾‹</h2><p><strong>Def.</strong> è®¾ $\Omega$ ä¸ºæ ·æœ¬ç©ºé—´ï¼Œè‹¥äº‹ä»¶ $B_1,B_2,\cdots ,B_n$ æ»¡è¶³ï¼š</p>
<ol>
<li>$B_1,B_2,\cdots ,B_n$ ä¸¤ä¸¤ä¸ç›¸å®¹</li>
<li>$B_1 \cup B_2 \cup \cdots \cup B_n = \Omega$</li>
</ol>
<p>åˆ™ç§° $B_1,B_2,\cdots ,B_n$ ä¸ºæ ·æœ¬ç©ºé—´çš„ä¸€ä¸ª<font color="red">åˆ’åˆ†</font>ã€‚</p>
<p>ç”±æ­¤æ¨å‡ºå…¨æ¦‚ç‡å…¬å¼ï¼š</p>
<blockquote class="blockquote-center">
<p>$<br>P(A)=\sum_{i=1}^{n} P(A|B_i) \cdot P(B_i)<br>$</p>

</blockquote>
<p>ç”±å…¨æ¦‚ç‡å…¬å¼å’Œæ¡ä»¶æ¦‚ç‡çš„ä¹˜æ³•å…¬å¼æ¨å¯¼å‡º <font color="red">Bayes å…¬å¼</font>ï¼š</p>
<blockquote class="blockquote-center">
<p>$<br>P(B_i|A)=\frac{P(A|B_i)P(B_i)}{\sum_{j=1}^{n} P(A|B_j)P(B_j)}<br>$</p>

</blockquote>
<p>Bayes å…¬å¼çš„å®é™…æ„ä¹‰ï¼š</p>
<p>å‡å®š $B_1,B_2,\cdots ,B_n$ ä¸ºå¯¼è‡´å®éªŒç»“æœçš„â€œåŸå› â€ï¼Œç§° $P(B_i) (i=1,2,\cdots ,n)$ ä¸º<font color="red">å…ˆéªŒæ¦‚ç‡</font>ã€‚</p>
<p>è‹¥è¯•éªŒäº§ç”Ÿäº‹ä»¶ A ï¼Œåˆ™è¦æ¢è®¨äº‹ä»¶å‘ç”Ÿçš„â€œåŸå› â€ï¼šç§° $P(B_i|A)$ ä¸º<font color="red">åéªŒæ¦‚ç‡</font>ï¼Œç§° $P(A|B_i)$ ä¸º<font color="red">åŸå› æ¦‚ç‡</font></p>
<h1 id="ç¬¬äºŒç« -éšæœºå˜é‡"><a href="#ç¬¬äºŒç« -éšæœºå˜é‡" class="headerlink" title="ç¬¬äºŒç«  éšæœºå˜é‡"></a>ç¬¬äºŒç«  éšæœºå˜é‡</h1><h2 id="ç¦»æ•£éšæœºå˜é‡"><a href="#ç¦»æ•£éšæœºå˜é‡" class="headerlink" title="ç¦»æ•£éšæœºå˜é‡"></a>ç¦»æ•£éšæœºå˜é‡</h2><p>å®šä¹‰ï¼š</p>
<blockquote class="blockquote-center">
<p>$<br>P\{ X=x_k \}= p(x_k),\ \ (k=1,2,3,\cdots)<br>$</p>

</blockquote>
<p>ä¸ºç¦»æ•£å‹ r.v. X çš„æ¦‚ç‡è´¨é‡å‡½æ•° (PMF)</p>
<blockquote class="blockquote-center">
<p>$<br>F(x)=P\{ X \le x \}, -\infty \lt x \lt \infty<br>$</p>

</blockquote>
<p>ä¸ºç¦»æ•£å‹ r.v. X çš„ç´¯è®¡åˆ†å¸ƒå‡½æ•° (CDF)</p>
<p><strong>æ³Šæ¾å®šç†</strong></p>
<p>è®¾ $\lambda \gt 0$ï¼Œ$n$ ä¸ºæ­£æ•´æ•°ï¼Œ$\lim_{n \to \infty} np_n=\lambda$ï¼Œåˆ™æœ‰</p>
<blockquote class="blockquote-center">
<p>$<br>\lim_{n\to \infty} C^k_n p^k_n(1-p_n)^{n-k}=\frac{\lambda^{k}e^{-\lambda}}{k!}<br>$</p>

</blockquote>
<h2 id="è¿ç»­éšæœºå˜é‡"><a href="#è¿ç»­éšæœºå˜é‡" class="headerlink" title="è¿ç»­éšæœºå˜é‡"></a>è¿ç»­éšæœºå˜é‡</h2><p>å®šä¹‰ï¼š</p>
<blockquote class="blockquote-center">
<p>$<br>F(x)=\int_{-\infty}^{x} f(t)\text{d}t,\ -\infty \lt x \lt \infty<br>$</p>

</blockquote>
<p>å…¶ä¸­ $f(t)$ ä¸ºè¿ç»­å‹ r.v. X çš„æ¦‚ç‡å¯†åº¦å‡½æ•° (PDF)</p>
<p><strong>æ ‡å‡†æ­£æ€åˆ†å¸ƒ</strong></p>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{l}<br>&amp;\Phi(x)=\int_{-\infty}^{x} \psi(x)\text{d}x \\<br>&amp;\psi(x)=\frac{1}{\sqrt{2\pi}\sigma} e^{-\frac{(x-\mu)^2}{2\sigma^2}} \\<br>&amp;s.t.\ \mu=0,\ \sigma^2=1<br>\end{array}<br>$</p>

</blockquote>
<h2 id="éšæœºå˜é‡çš„å‡½æ•°"><a href="#éšæœºå˜é‡çš„å‡½æ•°" class="headerlink" title="éšæœºå˜é‡çš„å‡½æ•°"></a>éšæœºå˜é‡çš„å‡½æ•°</h2><p>ä¾‹ï¼šè®¾éšæœºå˜é‡ $X$ï¼Œ$Y$ï¼Œæ»¡è¶³ $Y=aX+b$ï¼Œå¦‚ä½•é€šè¿‡ $X$ çš„æ¦‚ç‡å¯†åº¦åˆ†å¸ƒæ±‚å‡º $Y$ çš„ PDFï¼Ÿ</p>
<p>è§£ï¼šä»¤ $x=g(y)=\frac{y-b}{a}$ï¼Œå¯å¾— $F_Y(y)=P\{ Y\le y \}=P\{ X\le\frac{y-b}{a} \}=F_X(\frac{y-b}{a})$ã€‚</p>
<p>åŒ–ç®€å¾—ï¼š$f_Y(y)=F_{X}â€™(g(y))=(g(y))â€™f_X(g(y))$</p>
<p>å¦‚æ­£æ€åˆ†å¸ƒ $X\sim N(\mu,\sigma^2)$ çš„çº¿æ€§å‡½æ•° $aX+b \sim N(a\mu +b,(a\sigma)^2)$ ä¹Ÿæ˜¯æ­£æ€åˆ†å¸ƒ</p>
<h1 id="ç¬¬ä¸‰ç« -è”åˆåˆ†å¸ƒ"><a href="#ç¬¬ä¸‰ç« -è”åˆåˆ†å¸ƒ" class="headerlink" title="ç¬¬ä¸‰ç«  è”åˆåˆ†å¸ƒ"></a>ç¬¬ä¸‰ç«  è”åˆåˆ†å¸ƒ</h1><h2 id="è”åˆéšæœºå˜é‡"><a href="#è”åˆéšæœºå˜é‡" class="headerlink" title="è”åˆéšæœºå˜é‡"></a>è”åˆéšæœºå˜é‡</h2><p>å®šä¹‰ï¼š</p>
<blockquote class="blockquote-center">
<p>$<br>F(X,Y)\triangleq P\{ X\le x,Y\le y \}\ \ s.t.\ \{x,y\}\in \mathbb{R}<br>$</p>

</blockquote>
<p>ä¸º $X$ ä¸ $Y$ çš„è”åˆç´¯ç§¯åˆ†å¸ƒå‡½æ•°ã€‚</p>
<blockquote class="blockquote-center">
<p>$<br>F_X(x)= P\{ X\le x,Y\le \infty \}\ \ s.t.\ x\in \mathbb{R}<br>$</p>

</blockquote>
<p>ç§°ä¸º $X$ çš„è¾¹é™…åˆ†å¸ƒï¼Œ$Y$ åŒç†ã€‚</p>
<p><strong>æ¦‚ç‡å¯†åº¦å‡½æ•°</strong></p>
<blockquote class="blockquote-center">
<p>$<br>F(x,y)=\int_{-\infty}^{x} \int_{-\infty}^{y} f(u,v)\text{d}u\text{d}v,\ s.t.\ \{ x,y\}\in\mathbb{R}<br>$</p>

</blockquote>
<p>åˆ™ $f(x,y)$ ä¸º $X$ï¼Œ$Y$ çš„æ¦‚ç‡å¯†åº¦å‡½æ•°(joint PDF)</p>
<p><strong>è¾¹é™…å¯†åº¦</strong></p>
<blockquote class="blockquote-center">
<p>$<br>f_X(u)=\int_{-\infty}^{\infty} f(u,y)\text{d}y<br>$</p>

</blockquote>
<p>ç§°ä¸º $X$ çš„è¾¹é™…å¯†åº¦ï¼Œ$Y$ åŒç†ã€‚</p>
<h2 id="ç‹¬ç«‹éšæœºå˜é‡"><a href="#ç‹¬ç«‹éšæœºå˜é‡" class="headerlink" title="ç‹¬ç«‹éšæœºå˜é‡"></a>ç‹¬ç«‹éšæœºå˜é‡</h2><blockquote class="blockquote-center">
<p>$<br>f(x,y)=f_X(x)\cdot f_Y(y)<br>$</p>

</blockquote>
<p>å½“ä¸Šå¼æˆç«‹æ—¶ï¼Œ$X$ï¼Œ$Y$ ç›¸äº’ç‹¬ç«‹ï¼Œå³ç›¸å…³ç³»æ•° $\rho=0$ã€‚</p>
<h2 id="æ¡ä»¶åˆ†å¸ƒ"><a href="#æ¡ä»¶åˆ†å¸ƒ" class="headerlink" title="æ¡ä»¶åˆ†å¸ƒ"></a>æ¡ä»¶åˆ†å¸ƒ</h2><p>ï¼ˆåªçœ‹è¿ç»­ï¼Œç¦»æ•£æƒ…å†µå®¹æ˜“æ¨å¯¼ï¼‰</p>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{l}<br>P(X\le x|y\le Y\le y+\epsilon) &amp;=\frac{P\{X\le x,y\le Y\le y+\epsilon\}}{P\{ y\le Y\le y+\epsilon\ \}} \\<br>&amp;=\frac{\int_{-\infty}^{x}\int_{y}^{y+\epsilon} f(u,v)\text{d}u\text{d}v}{\int_{y}^{y+\epsilon} f_Y(v)\text{d}v} \\<br>&amp;=\frac{\epsilon\int_{-\infty}^{x}f(u,y_\epsilon)\text{d}u}{\epsilon f_Y(\tilde{y}_{\epsilon})} \\<br>&amp;= \int_{-\infty}^{x}\frac{f(u,y)}{f_Y(y)} \text{d}u\ \ (\epsilon\to 0)<br>\end{array}<br>$</p>

</blockquote>
<p>å®šä¹‰ $\frac{f(u,y)}{f_Y(y)} \triangleq f_{X|Y}(x|y)$ ä¸º $Y=y$ ä¸‹ $X$ çš„<font color="red">æ¡ä»¶å¯†åº¦</font></p>
<h2 id="è”åˆåˆ†å¸ƒéšæœºå˜é‡çš„å‡½æ•°"><a href="#è”åˆåˆ†å¸ƒéšæœºå˜é‡çš„å‡½æ•°" class="headerlink" title="è”åˆåˆ†å¸ƒéšæœºå˜é‡çš„å‡½æ•°"></a>è”åˆåˆ†å¸ƒéšæœºå˜é‡çš„å‡½æ•°</h2><p>1 . $Z=X+Y$</p>
<p>åˆ©ç”¨å·ç§¯å…¬å¼ (å¯å†™ä½œ $f_X * f_Y$)ï¼š</p>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{l}<br>&amp;f_Z(z)=\int_{-\infty}^{\infty}f_X(z-y)f_Y(y)\text{d}y \\<br>\text{or } &amp;f_Z(z)=\int_{-\infty}^{\infty}f_X(x)f_Y(z-x)\text{d}x<br>\end{array}<br>$</p>

</blockquote>
<font color="red">å‰æï¼š</font> 

<p>$X$ï¼Œ$Y$ ç›¸äº’ç‹¬ç«‹ï¼ˆå¦‚ä¸ç‹¬ç«‹ï¼Œå¯åˆ©ç”¨è”åˆåˆ†å¸ƒã€æ¡ä»¶åˆ†å¸ƒæ±‚å¾—ï¼Œæˆ–å˜æ¢æˆç‹¬ç«‹å˜é‡å†æ±‚è§£ï¼‰ã€‚</p>
<p>2 . $Z=\frac{X}{Y}$</p>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{l}<br>&amp;\text{ç”±äº }F_Z(z)=P\{ X/Y\le z \}=\underset{\frac{x}{y}\le z}{\int\int} f(x,y)\text{d}x \text{d}y \text{ ç§¯åˆ†åŒºåŸŸå¯èƒ½ä¸æ˜¯çŸ©å½¢} \\<br>&amp;\text{ä¸ºç®€åŒ–ç§¯åˆ†è®¡ç®—ï¼Œä½¿ç”¨ }\textbf{J}=\frac{\partial{(x,y)}}{\partial{(u, v)}}= \Large{\left| \begin{array}{c} \frac{\partial{x}}{\partial{u}} &amp; \frac{\partial{x}}{\partial{v}} \\ \frac{\partial{y}}{\partial{u}} &amp; \frac{\partial{y}}{\partial{v}} \end{array} \right|} \\<br>&amp;\text{å¾— }F_Z(z)=\underset{\Omega}{\int\int} f[x(u,v),y(u,v)] |\textbf{J}|\text{d}u \text{d}v<br>\end{array}<br>$</p>

</blockquote>
<h2 id="é¡ºåºç»Ÿè®¡é‡"><a href="#é¡ºåºç»Ÿè®¡é‡" class="headerlink" title="é¡ºåºç»Ÿè®¡é‡"></a>é¡ºåºç»Ÿè®¡é‡</h2><p>è®¾ $X_i\sim f(x)$ æ˜¯ç‹¬ç«‹åŒåˆ†å¸ƒçš„è¿ç»­å‹ r.v.ï¼Œåˆ™å¯¹äºé¡ºåºç»Ÿè®¡é‡ $X_{(1)}(\min),\cdots ,X_{(n)}(\max)$ ï¼Œå¦‚ä½•æ±‚ $X_{(k)}$ çš„å¯†åº¦ï¼Ÿ</p>
<p>è§£ï¼šå¯¹äºå……åˆ†å°çš„ç©ºé—´ $[x,x+\text{d}x]$ï¼Œæœ‰</p>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{l}<br>&amp;P\{ x\lt X_{(k)} \lt x+\text{d}x \}=\left(\begin{array}{c}n \\ k-1 \end{array} \right) F(x)^{k-1} \left(\begin{array}{c}n-k+1 \\ 1 \end{array} \right) [F(x+\text{d}x)-F(x)] \left(\begin{array}{c}n-k \\ n-k  \end{array} \right) [1-F(x+\text{d}x)^{n-k}] \\<br>\therefore\ \ &amp;f_k(x)=\frac{\text{d}P\{ x\lt X_{(k)} \lt x+\text{d}x \}}{\text{d}x}=\frac{n!}{(k-1)!(n-k)!}F(x)^{k-1} f(x)[1-F(x)]^{n-k}<br>\end{array}<br>$</p>

</blockquote>
<p>ç§°æ­¤ä¸º Veta åˆ†å¸ƒï¼Œè®°ä¸º $X\sim Beta(k, n-k+1)$</p>
<p>Beta å¯†åº¦ç”¨äºåˆ»ç”» [0, 1] ä¸Šçš„éšæœºå˜é‡ï¼š</p>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{l}<br>&amp;f(u)=\frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)}u^{a-1}(1-u)^{b-1} \\<br>s.t.\ &amp;\Gamma(x)=(x-1)! ,\ 0\le u\le 1<br>\end{array}<br>$</p>

</blockquote>
<h1 id="ç¬¬å››ç« -éšæœºå˜é‡çš„æ•°å­—ç‰¹å¾"><a href="#ç¬¬å››ç« -éšæœºå˜é‡çš„æ•°å­—ç‰¹å¾" class="headerlink" title="ç¬¬å››ç«  éšæœºå˜é‡çš„æ•°å­—ç‰¹å¾"></a>ç¬¬å››ç«  éšæœºå˜é‡çš„æ•°å­—ç‰¹å¾</h1><h2 id="åæ–¹å·®"><a href="#åæ–¹å·®" class="headerlink" title="åæ–¹å·®"></a>åæ–¹å·®</h2><p>å®šä¹‰ï¼š</p>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{l}<br>&amp;Cov(X,Y)\triangleq E[(X-E(X))\cdot (Y-E(Y))]<br>\end{array}<br>$</p>

</blockquote>
<p>ç§°ä¸º Xï¼ŒY çš„åæ–¹å·®ï¼Œå…¶ç›¸å…³ç³»æ•°è¡¨ç¤ºä¸ºï¼š</p>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{l}<br>&amp;\rho_{XY}\triangleq Cov(X^{*},Y^{*})=\frac{Cov(X,Y)}{\sqrt{D(X)}\sqrt{E(Y)}}<br>\end{array}<br>$</p>

</blockquote>
<p>åˆ©ç”¨è¿™ä¸ªå±æ€§è¿›è¡Œ Xï¼ŒY çº¿æ€§æ‹Ÿåˆçš„è®¡ç®—ï¼š</p>
<p>è®°å‡æ–¹è¯¯å·®ä¸º $e=E[(Y-\hat{Y})^2]=E[(Y-(aX+b))^2]$</p>
<p>ä»¤ $\left\{ \begin{array}{l} &amp;\frac{\partial{e}}{\partial{b}}=2b+2aE(X)-2E(Y)=0 \\ &amp;\frac{\partial{e}}{\partial{a}}=2aE(X^2)-2E(XY)+2bE(X)=0 \end{array} \right.$</p>
<p>è§£å¾— $\left\{ \begin{array}{l} &amp;b_0=\frac{Cov(X,Y)}{D(X)} \\ &amp;a_0=E(Y)-E(X)\cdot b_0 \end{array} \right.$</p>
<p>è¿›ä¸€æ­¥å¾— $\underset{a,b}{\min e}=D(Y)(1-\frac{Cov^2(X,Y)}{D(X)D(Y)})=D(Y)(1-\rho^2_{XY})$</p>
<font color="red">æ³¨æ„ï¼š</font>$\rho_{XY}=0$ å¹¶ä¸æ„å‘³ç€ Xï¼ŒY ç›¸äº’ç‹¬ç«‹ï¼ï¼ˆä½†æ­£æ€åˆ†å¸ƒèƒ½è¯æ˜ ä¸ç›¸å…³ = ç‹¬ç«‹ï¼‰



å®šä¹‰ï¼š

å¯¹ r.v. Xï¼ŒYï¼Œ

$E(X^k)\ \ \ (k=1,2,\cdots)$ ä¸º <font color="red">k é˜¶åŸç‚¹çŸ©</font>

<p>$E[(X-E(X))^k]\ \ \ (k=1,2,\cdots)$ ä¸º <font color="red">k é˜¶ä¸­å¿ƒçŸ©</font></p>
<p>$E[(X-E(X))^k(Y-E(Y))^l]\ \ \ (k,l=1,2,\cdots)$ ä¸º <font color="red">k+l é˜¶æ··åˆä¸­å¿ƒçŸ©</font></p>
<blockquote>
<p>å› æ­¤ï¼Œr.v. çš„æœŸæœ›æ˜¯ä¸€é˜¶åŸç‚¹çŸ©ï¼Œæ–¹å·®æ˜¯2é˜¶ä¸­å¿ƒçŸ©ï¼Œåæ–¹å·®æ˜¯2é˜¶æ··åˆä¸­å¿ƒçŸ©ã€‚</p>
</blockquote>
<h2 id="æ¡ä»¶æœŸæœ›"><a href="#æ¡ä»¶æœŸæœ›" class="headerlink" title="æ¡ä»¶æœŸæœ›"></a>æ¡ä»¶æœŸæœ›</h2><p>å®šä¹‰ï¼š</p>
<blockquote class="blockquote-center">
<p>$<br>\left\{\begin{array}{rl}<br>&amp;E(h(Y)|X=x)=\sum_{y}h(y)p_{Y|X}(y|x) &amp;\text{ï¼ˆç¦»æ•£ï¼‰} \\<br>&amp;E(h(Y)|X=x)=\int_{y}h(y)f_{Y|X}(y|x)\text{d}y &amp;\text{ï¼ˆè¿ç»­ï¼‰}<br>\end{array}\right.<br>$</p>

</blockquote>
<blockquote>
<p>ç‰¹æ®Šæƒ…å†µä¸‹ï¼Œ$h(y)=y$</p>
</blockquote>
<p><font color="green">å›é¡¾æ³Šæ¾åˆ†å¸ƒï¼š</font> $X\sim P(\lambda t)$</p>
<p>$P(X=k)=\frac{(\lambda t)^k}{k!}e^{-\lambda t}\ \ \ k\in\mathbb{N}$  ç§°ä¸ºæ³Šæ¾å¼ºåº¦ã€‚</p>
<p>ä¾‹ï¼šè€ƒè™‘ [0, 1] åŒºé—´ä¸Šå‡å€¼ä¸º $\lambda$ çš„æ³Šæ¾æµï¼Œä»¤ N æ˜¯ [0, 1] ä¸Šç‚¹çš„ä¸ªæ•°ã€‚å¯¹äº $p\lt 1$ï¼Œä»¤ X æ˜¯ [0, p] ä¸Šç‚¹çš„ä¸ªæ•°ã€‚è®¡ç®—ç»™å®š N = n çš„æƒ…å†µä¸‹ï¼ŒX çš„æ¡ä»¶åˆ†å¸ƒå’Œæ¡ä»¶æœŸæœ›ã€‚</p>
<p>è§£ï¼šè”åˆåˆ†å¸ƒ</p>
<p>$P\{X=x,N=n \}=\frac{(p\lambda)^xe^{-p\lambda}}{x!}\cdot \frac{((1-p)\lambda)^{(n-x)}e^{-(1-p)\lambda}}{(n-x)!}$</p>
<p>è€Œ $N\sim P(\lambda)$</p>
<p>å› æ­¤ $P\{X=x|N=n \}=\frac{n!}{x!(n-x)!}p^x(1-p)^{(n-x)}\sim b(n,p)$</p>
<p>ä»è€Œ $X$ çš„æ¡ä»¶æœŸæœ›ä¸º $np$ã€‚</p>
<h1 id="ç¬¬äº”ç« -æ•°ç†ç»Ÿè®¡ï¼ˆå…¥é—¨ï¼‰"><a href="#ç¬¬äº”ç« -æ•°ç†ç»Ÿè®¡ï¼ˆå…¥é—¨ï¼‰" class="headerlink" title="ç¬¬äº”ç«  æ•°ç†ç»Ÿè®¡ï¼ˆå…¥é—¨ï¼‰"></a>ç¬¬äº”ç«  æ•°ç†ç»Ÿè®¡ï¼ˆå…¥é—¨ï¼‰</h1><h2 id="å¤§æ•°å®šå¾‹"><a href="#å¤§æ•°å®šå¾‹" class="headerlink" title="å¤§æ•°å®šå¾‹"></a>å¤§æ•°å®šå¾‹</h2><p>ï¼ˆä¼¯åŠªåˆ©ç‰ˆï¼‰è®¾ $P(A)=p$ï¼Œåˆ™å¯¹ä»»æ„ $\epsilon\gt 0$ï¼Œæœ‰ $\color{red} \underset{n\to \infty}{\lim}=P\{|\frac{n_A}{n}-p|\ge \epsilon \}=0$</p>
<p>ï¼ˆåˆ‡æ¯”é›ªå¤«ç‰ˆï¼‰$\{X_n\}$ ä¸ºç‹¬ç«‹éšæœºå˜é‡åˆ—ï¼Œä¸”æœŸæœ›æ–¹å·®ç›¸åŒï¼Œåˆ™å¯¹ä»»æ„ $\epsilon\gt 0$ï¼Œæœ‰ $\color{red} \underset{n\to \infty}{\lim}=P\{|\frac{1}{n}\sum_{i=1}^{n}X_i-\mu|\ge \epsilon \}=0$</p>
<p>ï¼ˆè¿™æ„å‘³ç€æ ·æœ¬é‡è¶³å¤Ÿå¤§æ—¶ï¼ŒæœŸæœ›å¯è¢«æ ·æœ¬çš„ç®—æœ¯å‡å€¼æ›¿ä»£ï¼‰</p>
<h2 id="ä¸­å¿ƒæé™å®šç†"><a href="#ä¸­å¿ƒæé™å®šç†" class="headerlink" title="ä¸­å¿ƒæé™å®šç†"></a>ä¸­å¿ƒæé™å®šç†</h2><p>è‹¥ $X_n$ çš„åˆ†å¸ƒ $F_n(x)$ å¯¹ä»»æ„ $x$ æ»¡è¶³</p>
<blockquote class="blockquote-center">
<p>$<br>\color{red}<br>\begin{array}{l}<br>&amp;\underset{n\to \infty}{\lim} F_n(x)=\underset{n\to \infty}{\lim}P\{ \frac{\sum_{i=1}^{n}(X_i-\mu_i)}{\sqrt{\sum_{i=1}^{n}\sigma_i^2}}\le x \}=\psi(x)<br>\end{array}<br>$</p>

</blockquote>
<p>åˆ™ç§° $\{X_n \}$ æœä»ä¸­å¿ƒæé™å®šç†ï¼ˆ$\psi(x)$ ä¸ºæ ‡å‡†æ­£æ€ï¼‰</p>
<p>ç‰¹åˆ«å½“ $X_n$ ç‹¬ç«‹åŒåˆ†å¸ƒï¼Œåˆ™æœ‰ $\underset{n\to \infty}{\lim}P\{ \frac{\sum_{i=1}^{n}X_i-n\mu_i}{\sqrt{n}\sigma_i}\le x \}=\psi(x)$</p>
<blockquote>
<p>å¾·è«å¤«-æ‹‰æ™®æ‹‰æ–¯ä¸­å¿ƒæé™å®šç†ï¼šå¯¹ $\eta_n\sim b(n,p)$</p>
<p>$\frac{\eta_n-np}{\sqrt{np(1-p)}}\sim N(0,1)$</p>
<p>å‚è€ƒé«˜å°”é¡¿é’‰æ¿</p>
</blockquote>
<h1 id="ç¬¬å…­ç« -æ•°ç†ç»Ÿè®¡ï¼ˆåŸºç¡€ï¼‰"><a href="#ç¬¬å…­ç« -æ•°ç†ç»Ÿè®¡ï¼ˆåŸºç¡€ï¼‰" class="headerlink" title="ç¬¬å…­ç«  æ•°ç†ç»Ÿè®¡ï¼ˆåŸºç¡€ï¼‰"></a>ç¬¬å…­ç«  æ•°ç†ç»Ÿè®¡ï¼ˆåŸºç¡€ï¼‰</h1><h2 id="æŠ½æ ·åˆ†å¸ƒ"><a href="#æŠ½æ ·åˆ†å¸ƒ" class="headerlink" title="æŠ½æ ·åˆ†å¸ƒ"></a>æŠ½æ ·åˆ†å¸ƒ</h2><p>1 . $\chi^2$ - åˆ†å¸ƒ</p>
<p>è®¾ $X_1-X_n$ æ˜¯æ¥è‡ªæ€»ä½“ $X\sim N(0,1)$ çš„æ ·æœ¬ï¼Œä»¤</p>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{l}<br>\chi^2=X_1^2+X_2^2+\cdots +X_n^2<br>\end{array}<br>$</p>

</blockquote>
<p>ç§° $\chi^2$ æœä»è‡ªç”±åº¦ä¸º $n$ çš„ $\chi^2$ - åˆ†å¸ƒï¼ˆä¹Ÿç§°å¡æ–¹åˆ†å¸ƒï¼‰ï¼Œè®°ä¸º $\chi^2(n)$ã€‚</p>
<blockquote>
<p><font color="blue">è‡ªç”±åº¦ï¼š</font>è‡ªç”±åº¦æ˜¯äºŒæ¬¡å‹ $\chi^2=X_1^2+X_2^2+\cdots +X_n^2$ çš„ç§©ï¼Œå³å¯ç‹¬ç«‹å˜åŒ–çš„å˜é‡ä¸ªæ•°ã€‚</p>
</blockquote>
<p>æ•°å­—ç‰¹å¾ï¼š</p>
<ul>
<li>$E(\chi^2)=n$</li>
<li>$D(\chi^2)=2n$</li>
</ul>
<p>2 . t - åˆ†å¸ƒ</p>
<p>è®¾ $X\sim N(0,1)$ï¼Œ$Y\sim \chi^2(n)$ï¼Œä¸” $X$ï¼Œ$Y$ ç‹¬ç«‹ï¼Œä»¤</p>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{l}<br>t=X/\sqrt{Y/n}<br>\end{array}<br>$</p>

</blockquote>
<p>ç§° $t$ ä¸ºæœä»è‡ªç”±åº¦ä¸º n çš„ t - åˆ†å¸ƒï¼Œè®°ä¸º $t(n)$ã€‚</p>
<p>æ€§è´¨ï¼š</p>
<ul>
<li>æ•°å­—ç‰¹å¾<ul>
<li>$E(t)=0$</li>
<li>$D(t)=\frac{n}{n+2}$</li>
</ul>
</li>
<li>å½“ n å……åˆ†å¤§æ—¶ï¼ŒT è¿‘ä¼¼æœä» N(0, 1)ï¼Œå³è¶‹è¿‘æ ‡å‡†æ­£æ€åˆ†å¸ƒ<ul>
<li>å¯è¯æ˜ $\underset{n\to\infty}{\lim}f(x)=(2\pi)^{-\frac{1}{2}}e^{-\frac{x^2}{2}}$</li>
</ul>
</li>
</ul>
<p>3 . F - åˆ†å¸ƒ</p>
<p>è®¾ $U\sim \chi^2(n_1)$ï¼Œ$V\sim \chi^2(n_2)$ï¼Œä¸” $U$ï¼Œ$V$ ç‹¬ç«‹ï¼Œä»¤</p>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{l}<br>F=\Large\frac{U/n_1}{V/n_2}<br>\end{array}<br>$</p>

</blockquote>
<p>ç§° F ä¸ºæœä»è‡ªç”±åº¦ä¸º $(n_1,n_2)$ çš„ F - åˆ†å¸ƒï¼Œè®°ä¸º $F(n_1,n_2)$ã€‚</p>
<p>äºŒçº§ç»“è®ºï¼š</p>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{l}<br>&amp;T\sim t(n) \Rightarrow T^2\sim F(1,n) \\<br>\text{è¯ï¼š} &amp;T=\frac{X}{\sqrt{Y/n}} \Rightarrow T^2=\frac{X^2/1}{Y/n}, \\<br>\text{ ä¸” }&amp;X^2,Y\text{ ä»ç›¸äº’ç‹¬ç«‹}<br>\end{array}<br>$</p>

</blockquote>
<h2 id="æŠ½æ ·åˆ†å¸ƒå®šç†"><a href="#æŠ½æ ·åˆ†å¸ƒå®šç†" class="headerlink" title="æŠ½æ ·åˆ†å¸ƒå®šç†"></a>æŠ½æ ·åˆ†å¸ƒå®šç†</h2><p>1 . è®¾ $X_1\sim X_n$ æ˜¯æ¥è‡ªæ€»ä½“ $X\sim N(\mu,\sigma^2)$ çš„æ ·æœ¬ï¼Œåˆ™</p>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{l}<br>\bar{X}\sim N(\mu,\frac{\sigma^2}{n})<br>\end{array}<br>$</p>

</blockquote>
<p>å› ä¸º $\bar{X}=(X_1+\cdots +X_n)/n$ ï¼Œè€Œçº¿æ€§ç»„åˆä»æœä»æ­£æ€åˆ†å¸ƒã€‚</p>
<p>å› æ­¤ï¼Œ$E(\bar{X})=\mu$ï¼Œ$D(\bar{X})=\frac{\sigma^2}{n}$</p>
<p>2 . è®¾ $X_1\sim X_n$ æ˜¯æ¥è‡ªæ€»ä½“ $X\sim N(\mu,\sigma^2)$ çš„æ ·æœ¬ï¼Œ$\bar{X}$ ã€$S^2$ åˆ†åˆ«æ˜¯æ ·æœ¬å‡å€¼å’Œæ ·æœ¬æ–¹å·®ï¼Œåˆ™æœ‰</p>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{lr}<br>&amp;\frac{(n-1)S^2}{\sigma^2}\sim \chi^2(n-1) &amp;(1) \\<br>&amp;\bar{X},S^2\text{ ç›¸äº’ç‹¬ç«‹} &amp;(2)<br>\end{array}<br>$</p>

</blockquote>
<p>3 . waitingâ€¦</p>
<p>4 . </p>
<p>5 . </p>
<h1 id="ç¬¬ä¸ƒç« -å‚æ•°ä¼°è®¡"><a href="#ç¬¬ä¸ƒç« -å‚æ•°ä¼°è®¡" class="headerlink" title="ç¬¬ä¸ƒç«  å‚æ•°ä¼°è®¡"></a>ç¬¬ä¸ƒç«  å‚æ•°ä¼°è®¡</h1><h2 id="ç‚¹ä¼°è®¡"><a href="#ç‚¹ä¼°è®¡" class="headerlink" title="ç‚¹ä¼°è®¡"></a>ç‚¹ä¼°è®¡</h2><p>å®šä¹‰ï¼šè®¾æ€»ä½“åˆ†å¸ƒå‡½æ•° $F(x,\theta)$ ï¼Œ $X_1\sim X_n$ ä¸ºæ ·æœ¬ï¼Œæ„é€ ä¸€ä¸ªç»Ÿè®¡é‡ $\theta=\theta(X_1,\cdots ,X_n)$ æ¥ä¼°è®¡å‚æ•° $\theta$ ï¼Œåˆ™ç§°ä¸ºå‚æ•° $\theta$ çš„<strong>ä¼°è®¡é‡</strong>ã€‚</p>
<p>å°†è§‚æµ‹å€¼ $x_1,\cdots ,x_n$ å¸¦å…¥ $\theta(X_1,\cdots ,X_n)$ ï¼Œå¾—åˆ°çš„ $\theta(x_1,\cdots ,x_n)$ ç§°ä¸ºå‚æ•° $\theta$ çš„<strong>ä¼°è®¡å€¼</strong>ã€‚</p>
<p>å¸¸ç”¨ç‚¹ä¼°è®¡æ³•ï¼š</p>
<ul>
<li>çŸ©ä¼°è®¡ï¼šè®¾æ€»ä½“ $X\sim F(x;\theta)$ ï¼Œ$\theta_1\sim \theta_m$ æœªçŸ¥ï¼Œè®¾å¯¹ n ä¸ªæ ·æœ¬ï¼Œæ€»ä½“çŸ©éƒ½å­˜åœ¨ï¼ˆå³ $\alpha_k \triangleq E(X^k),(k=1,2,\cdots,m)$ ï¼‰ï¼Œç”±è¾›é’¦å¤§æ•°å®šå¾‹å¾—</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{l}<br>&amp;A_k=\frac{1}{n}\sum_{i=1}^{n}X^k_i \overset{P}{\longrightarrow}E(X^k)=\alpha_k\ \ (n\to\infty,k=1,2,\cdots,m) \\<br>\text{å¯è®¤ä¸º }&amp;A_k\approx E(X^k)=\int{x^k}\text{d}F \triangleq \alpha_k(\theta_1,\cdots, \theta_m) &amp; \\<br>\therefore &amp; \left\{\begin{array}{l}<br>&amp;\alpha_1(\theta_1,\cdots, \theta_m)=E(X) \approx A_1 \\<br>&amp;\alpha_2(\theta_1,\cdots, \theta_m)=E(X^2) \approx A_2 \\<br>&amp;\vdots \\<br>&amp;\alpha_m(\theta_1,\cdots, \theta_m)=E(X^m) \approx A_m<br>\end{array}\right.<br>\end{array}<br>$</p>

</blockquote>
<p>è§£ä¸Šè¿°æ–¹ç¨‹ç»„å¾—ï¼š</p>
<blockquote class="blockquote-center">
<p>$<br>\left\{<br>\begin{array}{l}<br>&amp;\hat{\theta}_1=\hat{\theta}_1(A_1,A_2,\cdots,A_m) \\<br>&amp;\vdots \\<br>&amp;\hat{\theta}_m=\hat{\theta}_m(A_1,A_2,\cdots,A_m) \\<br>\end{array}<br>\right.<br>$</p>

</blockquote>
<ul>
<li>æœ€å¤§ä¼¼ç„¶ä¼°è®¡ï¼šæ„é€ ä¼¼ç„¶å‡½æ•° $L(\theta)$ ï¼Œé€šè¿‡æ±‚æå¤§å€¼ç‚¹å¾—åˆ°å‚æ•°å€¼</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>L(\theta)=<br>\left\{<br>\begin{array}{lr}<br>&amp;p(x_1,x_2,\cdots,x_n;\theta)=\prod_{i=1}^{n}p(x_i;\theta) &amp;(\text{ç¦»æ•£}) \\<br>&amp;f(x_1,x_2,\cdots,x_n;\theta)=\prod_{i=1}^{n}f(x_i;\theta) &amp;(\text{è¿ç»­}) \\<br>\end{array}<br>\right.<br>$</p>

</blockquote>
<p>å–å¯¹æ•°ä¾¿äºæ±‚åå¯¼ï¼ˆå¯¹æ¯ä¸ªå‚æ•° $\theta_i$ æ±‚åå¯¼ï¼‰ï¼š$\large\frac{\partial{\ln{L}}}{\partial{\theta_i}}=0$</p>
<p><strong>å‚æ•°è¯„ä»·æ ‡å‡†</strong></p>
<ul>
<li>æ— åæ€§ï¼š$E(\hat\theta)=\theta$</li>
<li>æœ‰æ•ˆæ€§ï¼š$E(\hat\theta_1)=E(\hat\theta_2)=\theta$ ä¸” $D(\hat\theta_1)\le D(\hat\theta_2)$ï¼Œåˆ™ç§° $\hat\theta_1$ è¾ƒ $\hat\theta_2$ æœ‰æ•ˆã€‚</li>
<li>ç›¸åˆæ€§ï¼ˆä¸€è‡´æ€§ï¼‰ï¼šè®¾ $\hat\theta_n=\hat\theta(X_1,X_2,\cdots,X_n)$ æ˜¯ $\theta$ çš„ç‚¹ä¼°è®¡ï¼Œè‹¥ $\forall \theta\in\Theta$ æ»¡è¶³å¯¹ $\forall\epsilon\gt 0$ æœ‰ $\color{red}\underset{n\to\infty}{\lim}P\{|\hat\theta_n -\theta|\ge \epsilon \}=0$ ï¼Œåˆ™ç§° $\hat\theta_n$ æ˜¯ $\theta$ çš„<font color="red">ç›¸åˆä¼°è®¡</font>ï¼Œè®°ä½œ $\hat\theta_n\overset{P}{\longrightarrow}\theta(n\to\infty)$ ã€‚</li>
</ul>
<h2 id="åŒºé—´ä¼°è®¡"><a href="#åŒºé—´ä¼°è®¡" class="headerlink" title="åŒºé—´ä¼°è®¡"></a>åŒºé—´ä¼°è®¡</h2><blockquote>
<p>åŒºåˆ«ï¼šç‚¹ä¼°è®¡æ„é€ ä¸€ä¸ªå‚æ•°ç»Ÿè®¡é‡ï¼Œè€ŒåŒºé—´ä¼°è®¡æ„é€ ä¸¤ä¸ªå¹¶å°† $(\theta_1,\theta_2)$ ä»¥ä¸€å®šçš„ç½®ä¿¡åº¦ä½œä¸º $\theta$ çš„ä¼°ç®—åŒºé—´ã€‚</p>
</blockquote>
<p>å®šä¹‰ï¼šè®¾æ€»ä½“ $X\sim F(x;\theta)$ ï¼Œè‹¥å­˜åœ¨ 2 ä¸ªç»Ÿè®¡é‡</p>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{lr}<br>&amp;\underline{\theta}=\underline{\theta}(X_1,\cdots,X_n),\ \ \ \overline{\theta}=\overline{\theta}(X_1,\cdots,X_n) &amp;(\underline{\theta}\lt\overline{\theta})<br>\end{array}<br>$</p>

</blockquote>
<p>ä½¿å¾— $\forall\theta\in\Theta$ æœ‰ $P\{\underline{\theta}\le\theta\le\overline{\theta}\}\ge 1-\alpha$ ï¼Œåˆ™ç§°éšæœºåŒºé—´ $(\underline{\theta},\overline{\theta})$ ä¸º $\theta$ çš„<font color="red">ç½®ä¿¡æ°´å¹³</font>ä¸º $1-\alpha$ çš„<font color="red">ç½®ä¿¡åŒºé—´</font>ï¼Œ$\underline{\theta}$ å’Œ $\overline{\theta}$ åˆ†åˆ«ç§°ä¸ºç½®ä¿¡ä¸‹é™å’Œç½®ä¿¡ä¸Šé™ã€‚</p>
<ul>
<li>åŒºé—´ä¼°è®¡ä¸€èˆ¬æ–¹æ³•<ul>
<li>æ¢è½´æ³•ï¼ˆå¯¹åº” t-åˆ†å¸ƒçš„åº”ç”¨ï¼‰</li>
<li>æ³¢åŠ¨ç†è®ºï¼ˆå¯¹åº”å¡æ–¹åˆ†å¸ƒçš„åº”ç”¨ï¼‰</li>
</ul>
</li>
</ul>
<p><strong>äºŒçº§ç»“è®ºæ€»ç»“</strong></p>
<ol>
<li>$\sigma^2$ å·²çŸ¥ï¼Œå¯¹ $\mu$ ä¼°è®¡ï¼š$\color{red}(\bar{X}-u_{1-\frac{\alpha}{2}}\frac{\sigma}{\sqrt{n}},\bar{X}+u_{1-\frac{\alpha}{2}}\frac{\sigma}{\sqrt{n}})$</li>
<li>$\sigma^2$ æœªçŸ¥ï¼Œå¯¹ $\mu$ ä¼°è®¡ï¼š$\color{red}(\bar{X}-\frac{S}{\sqrt{n}}t_{1-\frac{\alpha}{2}}(n-1),\bar{X}+\frac{S}{\sqrt{n}}t_{1-\frac{\alpha}{2}}(n-1))$</li>
<li>$\mu$ æœªçŸ¥ï¼Œå¯¹ $\sigma^2$ ä¼°è®¡ï¼š$\large\color{red}(\frac{(n-1)S^2}{\chi^2_{1-\frac{\alpha}{2}}(n-1)}, \frac{(n-1)S^2}{\chi^2_{\frac{\alpha}{2}}(n-1)})$</li>
</ol>
<p><em>åä¸¤æ¡çš„æ¨å¯¼å¼ï¼š</em></p>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{c}<br>&amp;P\left\{ \frac{|\bar{X}-\mu|}{S/\sqrt{n}}\lt t_{1-\frac{\alpha}{2}}(n-1) \right\}=1-\alpha \\<br>&amp;P\left\{\chi^2_{\frac{\alpha}{2}}(n-1)\lt \frac{(n-1)S^2}{\sigma^2}\lt\chi^2_{1-\frac{\alpha}{2}}(n-1) \right\}=1-\alpha<br>\end{array}<br>$</p>

</blockquote>
<h1 id="ç¬¬å…«ç« -å‡è®¾æ£€éªŒ"><a href="#ç¬¬å…«ç« -å‡è®¾æ£€éªŒ" class="headerlink" title="ç¬¬å…«ç«  å‡è®¾æ£€éªŒ"></a>ç¬¬å…«ç«  å‡è®¾æ£€éªŒ</h1><h2 id="ä¸€ã€å»ºç«‹å¯¹ç«‹çš„å‡è®¾ï¼š"><a href="#ä¸€ã€å»ºç«‹å¯¹ç«‹çš„å‡è®¾ï¼š" class="headerlink" title="ä¸€ã€å»ºç«‹å¯¹ç«‹çš„å‡è®¾ï¼š"></a>ä¸€ã€å»ºç«‹å¯¹ç«‹çš„å‡è®¾ï¼š</h2><p>åŸå‡è®¾ï¼ˆé›¶å‡è®¾ï¼‰$H_0$ å’Œå¤‡æ‹©å‡è®¾ï¼ˆå¯¹ç«‹å‡è®¾ï¼‰$H_1$</p>
<ol>
<li>ä¿æŠ¤åŸå‡è®¾ï¼šåŸå‡è®¾é”™è¯¯çš„â€œä»£ä»·â€å¿…é¡»å°äºå¤‡æ‹©å‡è®¾ï¼ˆå¦‚åŸå‡è®¾æ–°è¯ç‰©æœ‰å‰¯ä½œç”¨ï¼‰</li>
<li>åŸå‡è®¾è¶‹äºç»´æŒç°çŠ¶</li>
<li>åŸå‡è®¾å–ç®€å•å‡è®¾</li>
</ol>
<h2 id="äºŒã€ç»™å‡ºæ£€éªŒç»Ÿè®¡é‡ï¼Œç¡®å®šæ‹’ç»åŸŸå½¢å¼"><a href="#äºŒã€ç»™å‡ºæ£€éªŒç»Ÿè®¡é‡ï¼Œç¡®å®šæ‹’ç»åŸŸå½¢å¼" class="headerlink" title="äºŒã€ç»™å‡ºæ£€éªŒç»Ÿè®¡é‡ï¼Œç¡®å®šæ‹’ç»åŸŸå½¢å¼"></a>äºŒã€ç»™å‡ºæ£€éªŒç»Ÿè®¡é‡ï¼Œç¡®å®šæ‹’ç»åŸŸå½¢å¼</h2><p>æ‹’ç»åŸŸæ˜¯æ‹’ç»åŸå‡è®¾çš„æ ·æœ¬å€¼èŒƒå›´ï¼Œå…¶è¡¥é›†ä¸ºæ¥å—åŸŸã€‚</p>
<p>è®¾ç½®åˆç†çš„ $C$ å€¼ï¼ˆå¾…å®šå¸¸æ•°ï¼‰ï¼Œä½¿å¾— $\bar{X}$ å¤§äº/å°äºè¯¥å¸¸æ•°æ—¶ï¼Œæ‹’ç»åŸå‡è®¾ã€‚</p>
<p><strong>I ç±»é”™è¯¯ä¸ II ç±»é”™è¯¯</strong></p>
<p>I ç±»é”™è¯¯æŒ‡æ‹’ç»åŸå‡è®¾ä½†æ˜¯åŸå‡è®¾ä¸ºçœŸçš„æƒ…å†µï¼Œç”¨ $\alpha$ è¡¨ç¤ºçŠ¯é”™æ¦‚ç‡ï¼Œä¸€èˆ¬æ§åˆ¶åœ¨ $(0.01,0.1)$ èŒƒå›´å†…ã€‚(ä¹Ÿç§°<font color="red">æ˜¾è‘—æ°´å¹³</font>)</p>
<p>II ç±»é”™è¯¯æŒ‡æ¥å—åŸå‡è®¾ä½†åŸå‡è®¾ä¸ºå‡çš„æƒ…å†µï¼Œç”¨ $\beta$ è¡¨ç¤ºã€‚</p>
<h2 id="ä¸‰ã€æ ¹æ®æ˜¾è‘—æ°´å¹³å’Œç»Ÿè®¡é‡çš„åˆ†å¸ƒç¡®å®šä¸´ç•Œå€¼"><a href="#ä¸‰ã€æ ¹æ®æ˜¾è‘—æ°´å¹³å’Œç»Ÿè®¡é‡çš„åˆ†å¸ƒç¡®å®šä¸´ç•Œå€¼" class="headerlink" title="ä¸‰ã€æ ¹æ®æ˜¾è‘—æ°´å¹³å’Œç»Ÿè®¡é‡çš„åˆ†å¸ƒç¡®å®šä¸´ç•Œå€¼"></a>ä¸‰ã€æ ¹æ®æ˜¾è‘—æ°´å¹³å’Œç»Ÿè®¡é‡çš„åˆ†å¸ƒç¡®å®šä¸´ç•Œå€¼</h2><p>æ ¹æ® NP åŸåˆ™ï¼Œå…ˆä¿è¯çŠ¯ I ç±»é”™è¯¯çš„æ¦‚ç‡ä¸è¶…è¿‡ $\alpha$ï¼Œå†ä»¤çŠ¯ II ç±»é”™è¯¯çš„æ¦‚ç‡å°½å¯èƒ½å°ã€‚</p>
<p>ä¾‹ï¼šå– $\alpha=0.05$ ï¼Œå½“ $H_0:\mu=0$ æˆç«‹æ—¶ï¼Œ$\frac{\bar{X}}{0.6/\sqrt{9}}\sim N(0,1)$ã€‚ï¼ˆç»Ÿè®¡é‡åˆ†å¸ƒï¼‰åˆ™å¯è¿›è¡Œå¦‚ä¸‹è®¡ç®—ï¼š</p>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{l}<br>P\{\bar{X}\ge C|\mu=0 \}&amp;=P\left\{\frac{\bar{X}}{\sigma/\sqrt{n}}\ge\frac{C}{\sigma/\sqrt{n}}|\mu=0 \right\} \\<br>&amp;=1-\psi\left(\frac{C}{\sigma/\sqrt{n}}\right)\le\alpha=0.05\ \ (0.05=\psi(-\textbf{z}_{0.05})) \\<br>&amp;\Rightarrow \frac{C}{0.6/\sqrt{9}}\ge \textbf{z}_{0.05}=1.645 \Rightarrow C\ge0.329<br>\end{array}<br>$</p>

</blockquote>
<p>å› æ­¤å– $C=0.329$ ä»¥å‡å° II ç±»é”™è¯¯ï¼</p>
<h2 id="å››ã€æ ¹æ®æ ·æœ¬æ•°æ®åˆ¤æ–­æ˜¯å¦è¦æ‹’ç»å‡è®¾"><a href="#å››ã€æ ¹æ®æ ·æœ¬æ•°æ®åˆ¤æ–­æ˜¯å¦è¦æ‹’ç»å‡è®¾" class="headerlink" title="å››ã€æ ¹æ®æ ·æœ¬æ•°æ®åˆ¤æ–­æ˜¯å¦è¦æ‹’ç»å‡è®¾"></a>å››ã€æ ¹æ®æ ·æœ¬æ•°æ®åˆ¤æ–­æ˜¯å¦è¦æ‹’ç»å‡è®¾</h2><blockquote>
<p>ä¾‹ï¼šå¦‚ $\bar{x}=0.522\gt 0.329$ï¼Œåˆ™æ‹’ç»åŸå‡è®¾ã€‚</p>
</blockquote>
<h2 id="æ­£æ€æ€»ä½“å‚æ•°çš„å‡è®¾æ£€éªŒæ ·ä¾‹"><a href="#æ­£æ€æ€»ä½“å‚æ•°çš„å‡è®¾æ£€éªŒæ ·ä¾‹" class="headerlink" title="æ­£æ€æ€»ä½“å‚æ•°çš„å‡è®¾æ£€éªŒæ ·ä¾‹"></a>æ­£æ€æ€»ä½“å‚æ•°çš„å‡è®¾æ£€éªŒæ ·ä¾‹</h2><p>In developmentâ€¦</p>
]]></content>
      <categories>
        <category>2023 Fall</category>
      </categories>
      <tags>
        <tag>CSE Learning</tag>
        <tag>Maths</tag>
      </tags>
  </entry>
  <entry>
    <title>NUS å¤ä»¤è¥æ—¥è®°</title>
    <url>/2024/06/30/Summer-Workshop-Diary/</url>
    <content><![CDATA[<h1 id="2024-6-29-Sat"><a href="#2024-6-29-Sat" class="headerlink" title="2024-6-29 (Sat.)"></a>2024-6-29 (Sat.)</h1><p>ã€€ã€€ç»è¿‡ 4 å°æ—¶å·¦å³çš„é£è¡Œï¼Œæˆ‘äºæ–°åŠ å¡å½“åœ°æ—¶é—´ï¼ˆå…¶å®å°±æ˜¯åŒ—äº¬æ—¶é—´ï¼‰16:50 å·¦å³æŠµè¾¾æ–°åŠ å¡çš„æ¨Ÿå®œæœºåœº(Changi Airport)ã€‚ç„¶åç¬¬ä¸€ä¸ªéš¾é¢˜å°±æ¥äº†ã€‚</p>
<p>ã€€ã€€å› ä¸ºæå‰åœ¨æ·˜å®ä¹°äº†æµé‡ç½‘å¡ï¼Œæ‰€ä»¥æˆ‘å–å®Œè¡Œæåè¿˜éœ€è¦å…ˆå»é¢†å–çª—å£å–æˆ‘çš„ç½‘å¡ï¼Œç„¶åæ‰èƒ½åœ¨ SG ä¸Šç½‘ã€‚æ‰€ä»¥æˆ‘åœ¨è¿™é‡Œè¶³è¶³æ‹–äº† 10-15 åˆ†é’Ÿã€‚ä¸è¿‡å¥½åœ¨å¤§éƒ¨åˆ†è·Ÿæˆ‘åŒä¸€ç­æœºçš„åŒå­¦éƒ½é‡åˆ°äº†ç±»ä¼¼çš„æƒ…å†µï¼Œæˆ‘ä»¬æœ€ç»ˆåœ¨å·®ä¸å¤šçš„æ—¶é—´é‡Œæ‰¾åˆ°äº†é¢†é˜Ÿï¼Œå°†æˆ‘ä»¬å¸¦å›äº† NUSã€‚</p>
<p>ã€€ã€€æ¯”è¾ƒåº†å¹¸çš„æ˜¯ï¼Œè¿™æ ·çš„å¼€å±€ç®—æ˜¯æ¯”è¾ƒä¸€å¸†é£é¡ºï¼Œè‡³æ­¤å”¯ä¸€çš„é—æ†¾å°±æ˜¯æˆ‘åˆ°è¾¾çš„æ—¶é—´æ˜¯ä¸‹åˆï¼Œæ‰€ä»¥åœ¨æ¨Ÿå®œæœºåœºçš„å•†åœºæ‹æ‘„åˆ°çš„å¤§å–·æ³‰æ˜¾å¾—å˜ˆæ‚ä¸”æ— è¶£ã€‚æˆ‘çš„å¦ä¸€ä½åŒå­¦ä¼¼ä¹æ‹åˆ°äº†å¤œæ™¯ï¼Œé‚£å¼ ç…§ç‰‡æˆ‘æ²¡è¦åˆ°ï¼Œåªèƒ½æš‚ä¸”æ‹¿ä¸€å¼ â€œæ—¥ä¸­çš„å–·æ³‰â€æ¥çŒ®ä¸‘äº†ã€‚</p>
<div align="center"><img src="/2024/06/30/Summer-Workshop-Diary/ft.jpg" alt="SGæœºåœºå–·æ³‰" style="width:700px">Fountain in Changi Airport</div>

<p>ã€€ã€€ä»¤æˆ‘æ„Ÿåˆ°æ— å¥ˆçš„æ˜¯ï¼Œå¼€å±€çš„ä¸€å¸†é£é¡ºå¹¶ä¸èƒ½æ©ç›–æ¥ä¸‹æ¥åœ¨æˆ‘èº«ä¸Šçš„ç§ç§çª˜æ€ã€‚ç›®å‰æ¥çœ‹ï¼Œæœ€ä»¤æˆ‘æ„Ÿåˆ°ä¸é€‚åº”çš„ï¼Œåè€Œæ˜¯æˆ‘åœ¨å›½å†…æœ€ä¹ ä»¥ä¸ºå¸¸ç”šè‡³æ„Ÿåˆ°ä¸€ä¸å«Œå¼ƒçš„æ–¹é¢ï¼šäººå£ã€‚å¯èƒ½æ˜¯åœ¨å¤§å­¦å°åŒºå†…ï¼Œä¹Ÿå¯èƒ½æ˜¯å‘¨æœ«çš„åŸå› ï¼Œå½“æˆ‘æ”¶æ‹¾å¥½è¡Œææ‰“ç®—æ‰¾ä¸ªé¤å…åƒæ™šé¥­çš„æ—¶å€™ï¼Œå°±åªèƒ½çœ‹ç€å‘¨å›´ç©ºè¡è¡çš„è¡—å¤´ï¼Œç›˜ç®—ç€ä»€ä¹ˆæ—¶å€™æ¥ä¸ªäººé—®é—®è·¯ã€‚è¿™è¾¹çš„äººå£ï¼ˆè‡³å°‘åœ¨è¿™æ®µæ—¶é—´ï¼‰å®åœ¨æ˜¯å°‘å¾—è¶…å‡ºæˆ‘çš„æƒ³è±¡</p>
<blockquote>
<font color="red">ä¸ºä»€ä¹ˆä¸çœ‹åœ°å›¾å‘¢ï¼Ÿ</font>
<br>
<font color="green">å…¶å® NUS æ ¡åŒºå†…æ˜¯æœ‰æ ¡å·´å¯ä»¥é€šå‘å¤§éƒ¨åˆ†æ ¡å†…åŒºåŸŸçš„ï¼Œç”šè‡³è¿˜èƒ½å»åˆ°åœ°é“ç«™ã€‚</font>

</blockquote>
<p>ã€€ã€€ä½†æ˜¯è¿™åˆæ¶‰åŠåˆ°ç¬¬äºŒä¸ªé—®é¢˜ï¼šç½‘ç»œã€‚æ¥åˆ°è¿™è¾¹åï¼Œæˆ‘æ‰å‘ç° NUS æ ¡å†…çš„ WiFi æ˜¯å¾ˆä¸ç¨³å®šçš„ã€‚å…·ä½“è¡¨ç°ä¸ºåå…¬äº¤è½¦çš„æ—¶å€™åŸºæœ¬ä¸Šåªæœ‰åœé ç«™ç‚¹çš„æ—¶å€™æ‰èƒ½è¿ä¸Š WiFiï¼ˆåæ¥æˆ‘ä»¬å‘ç°ä¼¼ä¹æ¯ä¸ªå…¬äº¤è½¦ç«™ç¡®å®è£…äº†ä¸€å°è·¯ç”±å™¨ï¼‰ã€‚</p>
<p>ã€€ã€€äºæ˜¯åœ¨è¿™ç§æ‰¾ä¸åˆ°äººé—®è·¯ï¼Œåˆåªèƒ½å¹²ç­‰ WiFi ä¿¡å·çš„æƒ…å†µä¸‹ï¼Œæˆ‘ç»ˆäºæƒ³åŠæ³•æ¥åˆ°äº† University Townï¼ˆä¹Ÿç§° U-Townï¼‰ã€‚æ¯•ç«Ÿæˆ‘ä¹Ÿæ²¡æƒ³åˆ°æ‰¾äº†å¥½å‡ ä¸ªæ•™å­¦åŒºçš„é£Ÿå ‚å‘ç°éƒ½æ²¡å¼€æ”¾ï¼Œæˆ‘çœŸçš„å“­æ­»ã€‚</p>
<div align="center"><img src="/2024/06/30/Summer-Workshop-Diary/night01.jpg" alt="U-Town å¤œæ™¯" style="width:700px">Night Scene of U-Town</div>

<p>ã€€ã€€å¤§çº¦åœ¨æ™šä¸Š 8 ç‚¹ï¼Œæˆ‘ç»ˆäºåœ¨ U-Town åƒä¸Šäº† SG è½åœ°åçš„ç¬¬ä¸€é¡¿æ™šé¥­ã€‚æˆ‘è¿›äº† U-Town çš„ä¸€å®¶éŸ©èœé¤é¦†ï¼Œç‚¹äº†ä¸ªä¸è®°å¾—å«ä»€ä¹ˆçš„ä¸œè¥¿ï¼ˆæˆ‘ä¸€å¼€å§‹ä»¥ä¸ºæ˜¯ç‚’é¥­ï¼‰ï¼Œä¸€å…± 4.4 SGDï¼ŒæŠ˜åˆäººæ°‘å¸å¤§çº¦ 23.6 å—ã€‚ç„¶åç­‰ç«¯ä¸Šæ¥äº†æ‰å‘ç°ï¼Œè¿™å°±æ˜¯ä¸ªåŠ äº†åŠç†Ÿé¸¡è›‹çš„æ–¹ä¾¿é¢ã€‚</p>
<p>ã€€ã€€Emmmâ€¦â€¦( Ã³ Ã— Ã²)</p>
<p>ã€€ã€€æ¥ä¸‹æ¥çš„ä¸€æ®µæ—¶é—´æˆ‘éœ€è¦ä»¥æ­¤ä¸ºåŸºç¡€é‡å¡‘æˆ‘çš„æ¶ˆè´¹è§‚ã€‚æˆ‘åœ¨å›½å†…ç”Ÿæ´»åœ¨ä¸€çº¿åŸå¸‚ï¼Œè‡ªè®¤ä¸ºæ¶ˆè´¹æ°´å¹³ä¹Ÿä¸ç®—ä½äº†ï¼Œä¸è¿‡ SG çš„ç‰©ä»·ä¾æ—§ä»¤äººéœ‡æƒŠã€‚</p>
<p>ã€€ã€€ä¸Šé¢è®²çš„éƒ½æ˜¯äº›æ§½ç‚¹ï¼Œä½†æ˜¯æˆ‘å¯¹æ­¤å¹¶ä¸è®¨åŒã€‚æ‰€æœ‰è®²åˆ°çš„æ§½ç‚¹å‡ ä¹éƒ½æ¥æºäºæˆ‘å¯¹äºæ–°ç¯å¢ƒçš„ä¸é€‚åº”ã€‚åŒ…æ‹¬ NUS ç¼ºå°‘å®¿èˆé¥®æ°´æœºå’Œæ´—è¡£æœºï¼Œå‡ºè¡Œä¸ä¾¿ç­‰ç­‰ï¼Œè¿™äº›åŸºæœ¬éƒ½æ˜¯åŸºäºæˆ‘åŸæ¥çš„å¤§å­¦ç¯å¢ƒä½œå‡ºçš„ç›´æ¥æ¯”è¾ƒã€‚ä¸€æ–¹é¢æˆ‘çš„å¤§å­¦æˆ‘è‚¯å®šå·²ç»ç†Ÿæ‚‰äº†ï¼Œå¦ä¸€æ–¹é¢æˆ‘çš„å¤§å­¦é¢ç§¯æ¯”è¾ƒå°ï¼Œç¡®å®ä¹Ÿä¸å­˜åœ¨ä»€ä¹ˆå‡ºè¡Œé—®é¢˜ã€‚</p>
<p>ã€€ã€€æˆ‘å¸Œæœ›æˆ‘èƒ½å°½å¿«é€‚åº”ï¼Œæ¯•ç«Ÿæˆ‘è¿˜å¾—åœ¨è¿™é‡Œå¾…ä¸€ä¸ªæœˆã€‚ä¸è¿‡åƒç½‘è´­ï¼Œç‚¹å¤–å–è¿™ç§äº‹æƒ…ï¼Œè™½ç„¶èƒ½è§£å†³æˆ‘çš„ç”¨é¤é—®é¢˜ï¼Œä½†æˆ‘ä¹Ÿä¸åœ¨è¿™é‡Œé•¿æœŸå±…ä½ï¼Œæˆ‘è‡ªå·±æ„Ÿè§‰ä¸å¤ªéœ€è¦ä¸ºæ­¤ç‰¹åœ°å»æä¸ª paynow ä¹‹ç±»çš„è´¦å·æ¥æ»¡è¶³è¿™äº›éœ€æ±‚ã€‚å†æ€ä¹ˆè¯´æˆ‘æ¥è¿™é‡Œçš„ä¸»è¦ä»»åŠ¡è¿˜æ˜¯äº¤æµå­¦ä¹ ï¼Œå¦‚æœä»¥åæƒ³æ¥è¿™é‡Œçš„è¯ï¼Œé‚£çº¿ä¸Šæ”¯ä»˜ä»€ä¹ˆçš„è¿Ÿæ—©ä¼šè§£å†³çš„ã€‚</p>
<p>ã€€ã€€ä»Šå¤©å…ˆèŠåˆ°è¿™ï¼Œä»¥ä¸‹å¥‰ä¸Šä¸€äº›å‡ºåˆ° NUS çš„å°æ”»ç•¥ï¼ˆä»…ä»…åŸºäºæˆ‘ç¬¬ä¸€å¤©çš„ä½“éªŒï¼Œåé¢å¯èƒ½ä¼šæ¨ç¿»ï¼‰ã€‚</p>
<blockquote>
<ol>
<li><p>å¿…é¡»ä¸‹è½½ NUS NextBus appï¼Œåœ¨ NUS äº¤æµåŸºæœ¬å¯ä»¥è§£å†³å¤§éƒ¨åˆ†å‡ºè¡Œé—®é¢˜ã€‚</p>
</li>
<li><p>ç½‘è´­å¯é€‰æ‹© Shopeeï¼›ç‚¹å¤–å–å¯é€‰æ‹© Grabï¼Œfoodpanda æˆ– Deliverooã€‚ä½†ç½‘ä¸Šå¤§éƒ¨åˆ†æ”»ç•¥æ”¯æŒä¼˜å…ˆé€‰ Grabï¼ˆåŠŸèƒ½é›†æˆï¼Œè¿˜èƒ½æ‰“è½¦ï¼‰ã€‚</p>
</li>
<li><p>ä¸å¤ªéœ€è¦æ‹…å¿ƒè‹±è¯­äº¤æµé—®é¢˜ã€‚è¿™è¾¹å¤§éƒ¨åˆ†çš„é¤é¥®äººå‘˜åªè¦ä¼šè¯´ä¸­æ–‡çš„ï¼ŒåŸºæœ¬èƒ½ä¸€çœ¼çœ‹å‡ºä½ æ˜¯ä¸­å›½å­¦ç”Ÿã€‚</p>
</li>
<li><p>è¿™è¾¹çš„é¥­å ‚ä¸å¤ªå¥½æ‰¾ï¼Œè€Œä¸”ä¸å®¹æ˜“åœ¨çº¿ä¸Šè·å–å¼€æ”¾ä¿¡æ¯ã€‚æ‰€ä»¥åˆšåˆ° SG æ—¶ä¸å¦¨å¤§èƒ†ä¸€ç‚¹ç›´æ¥å» U-Town è·å–ç¨³å®šé£Ÿç‰©æ¥æºã€‚</p>
</li>
<li><p>SG çš„é¤é¥®è´¹ç”¨æ¯‹åº¸ç½®ç–‘æ¯”å›½å†…è´µå¾—å¤šï¼Œä¸è¿‡ä¹Ÿæœ‰ä¸€äº›åŒºåˆ«ã€‚ä¸€èˆ¬æ€§ä»·æ¯”è¾ƒé«˜çš„å¤§æ¦‚æ˜¯åœ¨ 4.4 - 7 SGD è¿™ä¸ªä»·ä½ä¸Šï¼Œè‡³å°‘å¯¹äºæˆ‘ä¸€ä¸ªæˆå¹´äººæ¥è¯´ï¼Œè¿™ä¸ªä»·ä½å®Œå…¨èƒ½åƒé¥± + åƒå¥½ã€‚</p>
</li>
</ol>
</blockquote>
<hr>
<h1 id="2024-6-30-Sun"><a href="#2024-6-30-Sun" class="headerlink" title="2024-6-30 (Sun.)"></a>2024-6-30 (Sun.)</h1><p>ã€€ã€€ä¸å¾—ä¸è¯´ NUS çš„å®¿èˆå•äººé—´ä½çš„æå…¶èˆ’é€‚ï¼Œè™½ç„¶åºŠå°äº†ç‚¹ï¼Œåªèƒ½åˆšå¥½ç¡ä¸‹ä¸€ä¸ªäººï¼Œä½†æ˜¯å•äººé—´èˆ’æœå•Šï¼Œç‹ ç‹ åœ°æ»¡è¶³äº†æˆ‘çš„ç§äººç©ºé—´éœ€æ±‚ã€‚</p>
<p>ã€€ã€€ä¸­åˆæˆ‘çš„ä¸¤ä½æœ‹å‹ä¹Ÿåˆ°äº†ã€‚å› ä¸ºè¿™ä¸¤å¤©éƒ½æ˜¯ç»™æˆ‘ä»¬åŠå…¥ä½çš„ï¼Œæ‰€ä»¥æˆ‘æ—©ä¸€å¤©åˆ°çš„ç›¸å½“äºå¤šäº†ä¸€å¤©çš„é€‚åº”æœŸï¼ˆé€‚åº”æœŸæŒ‡çš„æ˜¯æ™šä¸Šç©æ–°åŠ å¡æœç›´æ¥å½“äº†ä¸€å› 4 ping æˆ˜å£« Â´ï½¡âœªÏ‰âœªï½¡ï½€ï¼‰ã€‚</p>
<p>ã€€ã€€æœ¬æ¥æ‰“ç®—æ˜¯åœ¨å®¿èˆ PGPR é™„è¿‘æ‰¾ä¸ªé¤å…åƒçš„ï¼ˆè¿™ä¸ªå±•å¼€ç®€ç›´å’Œæ˜¨å¤©ä¸€æ¨¡ä¸€æ ·ï¼‰ï¼Œç»“æœåˆåŒå’å•æ²¡æ‰¾åˆ°ï¼Œæ‰€ä»¥åˆåªèƒ½å» U-Town ã€‚ä¸è¿‡è¿™å›å»äº†ä¸ªæŒºä¸é”™çš„é¤å… FineFood ï¼Œå¯ä»¥è¯´å¾ˆç¬¦åˆå½“ä»£å¤§å­¦ç”Ÿçš„é¥­å ‚é£æ ¼ã€‚</p>
<div align="center"><img src="/2024/06/30/Summer-Workshop-Diary/FineFood.jpg" alt="FineFood" style="width:700px">FineFood Canteen</div>

<p>ã€€ã€€è¿™é‡Œé¢æœ‰è‡ªé€‰é¤ä¹Ÿæœ‰å¥—é¤ï¼Œè¿˜æœ‰é¥®æ–™ï¼Œè€Œä¸”æ€»çš„æ¥è¯´ä»·æ ¼ä¹Ÿèƒ½æ¥å—ã€‚åæ­£æˆ‘ç‚¹äº†è‡ªé€‰é¤ï¼Œä¸€ä»½èœã€ä¸€ä»½ç•ªèŒ„ç‚’è›‹ï¼ˆç®—ä½œè‚‰ï¼‰ã€ä¸€ä»½é»‘æ¤’ç‚’ç‰›è‚‰ä¸€å…± 6.2 SGD ã€‚ä»½é‡æ˜¯å¾ˆå¤Ÿçš„ï¼Œå°±ç®—æˆ‘æ²¡åƒæ—©é¥­ï¼Œåˆé¥­ä¹Ÿåƒå¾—æŒºé¥±ã€‚</p>
<p>ã€€ã€€æ™šä¸Šåœ¨æˆ‘ä»¬å®¿èˆåŒºçš„ä¸€ä¸ªå°å–éƒ¨ä¹°äº†ç‚¹ä¸œè¥¿è‰è‰äº†äº‹ï¼ˆå±…ç„¶ä¹ŸèŠ±äº† 4.4 SGDï¼‰ã€‚ä»Šå¤©åº”è¯¥å°±æ˜¯æœ€åçš„æ¯”è¾ƒè‡ªç”±çš„ä¸€å¤©äº†ã€‚æ˜å¤©æœ‰åŠ©ç†å¸¦é˜Ÿå‚è§‚å­¦æ ¡å’Œæ¬¢è¿æ™šå®´ï¼Œå¯ä»¥æœŸå¾…ä¸€ä¸‹ã€‚</p>
<hr>
<h1 id="2024-7-1-Mon"><a href="#2024-7-1-Mon" class="headerlink" title="2024-7-1 (Mon.)"></a>2024-7-1 (Mon.)</h1><p>ã€€ã€€ä»Šå¤©ä¸»è¦æœ‰ä¸¤ä¸ªæ´»åŠ¨ï¼šCampus Tour å’Œ Welcome Dinner ã€‚æ—©ä¸Šéšæ„å‚è§‚ï¼Œæœ‰å­¦ç”ŸåŠ©ç†ä»‹ç»å¼•å¯¼ã€‚ç„¶ååˆ°æ™šä¸Šå°±æ˜¯å» USC(University Sport Center) å‚åŠ æ¬¢è¿æ™šå®´ã€‚</p>
<div align="center"><img src="/2024/06/30/Summer-Workshop-Diary/com-3.jpg" alt="com3" style="width:700px">SoC COM 3</div>

<p>ã€€ã€€ç”±äºæƒ³æ›´å¥½åœ°ä¼‘æ¯ï¼Œæˆ‘æ²¡æœ‰èŠ±å¤ªå¤šæ—¶é—´åœ¨å‚è§‚æ ¡å›­ä¸Šã€‚æˆ‘å¤§æ¦‚äº†è§£äº†æˆ‘æ¥ä¸‹æ¥ä¸€ä¸ªæœˆçš„ä¸Šè¯¾æ•™å®¤ã€å›¾ä¹¦é¦†çš„å¤§è‡´ä½ç½®ã€é¥­å ‚å’Œé¤å…ç­‰ï¼Œå…¶å®å‰ä¸¤å¤©å·²ç»çœ‹å¾—å·®ä¸å¤šäº†ã€‚</p>
<p>ã€€ã€€è‡³äºæ¬¢è¿æ™šå®´ä¹Ÿæ²¡ä»€ä¹ˆç‰¹åˆ«çš„åœ°æ–¹ï¼Œè™½ç„¶æ˜¯è‡ªåŠ©ï¼Œä¸è¿‡ä½“é‡ä¸ç®—å¤§ï¼Œä»¥è‡³äºå½“æˆ‘æ™šä¸Šå¼€å§‹å†™æ—¥è®°æ—¶å·²ç»æ„Ÿåˆ°æœ‰äº›é¥¿äº†ã€‚æˆ‘èƒ½é¢„æ„Ÿåˆ°åœ¨æœªæ¥çš„ 4-5 å¤©å†…ï¼Œé¥®é£Ÿä»ç„¶ä¼šæˆä¸ºæˆ‘çš„ä¸€ä¸ªå›°æ‰°ä¹‹å¤„ã€‚ä¸è¿‡å‚è€ƒå‡ ä½åŒå­¦ï¼ˆå¤§ä½¬ï¼‰çš„é¤é¥®ä¹ æƒ¯ï¼Œåº”è¯¥ä¼šå¥½å¾ˆå¤šã€‚</p>
<div align="center"><img src="/2024/06/30/Summer-Workshop-Diary/welcome-dinner.jpg" alt="welcome dinner" style="width:700px">Place of Welcome Dinner</div>

<p>ã€€ã€€å€¼å¾—ä¸€æçš„æ˜¯ï¼Œåœ¨æ™šå®´ç»“æŸåï¼Œæˆ‘å’Œå‡ ä½åŒå­¦ä¸€èµ·å»äº†è‚¯ç‰¹å²—ï¼ˆåœ°é“ç«™ï¼Œå…¬äº¤è½¦å¯è¾¾ï¼‰ã€‚åœ°é“ç«™çš„é™„è¿‘æœ‰ä¸€ä¸ªè¶…å¸‚å« Fair Price ï¼Œé‡Œé¢çš„å•†å“å¯ä»¥è§£å†³å¤§éƒ¨åˆ†åˆåˆ°æ–°åŠ å¡çš„ç”Ÿæ´»ä¸ä¾¿é—®é¢˜ã€‚ï¼ˆè¿™ä¸ªè¶…å¸‚åœ¨ 2 æ¥¼ï¼Œæƒ³æ‰¾åˆ°å¯èƒ½è¦èŠ±äº›åŠŸå¤«ï¼‰</p>
<p>ã€€ã€€åœ¨è¶…å¸‚é‡Œå¯ä»¥æ‰¾åˆ°ä¸€äº›å°åƒã€é¥®å“ã€é¢åŒ…ï¼Œè¿˜æœ‰ç”Ÿæ´»ç”¨å“å¦‚æ°´æ¡¶ã€æ•å¤´ã€çº¸å·¾ã€æ´—æ¼±ç”¨å“ç­‰ã€‚è¿™é‡Œç”šè‡³è¿˜æœ‰æ–°é²œçš„æ°´æœï¼Œä½†æ˜¯æ™®éå¾ˆè´µâ€”â€”â€”æ–°åŠ å¡çš„æ°´æœä¼¼ä¹éƒ½å¾ˆè´µï¼Œå¯èƒ½è·Ÿä¾èµ–è¿›å£æœ‰å…³ã€‚ä¸è¿‡æˆ‘ä»¬æœ‰å¹¸å‘ç°äº†å›½å†…å– 5ã€6 å—é’±ï¼ˆRMBï¼‰çš„ä¸€ç§æ¤°å­æ°´ï¼Œåœ¨æ–°åŠ å¡å±…ç„¶åªéœ€è¦ 1 SGDï¼Œæ„å‘³ç€è¿™é‡Œçš„æ¤°å­æ°´å‡ ä¹å’Œå›½å†…çš„ä»·é’±ä¸€æ ·ï¼ï¼æˆ‘ä»¬å½“æ—¶å°±å†³å®šå¤§è§„æ¨¡è´­ä¹°ï¼Œä¸å¾—ä¸è¯´è¿™å¯¹äºæ–°åŠ å¡çš„å¤å¤©éå¸¸é€‚ç”¨ã€‚</p>
<div align="center"><img src="/2024/06/30/Summer-Workshop-Diary/fruit.jpg" alt="fruit" style="width:700px">Fruit in Fair Price</div>

<p>ã€€ã€€ä»¥ä¸Šå°±æ˜¯ä»Šå¤©çš„ä¸€äº›æ„Ÿå—ã€‚ä»æ˜å¤©å¼€å§‹å°±æ˜¯æ­£å¼ä¸Šè¯¾å’Œå†™é¡¹ç›®äº†ï¼Œæ—¥è®°åº”è¯¥ä¹Ÿä¸ä¼šå¤©å¤©å†™ï¼Œå¯èƒ½éš”ä¸€æ®µæ—¶é—´å†™ä¸€æ¬¡å­¦ä¹ å¿ƒå¾—å§ï¼ˆå­¦ä¹ ç¬”è®°å¦å¤–å†™ï¼‰ã€‚å›è§ï¼</p>
<h1 id="2024-7-2-Tue"><a href="#2024-7-2-Tue" class="headerlink" title="2024-7-2 (Tue.)"></a>2024-7-2 (Tue.)</h1><p>ã€€ã€€ä»Šå¤©æ—©ä¸Šå¼€è¯¾äº†ï¼ŒåŸºæœ¬ä¸Šæˆ‘å°±è¦å¼€å§‹ä¹ æƒ¯è¯¾ç¨‹å®‰æ’çš„æ—¶é—´ã€‚åƒä¸€äº› deep learning ä¹‹ç±»çš„è¯¾ç¨‹æ˜¯æ—©ä¸Šå’Œä¸‹åˆéƒ½æœ‰è¯¾çš„ï¼Œä¸€èˆ¬æ—©ä¸Š 9 ç‚¹åŠåˆ° 12 ç‚¹åŠï¼Œä¸‹åˆä¸¤ç‚¹åˆ°äº”ç‚¹ä¸Šè¯¾ï¼Œå¼ºåº¦æ¯”è¾ƒé«˜ï¼Œé¡¹ç›®æ¯”è¾ƒéš¾ä¹Ÿæ¯”è¾ƒç´¯ã€‚åƒæˆ‘çš„è¯¾ç¨‹æ˜¯å®æ—¶ 3D æ¸²æŸ“çš„è¯åªæœ‰ä¸‹åˆæœ‰è¯¾ï¼Œä»ä¸‹åˆä¸€ç‚¹ä¸Šåˆ°ä¸‹åˆå››ç‚¹ï¼Œå‰©ä¸‹çš„æ—¶é—´è‡ªç”±å®‰æ’ã€‚ç›¸å¯¹æ¥è¯´æˆ‘çš„è¯¾ç¨‹æ˜¯éå¸¸è½»æ¾çš„ï¼Œè€Œä¸”è¯¾ç¨‹éš¾åº¦æœ¬èº«ä¸é«˜ï¼ˆå‰ææ˜¯å¾ˆå¤šè€å¸ˆä¸Šè¯¾ä¸è®²çš„ä»£ç å†…å®¹è¦è‡ªå·±å­¦ä¼šï¼‰ã€‚è¿™æ ·å®½è£•çš„æ—¶é—´å®‰æ’ä¹Ÿç»™äº†åˆšæ¥æ–°åŠ å¡çš„æˆ‘ä¸å°‘åˆ°å¤„èµ°çš„æœºä¼šã€‚æ¯”å¦‚ä»Šæ™šå°±å»äº†æ–°åŠ å¡çš„å¤œé—´åŠ¨ç‰©å›­â€”â€”â€”â€” Night Safariã€‚</p>
<p>ã€€ã€€æˆ‘æ˜¯å’Œå‡ ä½æœ‹å‹ä¸€èµ·å»çš„ Night Safariï¼Œæœ‰ä¸€äº›æ˜¯è€æœ‹å‹äº†ï¼Œè¿˜æœ‰ä¸€äº›åˆšè®¤è¯†ä¸ä¹…ï¼Œä¸è¿‡æˆ‘ä»¬ä¹‹é—´æ°›å›´è¿˜ç®—æŒºå¥½ã€‚å¤œé—´åŠ¨ç‰©å›­å¸¦æ¥çš„ä½“éªŒä¸å…¶ä»–åŠ¨ç‰©å›­æœ‰å¾ˆå¤§ä¸åŒã€‚æˆ‘ä»¬å…ˆæ˜¯åæ¸¸è¡Œç”µç“¶è½¦ç»•äº†åŠ¨ç‰©å›­ä¸€åœˆï¼Œçœ‹åˆ°äº†ä¸å°‘å¤œé—´ç”Ÿæ´»çš„åŠ¨ç‰©å¦‚çŒ«å¤´é¹°ã€è±¹çŒ«ã€ä¸€äº›å¤§è±¡ç­‰ï¼Œåæ¥è§‰å¾—æ„çŠ¹æœªå°½åˆä»æ­¥è¡Œé“èµ°äº†ä¸€æ®µè·¯ã€‚ä¸€è¾¹å¤œé—´æ•£æ­¥ä¸€è¾¹è¿˜èƒ½å’Œæœ‹å‹ä»¬é—²èŠï¼Œè¿™å¯¹æˆ‘è¿™ä¸ª i äººæ¥è¯´ä¹Ÿæ˜¯ä¸€ç§å¥‡å¦™çš„ä½“éªŒï¼ˆå’Œå¤–å‘çš„äººäº¤æµçœŸçš„å®Œå…¨æ²¡æœ‰å¿ƒç†è´Ÿæ‹…ï¼ï¼‰ã€‚</p>
<div align="center"><img src="/2024/06/30/Summer-Workshop-Diary/nightzoo.jpg" alt="zoo" style="width:700px">Night Safari</div>

<p>ã€€ã€€æ€»çš„æ¥è¯´æˆ‘å·²ç»å¼€å§‹é€‚åº”è¿™è¾¹çš„ç”Ÿæ´»äº†ã€‚è™½ç„¶è¿™ä¸¤å¤©å¯èƒ½å› ä¸ºæ°´åœŸä¸æœï¼ˆæ–°åŠ å¡é¥®é£Ÿç±»å‹å¤šæ ·ï¼Œæˆ‘åƒçš„ä¹ŸåŸºæœ¬æ˜¯ä¸­å›½èœï¼Œå®Œå…¨ä¸åº”è¯¥æ‹‰è‚šå­ï¼‰è®©æˆ‘ä¼šæœ‰äº›éš¾å—ï¼Œä¸è¿‡è°ƒå…»ä¸€æ®µæ—¶é—´å°±ä¼šå¥½å¾ˆå¤šã€‚æˆ‘å¬ä¸€äº›è€å®¶åœ¨é‡åº†ï¼Œæµ™æ±Ÿçš„åŒå­¦éƒ½è¯´æ–°åŠ å¡è¿™è¾¹çš„ç¯å¢ƒå’Œæ¡ä»¶æ¯”å›½å†…å¥½ï¼Œå¯èƒ½æ˜¯æˆ‘ä½ä¸€çº¿åŸå¸‚çš„åŸå› å§ï¼Œæˆ‘è¿˜æ˜¯æ¯”è¾ƒå–œæ¬¢æˆ‘çš„å®¶ä¹¡ï¼Œä¸è¿‡æ–°åŠ å¡ç¯å¢ƒå¥½ç¡®å®æ˜¯å®¢è§‚çš„ï¼Œè‡³å°‘è¿™è¾¹å¹³å‡ç»¿æ¤è¦†ç›–é¢å¹¿ï¼Œè¡—é“å¹²å‡€ã€‚è¯¥è¯´ä¸è¯´å°å›½å®¶æœ‰å°å›½å®¶çš„ä¼˜åŠ¿ï¼Œåƒè¿™ç§é—®é¢˜æ²»ç†èµ·æ¥ç¡®å®æ–¹ä¾¿ï¼ˆæˆ‘æ€ä¹ˆå¼€å§‹çªå‘æ„Ÿæ…¨äº†ï¼Ÿï¼‰ã€‚</p>
<h1 id="2024-7-5-ï¼ˆFri-ï¼‰"><a href="#2024-7-5-ï¼ˆFri-ï¼‰" class="headerlink" title="2024-7-5 ï¼ˆFri.ï¼‰"></a>2024-7-5 ï¼ˆFri.ï¼‰</h1><p>ã€€ã€€ä»Šå¤©æ˜¯ç¬¬ä¸€å‘¨ä¸Šè¯¾çš„æœ€åä¸€å¤©ï¼Œå…³äºè¯¾ç¨‹çš„æ—¶é—´å®‰æ’å·²ç»å®Œå…¨é€‚åº”ã€‚æˆ‘å’Œæˆ‘çš„é˜Ÿå‹åŸºæœ¬ä¸Šåœ¨æ—©ä¸Šä¹ç‚¹åˆ°åç‚¹é†’ï¼Œåƒç‚¹ä¸œè¥¿è¡¥å……ä¸‹ç„¶åå»æ•™å®¤é¢„ä¹ æˆ–å¤ä¹ ä¸Šè¯¾å†…å®¹ï¼Œä¸‹åˆå››ç‚¹ä¸Šå®Œè¯¾å» Kent Ridge MRT(è‚¯ç‰¹å²—) åƒæ™šé¥­ï¼Œæœ‰æ—¶ä¹°ç‚¹å¤œå®µå¸¦å›å®¿èˆã€‚æ™šä¸Šå¦‚æœæ²¡æœ‰å°ç»„ä½œä¸šåŸºæœ¬å°±æ˜¯å„è‡ªåœ¨å®¿èˆå¹²æ´»æˆ–æ”¾æ¾ã€‚</p>
<p>ã€€ã€€ä»Šå¤©æˆ‘ä»¬å»äº†è‚¯ç‰¹çš„ä¸€å®¶é¤å…ï¼Œåƒåˆ°äº†æˆ‘æ¥æ–°åŠ å¡è¿™ä¹ˆå¤šå¤©ä»¥æ¥æœ€å¥½åƒçš„ä¸€é¡¿é¥­ï¼ˆä½†æ˜¯çˆ†äº† 9.9 SGD çš„é‡‘å¸ï¼‰ã€‚çœŸçš„éå¸¸æ¨èå»è¯•è¯•ï¼ä»–ä»¬é‚£å®¶çš„ç‚¸é¸¡ï¼Œé¸¡è‚‰çœŸçš„ç‰¹åˆ«å¤šï¼Œè€Œä¸”ä¸æŸ´ï¼Œ9.9 SGD ä¸€é¡¿ç®¡é¥±è€Œä¸”å¥½åƒï¼Œè¡€èµšï¼</p>
<p>ã€€ã€€By the wayï¼Œåˆšè¿›è‚¯ç‰¹å²—åœ°é“ç«™å·¦æ‰‹è¾¹çš„é£Ÿé˜ï¼Œä¸¤è¾¹æœ‰ä¸¤å®¶é¢åŒ…åº—ã€‚ä¸¤å®¶é¢åŒ…åº—åšçš„åå¤«é¥¼ä¹Ÿæ˜¯è¶…çº§å¥½åƒï¼ç°åšç°å–ï¼Œæœ‰è˜¸é…±çš„ä¸€ä¸ª 2.3 SGDï¼Œè¿˜ç®—æ˜¯æ¯”è¾ƒåˆé€‚çš„ä»·æ ¼äº†ï¼ˆå·²ç»é€æ¸é€‚åº”æ–°åŠ å¡çš„ç‰©ä»·ï¼‰ã€‚</p>
<p>ã€€ã€€ä¸ªäººæ„Ÿè§‰é™¤äº†è¿™ä¸¤ç‚¹ä»¥å¤–ï¼Œè‚¯ç‰¹å²—çš„é£Ÿé˜å°±æ²¡ä»€ä¹ˆæ¨èçš„äº†ï¼ŒåŸºæœ¬æ¯”ä¸ä¸Šå›½å†…çš„é¤é¥®ï¼Œä¸è¿‡è¿™ä¸¤å®¶çœŸçš„æ˜¯ï¼Œç»äº†ã€‚</p>
<div align="center"><img src="/2024/06/30/Summer-Workshop-Diary/fried-chi.jpg" alt="fried-chicken" style="width:700px">Food in Kent Ridge MRT</div>



<h1 id="2024-7-7-Sun"><a href="#2024-7-7-Sun" class="headerlink" title="2024-7-7 (Sun.)"></a>2024-7-7 (Sun.)</h1><p>ã€€ã€€ä»Šå¤©æˆ‘è¦æ”¶å›å‰é¢çš„ä¸€ä¸ªæš´è®ºâ€”â€”â€”â€” U-Town è·Ÿè‚¯ç‰¹å²—æ¯”ä¹Ÿä¸æ˜¯è¿™ä¹ˆç¼ºå°‘ç¾é£Ÿã€‚ä»Šå¤©ä¸­åˆå»äº†è¶Ÿ U-Town ï¼Œæœ¬æ¥æ˜¯æƒ³ç®€å•åœ¨ FineFood åƒä¸€ä¸‹çš„ï¼Œç»“æœåœ¨ä¸€äº›å¥‡ç‰¹æŒ‡å¼•ä¸‹ï¼Œæˆ‘æ‰¾åˆ°äº†ä¸€ä¸ªæ–°åœ°æ–¹ã€‚</p>
<div align="center"><img src="/2024/06/30/Summer-Workshop-Diary/u-town-dine.jpg" alt="u-town-dine" style="width:700px">More in U-Town</div>

<p>ã€€ã€€è¿™åœ°æ–¹å¥½åƒçš„ä¸œè¥¿ä¹ŸæŒºå¤šçš„ï¼Œè‡³å°‘æˆ‘åƒä¸Šäº†è´¨é‡è¾ƒé«˜çš„ç™½åˆ‡é¸¡ã€‚è¿™ä¸ªé¤å…å…¶å®å°±æ˜¯åœ¨ FineFood çš„é‚£æ ‹æ¥¼ç»§ç»­å¾€é‡Œèµ°çš„åœ°æ–¹ï¼Œä¸ç®—éš¾æ‰¾ï¼Œè€Œä¸”é‡Œé¢å–çš„ä¸œè¥¿è¿˜ç®—æ¯”è¾ƒå¤šæ ·ã€‚é™¤äº†æˆ‘åƒçš„ä¸­å›½èœï¼Œè¿˜æœ‰æ°´æœã€é¥®å“ã€å’Œä¸€äº›å…¶ä»–å›½å®¶çš„èœå¼ã€‚ä¸ªäººæ„Ÿè§‰æ¯” FineFood å¤§å¤šæ•°å¥—é¤å®æƒ ã€‚</p>
<p>ã€€ã€€ç”±äºä»Šå¤©å‡ ä¹ä¸€å¤©éƒ½åœ¨ä¸‹é›¨ï¼ŒåŸæœ¬æˆ‘é™¤äº†ä¸­åˆé›¨åœé‚£ä¼šåƒäº†ä¸ªåˆé¥­ï¼Œå°±è®¡åˆ’ä¸€ç›´å¾…åœ¨å®¿èˆé‡Œäº†ã€‚ç»“æœååˆ†æ„å¤–åœ°ï¼Œå¤§çº¦åœ¨ä¸‹åˆ 6 ç‚¹å·¦å³ï¼Œæˆ‘å‘ç°é›¨åœäº†å¥½ä¸€ä¼šå„¿äº†ï¼Œäºæ˜¯å½“å³äº§ç”Ÿäº†ä¸€ä¸ªå‡ºæ¸¸çš„æƒ³æ³•ï¼Œå¹¶ä¸”ç«‹å³ä»˜è¯¸è¡ŒåŠ¨ã€‚</p>
<div align="center"><img src="/2024/06/30/Summer-Workshop-Diary/raffle.jpg" alt="raffle" style="width:700px">Raffle Place</div>

<p>ã€€ã€€æˆ‘çš„æƒ³æ³•æ¥å¾—ä»“ä¿ƒï¼Œæ²¡æ¥å¾—åŠå«ä¸Šå…¶ä»–äººï¼Œæ‰€ä»¥ç‹¬è‡ªä¸€äººå°±ååœ°é“å»äº† Raffle Place åœ°é“ç«™ï¼Œå¹¶ä»é‚£è¾¹ç©¿è¿‡ä¸€æ ‹æ ‹å»ºç­‘ï¼Œæœ€ç»ˆæ¥åˆ°äº†æµ·æ¹¾è¾¹ã€‚</p>
<p>ã€€ã€€è¿™é‡Œï¼Œå°±æ˜¯æ–°åŠ å¡çš„åœ°æ ‡çº§æ™¯ç‚¹â€”â€”â€”â€”é±¼å°¾ç‹®å…¬å›­ (Merlion Park)ã€‚åœ¨é±¼å°¾ç‹®å…¬å›­çš„æµ·æ¹¾å²¸è¾¹ï¼Œå¯ä»¥ç›´æ¥çœ‹è§å¯¹å²¸çš„é‡‘æ²™ç©ºä¸­èŠ±å›­é…’åº— (Marina Bay Sands Hotel)ï¼Œä¹Ÿåªæœ‰åœ¨è¿™è¾¹æ‰èƒ½çœ‹åˆ°è¿™ä¸ªä¸‰æ ‹å»ºç­‘çš„å…¨è²Œã€‚</p>
<div align="center"><img src="/2024/06/30/Summer-Workshop-Diary/tri-hotel.jpg" alt="MBS Hotel" style="width:700px">MBS Hotel</div>

<p>ã€€ã€€å½“ç„¶äº†ï¼Œè¿˜æœ‰æ–°åŠ å¡æœ€è‘—åçš„æ™¯ç‚¹ä¹‹ä¸€â€”â€”â€”â€”é±¼å°¾ç‹®é›•åƒã€‚</p>
<div align="center"><img src="/2024/06/30/Summer-Workshop-Diary/merlion.jpg" alt="merlion" style="width:700px">the Merlion</div>

<p>ã€€ã€€ä¸å¾—ä¸è¯´ï¼Œå“ªæ€•æ˜¯æ˜ŸæœŸå¤©ï¼Œè¿™é‡Œçš„äººä¾ç„¶å¾ˆå¤šï¼Œå¯è§è¿™é‡Œç¡®å®æ˜¯ä¸è´Ÿç››åã€‚å› ä¸ºæ–°åŠ å¡ä¸´è¿‘å›½åº†ï¼Œæ‰€ä»¥æ¯å‘¨å…­æ™šä¸Šéƒ½ä¼šåœ¨è¿™ä¸ªæµ·æ¹¾æ”¾çƒŸèŠ±ï¼Œæˆ‘æ˜¨å¤©æ²¡æ¥å¯æƒœäº†ï¼Œä½†ä»Šå¤©æ¥è¿™è¾¹ä¾ç„¶æœ‰ä¸€äº›æƒŠå–œçš„æ”¶è·ã€‚</p>
<div align="center"><img src="/2024/06/30/Summer-Workshop-Diary/Jazz.jpg" alt="jazz" style="width:700px">Jazz Band Performance</div>

<p>ã€€ã€€æœ€å¤§çš„æƒŠå–œè«è¿‡äºå½“æˆ‘èµ°è¿‡é±¼å°¾ç‹®å…¬å›­ï¼Œç»è¿‡ä¸€åº§æ­¥è¡Œæ¡¥ï¼Œåˆç»•è¿‡äº†æ»¨æµ·è‰ºæœ¯ä¸­å¿ƒï¼ˆä¸€ä¸ªæ¦´è²å½¢çŠ¶çš„å‰§åœºï¼‰åï¼Œæˆ‘æ„å¤–å‘ç°äº†ä¸€ä¸ªçˆµå£«ä¹é˜Ÿåœ¨ Esplanade Mall æ¼”å¥ã€‚ç°åœºå¯ä»¥è¯´æ˜¯åæ»¡äº†äººï¼Œè¿å¾ˆå¤šç»è¿‡çš„æ¸¸å®¢éƒ½åœä¸‹æ¥ï¼Œå›´åœ¨äº†åœºåœ°å¤–é¢ï¼Œç«™ç€å¬ä»–ä»¬çš„æ¼”å¥ã€‚å¯ä»¥è¯´åœ¨è¿™æ ·çš„ä¸€ä¸ªåœºæ™¯ä¸‹ï¼Œçˆµå£«ä¹æ‹¥æœ‰æ— ä¸ä¼¦æ¯”çš„å¸å¼•åŠ›ã€‚æ— è®ºæ˜¯åäººï¼Œæ¬§æ´²æ¸¸å®¢ï¼Œè¿˜æ˜¯å°åº¦äººï¼Œé»‘äººï¼Œå‡ ä¹éƒ½èƒ½è¢«è¿™æ ·çš„æ¼”å¥å¸å¼•è¿‡æ¥ã€‚æ›´æœ‰æ„æ€çš„æ˜¯ï¼Œæˆ‘æ³¨æ„åˆ°ä¸€ä½ç«™ç€çš„åäººå¤§å”ï¼Œæå‡ºäº†ä»–çš„ä¸€ä¸ªå°æœ¬æœ¬ï¼Œç”¨ç­¾å­—ç¬”ç»™æ¯ä¸ª solo çš„ä¹æ‰‹ç”»å†™ç”Ÿã€‚è™½è¯´ç”»çš„ä¸å¤ªåƒï¼Œè€Œä¸”æ˜¯ç«™ç€éšæ‰‹ç”»çš„ï¼Œä½†æ˜¯ç¥æ€ç¡®å®åˆ°ä½äº†ï¼Œä¹Ÿç®—æ˜¯åˆ«æœ‰ä¸€ç•ªé£æ ¼ã€‚</p>
<p>ã€€ã€€æœ€åè¿™æ”¯ä¹é˜Ÿè¿˜ä¸“é—¨æ¼”å¥äº†ä¸€é¦–ä¸­å›½ä¹æ›²ï¼Œã€Šä¸‡æ°´åƒå±±æ€»æ˜¯æƒ…ã€‹ï¼Œç°åœºåå“éå¸¸å¥½ã€‚</p>
<div align="center"><img src="/2024/06/30/Summer-Workshop-Diary/tri-hotel-night.jpg" alt="MBS Hotel" style="width:700px">MBS Hotel(night)</div>

<p>ã€€ã€€ç­‰æˆ‘æ„è¯†åˆ°æˆ‘åœ¨é‚£é‡Œå¬äº†å°†è¿‘åŠä¸ªå°æ—¶æ—¶ï¼Œå¤©å·²ç»å‡ ä¹é»‘é€äº†ã€‚äºæ˜¯æˆ‘å¼€å§‹å¾€å›èµ°ï¼Œèµ°æ—¶è·¯è¿‡äº†é±¼å°¾ç‹®é›•åƒï¼Œåˆæ‹äº†å‡ å¼ é±¼å°¾ç‹®å’Œç©ºä¸­èŠ±å›­é…’åº—å’Œå‚æ™šçš„æ—¶å€™åšå¯¹æ¯”ã€‚åœ¨å¾€åœ°é“ç«™èµ°çš„é€”ä¸­ï¼Œæˆ‘ç‰¹åœ°æ‹åˆ°å¯¹å²¸å»çœ‹äº†çœ‹è±å¼—å£«æ•™å ‚ã€‚æ®è¯´è±å¼—å£« (Raffle) æ˜¯è‹±å›½äººï¼Œæ¥åˆ°æ–°åŠ å¡æ®–æ°‘åï¼Œæœ‰æ•ˆä¿ƒè¿›äº†è¿™ä¸€å¸¦çš„ç»æµå‘å±•ï¼Œæ‰€ä»¥åäººä¸ºäº†çºªå¿µä»–ï¼Œä¸ºä»–åœ¨è¿™é‡Œå»ºäº†ä¸€åº§æ•™å ‚ã€‚è€Œç°åœ¨ï¼Œæ•™å ‚å¤–çš„è‰åœ°ä¸Šï¼Œæœ‰ä¸å°‘äººé“ºå¼€äº†æ¯¯å­ï¼Œè¶ç€æ™šé£æ¸…å‡‰åœ¨è‰åœ°ä¸Šä¼‘æ¯ã€é‡ç‚Šï¼Œç”šè‡³æœ‰äººæ‹¿ç€å°éŸ³ç®±å¿˜æˆ‘åœ°å”±æ­Œï¼Œé¢‡æœ‰ä¸€ç§å›½å†…å¹¿åœºçš„çƒŸç«æ°”æ¯ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ç®—æ˜¯çœŸæ­£ä½“ä¼šåˆ°äº†æ–°åŠ å¡çš„ç™¾å§“ç”Ÿæ´»çš„ä¸€è§’ã€‚</p>
<p>ã€€ã€€å½“æˆ‘å›åˆ°å®¿èˆï¼Œæ—¶é—´ä¹Ÿæ‰ä¹ç‚¹åŠï¼Œæ˜å¤©è¿˜è¦ç»§ç»­ä¸Šè¯¾ï¼Œä»Šå¤©å°±å…ˆå†™åˆ°è¿™å§ã€‚</p>
<h1 id="2024-7-13-Sat"><a href="#2024-7-13-Sat" class="headerlink" title="2024-7-13 (Sat.)"></a>2024-7-13 (Sat.)</h1><p>ã€€ã€€ä¸Šå‘¨ä¸æ˜¯è‡ªå·±è·‘å»äº†é±¼å°¾ç‹®å…¬å›­å˜›ï¼Œè¿˜æ˜¯æ˜ŸæœŸå¤©æ²¡ç¢°ä¸ŠçƒŸèŠ±ã€‚è¿™æ˜ŸæœŸä¸€å¬è¯´</p>
]]></content>
      <categories>
        <category>Summer Camp</category>
      </categories>
      <tags>
        <tag>Exchange</tag>
        <tag>Dairy</tag>
      </tags>
  </entry>
  <entry>
    <title>NUS Soc SWS3005  å®æ—¶ 3D å›¾å½¢æ¸²æŸ“</title>
    <url>/2024/06/27/Real-Time-Rendering/</url>
    <content><![CDATA[<h1 id="I-Pre-Knowledge-Phase-1"><a href="#I-Pre-Knowledge-Phase-1" class="headerlink" title="I. Pre-Knowledge (Phase 1)"></a>I. Pre-Knowledge (Phase 1)</h1><h2 id="Image-Formation"><a href="#Image-Formation" class="headerlink" title="Image Formation"></a>Image Formation</h2><blockquote>
<p>How does a realistic graphic form? </p>
</blockquote>
<h3 id="Elements-of-Image-Formation"><a href="#Elements-of-Image-Formation" class="headerlink" title="Elements of Image Formation"></a>Elements of Image Formation</h3><ul>
<li>Objects</li>
<li>Viewer</li>
<li>Light sources</li>
<li>Materials (æè´¨)<ul>
<li>Attributes that govern how light interacts with the materials in the scene</li>
</ul>
</li>
</ul>
<h3 id="Models"><a href="#Models" class="headerlink" title="Models"></a>Models</h3><p><strong>Know about Pinhole Camera</strong></p>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr1.png" alt="Pinhole Camera" style="zoom:60%"></div>

<p>Use trigonometry(ä¸‰è§’å‡ ä½•) to find <strong>projection</strong> of 3D point at $(x, y, z)$</p>
<blockquote class="blockquote-center">
<p>$<br>x_p=-dx/z\ \ \ \ y_p=-dy/z\ \ \ \ z_p=-d<br>$</p>

</blockquote>
<p><strong>Synthetic Camera Model (åˆæˆç›¸æœºæ¨¡å‹)</strong></p>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr2.png" alt="Synthetic Camera Model
" style="zoom:60%"></div>

<p><strong>Luminance and Color Images (å…‰çº¿ä¸é¢œè‰²çš„æ˜ å°„)</strong></p>
<ul>
<li>Luminance Image<ul>
<li>Monochromatic(å•è‰²)<ul>
<li>Values are gray levels</li>
<li>Analogous to working with black and white film or television</li>
</ul>
</li>
</ul>
</li>
<li>Color Image<ul>
<li>Has perceptional attributes of hue(è‰²ç›¸), saturation(é¥±å’Œåº¦), and lightness</li>
</ul>
</li>
</ul>
<p>â†“</p>
<ul>
<li>Representation of Color<ul>
<li><font color="red">Additive color</font>: Form a color by adding amounts of three primaries<font color="grey">(RGB)</font><ul>
<li>E.g. CRTs, projection systems, positive film</li>
</ul>
</li>
<li><font color="red">Subtractive color</font>: Form a color by filtering white light with <font color="cyan">Cyan (C)</font>, <font color="magenta">Magenta (M)</font>, and <font color="deyellow">Yellow (Y)</font> filters<ul>
<li><font color="blue">Noted:</font> Cyan = â€“Red; Magenta = â€“Green; Yellow = â€“Blue</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<h2 id="Graphics-System-Design"><a href="#Graphics-System-Design" class="headerlink" title="Graphics System Design"></a>Graphics System Design</h2><font size="4">A graphics system has two main components</font>

<ol>
<li>Application Programmer Interface (API)<ul>
<li>For specifying the <font color="red"><b>scene</b></font><ul>
<li>objects, materials, viewer, lights</li>
</ul>
</li>
<li>For <font color="red">configuring/controlling</font> the system</li>
</ul>
</li>
<li>Renderer<ul>
<li>Renders the images<ul>
<li>Using scene info and system configuration</li>
</ul>
</li>
</ul>
</li>
</ol>
<h3 id="Rendering-Approaches"><a href="#Rendering-Approaches" class="headerlink" title="Rendering Approaches"></a>Rendering Approaches</h3><ol>
<li><strong>Ray tracing:</strong> follow rays of light from center of projection until they are absorbed by objects or go off to infinity<ul>
<li>ç¬¦åˆç‰©ç†è§£é‡Šï¼Œæ³›ç”¨æ€§å¹¿ï¼›ä½†æ˜¯é€Ÿåº¦æ…¢ï¼Œæ€§èƒ½ä½</li>
</ul>
</li>
<li>Radiosity: Energy based approach<ul>
<li>éå¸¸æ…¢ä¸”ä¸æ³›ç”¨</li>
</ul>
</li>
</ol>
<p><strong>Practical Approach</strong></p>
<ol>
<li><font coklor="red"><b>Polygon Rasterization</b></font>(å¤šè¾¹å½¢å…‰æ …)</li>
</ol>
<blockquote>
<p>3D ç‰©ä½“å¯ä»¥è¿‘ä¼¼åœ°è¡¨ç¤ºä¸ºå¹³é¢å¤šè¾¹å½¢åˆ»é¢ (planar polygonal facets) çš„ç½‘æˆ–ç½‘æ ¼</p>
</blockquote>
<table>
<tr>
<td><img src="/2024/06/27/Real-Time-Rendering/rtr3.png" alt="polygon rasterization
" style="zoom:60%"></td>
<td><img src="/2024/06/27/Real-Time-Rendering/rtr4.png" alt="polygon rasterization
" style="zoom:40%"></td>
</tr>
</table>

<font color="blue">Pipeline architecture</font>

<blockquote>
<p>The pipeline consists of stages that each primitive (e.g. polygon) must go through</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Vertices -&gt; |Vertex processor| -&gt; |Clipper and primitive assembler| -&gt; |Rasterizer| </span><br><span class="line">-&gt; |Fragment processor| -&gt; Pixels</span><br></pre></td></tr></table></figure>
<p>(i) Vertex Processing</p>
<ul>
<li>Much of the work in the pipeline is in converting object representations from one coordinate system to another<ul>
<li>Object coordinates</li>
<li>Camera (eye) coordinates</li>
<li>Screen coordinates</li>
</ul>
</li>
<li>Also computes vertex colors</li>
</ul>
<p>(ii) Projection</p>
<ul>
<li>Projection is the process that combines the <strong>3D</strong> viewer with the <strong>3D</strong> objects to produce the <strong>2D</strong> image<ul>
<li>Perspective projections: all projectors meet at the center of projection</li>
<li>Parallel projection: projectors are parallel, center of projection is replaced by a direction of projection</li>
</ul>
</li>
</ul>
<p>(iii) Clipping</p>
<ul>
<li>Simulate a <font color="red">virtual camera</font> to clip the images</li>
</ul>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr5.png" alt="clip" style="zoom:70%"></div>



<p>(iv) <font color="red">Rasterization</font></p>
<ul>
<li>Rasterizer produces a set of <a href="#fragment">fragments</a> for each object</li>
<li><a name="fragment">Fragments</a> are â€œpotential pixelsâ€<ul>
<li>Have a location in frame bufffer</li>
<li>Color and depth attributes</li>
</ul>
</li>
</ul>
<blockquote>
<p>Fragment Processing</p>
<ul>
<li>Fragments are processed to determine the color of the corresponding pixel in the frame buffer</li>
<li>Colors can be determined by texture mapping or interpolation(æ’å€¼) of vertex colors</li>
<li>Fragments may be blocked/occluded(é˜»å¡) by other fragments closer to the camera<ul>
<li>Using Hidden-surface removal</li>
</ul>
</li>
</ul>
</blockquote>
<hr>
<h2 id="API-Contents"><a href="#API-Contents" class="headerlink" title="API Contents"></a>API Contents</h2><ul>
<li><font color="green">Recall: Functions that specify what we need to form an image</font><ul>
<li>Objects</li>
<li>Viewer</li>
<li>Light Source(s)</li>
<li>Materials</li>
</ul>
</li>
</ul>
<h3 id="Object-Specifications"><a href="#Object-Specifications" class="headerlink" title="Object Specifications"></a>Object Specifications</h3><ul>
<li>Most APIs support a limited set of primitives including<ul>
<li>Points (0D object)</li>
<li>Line segments (1D objects)</li>
<li>Polygons (2D objects)</li>
<li>Some curves and surfaces<ul>
<li>Quadrics</li>
<li>Parametric polynomials</li>
</ul>
</li>
</ul>
</li>
<li>All are defined through locations in space or vertices</li>
</ul>
<h3 id="Camera-Specification"><a href="#Camera-Specification" class="headerlink" title="Camera Specification"></a>Camera Specification</h3><ul>
<li>Six degrees of freedom<ul>
<li>Position of center of lens</li>
<li>Orientation</li>
</ul>
</li>
<li>Lens</li>
<li>Film size</li>
<li>Orientation of film plane</li>
</ul>
<h3 id="Lights-and-Materials"><a href="#Lights-and-Materials" class="headerlink" title="Lights and Materials"></a>Lights and Materials</h3><ul>
<li>Types of lights<ul>
<li>Point sources vs distributed sources</li>
<li>Spot lights</li>
<li>Near and far sources</li>
<li>Color properties</li>
</ul>
</li>
<li>Material properties<ul>
<li>Absorption: color properties</li>
<li>Scattering<ul>
<li>Diffuse</li>
<li>Specular</li>
</ul>
</li>
</ul>
</li>
</ul>
<div align="center"><font color="grey" size="5">----- <font face="Segoe Script">Let's start Phase 2!</font> -----</font></div>

<h1 id="II-Elementary-OpenGL-Programming"><a href="#II-Elementary-OpenGL-Programming" class="headerlink" title="II. Elementary OpenGL Programming"></a>II. Elementary OpenGL Programming</h1><h2 id="OpenGL-Libraries"><a href="#OpenGL-Libraries" class="headerlink" title="OpenGL Libraries"></a>OpenGL Libraries</h2><h3 id="Core-Library"><a href="#Core-Library" class="headerlink" title="Core Library"></a>Core Library</h3><ul>
<li>OpenGL core library<ul>
<li>OpenGL32 on Windows</li>
<li>GL on most unix/linux systems ( <code>libGL.a</code> )</li>
</ul>
</li>
<li>OpenGL Utility Library ( GLU )<ul>
<li>Provides functionality in OpenGL core but avoids having to rewrite code</li>
</ul>
</li>
<li>Links with window system<ul>
<li><code>GLX</code> for X window systems</li>
<li><code>WGL</code> for Windows</li>
<li><code>AGL</code> for Macintosh</li>
</ul>
</li>
</ul>
<h3 id="GLUT-FreeGLUT-Libraries"><a href="#GLUT-FreeGLUT-Libraries" class="headerlink" title="GLUT / FreeGLUT Libraries"></a>GLUT / FreeGLUT Libraries</h3><ul>
<li><strong>GLUT = OpenGL Utility Toolkit</strong><ul>
<li><font color="red"><b>Not</b></font> part of OpenGL</li>
<li>Provides functionality common to all window systems<ul>
<li>Open a window</li>
<li>Get input from mouse and keyboard</li>
<li>Menus</li>
<li>Event-driven</li>
</ul>
</li>
<li>Code is portable but GLUT lacks the functionality of a good  toolkit for a specific platform<ul>
<li>No slide bars</li>
</ul>
</li>
</ul>
</li>
<li><a href="http://freeglut.sourceforge.net/">FreeGLUT</a></li>
</ul>
<h3 id="Software-Organization"><a href="#Software-Organization" class="headerlink" title="Software Organization"></a>Software Organization</h3><div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr6.png" alt="GL Organ" style="zoom:70%"></div>



<h2 id="Basic-OpenGL-Rendering-Pipeline"><a href="#Basic-OpenGL-Rendering-Pipeline" class="headerlink" title="Basic OpenGL Rendering Pipeline"></a>Basic OpenGL Rendering Pipeline</h2><ul>
<li>To render a primitive using OpenGL, the primitive goes through the following main stages: <ul>
<li><font color="green">Goal:</font> Turning primitive into pixels</li>
</ul>
</li>
</ul>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr7.png" alt="stage 1" style="zoom:70%"></div>



<h3 id="OpenGL-Functions"><a href="#OpenGL-Functions" class="headerlink" title="OpenGL Functions"></a>OpenGL Functions</h3><ul>
<li>Specify primitives<ul>
<li>E.g. points, line segments, triangles, quadrilaterals, polygons </li>
</ul>
</li>
<li>Specify vertex attributes<ul>
<li>E.g. color, normal vector, material, texture coordinates</li>
</ul>
</li>
<li>Specify transformations<ul>
<li>E.g. modeling, viewing</li>
</ul>
</li>
<li>Control (<code>GLUT</code>)</li>
<li>Input (<code>GLUT</code>)</li>
<li>Query: â€œask for the state of objectâ€ etc.</li>
</ul>
<h3 id="OpenGL-State"><a href="#OpenGL-State" class="headerlink" title="OpenGL State"></a>OpenGL State</h3><ul>
<li><font color="red">OpenGL is a <b>state machine</b></font>
</li>
<li><p>OpenGL functions are <font color="red">of two types</font></p>
<ul>
<li>Primitive generating<ul>
<li>Can cause output if primitive is visible</li>
<li>How vertices are processed and appearance of primitive are controlled by the state</li>
</ul>
</li>
<li>State changing<ul>
<li>Transformation functions</li>
<li>Attribute functions</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="Simple-Concept"><a href="#Simple-Concept" class="headerlink" title="Simple Concept"></a>Simple Concept</h2><h3 id="Examples"><a href="#Examples" class="headerlink" title="Examples"></a>Examples</h3><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;GL/glut.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">mydisplay</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="built_in">glClear</span>(GL_COLOR_BUFFER_BIT); </span><br><span class="line">    <span class="built_in">glBegin</span>(GL_POLYGON); </span><br><span class="line">    <span class="built_in">glVertex2f</span>(<span class="number">-0.5</span>, <span class="number">-0.5</span>); </span><br><span class="line">    <span class="built_in">glVertex2f</span>(<span class="number">-0.5</span>, <span class="number">0.5</span>); </span><br><span class="line">    <span class="built_in">glVertex2f</span>(<span class="number">0.5</span>, <span class="number">0.5</span>); </span><br><span class="line">    <span class="built_in">glVertex2f</span>(<span class="number">0.5</span>, <span class="number">-0.5</span>); </span><br><span class="line">    <span class="built_in">glEnd</span>();</span><br><span class="line">    <span class="built_in">glFlush</span>(); </span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span>** argv)</span> </span>&#123;</span><br><span class="line">    <span class="built_in">glutInit</span>(&amp;argc, argv);</span><br><span class="line">    <span class="built_in">glutCreateWindow</span>(<span class="string">&quot;simple&quot;</span>); </span><br><span class="line">    <span class="built_in">glutDisplayFunc</span>(mydisplay); </span><br><span class="line">    <span class="built_in">glutMainLoop</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>This code is to draw a white square in black background.</p>
</blockquote>
<h3 id="Event-Loop"><a href="#Event-Loop" class="headerlink" title="Event Loop"></a>Event Loop</h3><p>Note that the program defines a <font color="red">display callback</font> function named <code>mydisplay</code></p>
<ul>
<li>Every GLUT program <font color="red"><b>must</b></font> have a display callback</li>
<li>The display callback is executed whenever OpenGL decides the display must be refreshed<ul>
<li>For example, when the window is opened</li>
</ul>
</li>
<li>The <strong>main function ends</strong> with the program entering an event loop</li>
</ul>
<h2 id="Program-Structure"><a href="#Program-Structure" class="headerlink" title="Program Structure"></a>Program Structure</h2><ul>
<li>Most OpenGL programs have a similar structure that consists of the following functions<ul>
<li><code>main()</code>: <ul>
<li>defines the callback functions </li>
<li>opens one or more windows with the required properties</li>
<li>enters event loop (last executable statement)</li>
</ul>
</li>
<li><code>init()</code>: sets the state variables<ul>
<li>Viewing</li>
<li>Attributes</li>
</ul>
</li>
<li>callbacks<ul>
<li>Display callback function</li>
<li>Input and window functions</li>
</ul>
</li>
</ul>
</li>
</ul>
<blockquote>
<p>Then weâ€™re going to see an explicit form of <code>Example</code></p>
</blockquote>
<h3 id="main"><a href="#main" class="headerlink" title="main()"></a><code>main()</code></h3><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;GL/glut.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span>** argv)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="built_in">glutInit</span>(&amp;argc, argv); </span><br><span class="line">	<span class="built_in">glutInitDisplayMode</span>(GLUT_SINGLE | GLUT_RGB); </span><br><span class="line">	<span class="built_in">glutInitWindowSize</span>(<span class="number">500</span>, <span class="number">500</span>); </span><br><span class="line">	<span class="built_in">glutInitWindowPosition</span>(<span class="number">0</span>, <span class="number">0</span>); </span><br><span class="line">	<span class="built_in">glutCreateWindow</span>(<span class="string">&quot;simple2&quot;</span>); </span><br><span class="line">	<span class="built_in">glutDisplayFunc</span>(mydisplay); </span><br><span class="line">	<span class="built_in">init</span>(); </span><br><span class="line">	<span class="built_in">glutMainLoop</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li><code>glutInit</code> â€”â€” allows application to get command line arguments and initializes system</li>
<li><code>gluInitDisplayMode</code> â€”â€” requests properties for the window (the rendering context)<ul>
<li>RGB color</li>
<li>Single buffering</li>
<li>Properties logically ORed together</li>
</ul>
</li>
<li><code>glutWindowSize</code> â€”â€” in pixels</li>
<li><code>glutWindowPosition</code> â€”â€” from top-left corner of display</li>
<li><code>glutCreateWindow</code> â€”â€” create window with title â€œsimpleâ€</li>
<li><code>glutDisplayFunc</code> â€”â€” display callback</li>
<li><code>glutMainLoop</code> â€”â€” enter infinite event loop</li>
</ul>
<h3 id="init"><a href="#init" class="headerlink" title="init()"></a><code>init()</code></h3><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">init</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="built_in">glClearColor</span>(<span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">1.0</span>); </span><br><span class="line">	<span class="comment">// black clear color with opaque window</span></span><br><span class="line">	<span class="built_in">glColor3f</span>(<span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>); <span class="comment">// white fill color</span></span><br><span class="line">	<span class="built_in">glMatrixMode</span>(GL_PROJECTION); </span><br><span class="line">	<span class="built_in">glLoadIdentity</span>(); </span><br><span class="line">	<span class="built_in">glOrtho</span>(<span class="number">-1.0</span>, <span class="number">1.0</span>, <span class="number">-1.0</span>, <span class="number">1.0</span>, <span class="number">-1.0</span>, <span class="number">1.0</span>); <span class="comment">// viewing volume</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>Coordinate Systems (have a rough knowing)<ul>
<li>object coordinates (3D)</li>
<li>world coordinates (camera)</li>
<li>window coordinates</li>
</ul>
</li>
<li>About OpenGL Camera</li>
</ul>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr8.png" alt="opengl camera" style="zoom:50%"></div>

<ul>
<li>Orthographic Viewing and Transformation<ul>
<li>In the default orthographic view, points are projected forward along the $z$ axis onto the plane $z = 0$</li>
<li>In OpenGL, projection is carried out by a projection matrix (transformation)</li>
<li>There is only one set of transformation functions so we must set the matrix mode first<ul>
<li><code>glMatrixMode(GL_PROJECTION)</code></li>
</ul>
</li>
<li>Transformation functions are incremental so we start with an identity matrix and alter it with a projection matrix that gives the view volume<ul>
<li><code>glLoadIdentity();</code></li>
<li><code>glOrtho(-1.0, 1.0, -1.0, 1.0, -1.0, 1.0);</code></li>
</ul>
</li>
<li><code>glOrtho(left, right, bottom, top, near, far)</code> is used to determine the projection area.</li>
<li>If the application is in 2D, we can use the function <code>gluOrtho2D(left, right, bottom, top)</code></li>
</ul>
</li>
</ul>
<blockquote>
<p>Here is an example of how to draw a projection on 2D windows. </p>
<p>Because a projection from 3D to 2D is in <strong>OpenGL-Primitives</strong> (I show below), so we only need to paint it out.</p>
</blockquote>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">mydisplay</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="built_in">glClear</span>(GL_COLOR_BUFFER_BIT); </span><br><span class="line">	<span class="built_in">glBegin</span>(GL_POLYGON); </span><br><span class="line">	<span class="comment">// define as polygon</span></span><br><span class="line">	<span class="built_in">glVertex2f</span>(<span class="number">-0.5</span>, <span class="number">-0.5</span>); </span><br><span class="line">	<span class="built_in">glVertex2f</span>(<span class="number">-0.5</span>, <span class="number">0.5</span>); </span><br><span class="line">	<span class="built_in">glVertex2f</span>(<span class="number">0.5</span>, <span class="number">0.5</span>); </span><br><span class="line">	<span class="built_in">glVertex2f</span>(<span class="number">0.5</span>, <span class="number">-0.5</span>); </span><br><span class="line">	<span class="comment">// set 4 vertex to form 4-edges polygon</span></span><br><span class="line">	<span class="built_in">glEnd</span>();</span><br><span class="line">	<span class="built_in">glFlush</span>(); </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr11.png" alt="opengl primitives" style="zoom:70%"></div>



<h3 id="Other-methods-of-OpenGL"><a href="#Other-methods-of-OpenGL" class="headerlink" title="Other methods of OpenGL"></a>Other methods of OpenGL</h3><ol>
<li><code>glShadeModel()</code> to set the color rendering to be <code>GL_SMOOTH</code> (æ¸å˜) or <code>GL_FLAT</code> (å•è‰²).</li>
<li><code>glViewport(x, y, w, h)</code> to set the viewport of windows.</li>
</ol>
<h2 id="3D-OpenGL"><a href="#3D-OpenGL" class="headerlink" title="3D OpenGL"></a>3D OpenGL</h2><h3 id="Three-Dimensional-Applications"><a href="#Three-Dimensional-Applications" class="headerlink" title="Three-Dimensional Applications"></a>Three-Dimensional Applications</h3><ul>
<li>In OpenGL, 2D applications are a special case of 3D graphics</li>
<li>Going to 3D<ul>
<li>Not much changes</li>
<li>Use <code>glVertex3*()</code></li>
<li>Have to worry about the order in which polygons are drawn or use <strong>hidden-surface removal</strong> (occlusion problem)</li>
<li>Polygons should be simple, convex, flat</li>
</ul>
</li>
</ul>
<h3 id="Gasket-Program"><a href="#Gasket-Program" class="headerlink" title="Gasket Program"></a>Gasket Program</h3><div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr9.png" alt="triangle division" style="zoom:50%"></div>

<ul>
<li>Consider the filled area (black) and the perimeter (the length of all the lines around the filled triangles)</li>
<li>As we continue subdividing<ul>
<li>the area goes to zero (&lt; 2D)</li>
<li>but the perimeter goes to infinity (&gt; 1D)</li>
</ul>
</li>
<li>This is not an ordinary geometric object<ul>
<li>It is neither one- nor two-dimensional</li>
</ul>
</li>
<li>It is a fractal (fractional dimension) object<ul>
<li>Approximately 1.585 D</li>
</ul>
</li>
</ul>
<blockquote>
<font color="red">How to do in program?</font>

<font color="green">Using algorithm of Recursion!</font>


</blockquote>
<ul>
<li>Design <code>display()</code> and <code>myinit()</code></li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">display</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">glClear</span>(GL_COLOR_BUFFER_BIT);</span><br><span class="line">    <span class="built_in">glBegin</span>(GL_TRIANGLES);</span><br><span class="line">    <span class="built_in">divide_triangle</span>(v[<span class="number">0</span>], v[<span class="number">1</span>], v[<span class="number">2</span>], n);</span><br><span class="line">    <span class="built_in">glEnd</span>();</span><br><span class="line">    <span class="built_in">glFlush</span>();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">myinit</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">glMatrixMode</span>(GL_PROJECTION);</span><br><span class="line">    <span class="built_in">glLoadIdentity</span>();</span><br><span class="line">    <span class="built_in">gluOrtho2D</span>(<span class="number">-2.0</span>, <span class="number">2.0</span>, <span class="number">-2.0</span>, <span class="number">2.0</span>);</span><br><span class="line">    <span class="built_in">glMatrixMode</span>(GL_MODELVIEW);</span><br><span class="line">    <span class="built_in">glClearColor</span> (<span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>);</span><br><span class="line">    <span class="built_in">glColor3f</span>(<span class="number">0.0</span>,<span class="number">0.0</span>,<span class="number">0.0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>Then set parameter and callback function in <code>main()</code></li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span> **argv)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    n = <span class="number">4</span>;</span><br><span class="line">    <span class="built_in">glutInit</span>(&amp;argc, argv);</span><br><span class="line">    <span class="built_in">glutInitDisplayMode</span>(GLUT_SINGLE | GLUT_RGB);</span><br><span class="line">    <span class="built_in">glutInitWindowSize</span>(<span class="number">500</span>, <span class="number">500</span>);</span><br><span class="line">    <span class="built_in">glutCreateWindow</span>(<span class="string">&quot;Sierpinski Gasket&quot;</span>);</span><br><span class="line">    <span class="built_in">glutDisplayFunc</span>(display);</span><br><span class="line">    <span class="built_in">myinit</span>();</span><br><span class="line">    <span class="built_in">glutMainLoop</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="Move-to-3D-triangle"><a href="#Move-to-3D-triangle" class="headerlink" title="Move to 3D triangle"></a>Move to 3D triangle</h3><ul>
<li>Add an extra vertex to form tetrahedra</li>
<li>Then we can do like 2D triangle subdivision</li>
</ul>
<font color="red">But we have to deal with <b>Hidden-Surface Removal</b> !!</font>

<ul>
<li><ul>
<li>OpenGL uses a hidden-surface removal method called the z-buffer algorithm that saves depth information as objects are rendered so that only the front objects appear in the image.</li>
</ul>
</li>
</ul>
<blockquote class="blockquote-center">
<p><strong>Using the z-buffer Algorithm</strong></p>

</blockquote>
<p>Requested in <code>main()</code></p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="built_in">glutInitDisplayMode</span>(GLUT_SINGLE | GLUT_RGB | GLUT_DEPTH)</span><br></pre></td></tr></table></figure>
<p>Enabled in <code>init()</code></p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="built_in">glEnable</span>(GL_DEPTH_TEST)</span><br></pre></td></tr></table></figure>
<p>Cleared in the display callback</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="built_in">glClear</span>(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT)</span><br></pre></td></tr></table></figure>
<blockquote class="blockquote-center">
<p><strong>Surface vs. Volume Subdivision</strong></p>

</blockquote>
<ul>
<li>In our example, we subdivided the <strong>surface</strong> of each face</li>
<li>We could also subdivide the volume using the same midpoints</li>
<li>The midpoints define four smaller tetrahedrons, one for each vertex</li>
<li>Keeping only these tetrahedrons removes a volume in the middle</li>
<li>Good programming exercise</li>
</ul>
<hr>
<h1 id="III-Input-amp-Interaction"><a href="#III-Input-amp-Interaction" class="headerlink" title="III. Input &amp; Interaction"></a>III. Input &amp; Interaction</h1><h2 id="Concept"><a href="#Concept" class="headerlink" title="Concept"></a>Concept</h2><ul>
<li>Graphical Input<ul>
<li>Devices can be described either by<ul>
<li>Physical properties<ul>
<li>Mouse, Keyboard, Trackball, etc.</li>
</ul>
</li>
<li>Logical properties: What is returned to program via API<ul>
<li>A position</li>
<li>An object identifier</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>Trigger and Measure</p>
<ul>
<li>Input devices contain a <font color="red">trigger</font> which can be used to send a signal to the operating system<ul>
<li>Button on mouse</li>
<li>Pressing or releasing a key</li>
</ul>
</li>
<li>When triggered, input devices return information (their <font color="red">measure</font>) to the system<ul>
<li>Mouse returns position information</li>
<li>Keyboard returns ASCII code</li>
</ul>
</li>
</ul>
</li>
<li><p>Event Mode</p>
<ul>
<li>Each trigger generates an event whose measure is put in an event queue which can be examined by the user program</li>
</ul>
</li>
</ul>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr10.png" alt="procedure" style="zoom:70%"></div>

<ul>
<li><p>Event Type</p>
<ul>
<li>Window: resize, expose, minimize</li>
<li>Mouse: click one or more buttons</li>
<li>Motion: move mouse</li>
<li>Keyboard: press or release a key</li>
<li>Idle: non-event (æ— è¾“å…¥æ—¶çš„æ´»åŠ¨)<ul>
<li>Define what should be done if no other event is in queue</li>
</ul>
</li>
</ul>
</li>
<li><p><font color="green">Recall:</font> callbacks</p>
<ul>
<li>Define a callback function for <strong>each type of event</strong> the graphics system recognizes</li>
<li>E.g. <code>glutMouseFunc(mymouse)</code> where <code>mymouse</code> is a mouse callback function.</li>
</ul>
</li>
<li><font color="red">GLUT  recognizes a subset of the events recognized by any particular operation system</font> : <ul>
<li><code>glutDisplayFunc</code></li>
<li><code>glutMouseFunc</code></li>
<li><code>glutReshapeFunc</code></li>
<li><code>glutKeyboardFunc</code></li>
<li><code>glutIdleFunc</code></li>
<li><code>glutMotionFunc</code>, <code>glutPassiveMotionFunc</code> </li>
</ul>
</li>
</ul>
<h2 id="GLUT-Event-Loop"><a href="#GLUT-Event-Loop" class="headerlink" title="GLUT Event Loop"></a>GLUT Event Loop</h2><ul>
<li><font color="green">Recall:</font> the last statement in <code>main()</code> for a program using GLUT must be <code>glutMainLoop();</code></li>
<li>In each pass through the event loop, GLUT <ul>
<li>looks at the events in the <strong>queue</strong></li>
<li>execute each event if the corresponding callback function is defined.</li>
</ul>
</li>
</ul>
<font color="purple">Important before talking about callbacks:</font> 

<ul>
<li>The form of all GLUT callbacks is fixed</li>
<li>So we must use <strong>globals</strong> (å…¨å±€å˜é‡) to pass information to callbacks</li>
</ul>
<h3 id="Display-Callback"><a href="#Display-Callback" class="headerlink" title="Display Callback"></a>Display Callback</h3><ul>
<li>When windows are refreshed, apply display callbacks<ul>
<li><code>glutDisplayFunc(mydisplay)</code> in <code>main()</code></li>
<li><code>glutPostRedisplay()</code> to <font color="red">avoid multiple display</font> in one single pass through the event loop<ul>
<li>set a <strong>â€œflagâ€</strong> at the end of the event loop.</li>
<li>GLUT checks it and display callback function is executed.</li>
</ul>
</li>
</ul>
</li>
<li>Then whatâ€™s inside <code>mydisplay</code>?<ul>
<li><code>glClear()</code> to clear the window</li>
<li>Use <font color="red"><b>Double Buffer</b></font> to avoid <font color="blue">partial drawn</font> <ul>
<li><strong>Front Buffer</strong>: one that is <strong>displayed</strong> but not written to</li>
<li><strong>Back Buffer</strong>: one that is <strong>written</strong> to but not displayed</li>
</ul>
</li>
<li><code>glutInitDisplayMode(GLUT_RGB | GLUT_DOUBLE)</code> declare in <code>main()</code> to request a <font color="red">double buffer</font></li>
<li>At the end of display callback buffers are swapped.</li>
</ul>
</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">mydisplay</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"> <span class="built_in">glClear</span>(GL_COLOR_BUFFER_BIT|â€¦)</span><br><span class="line"> ...</span><br><span class="line"> <span class="comment">/* draw graphics here */</span></span><br><span class="line"> ...</span><br><span class="line"> <span class="built_in">glutSwapBuffers</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="Idle-Callback"><a href="#Idle-Callback" class="headerlink" title="Idle Callback"></a>Idle Callback</h3><ul>
<li>The idle callback is executed whenever there are <font color="red">no events</font> in the event queue<ul>
<li><code>glutIdleFunc(myidle)</code> in <code>main()</code></li>
<li><font color="blue">Useful for animation</font> 

</li>
</ul>
</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">myidle</span><span class="params">()</span> </span>&#123;</span><br><span class="line"> <span class="comment">/* change something */</span></span><br><span class="line"> t += dt</span><br><span class="line"> <span class="built_in">glutPostRedisplay</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="Mouse-and-Keyboard-Callbacks"><a href="#Mouse-and-Keyboard-Callbacks" class="headerlink" title="Mouse and Keyboard Callbacks"></a>Mouse and Keyboard Callbacks</h3><ul>
<li><code>glutMouseFunc(mymouse)</code> in <code>main()</code></li>
<li><code>void mymouse(GLint button, GLint state,  GLint x, GLint y)</code> to define mouse callbacks<ul>
<li>Buttons: <code>GLUT_LEFT_BUTTON</code>, <code>GLUT_MIDDLE_BUTTON</code> or <code>GLUT_RIGHT_BUTTON</code></li>
<li>States: <code>GLUT_UP</code> or <code>GLUT_DOWN</code></li>
<li>Cursor Position: top-left corner is (0,0) <font color="gray">[Others depend on winsize]</font></li>
</ul>
</li>
</ul>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr12.png" alt="position" style="zoom:50%"></div>

<blockquote class="blockquote-center">
<p>$<br>y_{\text{OpenGL}}= h-1-y_{text{win}}<br>$</p>

</blockquote>
<font color="blue">E.g. To draw a square when mouse click</font>

<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">mymouse</span><span class="params">(<span class="type">int</span> btn, <span class="type">int</span> state, <span class="type">int</span> x, <span class="type">int</span> y)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"> <span class="keyword">if</span> (btn==GLUT_RIGHT_BUTTON &amp;&amp; state==GLUT_DOWN) <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line"> <span class="keyword">if</span> (btn==GLUT_LEFT_BUTTON &amp;&amp; state==GLUT_DOWN) <span class="built_in">drawSquare</span>(x, y);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">drawSquare</span><span class="params">(<span class="type">int</span> x, <span class="type">int</span> y)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"> y = w â€“ <span class="number">1</span> - y; <span class="comment">/* invert y position */</span></span><br><span class="line"> <span class="comment">/* a random color */</span></span><br><span class="line"> <span class="built_in">glColor3ub</span>((<span class="type">char</span>)<span class="built_in">rand</span>()%<span class="number">256</span>,(<span class="type">char</span>)<span class="built_in">rand</span>()%<span class="number">256</span>,(<span class="type">char</span>)<span class="built_in">rand</span>()%<span class="number">256</span> );</span><br><span class="line"> <span class="built_in">glBegin</span>(GL_POLYGON);</span><br><span class="line"> <span class="built_in">glVertex2f</span>(x+size, y+size);</span><br><span class="line"> <span class="built_in">glVertex2f</span>(x-size, y+size);</span><br><span class="line"> <span class="built_in">glVertex2f</span>(x-size, y-size);</span><br><span class="line"> <span class="built_in">glVertex2f</span>(x+size, y-size);</span><br><span class="line"> <span class="built_in">glEnd</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<hr>
<ul>
<li>We can draw squares (or anything else) continuously as long as a mouse button is depressed by using the motion callback<ul>
<li><code>glutMotionFunc(drawSquare)</code></li>
</ul>
</li>
<li><p>We can draw squares without depressing a button using the <font color="red">passive motion</font> callback (ç”¨äºé¼ æ ‡æ²¡æŒ‰ä¸‹ä½†åœ¨ç§»åŠ¨æ—¶çš„æ“ä½œ)</p>
<ul>
<li><code>glutPassiveMotionFunc(drawSquare)</code></li>
</ul>
</li>
<li><p><strong>Keyboard is almost the same</strong></p>
<ul>
<li><code>glutKeyboardFunc(mykey)</code></li>
<li><code>void mykey(unsigned char key,  int x, int y)</code></li>
</ul>
</li>
</ul>
<p>E.g.</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">mykey</span><span class="params">(<span class="type">unsigned</span> <span class="type">char</span> key, <span class="type">int</span> x, <span class="type">int</span> y)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"> <span class="keyword">if</span> (key == <span class="string">&#x27;Q&#x27;</span> | key == <span class="string">&#x27;q&#x27;</span>) </span><br><span class="line"> <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p><strong>Others:</strong></p>
<p>GLUT defines the <strong>special keys</strong> in <code>glut.h</code></p>
<ul>
<li>Function key 1: <code>GLUT_KEY_F1</code></li>
<li>Up arrow key: <code>GLUT_KEY_UP</code></li>
</ul>
<p>Also check <strong>modifiers</strong></p>
<ul>
<li><code>GLUT_ACTIVE_SHIFT</code>, <code>GLUT_ACTIVE_CTRL</code>, <code>GLUT_ACTIVE_ALT</code> is depressed using <code>glutGetModifiers()</code> </li>
</ul>
</blockquote>
<h3 id="Reshape-Callback"><a href="#Reshape-Callback" class="headerlink" title="Reshape Callback"></a>Reshape Callback</h3><ul>
<li><code>glutReshapeFunc(myreshape)</code> in <code>main()</code></li>
<li><code>void myreshape(int w, int h)</code></li>
</ul>
<p>E.g.</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">myReshape</span><span class="params">(<span class="type">int</span> w, <span class="type">int</span> h)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"> <span class="built_in">glViewport</span>(<span class="number">0</span>, <span class="number">0</span>, w, h);</span><br><span class="line"> <span class="built_in">glMatrixMode</span>(GL_PROJECTION); <span class="comment">/* switch matrix mode */</span></span><br><span class="line"> <span class="built_in">glLoadIdentity</span>();</span><br><span class="line"> </span><br><span class="line"> <span class="keyword">if</span> (w &lt;= h)</span><br><span class="line"> <span class="built_in">gluOrtho2D</span>( <span class="number">-2.0</span>, <span class="number">2.0</span>, <span class="number">-2.0</span> * (GLfloat) h / w,</span><br><span class="line"> <span class="number">2.0</span> * (GLfloat) h / w );</span><br><span class="line"> <span class="keyword">else</span> </span><br><span class="line"> <span class="built_in">gluOrtho2D</span>( <span class="number">-2.0</span> * (GLfloat) w / h, </span><br><span class="line"> <span class="number">2.0</span> * (GLfloat) w / h, <span class="number">-2.0</span>, <span class="number">2.0</span> );</span><br><span class="line"> <span class="built_in">glMatrixMode</span>(GL_MODELVIEW); <span class="comment">/* return to modelview mode */</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="Menu"><a href="#Menu" class="headerlink" title="Menu"></a>Menu</h3><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// main()</span></span><br><span class="line">GLint menu_id = <span class="built_in">glutCreateMenu</span>(mymenu);</span><br><span class="line"><span class="built_in">glutAddMenuEntry</span>(<span class="string">&quot;Clear&quot;</span>, <span class="number">1</span>);</span><br><span class="line"><span class="built_in">glutAddMenuEntry</span>(<span class="string">&quot;Quit&quot;</span>, <span class="number">2</span>);</span><br><span class="line"><span class="built_in">glutAttachMenu</span>(GLUT_RIGHT_BUTTON);</span><br></pre></td></tr></table></figure>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">mymenu</span><span class="params">(<span class="type">int</span> id)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"> <span class="keyword">if</span>(id == <span class="number">1</span>) <span class="built_in">glClear</span>(GL_COLOR_BUFFER_BIT);</span><br><span class="line"> <span class="keyword">if</span>(id == <span class="number">2</span>) <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="Other-Functions"><a href="#Other-Functions" class="headerlink" title="Other Functions"></a>Other Functions</h3><ul>
<li>Dynamic Windows<ul>
<li>Create and destroy during execution</li>
</ul>
</li>
<li>Subwindows</li>
<li>Multiple Windows</li>
<li>Changing callbacks during execution</li>
<li>Timers (look up glutTimerFunc)<ul>
<li>Useful for controlling speed of animation</li>
</ul>
</li>
<li>Portable fonts<ul>
<li>glutBitmapCharacter</li>
<li>glutStrokeCharacter</li>
</ul>
</li>
</ul>
<hr>
<h1 id="IV-Geometric-Objects-amp-Transformations"><a href="#IV-Geometric-Objects-amp-Transformations" class="headerlink" title="IV. Geometric Objects &amp; Transformations"></a>IV. Geometric Objects &amp; Transformations</h1><ul>
<li>Basic elements<ul>
<li>Scalars</li>
<li>Vectors</li>
<li>Points</li>
</ul>
</li>
<li>Basic primitives<ul>
<li>Line segments</li>
<li>Polygons</li>
</ul>
</li>
</ul>
<h2 id="Representation"><a href="#Representation" class="headerlink" title="Representation"></a>Representation</h2><ul>
<li>Introduce<ul>
<li><strong>coordinate systems</strong> for representing vector spaces</li>
<li>frames for representing <strong>affine spaces</strong>(ä»¿å°„ç©ºé—´)</li>
</ul>
</li>
<li>Discuss change of frames and bases</li>
<li>Introduce homogeneous coordinates</li>
</ul>
<h3 id="Coordinate-Systems"><a href="#Coordinate-Systems" class="headerlink" title="Coordinate Systems"></a>Coordinate Systems</h3><font color="green">Recall: Linear Algebra</font>

<ul>
<li>basis: $v_1,v_2,â€¦,v_n$</li>
<li>a vector written as $v=\alpha_1 v_1+\alpha_2 v_2 + \cdots + \alpha_n v_n$</li>
<li>the <font color="red">coordinate</font> of $v$ in this basis is $\{ \alpha_1,\alpha_2, \cdots , \alpha_n \}$</li>
</ul>
<h3 id="Frame"><a href="#Frame" class="headerlink" title="Frame"></a>Frame</h3><p><strong>Def.</strong> A <font color="red">frame</font> is a system with a single point(origin $P_0$) and a basis vector <font color="blue">in an affine space</font>.</p>
<blockquote class="blockquote-center">
<p>$<br>P=P_0 + \beta_1 v_1 + \beta_2 v_2 + \cdots + \beta_n v_n<br>$</p>

</blockquote>
<h3 id="Homogeneous-Coordinates"><a href="#Homogeneous-Coordinates" class="headerlink" title="Homogeneous Coordinates"></a>Homogeneous Coordinates</h3><p>E.g. for a 3 * 3 space, the 3 * 3 matrices cannot used for translation(å¹³ç§»), because vectors have no position.</p>
<ul>
<li>We extend the $3\times 3$ point to 4-dimension: $(x,y,z) \rightarrow (x,y,z,1)$</li>
<li>and a $4\times 4$ matrix can represent translation, rotation and scaling and shear</li>
<li>using matrix(a template) below, we can maintain $w=0$ for vectors and $w=1$ for points for <font color="red">orthographic viewing</font> .</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\left( \begin{array}{c}<br>a &amp; b &amp; c &amp; tx \\<br>d &amp; e &amp; f &amp; ty \\<br>g &amp; h &amp; i &amp; tz \\<br>0 &amp; 0 &amp; 0 &amp; 1<br>\end{array}\right)<br>$</p>

</blockquote>
<font color="blue">E.g. For a 3D point $(x,y,z)$ , its homogeneous coordinate is $P_h = (x,y,z,1)$ . To translate it, we define a matrix:</font>

<blockquote class="blockquote-center">
<p>$<br>\left( \begin{array}{c}<br>1 &amp; 0 &amp; 0 &amp; tx \\<br>0 &amp; 1 &amp; 0 &amp; ty \\<br>0 &amp; 0 &amp; 1 &amp; tz \\<br>0 &amp; 0 &amp; 0 &amp; 1<br>\end{array}\right)<br>\left( \begin{array}{c}<br>x \\ y \\ z \\ 1<br>\end{array}\right) =<br>\left( \begin{array}{c}<br>x+ tx \\ y+ ty \\ z+ tz \\  1<br>\end{array}\right)<br>$</p>

</blockquote>
<ul>
<li>More generally, homogeneous coordinates are represented as $p=[ wx,wy,wz,w ]^T$</li>
</ul>
<h2 id="Transformation"><a href="#Transformation" class="headerlink" title="Transformation"></a>Transformation</h2><ul>
<li>Affine Transformation: Line preserving</li>
<li><p>Translation: move points</p>
<ul>
<li>$Pâ€™=P+d$ where $d=[d_x, d_y, d_z, 0]^T$ </li>
</ul>
</li>
<li><p><font color="green">Recall for Linear Algebra:</font> Some linear transformation: </p>
<ul>
<li>Rotation (2D)</li>
<li>Scaling</li>
<li>Reflection</li>
</ul>
</li>
</ul>
<blockquote>
<p>try to remember their transformation matrices.</p>
</blockquote>
<p><strong>Inverses</strong></p>
<ul>
<li>Translation: $\textbf{T}^{-1}=\textbf{T}(-d_x, -d_y, -d_z)$</li>
<li>Rotation: $\textbf{R}^{-1}(\theta)=\textbf{R}(- \theta)$<ul>
<li>Noted that only $cos(\theta)$ on orthogonal entry</li>
</ul>
</li>
<li>Scaling: $\textbf{S}^{-1}(s_x, s_y, s_z)=\textbf{S}(1/s_x, 1/s_y, 1/s_z)$ </li>
</ul>
<p><strong>Examples</strong></p>
<p>Rotation About a Fixed Point Other than the Origin:</p>
<ol>
<li>Move fixed point to origin</li>
<li>Rotate</li>
<li>Move fixed point back</li>
</ol>
<blockquote class="blockquote-center">
<p>$<br>\textbf{M}=\textbf{T}(p_f)\textbf{R}(\theta)\textbf{T}(-p_f)<br>$</p>

</blockquote>
<p>(bu)</p>
<h2 id="OpenGL-Transformations"><a href="#OpenGL-Transformations" class="headerlink" title="OpenGL Transformations"></a>OpenGL Transformations</h2><div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr13.png" alt="procedure" style="zoom:50%"></div>

<ul>
<li><p><font color="green">Recall:</font> <code>glMatrixMode(GLenum mode)</code> to change the mode of matrix calculation</p>
<ul>
<li>when doing transformation, use <code>GL_MODELVIEW</code> state</li>
</ul>
</li>
<li><p>For all CTM(Current Transformation Matrix) Operations, our CPP Code must load identity matrix first:</p>
</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="built_in">glMatrixMode</span>(GL_MODELVIEW);</span><br><span class="line"><span class="built_in">glLoadIdentity</span>(); <span class="comment">// é‡ç½®</span></span><br><span class="line"><span class="built_in">glTranslatef</span>(<span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">-5.0</span>); <span class="comment">// å¹³ç§»ç‰©ä½“</span></span><br></pre></td></tr></table></figure>
<ul>
<li>Beware of using <strong>post-multiplications</strong> (the later operations should be multipled to result matrix $\textbf{C}$ <font color="red">earlier</font>)<ul>
<li>E.g. Rotation About a Fixed Point: $\textbf{C}=\textbf{T}^{-1}\textbf{R}\textbf{T}$</li>
</ul>
</li>
<li>Other Transformation Matrix specifying<ul>
<li>rotation: <code>glRotatef(theta, vx, vy, yz)</code></li>
<li>translation: <code>glTranslatef(dx, dy, dz)</code></li>
<li>scale: <code>glScalef(sx, sy, sz)</code> </li>
</ul>
</li>
</ul>
<hr>
<h1 id="V-Camera-amp-Viewing"><a href="#V-Camera-amp-Viewing" class="headerlink" title="V. Camera &amp; Viewing"></a>V. Camera &amp; Viewing</h1><h2 id="Computer-Viewing"><a href="#Computer-Viewing" class="headerlink" title="Computer Viewing"></a>Computer Viewing</h2><ul>
<li><font color="red">2</font> attributes to define the viewing:<ul>
<li>Positioning the camera<ul>
<li><font color="green">Setting the <b>model-view</b> matrix</font> </li>
</ul>
</li>
<li>Selecting a lens<ul>
<li><font color="green">Setting the <b>projection</b> matrix</font></li>
<li>Perspective or orthographic / view volume / clipping volume â€¦</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="Specify-Different-Space"><a href="#Specify-Different-Space" class="headerlink" title="Specify Different Space"></a>Specify Different Space</h2><div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr13.png" style="zoom:60%"></div>

<ul>
<li>Local / Modeling / Object Space<ul>
<li>Each object model has its own local coordinate frame</li>
</ul>
</li>
<li>World Space (ç±»ä¼¼å…¨å±€ç©ºé—´)<ul>
<li><font color="blue">Lights and Camera pose</font> are defined in this space</li>
</ul>
</li>
</ul>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr17.png" style="zoom:60%"></div>

<ul>
<li><strong>Camera Space / View Space / Eye Space</strong><ul>
<li>Camera is located at the origin</li>
<li>Looking in negative $z$ direction</li>
<li>$+y$-axis is the â€œup-vectorâ€</li>
</ul>
</li>
</ul>
<blockquote>
<p>Initially the <strong>world</strong> and <strong>camera</strong> frames are the same.</p>
<p>To specify camera pose, we need to specify the camera coordinate frame with respect to the world coordinate frame.</p>
</blockquote>
<h2 id="View-Transformation"><a href="#View-Transformation" class="headerlink" title="View Transformation"></a>View Transformation</h2><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="built_in">glLookAt</span>( eyex, eyey, eyez,</span><br><span class="line">		  atx , aty , atz ,</span><br><span class="line">		  upx , upy , upz )</span><br></pre></td></tr></table></figure>
<ul>
<li>é€šè¿‡ eye å’Œ at æ±‚å‡ºå‰å‘é‡</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\text{forward}=\frac{\text{at} - \text{eye}}{|\text{at} - \text{eye}|}<br>$</p>

</blockquote>
<ul>
<li>é€šè¿‡ forward å’Œ up æ±‚å‡ºå³å‘é‡</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\text{side}=\frac{\text{forward} \times \text{up}}{|\text{forward} \times \text{up}|}<br>$</p>

</blockquote>
<ul>
<li>ç„¶åå°±èƒ½å¾—åˆ°ä¿®æ­£åçš„ä¸Šå‘é‡</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\text{upâ€™}= \text{forward} \times \text{side}<br>$</p>

</blockquote>
<ul>
<li>æ±‚å‡ºä¸‰ä¸ªå‘é‡åå°±èƒ½ç¡®å®š camera çš„ä½ç½®å’Œ pose äº†</li>
</ul>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr18.png" alt="view-trans" style="zoom:60%"></div>

<ul>
<li>Suppose the camera has been moved to the location $[e_x, e_y, e_z]^T$, and its $x_c$, $y_c$, $z_c$ axes are the unit vectors $\textbf{u}$, $\textbf{v}$, $\textbf{n}$, respectively, then</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\textbf{M}_{\text{view}}=<br>\left[ \begin{array}{c}<br>u_x &amp; u_y &amp; u_z &amp; 0 \\<br>v_x &amp; v_y &amp; v_z &amp; 0 \\<br>n_x &amp; n_y &amp; n_z &amp; 0 \\<br>0 &amp; 0 &amp; 0 &amp; 1<br>\end{array}\right]<br>\cdot<br>\left[ \begin{array}{c}<br>1 &amp; 0 &amp; 0 &amp; -e_x \\<br>0 &amp; 1 &amp; 0 &amp; -e_y \\<br>0 &amp; 0 &amp; 1 &amp; -e_z \\<br>0 &amp; 0 &amp; 0 &amp; 1<br>\end{array}\right]<br>$</p>

</blockquote>
<p>â–ª Note that $[e_x, e_y, e_z]^T$ and $\textbf{u}$, $\textbf{v}$, $\textbf{n}$ are all specified with respect to the world frame</p>
<h2 id="Projection-â€”â€”-Defining-the-View-Volume"><a href="#Projection-â€”â€”-Defining-the-View-Volume" class="headerlink" title="Projection â€”â€” Defining the View Volume"></a>Projection â€”â€” Defining the View Volume</h2><ul>
<li>For orthographic projection, use <code>glOrtho()</code></li>
<li>For perspective projection, use <code>glFrustum()</code></li>
</ul>
<h3 id="OpenGL-Orthographic-Projection"><a href="#OpenGL-Orthographic-Projection" class="headerlink" title="OpenGL Orthographic Projection"></a>OpenGL Orthographic Projection</h3><ul>
<li>The glOrtho() function then generates a matrix that linearly maps the view volume to the canonical view volume, where<ul>
<li>(left, bottom, â€“near) is mapped to (â€“1, â€“1, â€“1)</li>
<li>(right, top, â€“ far) is mapped to (1, 1, 1)</li>
</ul>
</li>
</ul>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr14.png" alt="ortho-projection" style="zoom:60%"></div>

<blockquote>
<p>æ­£æŠ•å½±ï¼Œèƒ½è¾ƒçœŸå®åœ°åæ˜ ç‰©ä½“å¤§å°ï¼Œç‰©ä½“æ˜¾ç¤ºçš„å¤§å°ä¸ä¼šå› è§†è§’å˜åŒ–æ”¹å˜ã€‚å¸¸ç”¨äºCADè®¾è®¡ã€åœ°å›¾ç»˜åˆ¶ã€2Dæ¸¸æˆç­‰ä¸éœ€è¦è¡¨ç°æ·±åº¦æ„Ÿçš„åœºæ™¯ã€‚</p>
</blockquote>
<h3 id="OpenGL-Perspective-Projection"><a href="#OpenGL-Perspective-Projection" class="headerlink" title="OpenGL Perspective Projection"></a>OpenGL Perspective Projection</h3><ul>
<li><code>glFrustum( left, right, bottom, top, near, far )</code><ul>
<li>The <code>glFrustum()</code> function allows (off-center) non-symmetric view volume</li>
</ul>
</li>
<li>Often, we want a <strong>symmetric view volume</strong>. We can use<ul>
<li><code>gluPerspective( fovy, aspect, near, far );</code></li>
</ul>
</li>
</ul>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr15.png" alt="persp-projection" style="zoom:60%"></div>

<blockquote>
<p>é€è§†æŠ•å½±ï¼Œæœ‰æ·±åº¦æ„Ÿï¼Œè¿‘å¤§è¿œå°ã€‚å¸¸ç”¨äº3Dæ¸¸æˆã€è™šæ‹Ÿç°å®ã€å»ºç­‘å¯è§†åŒ–ç­‰éœ€è¦çœŸå®æ„Ÿçš„åœºæ™¯ã€‚</p>
</blockquote>
<h4 id="Principle-of-Perspective-Projection"><a href="#Principle-of-Perspective-Projection" class="headerlink" title="Principle of Perspective Projection"></a>Principle of Perspective Projection</h4><div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr19.png" alt="persp-projection-d" style="zoom:60%"></div>

<ul>
<li>Center of projection at the origin</li>
<li>Projection plane is $z = d$, $d &lt; 0$</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>x_p=\frac{x}{z/d}\ \ \ \ y_p=\frac{y}{z/d}\ \ \ \ z_p=d<br>$</p>

</blockquote>
<ul>
<li>Consider $p=Mq$ where</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>p=<br>\left[ \begin{array}{c}<br>x \\ y \\ z \\ z/d<br>\end{array}\right] \ \ \ \ M=<br>\left[ \begin{array}{c}<br>1 &amp; 0 &amp; 0 &amp; 0 \\<br>0 &amp; 1 &amp; 0 &amp; 0 \\<br>0 &amp; 0 &amp; 1 &amp; 0 \\<br>0 &amp; 0 &amp; 1/d &amp; 0<br>\end{array}\right] \ \ \ \ q=<br>\left[ \begin{array}{c}<br>x \\ y \\ z \\ 1<br>\end{array}\right]<br>$</p>

</blockquote>
<ul>
<li>If we scale $p$ , then we get the projection point on plane $z=d$ .</li>
</ul>
<h1 id="VI-Rasterization"><a href="#VI-Rasterization" class="headerlink" title="VI. Rasterization"></a>VI. Rasterization</h1><h2 id="Recall-for-OpenGL-Rendering-Pipeline"><a href="#Recall-for-OpenGL-Rendering-Pipeline" class="headerlink" title="Recall for OpenGL Rendering Pipeline"></a>Recall for OpenGL Rendering Pipeline</h2><div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr16.png" alt="Rendering Pipeline" style="zoom:60%"></div>

<h3 id="Primitive-Assembly-etc"><a href="#Primitive-Assembly-etc" class="headerlink" title="Primitive Assembly, etc."></a>Primitive Assembly, etc.</h3><ul>
<li>Primitive assembly<ul>
<li>Vertex data is collected into complete primitives</li>
<li>Necessary for clipping and back-face culling</li>
</ul>
</li>
<li>Clipping</li>
<li>Perspective division (Object Oriented)<ul>
<li>To normalized device coordinate (NDC) space</li>
</ul>
</li>
<li>Viewport transformation (Viewer Oriented)<ul>
<li>To window space</li>
<li>Include depth range scaling</li>
</ul>
</li>
<li>Back-face culling</li>
</ul>
<h3 id="Rasterization-amp-Fragment-Processing"><a href="#Rasterization-amp-Fragment-Processing" class="headerlink" title="Rasterization &amp; Fragment Processing"></a>Rasterization &amp; Fragment Processing</h3><ul>
<li>Attribute values at fragments are computed by interpolating attribute values assigned to vertices<ul>
<li>Interpolation is performed in window space (2D)</li>
</ul>
</li>
</ul>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr20.png" alt="interpolation" style="zoom:55%"></div>

<ul>
<li>Each generated fragment is processed to determine the color of the corresponding pixel in the frame buffer</li>
<li>Fragment color can be modified by <strong>texture mapping</strong> (çº¹ç†æ˜ å°„)<ul>
<li>Texture access (using interpolated texture coordinates)<ul>
<li>Access texture map using texture coordinates</li>
</ul>
</li>
<li>Texture application<ul>
<li>Texture color can be combined with the fragment color of the primitive</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>Per-Fragment Operations</strong></p>
<ul>
<li><font color="blue">Fragment is discarded if it is blocked (occluded) by the corresponding pixel already in the frame buffer</font><ul>
<li>Z-buffer hidden-surface removal</li>
</ul>
</li>
<li><font color="blue">Fragment may be blended with the corresponding pixel already in the frame buffer</font> <ul>
<li>Blending</li>
</ul>
</li>
</ul>
<blockquote>
<p>Letâ€™s talk about something important !!!</p>
</blockquote>
<h2 id="Clipping"><a href="#Clipping" class="headerlink" title="Clipping"></a>Clipping</h2><blockquote>
<p>To clip out primitives that are outside the view volume</p>
</blockquote>
<h3 id="Clipping-2D-Line-Segments"><a href="#Clipping-2D-Line-Segments" class="headerlink" title="Clipping 2D Line Segments"></a>Clipping 2D Line Segments</h3><h4 id="Cohen-Sutherland-Algorithm"><a href="#Cohen-Sutherland-Algorithm" class="headerlink" title="Cohen-Sutherland Algorithm"></a>Cohen-Sutherland Algorithm</h4><ul>
<li>Using <a name="edge-table">edge table</a></li>
</ul>
<table>
<tr>
<td><img src="/2024/06/27/Real-Time-Rendering/rtr21.png" style="zoom:50%"></td>
<td><p><li>Case 1: Both endpoints inside all four lines
<ul><li>Draw (accept) line segment as is</li></ul></li>
<li>Case 2: Both endpoints outside same line
<ul><li>Discard (reject) the line segment</li></ul></li></p></td>
</tr>
<tr>
<td><img src="/2024/06/27/Real-Time-Rendering/rtr22.png" style="zoom:50%"></td>
<td><p><li>Case 3: One endpoint inside all lines and one outside
<ul><li>Must do at least one intersection</li></ul></li>
<li>Case 4: Both outside
<ul><li>May have part inside</li>
<li>Must do at least one intersection</li></ul></li></p></td>
</tr>
</table>

<p><strong>Using Outcode</strong></p>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr23.png" alt="outcode" style="zoom:60%"></div>

<p>E.g. Suppose a line $AB$ with endpoints $A$ and $B$ .</p>
<ul>
<li>If $\text{outcode}(A)=\text{outcode}(B)=0$ , accept the segment</li>
<li>If $\text{outcode}(A)=0$ , $\text{outcode}(B)\not= 0$ , <ul>
<li>Compute intersection</li>
<li>Location of $1$ in outcode($B$) determines which edge to intersect with</li>
<li>If outcode($B$) has two $1$â€™s, then need to do two intersections</li>
</ul>
</li>
<li>If $\text{outcode}(A)$ &amp; $\text{outcode}(B) \not= 0$ , reject the segment</li>
<li><p>If $\text{outcode}(A)$ &amp; $\text{outcode}(B) = 0$ , but neither of them are $0$ , </p>
<ul>
<li>Shorten line segment by intersecting with one of sides of window</li>
<li>Compute outcode of intersection (new endpoint of shortened line segment)</li>
<li>Re-execute algorithm</li>
</ul>
</li>
<li><p><strong>When it goes to 3D</strong>, we can use 6-bit outcode to represent 6 faces of the window.</p>
</li>
</ul>
<h3 id="Polygon-Clipping"><a href="#Polygon-Clipping" class="headerlink" title="Polygon Clipping"></a>Polygon Clipping</h3><blockquote>
<p>Problems of polygon clipping: may generate multiple polygons.</p>
<p>Solution: For concave polygons, use tessellation function(é•¶åµŒå‡½æ•°) in <code>GLU</code> to change it to multiple convex polygons.</p>
</blockquote>
<ul>
<li>simple way: set axis-aligned bounding box(AABB) for simple calculation.</li>
</ul>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr24.png" alt="outcode" style="zoom:50%"></div>



<h2 id="Rasterization"><a href="#Rasterization" class="headerlink" title="Rasterization"></a>Rasterization</h2><h3 id="Scan-Conversion-of-Line-Segments"><a href="#Scan-Conversion-of-Line-Segments" class="headerlink" title="Scan Conversion of Line Segments"></a>Scan Conversion of Line Segments</h3><p><a name="BA"><b>Bresenhamâ€™s Algorithm</b></a></p>
<ul>
<li><font color="red">Key thought</font>: A binary decision problem on how the next pixel lies based on the previous pixel.</li>
</ul>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr25.png" alt="BA" style="zoom:50%"></div>

<ul>
<li>On the next point: $y=m(x_k + 1) + b$</li>
<li>$d_\text{lower} = y-y_k$</li>
<li>$d_\text{upper}=(y_k+1)-y$</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\begin{align}<br>p_k&amp;=\Delta x(d_\text{lower} - d_\text{upper}) \\<br>&amp;=2x_k \Delta y - 2y_k \Delta x + c<br>\end{align}<br>$</p>

</blockquote>
<p>where $c=2\Delta y + \Delta x (2b - 1)$ is an <font color="red">integer constant</font> .</p>
<ul>
<li>If $p_k &gt; 0$ , plot upper pixel</li>
<li><p>If $p_k &lt; 0$ , plot lower pixel</p>
</li>
<li><p>We can incrementally compute $p_{k+1}$ from $p_k$</p>
<ul>
<li>If $p_k &gt; 0$ ,  $p_{k + 1} = p_k + 2\Delta y â€“ 2\Delta x$</li>
<li>If $p_k &lt; 0$, $p_{k + 1} = p_k + 2\Delta y$</li>
<li>where $p_0=2\Delta y - \Delta x$</li>
</ul>
</li>
</ul>
<h3 id="Scan-Conversion-of-Polygons"><a href="#Scan-Conversion-of-Polygons" class="headerlink" title="Scan Conversion of Polygons"></a>Scan Conversion of Polygons</h3><p><strong>Scan-Line Fill â€” Interpolation</strong></p>
<ul>
<li>$C_1$ $C_2$ $C_3$ specified by glColor or by vertex shading (lighting computation)</li>
<li>$C_4$ determined by interpolating between $C_1$ and $C_3$</li>
<li>$C_5$ determined by interpolating between $C_2$ and $C_3$</li>
<li>Interpolate between $C_4$ and $C_5$ along span</li>
</ul>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr26.png" alt="scPolygon" style="zoom:50%"></div>

<blockquote>
<p>So what we need to do in this algorithm is calculating : </p>
<ol>
<li>points intersact with scan-line (Recall <a href="#BA">Bresenhamâ€™s Algorithm</a>)</li>
<li>which polygons lie on this pixel (å¤šè¾¹å½¢æ‰«æè½¬æ¢ï¼Œ<a href="#edge-table">è¾¹è¡¨</a>ï¼Œæ´»åŠ¨è¾¹è¡¨)</li>
</ol>
</blockquote>
<h3 id="Hidden-Surface-Removal"><a href="#Hidden-Surface-Removal" class="headerlink" title="Hidden-Surface Removal"></a>Hidden-Surface Removal</h3><ul>
<li>Painterâ€™s Algorithm<ul>
<li>Fill the objects at the back first, then cover with the front objects</li>
</ul>
</li>
<li>Depth Sorting<ul>
<li>Need $O(n^2)$ at worst</li>
</ul>
</li>
</ul>
<p><strong>Back-Face Culling</strong></p>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr27.png" alt="BFC" style="zoom:90%"></div>

<ul>
<li>Polygons is <font color="red">back-facing</font> if $\textbf{N}_p \cdot \textbf{N} &lt;0$</li>
<li><font color="blue">In OpenGL, we can simply enable culling</font><ul>
<li>By default, polygon vertices must be provided in <font color="blue">counter clockwise</font> order</li>
<li>But may not work correctly for <font color="blue">non-convex</font> polygon</li>
</ul>
</li>
</ul>
<p><strong>Z-Buffer</strong></p>
<ul>
<li>Key thought: Exchange time with space</li>
<li>Use a <font color="red">z-buffer</font> (depth buffer) to store the depth of the closest object at each pixel found so far</li>
</ul>
<h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr16.png" alt="Rendering Pipeline" style="zoom:60%"></div>

<ul>
<li>Viewing this pipeline again:</li>
<li>Using back-face culling to remove hidden-surface</li>
<li>Using scan conversion to do rasterization</li>
<li>Using z-buffer to test the per-fragment</li>
<li>At the end, output frame buffer.</li>
</ul>
<hr>
<h1 id="VII-Illumination"><a href="#VII-Illumination" class="headerlink" title="VII. Illumination"></a>VII. Illumination</h1><p><strong>Local Reflection vs Global Illumination</strong></p>
<ul>
<li>Local reflection<ul>
<li>Considers relationship between a light source, a single surface point, and a view point</li>
<li>No interaction with other objects</li>
</ul>
</li>
<li>Global illumination<ul>
<li>Considers all light sources and surfaces</li>
<li>Inter-reflections and shadows</li>
</ul>
</li>
</ul>
<h2 id="Phong-Illumination-Equation"><a href="#Phong-Illumination-Equation" class="headerlink" title="Phong Illumination Equation"></a>Phong Illumination Equation</h2><blockquote class="blockquote-center">
<p>$<br>I_{\text{Phong}}=k_a i_a + \sum_{m \in \text{lights}} \left(k_d (\textbf{L}_m \cdot \textbf{N}) i_{m,d} + k_s (\textbf{R}_m \cdot \textbf{V})^{\alpha} i_{m,s}  \right)<br>$</p>

</blockquote>
<p>where :</p>
<ul>
<li>$k_a$ è¡¨ç¤ºç¯å¢ƒå…‰åå°„ç³»æ•°ï¼Œå¸¸æ•°</li>
<li>$k_d$ è¡¨ç¤ºæ¼«åå°„ç³»æ•°ï¼Œå¸¸æ•°</li>
<li>$k_s$ è¡¨ç¤ºé•œé¢é«˜å…‰åå°„ç³»æ•°ï¼Œå¸¸æ•°</li>
<li>$\alpha$ è¡¨ç¤ºç‰©ä½“æè´¨å…‰æ»‘ç¨‹åº¦ï¼Œç”±æè´¨å†³å®šï¼ˆæè´¨è¶Šå…‰æ»‘ç³»æ•°è¶Šå¤§ï¼‰ï¼Œå¸¸é‡</li>
<li>$\textbf{L}_m$ è¡¨ç¤ºç›¸å¯¹äº $L$ çš„åå°„å…‰çº¿æ–¹å‘</li>
<li>$\textbf{N}$ è¡¨ç¤ºè¯¥ç‚¹çš„æ³•çº¿ [Normal Vector]</li>
<li>$\textbf{R}_m$ è¡¨ç¤ºåå°„å…‰çš„æ–¹å‘</li>
<li>$\textbf{V}$ è¡¨ç¤ºæ‘„åƒæœºçš„æ–¹å‘</li>
<li>$i_{m,d}$ è¡¨ç¤ºå…‰æº$m$çš„æ¼«åå°„åå°„å…‰ç…§ï¼ŒRGB</li>
<li>$i_{m,s}$ è¡¨ç¤ºå…‰æº$m$çš„é«˜å…‰åå°„å…‰ç…§ï¼ŒRGB</li>
<li>$i_a$ è¡¨ç¤ºç¯å¢ƒå…‰çš„å…‰ç…§ï¼ŒRGB</li>
<li>$I_p$ è¡¨ç¤º $p$ çš„æ€»å…‰ç…§ï¼ŒRGB</li>
<li>$m$ è¡¨ç¤ºå…¶ä¸­ä¸€ä¸ªå…‰æº</li>
</ul>
<blockquote>
<p>Sum ä¸­çš„ä¸¤é¡¹åˆ†åˆ«å¯¹åº”ä¸‹å›¾çš„ä¸¤æ­¥ï¼ˆDiffuseã€æ¼«åå°„ã€‘æ˜¯ $L \cdot N$ ï¼ŒSpecular ã€é•œé¢ã€‘æ˜¯ $R \cdot V$ï¼‰ï¼Œambient å¯¹åº” $k_a \times i_a$ ï¼Œè¡¨ç¤ºå±€éƒ¨çš„ç¯å¢ƒè‰²æ¸²æŸ“ã€‚</p>
</blockquote>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr28.png" alt="PIE" style="zoom:70%"></div>


<ul>
<li>Diffuse Reflection: <strong>Lambertâ€™s Cosine Law</strong><ul>
<li>diffuse reflection $\propto \cos{\theta} = \textbf{N} \cdot \textbf{L}$</li>
</ul>
</li>
</ul>
<h2 id="Illumination-in-OpenGL"><a href="#Illumination-in-OpenGL" class="headerlink" title="Illumination in OpenGL"></a>Illumination in OpenGL</h2><ul>
<li>Lighting Computation at <strong>Vertex Processing</strong> stage.</li>
<li>Specifying Vertex Normal Vectors<ul>
<li>Set by <code>glNormal*()</code><ul>
<li><code>glNormal3f(x, y, z)</code></li>
<li><code>glNormal3fv(p)</code></li>
</ul>
</li>
<li><code>glEnable(GL_NORMALIZE)</code> allows for auto-normalization at a performance penalty</li>
</ul>
</li>
<li>Enabling Lighting Computation<ul>
<li>Shading calculations are enabled by<ul>
<li><code>glEnable(GL_LIGHTING)</code></li>
<li>Once lighting is enabled, <code>glColor()</code> is <font color="red">ignored</font></li>
</ul>
</li>
<li>Must enable each light source individually<ul>
<li><code>glEnable(GL_LIGHTi)</code> $i = 0, 1, 2, \cdots $</li>
</ul>
</li>
<li>Can choose light model parameters<ul>
<li><code>glLightModeli(parameter, GL_TRUE)</code><ul>
<li><code>GL_LIGHT_MODEL_LOCAL_VIEWER</code> do not use simplifying distant viewer assumption in calculation</li>
<li><code>GL_LIGHT_MODEL_TWO_SIDED</code> shades both sides of polygons independently</li>
</ul>
</li>
</ul>
</li>
<li><font color="red">An example code of using light</font>:</li>
</ul>
</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">GLfloat diffuse0[] = &#123;<span class="number">1.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">1.0</span>&#125;;</span><br><span class="line">GLfloat ambient0[] = &#123;<span class="number">1.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">1.0</span>&#125;;</span><br><span class="line">GLfloat specular0[] = &#123;<span class="number">1.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">1.0</span>&#125;;</span><br><span class="line">GLfloat light0_pos[] = &#123;<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3</span>,<span class="number">0</span>, <span class="number">1.0</span>&#125;;</span><br><span class="line"></span><br><span class="line"><span class="built_in">glEnable</span>(GL_LIGHTING);</span><br><span class="line"><span class="built_in">glEnable</span>(GL_LIGHT0);</span><br><span class="line"><span class="built_in">glLightfv</span>(GL_LIGHT0, GL_POSITION, light0_pos);</span><br><span class="line"><span class="built_in">glLightfv</span>(GL_LIGHT0, GL_AMBIENT, ambient0);		<span class="comment">// def ambient</span></span><br><span class="line"><span class="built_in">glLightfv</span>(GL_LIGHT0, GL_DIFFUSE, diffuse0);		<span class="comment">// def diffuse</span></span><br><span class="line"><span class="built_in">glLightfv</span>(GL_LIGHT0, GL_SPECULAR, specular0);	<span class="comment">// def spec</span></span><br></pre></td></tr></table></figure>
<ul>
<li>Or using <strong>Global Ambient Light</strong> : <code>glLightModelfv(GL_LIGHT_MODEL_AMBIENT, global_ambient)</code></li>
</ul>
<blockquote>
<p>è®¾ç½®æè´¨å’Œè®¾ç½®å…‰æºçš„å‚æ•°å¾ˆåƒï¼Œç”¨ <code>glMaterialfv()</code> å‡½æ•°ï¼Œç¬¬ä¸€ä¸ªå‚æ•°æ”¹æˆ <code>GL_FRONT, GL_BACK, GL_FRONT_AND_BACK</code> è¡¨ç¤ºå†…å¤–æ¸²æŸ“</p>
</blockquote>
<h2 id="Shading"><a href="#Shading" class="headerlink" title="Shading"></a>Shading</h2><h3 id="Gouraud-Shading-vs-Phong-Shading"><a href="#Gouraud-Shading-vs-Phong-Shading" class="headerlink" title="Gouraud Shading vs. Phong Shading"></a>Gouraud Shading vs. Phong Shading</h3><ul>
<li>Flat shading is â€œbadâ€</li>
<li>Gouraud Shading<ol>
<li>For each vertex, compute the <font color="red">average normal vector</font> of the polygons that share the vertex</li>
<li>Apply <font color="red">PIE</font> at the vertex using its <font color="blue">average normal vector</font></li>
<li>Smoothly interpolate the computed colors at the vertices of the polygon to the interior of the polygon</li>
</ol>
</li>
<li>Using <font color="red">Gouraud Shading</font> in OpenGL: <code>glShadeModel(GL_SMOOTH)</code> (No Phong Shading use directly)</li>
</ul>
<ul>
<li>Phong Shading<ol>
<li>In Phong Shading, we do not compute the colors of the vertices for interpolation. Instead, for each fragment in the polygon, we interpolate the normal vectors from the vertices</li>
<li>Then, at each fragment, we apply PIE on the interpolated normal vector to compute a color for the fragment</li>
</ol>
</li>
</ul>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr30.png" alt="Gouraud-and-Phong" style="zoom:70%"></div>

<ul>
<li>Differences<ul>
<li>Highlights are produced more faithfully with Phong shading</li>
<li>Gouraud shading produces only â€œlinear interpolationâ€ of colors</li>
<li>Gouraud shading may even miss the highlight</li>
</ul>
</li>
<li>OpenGL does not support Phong Shading<ul>
<li>But can be done by reprogramming the rendering pipeline <font color="red">using shaders</font></li>
</ul>
</li>
</ul>
<h1 id="VIII-Modern-OpenGL-Intro"><a href="#VIII-Modern-OpenGL-Intro" class="headerlink" title="VIII. Modern OpenGL (Intro)"></a>VIII. Modern OpenGL (Intro)</h1><div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr29.png" alt="modern-opengl" style="zoom:60%"></div>

<h2 id="Example-OpenGL-Programs-The-Modern-Way"><a href="#Example-OpenGL-Programs-The-Modern-Way" class="headerlink" title="Example OpenGL Programs: The Modern Way"></a>Example OpenGL Programs: The Modern Way</h2><h3 id="New-Lib"><a href="#New-Lib" class="headerlink" title="New Lib"></a>New Lib</h3><ul>
<li><code>GLEW</code><ul>
<li><font coolr="blue">The OpenGL Extension Wrangler Library</font> </li>
<li>a cross-platform open-source C/C++ extension loading library</li>
<li>provides efficient run-time mechanisms for determining which OpenGL extensions are supported on the target platform</li>
<li><font color="red">Automatically initializes</font> the entry points of new OpenGL functions</li>
</ul>
</li>
<li><code>GLM</code><ul>
<li><font color="blue">OpenGL Mathematics</font> 


</li>
</ul>
</li>
</ul>
<h3 id="Examples-1"><a href="#Examples-1" class="headerlink" title="Examples"></a>Examples</h3><blockquote>
<p>æ³¨æ„ï¼šç”±äºè¯¾ç¨‹ä¸Šç»™å‡ºçš„ç¤ºä¾‹ä»£ç è¿‡é•¿ï¼Œè¿™é‡Œåªæ€»ç»“ä¸€äº›é‡è¦éƒ¨åˆ†ï¼Œä¸å±•ç¤ºç¤ºä¾‹ä»£ç ã€‚OpenGL çš„ç›¸å…³æ•™ç¨‹ç½‘ä¸Šä¸ä¼šç¼ºï¼Œå¯ä»¥è‡ªè¡Œè·å–ã€‚</p>
</blockquote>
<h1 id="IX-Shading-Language"><a href="#IX-Shading-Language" class="headerlink" title="IX. Shading Language"></a>IX. Shading Language</h1><blockquote>
<p>This section is all about coding.</p>
<p>Some basis(Data Type, Data Structure, etc.) is ignored.</p>
</blockquote>
<p><strong>Storage Quantifiers</strong></p>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr31.png" style="zoom:60%"></div>

<p><strong>Function Parameter Qualifiers</strong></p>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr32.png" style="zoom:60%"></div>

<ul>
<li>GLSL has no concepts of pointer or reference</li>
<li>Functions are called by <font color="red">value-return</font></li>
</ul>
<p><strong>Vertex and Fragment Built-in Variables</strong></p>
<table>
<tr>
<td><img src="/2024/06/27/Real-Time-Rendering/rtr33.png"></td>
<td><img src="/2024/06/27/Real-Time-Rendering/rtr34.png"></td>
</tr>
</table>



<ul>
<li><code>gl_FragCoord</code> contains window relative coordinates $(x, y, z, 1/w)$<ul>
<li>$z$ is the depth value (after depth range scaling)</li>
<li>$w$ is $â€“z_e$ where $z_e$ is the $z$-coordinate of the fragment in the eye space</li>
</ul>
</li>
<li>If <code>gl_FragDepth</code> is not written to, <code>gl_FragCoord.z</code> is used as fragmentâ€™s depth</li>
</ul>
<ul>
<li>A fragmentâ€™s 2D position is the window-relative coordinates of the fragmentâ€™s center<ul>
<li>By default, for the <font color="red">bottom-left-most</font> pixel in the window<ul>
<li><code>gl_FragCoord.x == 0.5</code></li>
<li><code>gl_FragCoord.y == 0.5</code></li>
</ul>
</li>
</ul>
</li>
</ul>
<blockquote>
<p>Modern OpenGL uses <code>.vert</code> and <code>.frag</code> to describe the vertex and fragment rendering.</p>
</blockquote>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// A simple pseudo-code</span></span><br><span class="line">GLuint ShaderProjObj;</span><br><span class="line"><span class="type">const</span> <span class="type">char</span> vert[] = <span class="string">&quot;exmaple.vert&quot;</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">char</span> frag[] = <span class="string">&quot;example.frag&quot;</span>;</span><br><span class="line"><span class="type">const</span> GLfloat lightAmbient[] = &#123; <span class="number">0.0f</span>, <span class="number">0.0f</span>, <span class="number">0.0f</span>, <span class="number">1.0f</span> &#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">static</span> <span class="type">void</span> <span class="title">MyInit</span><span class="params">(<span class="type">void</span>)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// Create Gouraud Shading shader program object.</span></span><br><span class="line">  ShaderProjObj = <span class="built_in">makeShaderProgramFromFiles</span>(vert, frag, <span class="literal">NULL</span>);</span><br><span class="line">  <span class="comment">// Install Gauraud Shading shader program to the rendering pipeline first.</span></span><br><span class="line">  <span class="built_in">glUseProgram</span>(ShaderProjObj);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">static</span> <span class="type">void</span> <span class="title">MyDrawFunc</span><span class="params">(<span class="type">void</span>)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// Query locations of uniform variables.(exmaple)</span></span><br><span class="line">  GLint la = <span class="built_in">glGetUniformLocation</span>(ShaderProjObj, <span class="string">&quot;LightAmbient&quot;</span>);</span><br><span class="line">  <span class="comment">// Set Uniform variable</span></span><br><span class="line">  <span class="built_in">glUniform4fv</span>(la, <span class="number">1</span>, lightAmbient);</span><br><span class="line">  </span><br><span class="line">  objModel3D-&gt;<span class="built_in">render</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<hr>
<h1 id="X-Texture-Mapping-amp-Applications"><a href="#X-Texture-Mapping-amp-Applications" class="headerlink" title="X. Texture Mapping &amp; Applications"></a>X. Texture Mapping &amp; Applications</h1><h2 id="Surface-Parameterization"><a href="#Surface-Parameterization" class="headerlink" title="Surface Parameterization"></a>Surface Parameterization</h2><ul>
<li>Defines a mapping between the 3D surfaces and the 2D texture map<ul>
<li>Defines the mapping $(x_w, y_w, z_w) \leftrightarrow (s,t)$<ul>
<li>$(x_w, y_w, z_w)$ is the 3D coordinates of surface point</li>
<li>$(s, t )$ is the 2D texture coordinates (limited to $[0,1]^2$)</li>
</ul>
</li>
<li>Defines which <strong>â€œtexelâ€</strong> maps to each surface point</li>
</ul>
</li>
<li>Difficulty<ul>
<li>Non-trivial surface topology causes severe distortion of textures (æœ‰äº›ä¸æ­£å¸¸çš„è¡¨é¢æ‹“æ‰‘åä¼šäº§ç”Ÿçº¹ç†æ··ä¹±)</li>
</ul>
</li>
</ul>
<h1 id="XI-FBO-amp-Shadow-Mapping"><a href="#XI-FBO-amp-Shadow-Mapping" class="headerlink" title="XI. FBO &amp; Shadow Mapping"></a>XI. FBO &amp; Shadow Mapping</h1><h2 id="Framebuffer-Objects-FBO"><a href="#Framebuffer-Objects-FBO" class="headerlink" title="Framebuffer Objects(FBO)"></a>Framebuffer Objects(FBO)</h2><h3 id="Multi-Pass-Rendering"><a href="#Multi-Pass-Rendering" class="headerlink" title="Multi-Pass Rendering"></a>Multi-Pass Rendering</h3><p><strong>Def.</strong> Render 3D scene multiple times (passes), and â€œcombineâ€ the multiple rendered images to synthesize final frame</p>
<ul>
<li>Allows creation of non-displayable framebuffers</li>
<li>OpenGL can redirect rendering output to FBO</li>
<li>Each FBO contains a collection of rendering destinations</li>
</ul>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr37.png" style="zoom:50%"></div>



<ul>
<li>Two types of framebuffer-attachable images<ul>
<li>Texture images<ul>
<li>Render to texture</li>
</ul>
</li>
<li>Renderbuffer images<ul>
<li>Offscreen rendering</li>
</ul>
</li>
</ul>
</li>
<li>Many color attachment points allow multiple render targets (MRT)<ul>
<li>Can query the maximum number of color attachment points with <code>GL_MAX_COLOR_ATTACHMENTS</code> (usually 8)</li>
</ul>
</li>
</ul>
<h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// cpp file</span></span><br><span class="line"><span class="comment">// set up FBO</span></span><br><span class="line">GLuint fboHandle; <span class="comment">// The handle to the FBO</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Generate and bind the framebuffer</span></span><br><span class="line"><span class="built_in">glGenFramebuffers</span>(<span class="number">1</span>, &amp;fboHandle);</span><br><span class="line"><span class="built_in">glBindFramebuffer</span>(GL_FRAMEBUFFER, fboHandle);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Create first texture object</span></span><br><span class="line">GLuint renderTexA;</span><br><span class="line"><span class="built_in">glGenTextures</span>(<span class="number">1</span>, &amp;renderTexA);</span><br><span class="line"><span class="built_in">glActiveTexture</span>(GL_TEXTURE0); <span class="comment">// Use texture unit 0</span></span><br><span class="line"><span class="built_in">glBindTexture</span>(GL_TEXTURE_2D, renderTexA);</span><br><span class="line"><span class="built_in">glTexImage2D</span>(GL_TEXTURE_2D, <span class="number">0</span>, GL_RGBA8, fboWidth, fboHeight, <span class="number">0</span>,</span><br><span class="line">  GL_RGBA, GL_UNSIGNED_BYTE, <span class="literal">NULL</span>);</span><br><span class="line"><span class="comment">// ...</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Attach first texture to FBO</span></span><br><span class="line"><span class="built_in">glFramebufferTexture2D</span>(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT2,</span><br><span class="line">  GL_TEXTURE_2D, renderTexA, <span class="number">0</span>);</span><br><span class="line">  </span><br><span class="line"><span class="comment">// ... second texture object as above</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Create the depth buffer</span></span><br><span class="line">GLuint depthBuf;</span><br><span class="line"><span class="built_in">glGenRenderbuffers</span>(<span class="number">1</span>, &amp;depthBuf);</span><br><span class="line"><span class="built_in">glBindRenderbuffer</span>(GL_RENDERBUFFER, depthBuf);</span><br><span class="line"><span class="built_in">glRenderbufferStorage</span>(GL_RENDERBUFFER, GL_DEPTH_COMPONENT, </span><br><span class="line">  fboWidth, fboHeight);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Bind the depth buffer to the FBO</span></span><br><span class="line"><span class="built_in">glFramebufferRenderbuffer</span>(GL_FRAMEBUFFER, GL_DEPTH_ATTACHMENT,</span><br><span class="line">  GL_RENDERBUFFER, depthBuf);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Set the target for the fragment shader outputs</span></span><br><span class="line">GLenum drawBufs[] = &#123; GL_COLOR_ATTACHMENT2, GL_COLOR_ATTACHMENT3 &#125;;</span><br><span class="line"><span class="built_in">glDrawBuffers</span>(<span class="number">2</span>, drawBufs);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Unbind the framebuffer, and revert to default</span></span><br><span class="line"><span class="built_in">glBindFramebuffer</span>(GL_FRAMEBUFFER, <span class="number">0</span>);</span><br></pre></td></tr></table></figure>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// often in other functions</span></span><br><span class="line"><span class="comment">// DRAW TO TEXTURES</span></span><br><span class="line"><span class="comment">// Bind to texture&#x27;s FBO</span></span><br><span class="line"><span class="built_in">glBindFramebuffer</span>(GL_FRAMEBUFFER, fboHandle);</span><br><span class="line"></span><br><span class="line"><span class="built_in">glViewport</span>(<span class="number">0</span>, <span class="number">0</span>, fboWidth, fboHeight); <span class="comment">// Viewport for the texture</span></span><br><span class="line"><span class="built_in">glClear</span>(GL_DEPTH_BUFFER_BIT);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Use glClearBufferfv() to individually clear color buffers</span></span><br><span class="line"><span class="type">const</span> GLfloat lightGreen[<span class="number">4</span>] = &#123; <span class="number">0.5f</span>, <span class="number">1.0f</span>, <span class="number">0.5f</span>, <span class="number">1.0f</span> &#125;;</span><br><span class="line"><span class="type">const</span> GLfloat lightRed[<span class="number">4</span>] = &#123; <span class="number">1.0f</span>, <span class="number">0.5f</span>, <span class="number">0.5f</span>, <span class="number">1.0f</span> &#125;;</span><br><span class="line"><span class="built_in">glClearBufferfv</span>(GL_COLOR, <span class="number">0</span>, lightGreen);</span><br><span class="line"><span class="built_in">glClearBufferfv</span>(GL_COLOR, <span class="number">1</span>, lightRed);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Setup the projection matrix and view matrix</span></span><br><span class="line"><span class="comment">// for the scene to be rendered to the texture here.</span></span><br><span class="line"><span class="comment">// ...</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">renderTextureScene</span>();</span><br></pre></td></tr></table></figure>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// DRAW FINAL FRAME</span></span><br><span class="line"><span class="comment">// Unbind texture&#x27;s FBO (back to default FB)</span></span><br><span class="line"><span class="built_in">glBindFramebuffer</span>(GL_FRAMEBUFFER, <span class="number">0</span>);</span><br><span class="line"><span class="built_in">glViewport</span>(<span class="number">0</span>, <span class="number">0</span>, winWidth, winHeight); <span class="comment">// Viewport for main window</span></span><br><span class="line"><span class="built_in">glClear</span>(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Setup the projection matrix and view matrix.</span></span><br><span class="line"><span class="comment">// ...</span></span><br><span class="line"><span class="built_in">renderScene</span>();</span><br></pre></td></tr></table></figure>
<h2 id="Shadow-Mapping"><a href="#Shadow-Mapping" class="headerlink" title="Shadow Mapping"></a>Shadow Mapping</h2><table>
<tr align="center">
<td><img src="/2024/06/27/Real-Time-Rendering/rtr38.png"></td>
<td><img src="/2024/06/27/Real-Time-Rendering/rtr39.png"></td>
</tr>
</table>



<h3 id="Algorithm-Overview"><a href="#Algorithm-Overview" class="headerlink" title="Algorithm Overview"></a>Algorithm Overview</h3><ol>
<li>Render the scene using the light source as viewpoint</li>
<li>Save the depth buffer <font color="blue">(a.k.a. shadow map)</font></li>
<li>Clear the framebuffer</li>
<li>Render the scene from cameraâ€™s viewpoint<ul>
<li>For each fragment, transform it to the â€œlight spaceâ€ and compare its â€œlight spaceâ€ $z$ value with the corresponding $z$ value in the shadow map<ul>
<li>If â€œlight spaceâ€ z value is larger, the fragment is in shadow and it is lit with only ambient light</li>
<li>Otherwise, the fragment is <font color="red">not</font> in shadow and is <font color="red">fully lit</font></li>
</ul>
</li>
</ul>
</li>
</ol>
<h3 id="Shadow-Map-Coordinates"><a href="#Shadow-Map-Coordinates" class="headerlink" title="Shadow Map Coordinates"></a>Shadow Map Coordinates</h3><ul>
<li>Any 3D point in the view frustum(è§†å›¾) of the light source must be transformed to the shadow map coordinates $[s, t, p]$ where $s$, $t$, $p$ are in the range $[0,1]$</li>
<li>Given a 3D point $p_M$ in modeling coordinates, its shadow map coordinates $p_L$ is</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>p_L=B \cdot P_L \cdot V_L \cdot M \cdot p_M<br>$</p>

</blockquote>
<ul>
<li>$M$ is the modeling matrix</li>
<li>$V_L$ is the lightâ€™s view transformation matrix</li>
<li>$P_L$ is the lightâ€™s projection matrix</li>
<li>and $B=\left[ \begin{array} \\<br>0.5&amp;0&amp;0&amp;0.5 \\<br>0&amp;0.5&amp;0&amp;0.5 \\<br>0&amp;0&amp;0.5&amp;0.5 \\<br>0&amp;0&amp;0&amp;1 \\<br>\end{array}\right]$</li>
</ul>
<h3 id="Issues"><a href="#Issues" class="headerlink" title="Issues"></a>Issues</h3><ul>
<li>shadow acnes(å¤±çœŸ)<ul>
<li>Sol 1: Subtract a tolerance value from <code>ShadowCoord.z</code> in the fragment shader before the depth comparison</li>
<li>Sol 2: â€œOffsetâ€ the scene backwards when generating the shadow map from the light source<ul>
<li>Use OpenGL function <code>glPolygonOffset()</code></li>
</ul>
</li>
</ul>
</li>
<li>Obvious jaggies(é”¯é½¿)<ul>
<li>Percentage Closer Filtering (PCF)</li>
</ul>
</li>
</ul>
<figure class="highlight glsl"><table><tr><td class="code"><pre><span class="line"><span class="comment">// before using PCF</span></span><br><span class="line"><span class="type">void</span> shadeWithShadow()</span><br><span class="line">&#123;</span><br><span class="line">  <span class="type">vec3</span> ambient = ...; <span class="comment">// ambient</span></span><br><span class="line">  <span class="type">vec3</span> diffSpec = ...; <span class="comment">// diffuse and specular</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">// Do the shadow-map lookup</span></span><br><span class="line">  <span class="type">float</span> shadow = <span class="built_in">textureProj</span>(ShadowMap, ShadowCoord);</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// If the fragment is in shadow, use ambient light only.</span></span><br><span class="line">  FragColor = <span class="type">vec4</span>(diffSpec * shadow + ambient, <span class="number">1.0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight glsl"><table><tr><td class="code"><pre><span class="line"><span class="comment">// after using PCF</span></span><br><span class="line"><span class="type">void</span> shadeWithShadow()</span><br><span class="line">&#123;</span><br><span class="line">  <span class="type">vec3</span> ambient = ...; <span class="comment">// ambient</span></span><br><span class="line">  <span class="type">vec3</span> diffSpec = ...; <span class="comment">// diffuse and specular</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">// The sum of the comparisons with nearby texels</span></span><br><span class="line">  <span class="type">float</span> sum = <span class="number">0.0</span>;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// Sum contributions from texels around ShadowCoord</span></span><br><span class="line">  sum += <span class="built_in">textureProjOffset</span>(ShadowMap, ShadowCoord, <span class="type">ivec2</span>(<span class="number">-1</span>,<span class="number">-1</span>));</span><br><span class="line">  sum += <span class="built_in">textureProjOffset</span>(ShadowMap, ShadowCoord, <span class="type">ivec2</span>(<span class="number">-1</span>,<span class="number">1</span>));</span><br><span class="line">  sum += <span class="built_in">textureProjOffset</span>(ShadowMap, ShadowCoord, <span class="type">ivec2</span>(<span class="number">1</span>,<span class="number">1</span>));</span><br><span class="line">  sum += <span class="built_in">textureProjOffset</span>(ShadowMap, ShadowCoord, <span class="type">ivec2</span>(<span class="number">1</span>,<span class="number">-1</span>));</span><br><span class="line">  <span class="type">float</span> shadow = sum * <span class="number">0.25</span>;</span><br><span class="line">  </span><br><span class="line">  FragColor = <span class="type">vec4</span>(diffSpec * shadow + ambient, <span class="number">1.0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="XII-Image-Processing"><a href="#XII-Image-Processing" class="headerlink" title="XII. Image Processing"></a>XII. Image Processing</h1><h1 id="XIII-Ray-Tracing"><a href="#XIII-Ray-Tracing" class="headerlink" title="XIII. Ray Tracing"></a>XIII. Ray Tracing</h1><h2 id="Basic-Ray-Casting"><a href="#Basic-Ray-Casting" class="headerlink" title="Basic Ray Casting"></a>Basic Ray <font color="red">Casting</font></h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">For every pixel</span><br><span class="line">  Construct a ray from the eye</span><br><span class="line">  For every object in the scene</span><br><span class="line">    Find intersection with the ray </span><br><span class="line">    Keep if closest</span><br><span class="line">  Shade depending on light and normal vector(using Phong reflection)</span><br></pre></td></tr></table></figure>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr35.png" style="zoom:50%"></div>



<p><strong>Rasterization vs. Ray Casting</strong></p>
<ul>
<li>Rasterization<ul>
<li>Given a primitive in 3D space, determine which pixels are covered by the primitive</li>
</ul>
</li>
<li>Ray Casting<ul>
<li>At each pixel, determine which primitive covers it</li>
</ul>
</li>
</ul>
<h2 id="Ray-Tracing"><a href="#Ray-Tracing" class="headerlink" title="Ray Tracing"></a>Ray <font color="red">Tracing</font></h2><ul>
<li>From the closest intersection point, secondary rays are shot out<ul>
<li>Reflection ray</li>
<li>Refraction ray</li>
<li>Shadow rays</li>
</ul>
</li>
</ul>
<h3 id="Whitted-style-Recursive-Ray-Tracing"><a href="#Whitted-style-Recursive-Ray-Tracing" class="headerlink" title="Whitted-style(Recursive) Ray Tracing"></a>Whitted-style(Recursive) Ray Tracing</h3><blockquote class="blockquote-center">
<p>$<br>\begin{align}<br>&amp;\textbf{I}= \textbf{I}_{\text{local}}+k_{\text{rg}} \textbf{I}_{\text{reflected}}+k_{\text{tg}} \textbf{I}_{\text{transmitted}} \\<br>\text{where }&amp;\textbf{I}_{\text{local}}= \textbf{I}_{a}k_a+ \color{red}k_{\text{shadow}}\color{black}\textbf{I}_{\text{source}}\left[ k_d(\textbf{N} \cdot \textbf{L}) + k_r (\textbf{R} \cdot \textbf{V})^n + k_t (\textbf{T} \cdot \textbf{V})^m \right]<br>\end{align}<br>$</p>

</blockquote>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr36.png" style="zoom:50%"></div>

<ul>
<li>So if the material is opaque, the $k_t (\textbf{T} \cdot \textbf{V})^m$ can be omitted.</li>
<li>Also consider <font color="red">Shadow Rays</font>.</li>
</ul>
<p><strong>Scene Description</strong></p>
<ul>
<li>Camera view &amp; image resolution<ul>
<li>Camera position and orientation in world coordinate frame<ul>
<li>Similar to <code>gluLookAt()</code></li>
</ul>
</li>
<li>Field of view<ul>
<li>Similar to <code>gluPerspective()</code>, but <font color="red">no need</font> near &amp; far plane</li>
</ul>
</li>
<li>Image resolution<ul>
<li>Number of pixels in each dimension</li>
</ul>
</li>
</ul>
</li>
<li>Each point light source<ul>
<li>Position</li>
<li>Brightness and color ($\text{I}_{source}$)</li>
<li>A global ambient ($\text{I}_{a}$)</li>
<li>Spotlight is also possible</li>
</ul>
</li>
<li>Each object surface material<ul>
<li>$k$ (each is a RGB vector)</li>
<li>$n$, $m$</li>
<li>Refractive index $\mu$ if $k_{tg} \not= 0$ or $k_{t} \not= 0$</li>
</ul>
</li>
<li>Objects<ul>
<li>Implicit representations (e.g. plane, sphere, quadrics)</li>
<li>Polygon</li>
<li>Parametric (e.g. bicubic Bezier patches)</li>
<li>Volumetric</li>
</ul>
</li>
</ul>
<blockquote>
<p>Q: When to stop recursion?</p>
</blockquote>
<ul>
<li>When the surface is totally diffuse (and opaque)</li>
<li>When reflected/refracted ray hits nothing</li>
<li>When maximum recursion depth is reached</li>
<li>When the contribution of the reflected/refracted ray to the color at the top level is too small<ul>
<li>$(k_{rg1} | k_{tg1}) \times â€¦ \times (k_{rg(nâˆ’1)} | k_{tg(nâˆ’1)}) &lt; \text{threshold}$ </li>
</ul>
</li>
</ul>
<h1 id="Appendices-Reference"><a href="#Appendices-Reference" class="headerlink" title="Appendices (Reference)"></a>Appendices (Reference)</h1><p>If you want to search the reference pages of OpenGL Programming on <code>C++</code> , or use real-time 3D rendering in other field using OpenGL API, please refer to the <a href="https://registry.khronos.org/OpenGL-Refpages/gl4/">OpenGLÂ® 4.5 Reference Pages</a> .</p>
<p>If you are just interesting in shader rendering (like only do fragment shaders), you can go to <a href="https://www.shadertoy.com/">shadertoy</a> to take a look at othersâ€™ work or create your own.</p>
<p>One of the contributor of â€œshadertoyâ€, Inigo Quilez, has published a tutorial of the skills of shadertoy, and you can learn it here â†’ <a href="https://iquilezles.org/articles/">https://iquilezles.org/articles/</a></p>
]]></content>
      <categories>
        <category>2024 Summer</category>
      </categories>
      <tags>
        <tag>CSE Learning</tag>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title>MA234 å¤§æ•°æ®å¯¼è®ºä¸å®è·µï¼ˆä¸€ï¼‰</title>
    <url>/2024/06/22/Big-Data-1/</url>
    <content><![CDATA[<h1 id="Big-Data-I"><a href="#Big-Data-I" class="headerlink" title="Big Data (I)"></a>Big Data (I)</h1><h2 id="I-Pre-Knowledge"><a href="#I-Pre-Knowledge" class="headerlink" title="I. Pre-Knowledge"></a>I. Pre-Knowledge</h2><h3 id="Recall-for-Linear-Algebra"><a href="#Recall-for-Linear-Algebra" class="headerlink" title="Recall for Linear Algebra"></a>Recall for Linear Algebra</h3><p><strong>1. Linear Combination and Linear Function</strong></p>
<p><strong>Def.</strong> Suppose $\vec\alpha_1,\vec\alpha_2,\cdots, \vec\alpha_e$ are finite vector from <font color="red">linear space</font> $\textbf{V}$. If any vector from $\textbf{V}$ can be represented as $\vec\alpha = k_1\vec\alpha_1+k_2\vec\alpha_2+\cdots + k_e \vec\alpha_e$ , we say that $\vec\alpha$ can be linearly represented by vector group $\{\vec\alpha_1,\vec\alpha_2,\cdots, \vec\alpha_e\}$ , or $\alpha$ is a Linear Combination of $\{\vec\alpha_1,\vec\alpha_2,\cdots, \vec\alpha_e\}$. </p>
<blockquote class="blockquote-center">
<p>$<br>\begin{align}<br>&amp;\text{Set }A=\{\vec\alpha_1,\vec\alpha_2,\cdots, \vec\alpha_e\}\\<br>&amp;V=\text{Span}(A)=\{k_1\vec\alpha_1+k_2\vec\alpha_2+\cdots + k_e \vec\alpha_e | k_i\in \mathbb R, 1\le i\le e\}<br>\end{align}<br>$</p>

</blockquote>
<blockquote>
<p>In a <strong>matrix</strong> (i.e. $A$), set all rows as a vector group, and it span a space called <strong>Row Space</strong> (Noted: $R(A)$). All columns span a space called <strong>Column Space</strong> (Noted: $\text{Col}(A)$).</p>
<p>Linear Function $Ax=b$ is solutable <font color="red">if and only if</font> $b$ is a linear combination of $\text{Col}(A)$ (or $b \in \text{Col}(A)$).</p>
<p>Specially, if $b=0$ ($Ax=0$), then all solution of $x$ group as a vector space called <strong>Null Space</strong> (Noted: $\text{Nul}(A)$)</p>
</blockquote>
<hr>
<p><strong>2. Basis and Orthogonal</strong></p>
<ul>
<li>About <strong>Rank</strong><ul>
<li><font color="green">Recall: </font>$\color{green}LU$ <font color="green">factorization</font><ul>
<li>$\color{green}PA=LDU$, where $P$ is row exchange matrix (é¿å… A ä¸»å…ƒä¸º 0), $L$ is lower-triangle matrix with diagonal is all 1, $D$ is the coefficient matrix and $U$ is upper-triangle matrix.</li>
</ul>
</li>
<li>For a $m\times n$ matrix ranked $r$, there are $(n-r)$ particular solution of $Ax=b$ in the solution space of $A$ ($\text{Nul}(A)$).</li>
<li>For $Ax=b$ , $Ux=c$ or $Rx=d$ , there must be $\color{red}(m-r)$ <font color="red">conditions</font> for formula to be solutable.</li>
</ul>
</li>
</ul>
<ul>
<li>About <strong>Linear Independent</strong><ul>
<li><strong>Def.</strong> Suppose $A=\{v_1,v_2,\cdots, v_n\}$ is vector set of $\mathbb R^n$. If $\exists v_i \in A, v_i=\sum_{j\neq i} \lambda_j v_j, \lambda_j \in \mathcal R$ , then we say $A$ is <strong>linear dependent</strong>. <font color="red">If not, we say itâ€™s <strong>Linear Independent</strong>.</font></li>
<li><strong>Thm.</strong> $A$ is linear independent <font color="red">if and only if</font> $\lambda_1 \vec{v_1}+\lambda_2\vec{v_2}+\cdots +\lambda_k\vec{v_k}=0$ only holds when $\lambda_1=\lambda_2=\cdots =\lambda_k=0$</li>
</ul>
</li>
</ul>
<blockquote>
<p>Then we can talk about <strong>Basis</strong>(åŸº)</p>
</blockquote>
<p><strong>Def.</strong> For vector space $V$ , if vector group $A=\{v_1,v_2,\cdots, v_k\}$ satisfies that $V=\text{Span}(A)$ , and $A$ is <font color="red">linear independent</font> , then we say that $\color{red}A$ <font color="red">is one of the <strong>basis</strong> of</font> $\color{red}V$.</p>
<ul>
<li>If $A$ is a basis of $V$ , then $\forall \vec{w} \in V$ , there must be unique array $[a_1, a_2,\cdots,a_k]$ such that $\vec{w}=a_1v_1+a_2v_2+\cdots +a_kv_k$ . Then we call this array a <font color="red">coordinate</font> of $\vec w$ in $A$ , noted $[\vec w]_{A}$</li>
</ul>
<h3 id="Recall-for-Calculus"><a href="#Recall-for-Calculus" class="headerlink" title="Recall for Calculus"></a>Recall for Calculus</h3><p><strong>1. Langrange Multiplier</strong> [æ‹‰æ ¼æœ—æ—¥ä¹˜æ•°æ³•]</p>
<h3 id="Other-Prepared-Knowledge"><a href="#Other-Prepared-Knowledge" class="headerlink" title="Other Prepared Knowledge"></a>Other Prepared Knowledge</h3><p><strong>1. Norm</strong></p>
<p>On vectors :</p>
<ul>
<li>1-Norm: $|x|_1 = \sum_{i=1}^{N}{|x_i|}$</li>
<li>2-Norm: $|\textbf{x}|_2= \sqrt{\sum_{i=1}^{N} x_i^2}$</li>
<li>$\pm\infty$-Norm: $|\textbf{x}|_{\infty}=\underset{i}\max{|x_i|}$  ;  $|\textbf{x}|_{-\infty}=\underset{i}\min{|x_i|}$</li>
<li>p-Norm: $|\textbf{x}|_p=(\sum_{i=1}^{N}{|x_i|}^p)^{\frac{1}{p}}$</li>
</ul>
<p>On matrix :</p>
<ul>
<li>1-Norm(åˆ—å’ŒèŒƒæ•°) : $|A|_1=\underset{j}\max \sum_{i=1}^{m}{|a_{i,j}|}$  , maximum among <font color="red">absolute sum of column vector</font>.</li>
<li>2-Norm: $|A|_2=\sqrt{\lambda_1}$  , where $\lambda_1$ is the maximum eigenvalue(ç‰¹å¾å€¼) of $A^TA$</li>
<li>$\infty$-Norm(è¡Œå’ŒèŒƒæ•°) : $|A|_\infty=\underset{i}\max \sum_{j=1}^{n}{|a_{i,j}|}$  , maximum among <font color="red">absolute sum of row vector</font>.</li>
<li>F-Norm(æ ¸èŒƒæ•°) : $|A|_*=\sum_{i=1}^{n}\lambda_i$  , where $\lambda_i$ is singular value(å¥‡å¼‚å€¼) of $A$</li>
</ul>
<h2 id="II-Intro"><a href="#II-Intro" class="headerlink" title="II. Intro"></a>II. Intro</h2><h3 id="About-Big-Data"><a href="#About-Big-Data" class="headerlink" title="About Big Data"></a>About Big Data</h3><ul>
<li><font color="Red"><strong>4 Big â€œVâ€</strong></font> required in Big Data<ul>
<li><strong>Volume</strong>: KB, MB, GB ($10^9$ bytes), TB, PB, EB ($10^{18}$ bytes), ZB, YB<ul>
<li>Data of Baidu: several ZB</li>
</ul>
</li>
<li><strong>Variety</strong>: diï¬€erent sources from business to industry, diï¬€erent types</li>
<li><strong>Value</strong>: redundant information contained in the data, need to retrieve useful information</li>
<li><strong>Velocity</strong> (é€Ÿåº¦): fast speed for information transfer</li>
</ul>
</li>
<li><em>Two perspectives of data sciences</em> :<ul>
<li>Study science with the help of data : bioinformatics, astrophysics, geosciences, etc.</li>
<li>Use scientiï¬c methods to exploit (åˆ©ç”¨) data : statistics, machine learning, data mining, pattern recognition, data base, etc.</li>
</ul>
</li>
<li><em>Data Analysis</em><ul>
<li>Ordinary data types :<ul>
<li>Table : classical data (could be treated as matrix)</li>
<li>Set of points : mathematical description</li>
<li>Time series : text, audio, stock prices, DNA sequences, etc.</li>
<li>Image : 2D signal (or matrix equivalently, e.g., pixels), MRI, CT, supersonic imaging</li>
<li>Video : Totally 3D, with 2D in space and 1D in time (another kind of time series)</li>
<li>Webpage and newspaper : time series with spacial structure</li>
<li>Network : relational data, graph (nodes and edges)</li>
</ul>
</li>
<li>Basic assumption : the data are generated from an underlying model, which is unknown in practice<ul>
<li>Set of points : probability distribution</li>
<li>Time series : stochastic processes, e.g., Hidden Markov Model (HMM)</li>
<li>Image : random ï¬elds, e.g., Gibbs random ï¬elds</li>
<li>Network : graphical models, Beyesian models</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>Difficulties of Data Analysis</strong></p>
<ul>
<li>Huge <font color="#921aff">volume</font> of data</li>
<li>Extremely high dimensions<ul>
<li>Solutions: <ul>
<li>Make use of prior information</li>
<li>Restrict to simple models</li>
<li>Make use of special structures, e.g., sparsity, low rank, smoothness</li>
<li>Dimensionality reduction, e.g., PCA, LDA, etc.</li>
</ul>
</li>
</ul>
</li>
<li>Complex <font color="#921aff">variety</font> of data</li>
<li>Large noise (å™ªç‚¹, <font color="#921aff">values</font>) : data are always contaminated with noises</li>
</ul>
<h3 id="Representation-of-Data"><a href="#Representation-of-Data" class="headerlink" title="Representation of Data"></a>Representation of Data</h3><ul>
<li>Input space $\mathcal X = \{\text{All possible samples}\}$ ; $\textbf{x} \in \mathcal{X}$ is an input vector, also called feature, predictor, independent variable, etc; <strong>typically multi-dimension</strong>. For multi-dimension, $\textbf{x} \in \mathbb R^p$ is a weight vector (æƒé‡å‘é‡ï¼Œæ¯ä¸€ç»´åº¦æ‰€å æƒé‡å¯è°ƒæ•´) or coding vector (ç¼–ç å‘é‡ï¼Œe.g. çŸ¢é‡å›¾).</li>
<li>Output space $\mathcal{Y} = \{\text{All possible results}\}$ ; $y \in \mathcal{Y}$ is an output vector, also called response, dependent variable, etc; <strong>typically one dimension</strong>. E.g. $y = 0\ \text{or}\ 1$ for classiï¬cation problems, $y \in \mathbb{R}$ for regression problems.</li>
<li>For supervised learning, assume that $(\textbf{x},y)\sim \mathcal P$, a joint distribution on the sample space $\mathcal X \times \mathcal Y$</li>
</ul>
<hr>
<font size="4"><b>Supervised Learning (ç›‘ç£å­¦ä¹ ) â€”â€” <font color="Grey">given labels of data</font></b></font>

<ul>
<li>Training : ï¬nd the optimal parameters (or model) to minimize the error between the prediction and target</li>
<li>Classiï¬cation <font color="Grey">(if output is discrete)</font>: SVM (æ”¯æŒå‘é‡æœº), KNN (K-Nearest Neighbor), Desicion tree, etc.</li>
<li>Regression <font color="Grey">(if output is continuous)</font>: linear regression, CART, etc.</li>
</ul>
<p>Maths method about Supervised Learning </p>
<ul>
<li>Goal: Find the conditional distribution $\mathcal P(y|\textbf{x})$ of $y$ given $\textbf{x}$ </li>
<li>Training dataset: $\{(\textbf{x}_i, y_i)\}_{i=1}^{n} \overset{\text{i.i.d}}{\sim} \mathcal P$, used to learn an approximation $\hat{f}(\textbf{x})$ or $\hat{\mathcal P}(y|\textbf{x})$</li>
<li>Test dataset: $\{(\textbf{x}_j, y_j)\}_{j=n+1}^{n+m} \overset{\text{i.i.d}}{\sim} \mathcal P$, used to test</li>
</ul>
<div align="center">
<img src="/2024/06/22/Big-Data-1/bd2.png" alt="bd2" width="80%">
</div>

<blockquote>
<p>So we can conclude that a predictor must be developed from a Supervised Learning Model.</p>
</blockquote>
<font size="4"><b>Unsupervised Learning (æ— ç›‘ç£å­¦ä¹ ) â€”â€” <font color="Grey">no labels</font></b></font>

<ul>
<li>Optimize the parameters based on some <font color="#ce0000">natural rules</font>, e.g., cohesion (æ”¶æ•›) or divergence (å‘æ•£)</li>
<li>Clutering : K-Means, SOM (Self-Organizing Map)</li>
</ul>
<div align="center">
<img src="/2024/06/22/Big-Data-1/bd3.png" alt="bd3" width="80%">
</div>


<p>Maths method about Unsupervised Learning</p>
<ul>
<li>Goal : in probabilistic settings, find the distribution (PDF) $\mathcal P(\textbf{x})$ of $\textbf{x}$ and approximate it (there is no y)</li>
<li>Training dataset : $\{(x_i)\}_{i=1}^{n} \overset{\text{i.i.d}}{\sim} \mathcal P$ , used to learn an approximation $\hat{\mathcal P}(\textbf{x})$ (no test data in general)</li>
</ul>
<font size="4"><b>Semi-supervised learning:</b></font> 

<ul>
<li>with missing data, e.g., EM; self-supervised learning, learn the missing part of images, inpainting.</li>
</ul>
<font size="4"><b>Reinforcement learning (å¼ºåŒ–å­¦ä¹ ):</b></font>  

<ul>
<li><font color="red">No label, but have target</font>. Play games, e.g., Go, StarCraft; robotics; auto-steering.</li>
</ul>
<h3 id="Modeling-and-Analysis"><a href="#Modeling-and-Analysis" class="headerlink" title="Modeling and Analysis"></a>Modeling and Analysis</h3><ul>
<li>Decision function (hypothesis) space : <ul>
<li>$\mathcal{F}=\{\mathcal{f_\theta}=\mathcal{f_\theta}(x), \theta \in \Theta \}$ </li>
<li>or $\mathcal{F}=\{\mathcal{P_\theta}=\mathcal{P_\theta}(y|x), \theta \in \Theta \}$</li>
</ul>
</li>
<li><font color="red">Loss function :</font> a measure for the â€œgoodnessâ€ of the prediction, $L(y, \mathcal{f}(x))$ <ul>
<li><a name="0-1 loss"><i>0-1 loss</i></a>: $L(y, \mathcal{f}(x))=\textbf{l}_{y\not{=}f(x)}=1-\textbf{l}_{y=f(x)}$ ï¼ˆä¸ªäººç†è§£ä¸€èˆ¬æ˜¯ç”¨äºäºŒå…ƒé¡¹é¢„æµ‹çš„è¯¯å·®åˆ¤æ–­ï¼‰</li>
<li><i>Square loss</i>: $L(y, \mathcal{f}(x))=(y-f(x))^2$ ï¼ˆæ¯”ç»å¯¹å€¼è¯¯å·®æ›´æ³›ç”¨ï¼‰</li>
<li><i>Absolute loss</i>: $L(y, \mathcal{f}(x))={|y-f(x)|}$ </li>
<li><i>Cross-entropy (äº¤å‰ç†µ) loss</i>: <br>   $\color{red}L(y, \mathcal{f}(x))=-y\log{f(x)}-(1-y)\log{(1-f(x))}$</li>
</ul>
</li>
<li><strong>Risk</strong> : in average sense,<br> $\mathcal{R}(f)=E_{\mathcal P} [L(y, f(x))]=\underset{\mathcal X \times \mathcal Y}{\int}L(y, f(x))\mathcal{P}(x,y)\text d x \text d y$ </li>
<li><font color="Red"><b>Target of Learning</b></font> : minimize $\mathcal R_{exp}(f)$ to get $f^{\ast}$ ( $\text{å³} f^{\ast}=\underset{f}{min}\ \mathcal{R}_{exp}(f)$ )</li>
</ul>
<p><strong>Risk Minimize Strategy :</strong> </p>
<ul>
<li>Empirical risk minimization (<strong>ERM</strong>) : <ul>
<li>given training set $\{(\textbf{x}_i,y_i)\}_{i=1}^{n}$ , $R_{emp}(f)=\frac{1}{n}\sum_{i=1}^{n}L(y_i,f(\textbf{x}_i))$ <font color="grey">(Loss function çš„å‡å€¼å®šä¹‰ä¸ºé¢„æµ‹æ¨¡å‹ f çš„ç»éªŒé£é™©)</font> .<ul>
<li>By law of large number, $\underset{n\to\infty}{\lim} R_{emp}(f)=R_{exp}(f)$ . <font color="Grey">(å³ç»éªŒé£é™©è¶‹è¿‘äºé¢„æµ‹é£é™©)</font></li>
<li>Optimization problem <font color="red">(What Machine Learning truly do)</font> : $\underset{f\in\mathcal F}{\min}\frac{1}{n}\sum_{i=1}^{n}L(y_i,f(\textbf{x}_i))$ </li>
<li><font color="Green">Now we only need to know</font>  $\color{green}f$ <font color="Green">and training set</font>  $\color{green}\textbf{x}_i$ </li>
</ul>
</li>
</ul>
</li>
<li>Structural risk minimization (<strong>SRM</strong>) : <ul>
<li>given training set $\{(\textbf{x}_i,y_i)\}_{i=1}^{n}$ , and a complexity function $J=J(f)$ , $R_{SRM}(f)=\frac{1}{n}\sum_{i=1}^{n}L(y_i,f(\textbf{x}_i))+\lambda J(f)$ <ul>
<li>$J(f)$ measures how complex the model $f$ is, typically the degree of complexity</li>
<li>$Î»\ge 0$ is a tradeoff(å¹³è¡¡é¡¹) between the empirical risk and model complexity</li>
<li>Optimization problem <font color="red">(What Machine Learning truly do)</font> : $\underset{f\in\mathcal F}{\min}\frac{1}{n}\sum_{i=1}^{n}L(y_i,f(\textbf{x}_i))+\lambda J(f)$ </li>
<li><font color="Green">We need to know</font> $\color{green}f$ <font color="Green">and training set</font> $\color{green}{\textbf{x}_i}$ <font color="Green">, and need to</font> <font color="#00CD00">adjust the parameter</font>  $\color{green}{\lambda}$</li>
</ul>
</li>
</ul>
</li>
</ul>
<blockquote>
<p>We see that <font color="#c6a300">Optimization Method</font> is essencial in machine learning. Here are some of them: </p>
<ul>
<li>Gradient descent method (æ¢¯åº¦ä¸‹é™), including coordinate descent, sequential minimal optimization (SMO), etc.</li>
<li>Newtonâ€™s method and quasi-Newtonâ€™s method (æ‹Ÿç‰›é¡¿æ³•)</li>
<li>Combinatorial optimization (ç»„åˆä¼˜åŒ–)</li>
<li>Genetic algorithms (é—ä¼ ç®—æ³•)</li>
<li>Monte Carlo methods (éšæœºç®—æ³•)</li>
</ul>
</blockquote>
<p><strong>Model assessment :</strong></p>
<ul>
<li>Training error: $R_{emp}(\hat f)=\frac{1}{n}\sum_{i=1}^{n}L(y_i,\hat f(\textbf{x}_i))$ , tells the diï¬ƒculty of learning problem</li>
<li>Test error: $e_{test}(\hat f)=\frac{1}{m}\sum_{j=n+1}^{n+m}L(y_j,\hat f(\textbf{x}_j))$ , tells the capability of prediction ;<br> In particular, if 0-1 loss is used (below)<ul>
<li>Error rate : $e_{test}(\hat f) = \frac{1}{m}\sum_{j=n+1}^{n+m}\textbf{l}_{y_j\ne\hat f(\textbf{x}_j)}$</li>
<li>Accuracy : $r_{test}(\hat f) = \frac{1}{m}\sum_{j=n+1}^{n+m}\textbf{l}_{y_j=\hat f(\textbf{x}_j)}$</li>
<li>$e_{test}+ r_{test} = 1$ </li>
</ul>
</li>
<li><p>Generalization error (æ³›åŒ–è¯¯å·®â€”â€”æ¨¡å‹å¯¹æ–°æ ·æœ¬çš„é¢„æµ‹æ€§çš„åº¦é‡)</p>
<ul>
<li>$R_{exp}(\hat f)=E_{\mathcal P}[L(y,\hat f(\textbf{x}))]=\underset{\mathcal X\times\mathcal Y}{\int}L(y,\hat f(\textbf{x}))\mathcal P(\textbf{x},y)\text d\textbf{x} \text d y$ <br>tells the capability for predicting <font color="#9f4d95">unknown data</font> from the same distribution</li>
<li>Its upper bound $M$ deï¬nes the generalization ability (è´Ÿç›¸å…³)<ul>
<li>As $n\to\infty$, $M\to 0$ (which means almost no error)</li>
<li>As $\mathcal F$ becomes larger, $M$ increases.</li>
</ul>
</li>
</ul>
</li>
<li><p><em>Overfitting</em></p>
<ul>
<li>Too many model paramters ï¼ˆæ¨¡å‹å¤ªå¤æ‚ï¼‰</li>
<li>Better for training set, but worse for test set</li>
</ul>
</li>
<li><em>Underfitting</em><ul>
<li>Better for test set, but worse for training set</li>
</ul>
</li>
</ul>
<p><strong>Model Selection :</strong> choose the most proper model.</p>
<ul>
<li><a name="cross validation">Cross-validation</a> (äº¤å‰éªŒè¯) : split the training set into training subset and validation subset, use training set to train diï¬€erent models repeatedly, use validation set to select the best model with the smallest (validation) error<ul>
<li>Simple CV : randomly split the data into two subsets</li>
<li>K-fold CV : randomly split the data into $K$ disjoint subsets with the same size, treat the union of $K âˆ’ 1$ subsets as training set, the other one as validation set, do this repeatedly and select the best model with smallest mean (validation) error</li>
<li>Leave-one-out CV : $K = n$ in the previous case</li>
</ul>
</li>
</ul>
<h3>Data Science vs. Other Techniques</h3>

<div align="center">
<img src="/2024/06/22/Big-Data-1/bd1.png" alt="bd1" width="60%">
</div>

<hr>
<h2 id="III-Data-Preprocessing"><a href="#III-Data-Preprocessing" class="headerlink" title="III. Data Preprocessing"></a>III. Data Preprocessing</h2><h3 id="Data-Type"><a href="#Data-Type" class="headerlink" title="Data Type"></a>Data Type</h3><ul>
<li>Types of Attributes  <font size="2">(æ¯é—¨è¯¾å‡ ä¹éƒ½ç¦»ä¸å¼€è¿™ä¸ª)</font><ul>
<li>Discrete: $x \in \text{some countable sets}$, e.g., $\mathbb N$ <ul>
<li><a name="nominal">Nominal (åˆ—ä¸¾åä¹‰)</a> </li>
<li><a name="boolean">Boolean (0 or 1) </a> </li>
<li><a name="ordinal">Ordinal (åŸºæ•°ç­‰çº§, e.g. A+, A-, B+,â€¦) </a> </li>
</ul>
</li>
<li>Continuous: $x \in \text{some subset in }\mathbb R$ </li>
</ul>
</li>
</ul>
<ol>
<li><strong>Basic Statistics</strong> (ç»Ÿè®¡é‡)<ul>
<li>Mean</li>
<li>Median (ä¸­ä½æ•°)</li>
<li>extremum (æå€¼)</li>
<li>Quantile (åˆ†ä½æ•°) </li>
<li>Variance, Standard deviation (æ ‡å‡†å·®)</li>
<li>Mode (ä¼—æ•°)</li>
</ul>
</li>
</ol>
<div align="center">
<img src="/2024/06/22/Big-Data-1/bd4.png" alt="bd4" width="90%">
</div>

<blockquote>
<p>Empiricism:  Mean âˆ’ Mode = 3 $\times$ (Mean âˆ’ Median)</p>
</blockquote>
<ul>
<li>Box Plot (ç®±çº¿å›¾) â€”â€” used to describe statistics</li>
</ul>
<div align="center">
<img src="/2024/06/22/Big-Data-1/bd5.png" alt="bd5" width="40%">
</div>



<ol>
<li><strong>Metrics</strong> (åº¦é‡â€”â€”äº¦ç§°è·ç¦»å‡½æ•°ï¼Œæ˜¯åº¦é‡ç©ºé—´ä¸­æ»¡è¶³ç‰¹å®šæ¡ä»¶çš„ç‰¹æ®Šå‡½æ•°ã€‚åº¦é‡ç©ºé—´ç”±æ¬§å‡ é‡Œå¾—ç©ºé—´çš„è·ç¦»æ¦‚å¿µæŠ½è±¡åŒ–å®šä¹‰è€Œæ¥ã€‚)<ul>
<li>Proximity :<ul>
<li>Similarity : range is $[0, 1]$ </li>
<li>Dissimilarity : range is $[0, \infty]$ , sometimes <a href="#distance">distance</a> (noted by <code>d</code>)</li>
</ul>
</li>
<li>For <a href="#nominal">nominal data</a>, $d(\textbf{x}_i,\textbf{x}_j)=\frac{\sum_{k}\textbf{l}(\textbf{x}_{i,k}\neq\textbf{x}_{j,k})}{p}$ ,or one-hot encoding into Boolean data</li>
<li>For <a href="#boolean">Boolean data</a>, <strong>symmetric distance</strong> (rand disrance) $\text d(\textbf{x}_i,\textbf{x}_j) =\frac {r+s}{q+r+s+t}$ or <strong>Rand index</strong> $\text{Sim}_{\text{Rand}}(\textbf{x}_i,\textbf{x}_j)=\frac{q+t}{q+r+s+t}$ ; <strong>non-symmetric distance</strong> (<a name="Jaccard"><font color="black"> Jaccard distance </font></a>) $\text d(\textbf{x}_i,\textbf{x}_j)=\frac{r+s} {q+r+s}$ or <strong>Jaccard index</strong> $\text{Sim}_{\text{Jaccard}}(\textbf{x}_i,\textbf{x}_j)=\frac {q} {q+r+s}$ </li>
</ul>
</li>
</ol>
<div align="center">
<img src="/2024/06/22/Big-Data-1/bd6.png" alt="bd6" width="40%">
</div>



<p><a name="distance"><font color="Red"><strong>Distance :</strong></font></a></p>
<p><strong>Def.</strong> Distance <code>d</code> is the difference between two samples.</p>
<ul>
<li>Properties of Distance : <ul>
<li>Non-negative: $\text{d}(x,y)\ge 0$</li>
<li>Identity: $\text d(x,y)=0\Leftrightarrow x=y$ </li>
<li>Symmetric: $\text d(x,y)=\text d(y,x)$ </li>
<li>Basic Vector Attributes : e.g. $\text d(x,y)\le \text d(x,z)+\text d(z,y)$ </li>
</ul>
</li>
<li>è·ç¦»åº¦é‡åˆ†ä¸ºSpace Distance (e.g. Euclidean) ã€String Distance (e.g. Hamming distance) ã€Set Proximity (e.g. Jaccard distance) å’Œ Distribution Distance (e.g. Chi-square measure)</li>
</ul>
<font color="blue">ä»¥ä¸‹ç®€å•ä»‹ç»å‡ ç§è·ç¦»ï¼Œæ›´å¤šè¯·å‚è€ƒ<a href="https://blog.csdn.net/hy592070616/article/details/121723169?spm=1001.2014.3001.5501">æ­¤å¤„ (csdn note)</a></font><br>



<font color="blue">1 .  Minkowski distance (é—µå¯å¤«æ–¯åŸºè·ç¦»)</font>

<blockquote class="blockquote-center">
<p>$<br>\begin{align}<br>&amp;\text d(\textbf{x}_i,\textbf{x}_j)=\sqrt[h]{\sum_{k=1}^{p}|\text x_{ik}-\text x_{jk}|^h}&amp;<br>\end{align}<br>$</p>

</blockquote>
<blockquote>
<p>Parameter <code>h</code> is to <font color="blue">emphasize the character of the data</font>. By changing the value of <code>h</code> , Minkowski distance can cover many Distance Metrics.</p>
</blockquote>
<font color="blue">2 .  Manhattan distance (æ›¼å“ˆé¡¿è·ç¦») </font>


<blockquote>
<p>Minkowski distance where $h = 1$</p>
</blockquote>
<blockquote class="blockquote-center">
<p>$<br>\text d(\textbf{x}_i,\textbf{x}_j)=\sum_{k=1}^{p}|\text x_{ik}-\text x_{jk}|<br>$</p>

</blockquote>
<font color="blue">3 .  Euclidean distance (æ¬§æ°è·ç¦»)</font>

<blockquote>
<p>Minkowski distance where $h = 2$ </p>
</blockquote>
<blockquote class="blockquote-center">
<p>$<br>\text d(\textbf{x}_i,\textbf{x}_j)=\sqrt{\sum_{k=1}^{p}(\text x_{ik}-\text x_{jk})^2}<br>$</p>

</blockquote>
<font color="blue">4 .  Supremum distance (or Chebyshev distance, åˆ‡æ¯”é›ªå¤«è·ç¦»)</font>

<blockquote>
<p>Minkowski distance where $h \to \infty$ </p>
</blockquote>
<blockquote class="blockquote-center">
<p>$<br>\text d(\textbf{x}_i,\textbf{x}_j)=\max_{k=1}^{p}|\text x_{ik}-\text x_{jk}|<br>$</p>

</blockquote>
<p><a name="cosine distance"><font color="blue">5 .  Cosine distance (ä½™å¼¦è·ç¦»)</font></a> </p>
<blockquote class="blockquote-center">
<p>$<br>\cos(\textbf{x}_i,\textbf{x}_j)=\frac{\sum_{k=1}^{p}\text x_{ik}\text x_{jk}}{\sqrt{\sum_{k=1}^{p}\text x_{ik}^2}\sqrt{\sum_{k=1}^{p}\text x_{ik}^2}}=\frac{\textbf{x}_i\cdot\textbf{x}_j}{\left|\textbf{x}_i\right|\left|\textbf{x}_j\right|}<br>$</p>

</blockquote>
<p><strong>Other Distance:</strong></p>
<ul>
<li>For <a href="#ordinal">ordinal data</a>, mapping the data to numerical data : $X=\{x_{(1)}, x_{(2)},â€¦, x_{(n)}\}, x_{(i)} \mapsto \frac{iâˆ’1} {nâˆ’1}\in [0, 1]$ </li>
<li>For mixed type, use weighed distance (åŠ æƒ) with prescribed weights :</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\text d(\textbf{x}_i,\textbf{x}_j)=\frac{\sum_{g=1}^{G}w_{ij}^{(g)}\text d_{ij}^{(g)}}{\sum_{g=1}^{G}w_{ij}^{(g)}}<br>$</p>

</blockquote>
<h3 id="Data-Preprocessing-Lecture"><a href="#Data-Preprocessing-Lecture" class="headerlink" title="Data Preprocessing (Lecture)"></a>Data Preprocessing (Lecture)</h3><div align="center">
<img src="/2024/06/22/Big-Data-1/bd7.png" alt="bd7" width="90%">
</div>

<ul>
<li>Data Scaling (å½’ä¸€åŒ–ï¼Œæ ‡å‡†åŒ–)<ul>
<li>Why scaling?<ul>
<li>For better performance or normalize diï¬€erent dimensions</li>
</ul>
</li>
<li><a name="z-score"><b>Z-score scaling</b></a>:   <font size="5">$x_i^\ast=\frac{x_i-\hat\mu}{\hat\sigma}$ </font> ,<br>applicable when max and min unknown and data distributes well (e.g. normal distribution)</li>
<li><strong>0-1 scaling</strong> (Min-Max scaling) :   <font size="5">$x_i^\ast=\frac{x_i-\min_k x_k}{\max_k x_k-\min_k x_k}$ </font> ,<br>applicable for bounded data sets, and need to <font color="red">recompute</font> max and min when new data added</li>
<li>Decimal scaling: $x_{i}^{\ast}=\frac{x_i}{10^k}$, applicable for data varying across many magnitudes (åˆ†å¸ƒå¤ªå¹¿)</li>
<li>Logistic scaling: $x_i^{\ast}=\frac{1}{1+e^{-x_i}}$ , applicable for data concentrating nearby origin (åˆ†å¸ƒå¤ªçª„)</li>
</ul>
</li>
<li>Data Discretization (ç¦»æ•£åŒ–)<ul>
<li>Why discretization?<ul>
<li>Improve the robustness : removing the outliers by putting them into certain intervals</li>
<li>For better interpretation</li>
<li>Reduce the storage and computational power</li>
</ul>
</li>
<li><strong>Unsupervised discretization</strong>: equal-distance discretization (ç­‰è·ï¼Œæ•°æ®åˆ†å¸ƒå¯èƒ½ä¸å‡), equal-frequency discretization, clustering-based discretization (èšç±»), 3$\sigma$-based discretization</li>
<li><strong>Supervised discretization</strong>: information gain based discretization (e.g. å†³ç­–æ ‘), $\mathcal X^2$-based discretization (Chi-Merge)</li>
</ul>
</li>
<li>Data Redundancy <ul>
<li>Why redundancy exists?<ul>
<li>Correlations exist among different attributes (E.g. Age, birthday and current time), <font color="green">recalling the linear dependency for vectors</font></li>
</ul>
</li>
<li><strong>Continuous variables:</strong> compute the correlation coefficient (ç›¸å…³ç³»æ•°) <font size="4">$\rho_{A,B}=\frac{\sum_{i=1}^{k}{(a_i-\bar A)(b_i-\bar B)}}{k\hat\sigma_{A}\hat\sigma_{B}}\in[-1,1]$ </font></li>
<li><strong>Discrete variables:</strong> compute the $\mathcal X^{2}$ statistics : large $\hat{\mathcal{X}^{2}}$ value implies small correlation.</li>
</ul>
</li>
</ul>
<blockquote>
<p>About missing data: (<code>NA</code>, \<Empty>, <code>NaN</code>)</Empty></p>
<p>Delete or Pad </p>
<ul>
<li>Pad (or filling)<ul>
<li>fill with <font color="blue">0</font>, with <font color="blue">mean value</font>, with <font color="blue">similar variables</font> (auto-correlation is introduced), with <font color="blue">past data</font>, with <font color="blue">Expectation-Maximization</font> or by K-Means</li>
</ul>
</li>
</ul>
<p>In Python, <code>NaN</code> means missing values (Not a Number, missing float values)</p>
<p><code>None</code> is a Python object, representing missing values of the object type</p>
<p>For some multi-classifications (e.g. â€œMaleâ€ and â€œFemaleâ€) model, we should refer to <strong>Dummy Variables</strong> to describe. (We usually set â€œUnknownâ€ as reference variable <code>00</code>, and describe â€œMaleâ€ and â€œFemaleâ€ as <code>01</code> &amp; <code>10</code>)</p>
</blockquote>
<ul>
<li>Random filling : <ul>
<li>Bayesian Bootstrap : for discrete data with range $\{x_i\}^k_{i=1}$, randomly sample $k âˆ’ 1$ numbers from $U(0, 1)$ as $\{a_{(i)}\}^k_{i=0}$ with $a_{(0)} = 0$ and $a_{(k)} = 1$ ; then randomly sample from $\{x_i\}^k_{i=1}$ with probability distribution $\{a_{(i)} âˆ’ a_{(iâˆ’1)}\}^k_{i=1} $accordingly to fill in the missing values</li>
<li>Approximate Bayesian Bootstrap : Sample with replacement from $\{x_i\}^k_{i=1}$ to form new data set $X^\ast = \{x^\ast_{i} \}^{k^\ast}_{i=1}$ ; then randomly sample $n$ values from $X^\ast$ to fill in the missing values, allowing for repeatedly filling missing values</li>
</ul>
</li>
<li>Model based methods : treat missing variable as <code>y</code>, other variables as <code>x</code> ; take the  data without missing values as out training set to train a <font color="#009100">classification</font> or <font color="#009100">regression</font> model ; take those with missing values as test set to predict the missing values.</li>
</ul>
<h3 id="Outlier-å¼‚å¸¸å€¼"><a href="#Outlier-å¼‚å¸¸å€¼" class="headerlink" title="Outlier (å¼‚å¸¸å€¼)"></a>Outlier (å¼‚å¸¸å€¼)</h3><ul>
<li><p>Outlier Detection</p>
<ul>
<li>Statistics Based Methods</li>
<li>Local Outlier Factor</li>
</ul>
</li>
<li><p>Computing Density by Distance</p>
<ul>
<li>$d(A, B)$ : distance between $A$ and $B$ </li>
<li>$d_k (A)$ : k-distance of $A$, or the distance between $A$ and the <font color="red">k-th nearest point</font> from $A$ ;</li>
<li>$N_k (A)$ : Set of k-distance neighborhood of $A$, or the points within $d_k (A)$ from $A$ ;</li>
<li>$rd_k (B, A)$ : k-reach distance from $A$ to $B$, the repulsive distance from $A$ to $B$ as if $A$ has a hard-core with radius $d_k (A)$, $rd_k (B, A) = max\{d_k (A), d(A, B)\}$ ; k-reach-distance is not symmetric. [ $rd_k (B, A)\neq rd_k(A,B)$ ]  <br><font color="Grey">Personal understanding: Itâ€™s like adding a weight at two edge between two nodes in a directed graph.</font></li>
</ul>
</li>
</ul>
<blockquote>
<p>å¦‚æœ $B$ åœ¨ $A$ çš„ $k$ é‚»è¿‘ç‚¹ä»¥å¤–ï¼Œåˆ™å– $A$, $B$ è·ç¦»ï¼Œå¦‚æœ $B$ åœ¨ $A$ çš„ $k$ é‚»è¿‘ç‚¹ä»¥å†…ï¼Œåˆ™å– $A$ ä¸å…¶ $k$ é‚»è¿‘ç‚¹çš„è·ç¦»</p>
</blockquote>
<ul>
<li>Local Outlier Factor (Some definition)<ul>
<li>$lrd_k (A)$ : <font color="red">local reachability density</font> is inversely proportional (æˆåæ¯”) to the average distance</li>
<li>$lrd_k (A)=1/\left(\frac{ \sum_{O\in N_k (A)} rd_k (A,O) }{| N_k (A)|}\right)$ <font color="blue">(Definition)</font> </li>
<li>If for most $O\in N_k (A)$ , more than $k$ points are closer to $O$ than $A$ is, then the denominator (åˆ†æ¯) is much larger than $d_k(A)$ , and $lrd_k(A)$ is small (e.g. $k=3$ in following Pic)</li>
<li><font color="red">Local Outlier Factor</font> : $LOF_k(A)=\Large{\frac{ \sum_{O\in N_k(A)} \frac{lrd_k(O)}{lrd_k(A)}}{|N_k(A)|}}$ </li>
<li>$LOF_k(A) \ll 1$ , the density of $A$ is locally higher ; $LOF_k(A)\gg 1$ , the density of $A$ is locally lower, probably <font color="#ff359a">outlier</font> </li>
</ul>
</li>
</ul>
<div align="center">
<img src="/2024/06/22/Big-Data-1/bd10.png" alt="bd10" width="40%">
</div>

<blockquote>
<font face="åæ–‡æ¥·ä½“" size="4">æ³¨ï¼š</font>$LOF$ <font face="åæ–‡æ¥·ä½“" size="4">ä¸»è¦ç”¨äºæ£€æµ‹ç‚¹</font> $A$ <font face="åæ–‡æ¥·ä½“" size="4">çš„é‚»è¿‘ç‚¹å¯†åº¦ï¼Œå¹¶ç”±æ­¤æ¨æµ‹è¯¥ç‚¹æ˜¯å¦å¼‚å¸¸å€¼</font>

</blockquote>
]]></content>
      <categories>
        <category>2024 Spring</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>CSE Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>CS202 è®¡ç®—æœºç»„æˆåŸç†</title>
    <url>/2024/06/25/Computer-Organization/</url>
    <content><![CDATA[<h1 id="Computer-Organization"><a href="#Computer-Organization" class="headerlink" title="Computer Organization"></a>Computer Organization</h1>]]></content>
      <categories>
        <category>2024 Spring</category>
      </categories>
      <tags>
        <tag>CSE Learning</tag>
        <tag>Verilog</tag>
      </tags>
  </entry>
  <entry>
    <title>Introduction to Hexo and Github Page</title>
    <url>/2024/06/07/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is the very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
  </entry>
</search>
