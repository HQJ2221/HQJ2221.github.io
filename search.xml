<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>CS303 äººå·¥æ™ºèƒ½</title>
    <url>/2025/01/01/Artificial-Intelligence/</url>
    <content><![CDATA[<h1 id="Contents"><a href="#Contents" class="headerlink" title="Contents"></a>Contents</h1><p><strong>AI Search</strong></p>
<ul>
<li>Lecture 1. AI as Search</li>
<li>Lecture 2. Beyond Classical Search</li>
<li>Lecture 3. Problem-Specific Search</li>
</ul>
<p><strong>Machine Learning</strong></p>
<ul>
<li>Lecture 4. Principles of Machine Learning</li>
<li>Lecture 5. Supervised Learning</li>
<li>Lecture 6. Performance Evaluation for Machine Learning</li>
<li>Lecture 7. Unsupervised Learning</li>
<li>Lecture 8. Recommender System</li>
<li>Lecture 9. Automated Machine Learning</li>
</ul>
<p><strong>Knowledge and Reasoning</strong></p>
<ul>
<li>Lecture 10. Logical Agents</li>
<li>Lecture 11. First Order Logic</li>
<li>Lecture 12. Representing and Inference with Uncertainty</li>
<li>Lecture 13. Knowledge Graph</li>
</ul>
<h1 id="Lecture-1-AI-as-Search"><a href="#Lecture-1-AI-as-Search" class="headerlink" title="Lecture 1. AI as Search"></a>Lecture 1. AI as Search</h1><h2 id="Outline"><a href="#Outline" class="headerlink" title="Outline"></a>Outline</h2><ul>
<li>From searching to search tree</li>
<li>Uninformed Search Methods </li>
<li><font color="red">Heuristic (informed) Search</font> 



</li>
</ul>
<h2 id="Search-in-a-Tree"><a href="#Search-in-a-Tree" class="headerlink" title="Search in a Tree ?"></a>Search in a Tree ?</h2><blockquote>
<p><strong>æ¦‚å¿µï¼šæœ€çŸ­è·¯å¾„é€‰æ‹©ï¼Œæœç´¢æ ‘</strong></p>
<p>é€šè¿‡å°†æ‰€æœ‰â€œå›¾â€ä¸­çš„è·¯å¾„å±•å¼€ï¼Œå¯ä»¥å¾—åˆ°ä¸€ä¸ªæœç´¢æ ‘ã€‚å¯¹æ ‘è¿›è¡Œå…¨å±€æœç´¢å¿…ç„¶å¯ä»¥å¾—åˆ°æœ€çŸ­è·¯å¾„ã€‚</p>
<p>ä½†æ˜¯ï¼Œå½“å›¾å˜å¾—å¤æ‚æ—¶ï¼ˆå¦‚ä¸€ä¸ªçœçš„åœ°å›¾ï¼Œor a stateï¼‰ï¼Œæœç´¢é‡æå¤§ï¼Œå…¨å±€æœç´¢åŠå…¶ä½èƒ½ã€‚</p>
</blockquote>
<ul>
<li><font color="red">Q:</font> What is A Good Search Method?<ul>
<li><font color="green">Completeness</font>: Does it always find a solution if it exists?</li>
<li><font color="green">Optimality</font>: Does it always find the least-cost solution?</li>
<li><font color="green">Time complexity</font>: # nodes generated/expanded.</li>
<li><font color="green">Space complexity</font>: maximum # nodes in memory.</li>
</ul>
</li>
<li>In general, time and space complexity depend on:<ul>
<li>$b$ ğŸ‘‰ maximum # successors of any node in search tree. [æ]</li>
<li>$d$ ğŸ‘‰ depth of the least-cost solution. </li>
<li>$m$ ğŸ‘‰ maximum length of any path in the state space.</li>
</ul>
</li>
</ul>
<h2 id="Un-informed-Search-Methods"><a href="#Un-informed-Search-Methods" class="headerlink" title="Un-informed Search Methods"></a>Un-informed Search Methods</h2><blockquote>
<p>How to define â€œun-informedâ€ ?</p>
</blockquote>
<ul>
<li>Use only the information available in the problem definition.</li>
<li>Use <strong>NO</strong> problem-specific knowledge.</li>
</ul>
<blockquote>
<p>As some algorithms have been learnt in course Algorithm Design and Analysis, we skip them.</p>
</blockquote>
<h3 id="BFS"><a href="#BFS" class="headerlink" title="BFS"></a>BFS</h3><ul>
<li><font color="DodgerBlue">Completeness?</font> Yes (Suppose $b$ is finite)</li>
<li><font color="DodgerBlue">Optimality?</font> Yes (Suppose all edge values are <strong>non-negative</strong>)</li>
<li><font color="DodgerBlue">Time &amp; Space?</font> Both $O(b^{d+1})$</li>
</ul>
<h3 id="UCS-Uniform-Cost-Search"><a href="#UCS-Uniform-Cost-Search" class="headerlink" title="UCS (Uniform-Cost Search)"></a>UCS (Uniform-Cost Search)</h3><ul>
<li>Idea<ul>
<li>Expand the cheapest unexpanded node.</li>
<li>Implementation: a queue ordered by path cost, lowest first.</li>
</ul>
</li>
</ul>
<p><img src="/2025/01/01/Artificial-Intelligence/ai101.png" style="zoom:60%"></p>
<ul>
<li><font color="DodgerBlue">Completeness?</font> Yes (Suppose every step costs $\ge \epsilon$)</li>
<li><font color="DodgerBlue">Optimality?</font> Yes (Suppose all edge values are <strong>non-negative</strong>)</li>
<li><font color="DodgerBlue">Time &amp; Space?</font>  $O(b^{1+\lfloor C^{*}/\epsilon\rfloor})$<ul>
<li>$C^{*}$ : the cost of the optimal solution.</li>
<li>every action costs at least $\epsilon$.</li>
<li>Only if all step costs are equal, time/space $=O(b^{d+1})$</li>
</ul>
</li>
</ul>
<h3 id="DFS"><a href="#DFS" class="headerlink" title="DFS"></a>DFS</h3><ul>
<li><font color="DodgerBlue">Completeness?</font> No (fail in infinite-depth space and space with loops.)</li>
<li><font color="DodgerBlue">Optimality?</font> No</li>
<li><font color="DodgerBlue">Time?</font> $O(b^m)$<ul>
<li>Terrible if $m$ is much larger than $d$.</li>
</ul>
</li>
<li><font color="DodgerBlue">Space?</font> $O(bm)$ - linear!</li>
</ul>
<h3 id="DLS-Depth-Limit-Search"><a href="#DLS-Depth-Limit-Search" class="headerlink" title="DLS (Depth-Limit Search)"></a>DLS (Depth-Limit Search)</h3><ul>
<li>A variant of DFS: node at depth $l$ has no sucessors.</li>
<li><font color="DodgerBlue">Completeness?</font> No</li>
<li><font color="DodgerBlue">Optimality?</font> No</li>
<li><font color="DodgerBlue">Time?</font> $O(b^l)$</li>
<li><font color="DodgerBlue">Space?</font> $O(bl)$</li>
</ul>
<h3 id="IDS-Iterative-Deepening-Search"><a href="#IDS-Iterative-Deepening-Search" class="headerlink" title="IDS (Iterative Deepening Search)"></a>IDS (Iterative Deepening Search)</h3><ul>
<li>Idea<ul>
<li>Apply <strong>DLS</strong> with increasing limits</li>
<li>Combine benefit of <strong>BFS</strong> and <strong>DFS</strong></li>
</ul>
</li>
<li><font color="DodgerBlue">Completeness?</font> Yes</li>
<li><font color="DodgerBlue">Optimality?</font> Yes (Suppose costs of edges are non-negative)</li>
<li><font color="DodgerBlue">Time?</font> $O(b^d)$<ul>
<li>$(d+1)b^{0}+ db^{1}+(d-1)b^{2}+\cdots +b^d=O(b^{d})$</li>
</ul>
</li>
<li><font color="DodgerBlue">Space?</font> $O(bd)$</li>
</ul>
<blockquote>
<p>Preference when <strong>search space</strong> is large and <strong>depth</strong> of solution is unknown.</p>
</blockquote>
<h3 id="Bi-directional-Search"><a href="#Bi-directional-Search" class="headerlink" title="Bi-directional Search"></a>Bi-directional Search</h3><ul>
<li>Idea: simultaneous<ul>
<li>Replace single search tree with two smaller sub trees.</li>
<li>Forward tree: forward search from source to goal.</li>
<li>Backward tree: backward search from goal to source.</li>
</ul>
</li>
<li><font color="DodgerBlue">Completeness &amp; Optimality?</font> Like BFS (if BFS used in both trees)</li>
<li><font color="DodgerBlue">Time &amp; Space?</font> $O(b^{d/2})$</li>
<li>Cons: not always applicable<ul>
<li>Reversible actions? [æ˜¯å¦å¯ä»¥â€œç”±æœæº¯å› â€ï¼Ÿ]</li>
<li>Explicitly stated goal state? [å¶å­èŠ‚ç‚¹ä»£è¡¨â€œç»“å±€â€ï¼Œæ‰€æœ‰ç»“å±€æ˜¯å¦å·²çŸ¥ï¼Ÿ]</li>
</ul>
</li>
</ul>
<h2 id="Heuristic-informed-Search"><a href="#Heuristic-informed-Search" class="headerlink" title="Heuristic (informed) Search"></a><font color="red">Heuristic (informed) Search</font></h2><blockquote>
<p><font color="red">Q:</font> What is â€œHeuristicâ€ ?</p>
<p><font color="green">A:</font> Based on algorithm design, it searches the trees with intelligence, making use of <strong>domain knowledge</strong>.</p>
<p><font color="red">Q:</font> How to Design the Evaluation Function?</p>
<p><font color="green">A:</font> It depends (but some advice). Use heuristic function $f(x)$ to estimates the cheapest cost from $x$ to the goal state.</p>
<ol>
<li>$h(x)=0$ if $x$ is the goal state</li>
<li>non-negative</li>
<li><strong>problem-specific</strong></li>
</ol>
</blockquote>
<h3 id="Greedy-Best-first-Search"><a href="#Greedy-Best-first-Search" class="headerlink" title="Greedy Best-first Search"></a>Greedy Best-first Search</h3><ul>
<li>A simple example to describe heuristic function: letâ€™s say $f(x)=h_{SLD}(x)$ , where $h_{SLD}(x)$ is physical distance between two nodes (cities)</li>
</ul>
<p><img src="/2025/01/01/Artificial-Intelligence/ai102.png" style="zoom:60%"></p>
<ul>
<li><font color="DodgerBlue">Completeness?</font> Yes (finite space + repeated-state checking)</li>
<li><font color="DodgerBlue">Optimality?</font> No</li>
<li><font color="DodgerBlue">Time?</font> $O(b^m)$ (In practice, good heuristic gives drastic improvement)</li>
<li><font color="DodgerBlue">Space?</font> $O(b^m)$</li>
</ul>
<h3 id="A-Search"><a href="#A-Search" class="headerlink" title="A* Search"></a>A* Search</h3><ul>
<li>Idea: avoid expanding paths that are already expensive.<ul>
<li>Expand the node $x$ that has minimal $f(x)=h(x)+g(x)$<ul>
<li>$g(x)$ : cost so far to reach $x$</li>
<li>$h(x)$ : estimated cost from $x$ to goal</li>
<li>$f(x)$ : total cost</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>PF(performance) Metrics</strong></p>
<ul>
<li><font color="DodgerBlue">Completeness?</font> Yes</li>
<li><font color="DodgerBlue">Optimality?</font> Yes, if $h$ is <strong>admissible</strong> [å–å†³äºå¯å‘å¼ç®—æ³•]</li>
<li><font color="DodgerBlue">Time?</font> $O(b^d)$</li>
<li><font color="DodgerBlue">Space?</font> $O(b^d)$</li>
</ul>
<p><strong>Admissible heuristic</strong></p>
<ul>
<li><strong>Def.</strong> Heuristic function $h$ is admissible if $\forall x \to h(x)\ge hâ€™(x)$, where $hâ€™(x)$ is the <strong>true</strong> cost from $x$ to goal.</li>
<li>Search Efficiency of Admissible Heuristic<ul>
<li>For admissible $h_1$ and $h_2$, if $h_2(x)\ge h_1(x)$ for all $n$, then $h_2$ <strong>deminates</strong> $h_1$ and is more efficient for search.</li>
</ul>
</li>
</ul>
<blockquote>
<p>A* ç®—æ³•å¯ä»¥è®¤ä¸ºæ˜¯å­¦ä¹  AI çš„ç¬¬ä¸€åŸºç¡€ç®—æ³•ã€‚å®ƒæ˜ç¡®äº† AI éœ€è¦å…·æœ‰çš„é¦–è¦ç‰¹æ€§ï¼šå­¦ä¹ ã€‚A* ç®—æ³•æ˜¯æ ‘/å›¾æœç´¢ç®—æ³•ä¸­ç¬¬ä¸€ä¸ªå¯ä»¥åˆ©ç”¨â€œçŸ¥è¯†â€è¿›è¡Œå†³ç­–çš„ç®—æ³•ï¼Œä¸å†æ˜¯åƒéå†è¿™æ ·â€œæœºæ¢°ã€éšæœºâ€çš„ç®—æ³•ã€‚</p>
</blockquote>
<h1 id="Lecture-2-Beyond-Classical-Search"><a href="#Lecture-2-Beyond-Classical-Search" class="headerlink" title="Lecture 2. Beyond Classical Search"></a>Lecture 2. Beyond Classical Search</h1><h2 id="Outline-1"><a href="#Outline-1" class="headerlink" title="Outline"></a>Outline</h2><ul>
<li>More representations</li>
<li>General Search Frameworks</li>
<li>Summary</li>
</ul>
<h2 id="More-representations"><a href="#More-representations" class="headerlink" title="More representations"></a>More representations</h2><blockquote>
<p>Last lecture, we solve the search problem by Searching Tree.</p>
<p>But is there any more efficient data structure in some specific tasks ?</p>
</blockquote>
<h3 id="Direct-Search-in-the-Solution-Space"><a href="#Direct-Search-in-the-Solution-Space" class="headerlink" title="Direct Search in the Solution Space"></a>Direct Search in the Solution Space</h3><ul>
<li>Consider that the solution space is continuous, like $\mathbb{R}^{2}$.</li>
<li>Then if we generate a tree to describe each step, thatâ€™s silly.</li>
</ul>
<hr>
<ul>
<li>Representations of a solution space can be roughly categorized as:<ul>
<li>Continuous</li>
<li>Discrete: Binary, Integer, Permutation, etc.</li>
</ul>
</li>
<li>Different representations may favor different search methods, but most of them share a <strong>common framework</strong>.</li>
</ul>
<h2 id="General-Search-Frameworks"><a href="#General-Search-Frameworks" class="headerlink" title="General Search Frameworks"></a>General Search Frameworks</h2><p><img src="/2025/01/01/Artificial-Intelligence/ai201.png"></p>
<ul>
<li>Typical Frameworks:<ul>
<li>Local Search</li>
<li>Simulated Annealing</li>
<li>Tabu Search</li>
<li>Population-based search</li>
</ul>
</li>
<li>Two basic issues (differs over concrete search methods): <ul>
<li>search operator (how to generate a new candidate solution)</li>
<li>evaluation criterion (or replacement strategy)</li>
</ul>
</li>
</ul>
<h3 id="Typical-Search-Operators"><a href="#Typical-Search-Operators" class="headerlink" title="Typical Search Operators"></a>Typical Search Operators</h3><ul>
<li>A Search Operator generate a new solution based on previous ones.</li>
</ul>
<script type="math/tex; mode=display">
\phi : x\to x',\forall x,x' \in \mathcal{X}</script><blockquote>
<p>Now we use continuous case as an example.</p>
</blockquote>
<h3 id="Greedy-Local-Search-Framework"><a href="#Greedy-Local-Search-Framework" class="headerlink" title="Greedy Local Search Framework"></a>Greedy Local Search Framework</h3><ul>
<li>Given a predefined Local Search Operator</li>
<li>Iteratively generate new solutions</li>
<li>Always pick the best solution so far, sometimes also known as <font color="DodgerBlue">Hill Climbing</font>.</li>
</ul>
<p><img src="/2025/01/01/Artificial-Intelligence/ai202.png"></p>
<blockquote>
<p>but sometimes trapped in local optimum</p>
</blockquote>
<h3 id="SA-Tabu-and-Bayesian-Optimizations"><a href="#SA-Tabu-and-Bayesian-Optimizations" class="headerlink" title="SA, Tabu and Bayesian Optimizations"></a>SA, Tabu and Bayesian Optimizations</h3><h4 id="Simulated-Annealing"><a href="#Simulated-Annealing" class="headerlink" title="Simulated Annealing"></a>Simulated Annealing</h4><blockquote>
<p>æ¦‚å¿µï¼šæ¸©åº¦ï¼Œä¸‹é™ç‡</p>
<p>æ¨¡æ‹Ÿé€€ç«æ˜¯åŸºäºç‰©ç†é€€ç«ç°è±¡çš„ä¸€ç§å¯¹äºè´ªå¿ƒç­–ç•¥çš„ä¼˜åŒ–æ–¹æ³•ã€‚ç›®çš„æ˜¯åœ¨ä¸€å®šæ¦‚ç‡ä¸Šå¸®åŠ©è·³å‡ºå±€éƒ¨æœ€ä¼˜çš„å±€é¢ã€‚ï¼ˆéšæœºï¼‰</p>
<p>è¯¥ä¼˜åŒ–æ–¹æ³•éœ€è¦æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´è¶…å‚æ•°ï¼šåˆå§‹æ¸©åº¦ $T_0$ï¼Œç»“æŸæ¸©åº¦ $T_t$ï¼Œå’Œæ¸©åº¦ä¸‹é™ç‡ $\alpha$ã€‚</p>
</blockquote>
<script type="math/tex; mode=display">
p=\left\{
\begin{array}{cl}
&1 &\text{if } f(x_i) \lt f(x_i') \\
&\exp{-\frac{f(x_i)-f(x_i')}{T}} &\text{if } f(x_i) \lt f(x_i')
\end{array}\right.</script><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="type">Set</span> T(<span class="number">0</span>), T(t), alpha</span><br><span class="line">init x(<span class="number">0</span>), T(i) = T(<span class="number">0</span>)</span><br><span class="line"><span class="keyword">while</span> T(i) &lt; T(t):</span><br><span class="line">  generate xâ€˜ based on x(i)</span><br><span class="line">  calc f(xâ€˜)</span><br><span class="line">  calc p</span><br><span class="line">  <span class="keyword">if</span> c = random[<span class="number">0</span>,<span class="number">1</span>] &lt; p: x(i+<span class="number">1</span>) = xâ€˜</span><br><span class="line">  <span class="keyword">else</span>: x(i+<span class="number">1</span>) = x(i)</span><br><span class="line">  i += <span class="number">1</span></span><br><span class="line">  Update T(i) = T(i) * alpha</span><br><span class="line">end</span><br><span class="line"><span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<h4 id="Tabu"><a href="#Tabu" class="headerlink" title="Tabu"></a>Tabu</h4><p><strong>Hill climbing â†’ Tabu Search</strong></p>
<ul>
<li>Key idea: Donâ€™t visit the sample candidate solution twice.</li>
<li>Challenge: How to define the Tabu list?</li>
<li>Concept:<ul>
<li>Tabu List [ç¦å¿Œè¡¨]</li>
<li>Tabu Object: items in TL, e.g., in Traveling Salesman Problem (TSP), we can set cities as TO (can be some attributes involved to $f(x)$)</li>
<li>Tabu Tenure: â€œTimeâ€ that TO stay in TL. ğŸ‘‰ to avoid short loop(TTâ†“) or low PF(TTâ†‘)</li>
<li>Aspiration Criteria: to choose TO with best PF, and pop it out from TL.</li>
</ul>
</li>
</ul>
<blockquote>
<p>é€šè¿‡ç»´æŒä¸€ä¸ªç¦å¿Œè¡¨çš„æ–¹å¼ï¼Œåœ¨ä¸€å®šç¨‹åº¦ä¸Šæ¥æ”¶æ¯”å½“å‰æœ€ä¼˜è§£è¦å·®çš„ç»“æœï¼Œä»è€Œè·³å‡ºå±€éƒ¨æœ€ä¼˜</p>
</blockquote>
<h4 id="Bayesian-Optimizations"><a href="#Bayesian-Optimizations" class="headerlink" title="Bayesian Optimizations"></a>Bayesian Optimizations</h4><p><strong>Hill climbing â†’ Bayesian Optimizations</strong></p>
<ul>
<li>Key idea: Build a model to â€guessâ€ which solution is good.</li>
<li>Challenge: <ul>
<li>model building is non-trivial</li>
<li>may need lots of data to build the model, limited to low-dimensional problem</li>
</ul>
</li>
</ul>
<blockquote>
<p>æ¶‰åŠæœºå™¨å­¦ä¹ å†…å®¹</p>
</blockquote>
<h3 id="Population-based-Search"><a href="#Population-based-Search" class="headerlink" title="Population-based Search"></a>Population-based Search</h3><ul>
<li>Idea: Since we sample from a probability distribution, why 1 at a time?</li>
<li><font color="red">Evolutionary Algorithm</font>:</li>
</ul>
<p><img src="/2025/01/01/Artificial-Intelligence/ai203.png"></p>
<ul>
<li>Seeking a good distribution: maximize the following â€œobjective functionâ€:</li>
</ul>
<script type="math/tex; mode=display">
\mathcal{J}=\int f(x)p(x|\theta_{1}) dx</script><ul>
<li>where $p(x|\theta_{1})$ is prob density function parameterized by $\theta_{1}$</li>
<li>Using â€œPopulationâ€ help making objective function â€œsmoothâ€</li>
</ul>
<p><img src="/2025/01/01/Artificial-Intelligence/ai204.png"></p>
<ul>
<li>Suppose we now converge to some (global or local) optimum</li>
<li>If run the algorithm again, we hope the algorithm (i.e., the distribution corresponding to the final population) <font color="red">converge to a different optimum</font> (and thus a different PDF).</li>
</ul>
<script type="math/tex; mode=display">
\mathcal{J}= \sum_{i=1}^{\lambda} \int f(x)p(x|\theta_{i}) dx - \sum_{i=1}^{\lambda} \sum_{j=1}^{\lambda} C(\theta_{i}, \theta_{j})</script><ul>
<li>where $C(\theta_{i},\theta_{j})$ is similarity of the two PDFs [æ¦‚ç‡å¯†åº¦åˆ†å¸ƒ]</li>
</ul>
<p><strong>EA Applications</strong></p>
<ul>
<li>N-Queen Problems [é€šè¿‡â€œæ‚äº¤â€æ“ä½œç”Ÿæˆæ–°ç»„åˆï¼Œæ¯æ¬¡è¿›è¡Œå¤šä¸ªç»„åˆè®¡ç®—]</li>
<li>é¸Ÿå·¢è®¾è®¡ï¼ŒåŠ¨è½¦è½¦å¤´è®¾è®¡ç­‰</li>
</ul>
<h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><ul>
<li>This lecture is talking about <font color="red">general-purpose search frameworks</font>, rather than search algorithm.</li>
<li>When addressing a specific problem, heuristics derived from domain knowledge needs to be incorporated in forms of search operators to obtain the best performance.</li>
<li>For some problem of great importance, mature <font color="red">application-specific optimization approaches</font> have been developed such that algorithm design from scratch is not needed.</li>
</ul>
<blockquote>
<p>Therefore, next lecture will talk about some problem-specific search algorithms.</p>
</blockquote>
<h1 id="Lecture-3-Problem-Specific-Search"><a href="#Lecture-3-Problem-Specific-Search" class="headerlink" title="Lecture 3. Problem-Specific Search"></a>Lecture 3. Problem-Specific Search</h1><h2 id="Outline-2"><a href="#Outline-2" class="headerlink" title="Outline"></a>Outline</h2><ul>
<li>Make Search Algorithms Less General</li>
<li>Gradient-based Methods for Numerical Optimization</li>
<li>Quadratic Programming Problems</li>
<li>Constraint Satisfaction Problems</li>
<li>Adversarial Search</li>
</ul>
<h2 id="Make-Search-Algorithms-Less-General"><a href="#Make-Search-Algorithms-Less-General" class="headerlink" title="Make Search Algorithms Less General"></a>Make Search Algorithms Less General</h2><blockquote>
<p>Why we need problem-specific search ?</p>
</blockquote>
<ul>
<li>When designing an algorithm for a problem (class), taking the problem characteristics into account usually helps us get the desired solution by <font color="red">searching only a part of the search/state space</font>, making the search more efficient.</li>
</ul>
<font color="green"><b>Recall</b></font>

<ul>
<li>consider the ubiquitous (æ™®éçš„) optimization problems:</li>
</ul>
<script type="math/tex; mode=display">
\begin{array}{ll}
&\text{maximize} &f(x) \\
&\text{subject to:} &g_i(x)\le 0,\ i=1\cdots m \\
& &h_j(x)=0,\ j=1\cdots p
\end{array}</script><ul>
<li>What is â€œproblem characteristicâ€? Most basically:<ul>
<li>What is $x$ ?</li>
<li>What is $f$ ?</li>
<li>Does $f$ fulfill some properties that would lead to a more efficient search?</li>
</ul>
</li>
</ul>
<h2 id="Gradient-based-Methods-for-Numerical-Optimization"><a href="#Gradient-based-Methods-for-Numerical-Optimization" class="headerlink" title="Gradient-based Methods for Numerical Optimization"></a>Gradient-based Methods for Numerical Optimization</h2><ul>
<li>Suppose the objective function $f(x_1 , y_1, x_2, y_2, x_3, y_3)$ is continuous and differentiable (thus the gradient could be calculated)</li>
<li>Compute:</li>
</ul>
<script type="math/tex; mode=display">
\nabla f=\left( \large{\frac{\partial f}{\partial x_1}, \frac{\partial f}{\partial y_1}, \frac{\partial f}{\partial x_2}, \frac{\partial f}{\partial y_2}, \frac{\partial f}{\partial x_3}, \frac{\partial f}{\partial y_3}} \right)</script><ul>
<li>to increase/reduce $f$, e.g., by $x \leftarrow x + \alpha \nabla f(x)$ [æ¢¯åº¦ä¸‹é™]</li>
</ul>
<h2 id="Quadratic-Programming-Problems"><a href="#Quadratic-Programming-Problems" class="headerlink" title="Quadratic Programming Problems"></a>Quadratic Programming Problems</h2><ul>
<li>The objective function is a <font color="red">quadratic(äºŒæ¬¡) function</font> of $x$</li>
<li>The constraints are linear functions of $x$</li>
</ul>
<script type="math/tex; mode=display">
\begin{array}{ll}
& &\min f(x)=q^{T}x + \frac{1}{2}x^{T}Qx \\
&\text{s.t.} & Ax = a,\ Bx \le b,\ x\ge 0 \\
\end{array}</script><ul>
<li>When there is <strong>no constraint</strong>, we can solve this problem by differenctiation. ($fâ€™(x)=0$)</li>
<li>But when there are constraints, search is still needed (<font color="green">Recall:</font> Lagrange multiplier)</li>
</ul>
<blockquote>
<p>å¼•å‡ºæ¥ä¸‹æ¥çš„é—®é¢˜ï¼šCSP</p>
</blockquote>
<h2 id="Constraint-Satisfaction-Problems-CSP"><a href="#Constraint-Satisfaction-Problems-CSP" class="headerlink" title="Constraint Satisfaction Problems (CSP)"></a><font color="red">Constraint Satisfaction Problems (CSP)</font></h2><ul>
<li>Standard Search Problem<ul>
<li><strong>state</strong> is a â€œblack boxâ€ ğŸ‘‰ any old data structure that supports goal test, eval, successors</li>
</ul>
</li>
<li>CSP<ul>
<li><strong>state</strong> is defined by variable $X_i$ with values from domain $D_i$</li>
<li><strong>goal test</strong> is a set of constraints specifying allowable combinations of values for subsets of variables</li>
</ul>
</li>
</ul>
<blockquote>
<p>ä¾‹ï¼šåœ°å›¾ä¸Šè‰²é—®é¢˜ã€‚é™åˆ¶ï¼šç›¸é‚»åŒºå—ä¸èƒ½ä¸ŠåŒä¸€é¢œè‰²ã€‚</p>
<p>å‡è®¾ä¸¤ä¸ªåŒºå— $X=\{A,B\}$ï¼Œå››ç§é¢œè‰² $D=\{R, G, B, Y\}$ï¼ŒåŸæœ¬å¯ä»¥æœ‰ 16 ç§ç»„åˆï¼Œä½†æ˜¯ç”±äºé™åˆ¶æ¡ä»¶åªæœ‰ 12 ç§ã€‚</p>
</blockquote>
<h3 id="Characteristics-of-CSPs"><a href="#Characteristics-of-CSPs" class="headerlink" title="Characteristics of CSPs"></a>Characteristics of CSPs</h3><h4 id="Real-world-CSPs"><a href="#Real-world-CSPs" class="headerlink" title="Real-world CSPs"></a>Real-world CSPs</h4><ul>
<li>Assignment problems</li>
<li>Timetabling problems</li>
<li>Hardware configuration</li>
<li>Floorplanning</li>
<li>Factory scheduling</li>
<li>â€¦â€¦</li>
</ul>
<h4 id="Commutativity"><a href="#Commutativity" class="headerlink" title="Commutativity"></a>Commutativity</h4><blockquote>
<p>First character</p>
</blockquote>
<ul>
<li>Commutativity help us formulate the search tree (only 1 variable needs to be considered at each node in the search tree).</li>
</ul>
<p><img src="/2025/01/01/Artificial-Intelligence/ai301.png"></p>
<h4 id="Constraint-Graph"><a href="#Constraint-Graph" class="headerlink" title="Constraint Graph"></a>Constraint Graph</h4><blockquote>
<p>Second</p>
</blockquote>
<p><img src="/2025/01/01/Artificial-Intelligence/ai302.png"></p>
<h4 id="Inference"><a href="#Inference" class="headerlink" title="Inference"></a>Inference</h4><ul>
<li>A constraint graph allows the agent to do <font color="red">inference</font> in addition to search. </li>
<li>Inference basically means <font color="red">checking local consistency</font> (or detecting inconsistency) <ul>
<li>Node consistency</li>
<li>Arc Consistency</li>
<li>Path Consistency</li>
<li>K-consistency</li>
<li>Global consistency</li>
</ul>
</li>
<li>Inference helps <font color="red">prune</font> the search tree, either before or during the search.</li>
</ul>
<h3 id="Backtracking-Search-for-CSP"><a href="#Backtracking-Search-for-CSP" class="headerlink" title="Backtracking Search for CSP"></a>Backtracking Search for CSP</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">backtracking_search</span>(<span class="params">csp</span>) -&gt; (solution/failure):</span><br><span class="line">  <span class="keyword">return</span> recursive_backtracking(&#123;&#125;, csp)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">recursive_backtracking</span>(<span class="params">&#123;&#125;, csp</span>) -&gt; (result/failure):</span><br><span class="line">  <span class="keyword">if</span> assignment <span class="keyword">is</span> complete then <span class="keyword">return</span> assignment</span><br><span class="line">  var &lt;- Select_Unassigned_Variable(Variable[csp], assignment, csp)</span><br><span class="line">  <span class="keyword">for</span> value <span class="keyword">in</span> Order_Domain_Value(var, assignment, csp) do</span><br><span class="line">    <span class="keyword">if</span> value <span class="keyword">is</span> consistent <span class="keyword">with</span> assignment given constraint[csp] then</span><br><span class="line">      add &#123;var = value&#125; to assignment</span><br><span class="line">      result &lt;- recursive_backtracking(assignment, csp)</span><br><span class="line">      <span class="keyword">if</span> result != failure then <span class="keyword">return</span> result</span><br><span class="line">      remove &#123;var = value&#125; <span class="keyword">from</span> assignment</span><br><span class="line">  <span class="keyword">return</span> failure</span><br></pre></td></tr></table></figure>
<ul>
<li>More improvement can be done:<ul>
<li>E.g. in <code>Select_Unassigned_Variable</code>, design some strategies to choose the optimal variable</li>
<li>E.g. maintain a conflict set, etc.</li>
</ul>
</li>
</ul>
<h2 id="Adversarial-å¯¹æŠ—æ€§-Search"><a href="#Adversarial-å¯¹æŠ—æ€§-Search" class="headerlink" title="Adversarial(å¯¹æŠ—æ€§) Search"></a>Adversarial(å¯¹æŠ—æ€§) Search</h2><blockquote>
<p>ä»¥ä¸€ä¸ªæ¸¸æˆä¸ºä¾‹ï¼š</p>
</blockquote>
<p><img src="/2025/01/01/Artificial-Intelligence/ai303.png"></p>
<p><strong>Algorithm.</strong> Minimax Algorithm</p>
<ul>
<li>Idea<ul>
<li>Assume the game is deterministic and perfect information is available</li>
<li>For player â€œMAXâ€, choose the move to position the <font color="dodgerblue">highest minimax value</font></li>
</ul>
</li>
</ul>
<p><img src="/2025/01/01/Artificial-Intelligence/ai304.png"></p>
<ul>
<li>Perform a <strong>complete</strong>(later we will optimize this) depth-first search of the game tree.</li>
<li><strong>Recursively</strong> compute the minimax values of each successor state.</li>
<li>Maximize the worst-case outcome for MAX.</li>
</ul>
<h3 id="Alpha-Beta-Pruning"><a href="#Alpha-Beta-Pruning" class="headerlink" title="Alpha-Beta Pruning"></a>Alpha-Beta Pruning</h3><ul>
<li>Idea: Remove (unneeded) part of the minimax tree from consideration.</li>
</ul>
<p><img src="/2025/01/01/Artificial-Intelligence/ai305.png"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># AB Search</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">alpha_beta_search</span>(<span class="params">state</span>):</span><br><span class="line">  <span class="keyword">return</span> max_value(state, -INF, INF)</span><br><span class="line"></span><br><span class="line"><span class="comment"># MAX search</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">max_value</span>(<span class="params">state, alpha, beta</span>):</span><br><span class="line">  <span class="keyword">if</span> <span class="keyword">is</span> terminal state:</span><br><span class="line">    <span class="keyword">return</span> util(state)</span><br><span class="line">  v &lt;- (-INF)</span><br><span class="line">  <span class="keyword">for</span> a <span class="keyword">in</span> action(state):</span><br><span class="line">    v &lt;- <span class="built_in">max</span>(v, min_value(result(s, a), alpha, beta))</span><br><span class="line">    <span class="keyword">if</span> v &gt;= beta:  <span class="comment"># pruning</span></span><br><span class="line">      <span class="keyword">return</span> v</span><br><span class="line">    alpha &lt;- <span class="built_in">max</span>(alpha, v)</span><br><span class="line">  <span class="keyword">return</span> v</span><br><span class="line"></span><br><span class="line"><span class="comment"># MIN search</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">min_value</span>(<span class="params">state, alpha, beta</span>):</span><br><span class="line">  <span class="keyword">if</span> <span class="keyword">is</span> terminal state:</span><br><span class="line">    <span class="keyword">return</span> util(state)</span><br><span class="line">  v &lt;- INF</span><br><span class="line">  <span class="keyword">for</span> a <span class="keyword">in</span> action(state):</span><br><span class="line">    v &lt;- <span class="built_in">min</span>(v, max_value(result(s, a), alpha, beta))</span><br><span class="line">    <span class="keyword">if</span> v &lt;= alpha:  <span class="comment"># pruning</span></span><br><span class="line">      <span class="keyword">return</span> v</span><br><span class="line">    beta &lt;- <span class="built_in">min</span>(beta, v)</span><br><span class="line">  <span class="keyword">return</span> v</span><br></pre></td></tr></table></figure>
<ul>
<li>Explanation:<ul>
<li>when we search maximum for â€œMAXâ€, we first suppose â€œMAXâ€ choose action a, and â€œMINâ€ make perfect action (minimum in â€œMAXâ€ view), assuming that value is 3.</li>
<li>Then â€œMAXâ€ will focus on range $[3, \infty]$.</li>
<li>We then suppose â€œMAXâ€ choose action b, and â€œMINâ€ make a choice for an action value 2.</li>
<li>Weâ€™re sure that â€œMINâ€ ultimately will make a choice having value $\le 2$ (optimal for â€œMINâ€). However, â€œMAXâ€ only accept actions value $\ge 3$, so action b wonâ€™t be accepted.</li>
<li>Therefore, we can stop â€œMINâ€ from searching the other actions.</li>
</ul>
</li>
<li>So we found that Alpha-Beta Pruning have limitation:<ul>
<li>games with more than 2 players ?</li>
<li>2-players game that is not zero-sum ? [éæ•Œå¯¹ï¼Ÿ]</li>
<li>Minimax or Alpha-Beta Pruning donâ€™t apply ?</li>
</ul>
</li>
<li>And sometimes the <strong>order</strong> of â€œactionsâ€ affects the PF.</li>
</ul>
<h2 id="Summary-on-Search"><a href="#Summary-on-Search" class="headerlink" title="Summary on Search"></a>Summary on Search</h2><ul>
<li>How to <font color="red">represent</font> the search space?<ul>
<li>Search Tree (state space)</li>
<li>Solution space</li>
</ul>
</li>
<li>What is the <font color="red">objective function and constraint</font>, and algorithm in textbook already good enough? </li>
<li>Which <font color="red">algorithmic framework</font> to choose?<ul>
<li>Tree search, e.g., Un-informed Search, Heuristic Search (A*â€¦)</li>
<li>Direct search in the solution space, e.g., Hill Climbing, Simulated Annealing, Genetic Algorithmâ€¦ </li>
</ul>
</li>
<li>How to define <font color="red">concrete components</font> of the algorithm framework? <ul>
<li>General-purpose operators in literature</li>
<li>Problem-specific operators, designed based on domain knowledge</li>
</ul>
</li>
</ul>
<blockquote>
<p>Always <strong>trade-off</strong> among solution quality, efficiency, and your domain knowledge</p>
</blockquote>
<h1 id="Lecture-4-Principles-of-Machine-Learning"><a href="#Lecture-4-Principles-of-Machine-Learning" class="headerlink" title="Lecture 4. Principles of Machine Learning"></a>Lecture 4. Principles of Machine Learning</h1><h2 id="Outline-3"><a href="#Outline-3" class="headerlink" title="Outline"></a>Outline</h2><ul>
<li>What is Learning</li>
<li>Key Questions for Learning</li>
<li>Learning Paradigms and Principles</li>
</ul>
<h2 id="What-is-Learning"><a href="#What-is-Learning" class="headerlink" title="What is Learning?"></a>What is Learning?</h2><ul>
<li><strong>Machine Learning</strong>: Given some observations (data) from the environment, how could an agent improve its agent function?</li>
<li>Intuitive assumptions<ul>
<li>the data share something in common</li>
<li>â€œsomethingâ€ could be obtained by an algorithm/program</li>
</ul>
</li>
</ul>
<h3 id="Two-simple-methods"><a href="#Two-simple-methods" class="headerlink" title="Two simple methods"></a>Two simple methods</h3><p><strong>A Naive Parametric Method â€”â€” Bayesian Formula</strong></p>
<ul>
<li>Classify a data to the class with the highest posterior probability</li>
<li><font color="dodgerblue">Assumption:</font> data follows independent identically distribution</li>
</ul>
<script type="math/tex; mode=display">
\begin{array}{c}
&P(w_j|x)=\frac{p(x|w_j)p(w_j)}{p(x)} \\
&P(w_2|x)\gt P(w_1|x) \Leftrightarrow \ln{p(x|w_2)}+\ln{p(w_2)} \gt \ln{p(x|w_1)}+\ln{p(w_1)} \\
\end{array}</script><ul>
<li><strong>â€œParametricâ€</strong>: the assumption on the probability density function (PDF).</li>
<li>Parametric methods usually do not involve parameters to fine-tune, while Nonparametric methods usually do.</li>
</ul>
<p><strong>A Linear Function</strong></p>
<ul>
<li>Find a straight line/hyper-plane to separate data from different classes.</li>
</ul>
<p><a name="ai401"><img src="/2025/01/01/Artificial-Intelligence/ai401.png"></a></p>
<h2 id="Key-Questions-for-Machine-Learning"><a href="#Key-Questions-for-Machine-Learning" class="headerlink" title="Key Questions for Machine Learning"></a>Key Questions for Machine Learning</h2><ul>
<li>What is the format of the data? (data representation)</li>
<li>What does the agent function look like? (model representation)</li>
<li>How to measure the â€œimprovementâ€? (objective function)</li>
<li>What is the learning algorithm? (to get a good agent function)</li>
</ul>
<center><b>Representation + Algorithm + Evaluation = Agent function/Model</b></center>



<h2 id="Learning-Paradigms-and-Principles"><a href="#Learning-Paradigms-and-Principles" class="headerlink" title="Learning Paradigms and Principles"></a>Learning Paradigms and Principles</h2><ul>
<li>Learning Principles: <font color="magenta">Generalization!</font><ul>
<li>the learned agent function is expected to be able to handle previously unseen situations.</li>
</ul>
</li>
<li>Learning Paradigms (èŒƒå¼)<ul>
<li>A Machine Learning process typically involves two phases<ul>
<li>Training: build the agent function</li>
<li>Testing/Inference: test the agent function/deploy the agent function in real use.</li>
</ul>
</li>
<li>Different ML techniques may use different training/learning paradigms<ul>
<li><font color="red">Supervised Learning:</font> the correct answer is available to the learning algorithm.</li>
<li><font color="red">Reinforcement Learning:</font> the only feedback is the reward of an output, e.g., the output is correct or not (the correct answer is not given).</li>
<li><font color="red">Unsupervised Learning:</font> no correct answer is available</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="Lecture-5-Supervised-Learning"><a href="#Lecture-5-Supervised-Learning" class="headerlink" title="Lecture 5. Supervised Learning"></a>Lecture 5. Supervised Learning</h1><blockquote>
<p>æ³¨æ„ï¼šä»¥ä¸‹å†…å®¹éƒ¨åˆ†ä¸è¯¾ç¨‹ MA234 å¤§æ•°æ®å¯¼è®ºä¸å®è·µç›¸é‡åˆï¼</p>
</blockquote>
<h2 id="Outline-4"><a href="#Outline-4" class="headerlink" title="Outline"></a>Outline</h2><ul>
<li>LDA</li>
<li>SVM</li>
<li>ANN (NN)</li>
<li>DT</li>
</ul>
<h2 id="Linear-Discriminant-Analysis"><a href="#Linear-Discriminant-Analysis" class="headerlink" title="Linear Discriminant Analysis"></a>Linear Discriminant Analysis</h2><ul>
<li>Idea: Viewing each datum to lie in a Euclidean space, find a straight line (a linear function) in the space (recall the <a href="#ai401">example</a> used in the last lecture), where the data projection on this line/plane can be well separate according to their label.</li>
<li>Letâ€™s learn some Maths:<ul>
<li>Given dataset $D=\{ (\mathbf{x}_i, y_i) \}^{m}_{i=1}$, $y_i \in \{0,1\}$</li>
<li>Suppose $X_i$ is the data subset with label $i\in \{0,1\}$, $\mathbf{\mu_i}$ is the mean vector, $\Sigma_i$ is the Covariance Matrix</li>
</ul>
</li>
</ul>
<p><img src="/2025/01/01/Artificial-Intelligence/ai501.png" style="zoom:50%"></p>
<ul>
<li>Then the projection of samples in two classes are $w^T \mu_0$, $w^T \mu_1$</li>
<li>And the covariance within two classes are $w^T\Sigma_0 w$, $w^T\Sigma_1 w$</li>
<li>Trying to make projections of data in the same class closer, and in different classes farther, we describe the objective function $J$ in this way:</li>
</ul>
<script type="math/tex; mode=display">
\begin{array}{rcl}
\text{define within-class scatter matrix:} &\mathbf{S_w}&=\mathbf{\Sigma_0}+\mathbf{\Sigma_1} \\
&&=\sum_{x\in X_0}(\mathbf{x}-\mathbf{\mu_0})^T+\sum_{x\in X_1}(\mathbf{x}-\mathbf{\mu_1})^T \\
\text{define between-class scatter matrix:}&\mathbf{S_b}&=(\mathbf{\mu_0}-\mathbf{\mu_1})(\mathbf{\mu_0}-\mathbf{\mu_1})^T \\
\text{Then we get objective function:}&J&=\large\frac{|| w^T\mathbf{\mu_0}-w^T\mathbf{\mu_1} ||^{2}_{2}}{w^T\Sigma_0 w+w^T\Sigma_1 w} \\
&&=\large\frac{w^T (\mathbf{\mu_0}-\mathbf{\mu_1})(\mathbf{\mu_0}-\mathbf{\mu_1})^T w}{w^T (\Sigma_0+\Sigma_1)w} \\
&&=\large\frac{w^T \mathbf{S_b} w}{w^T \mathbf{S_w} w}
\end{array}</script><ul>
<li>So we get what LDA wants to maximize (also called <strong>generalized Rayleigh quotient</strong>)</li>
<li>then weâ€™re going to optimize this function to obtain an easy form:</li>
</ul>
<script type="math/tex; mode=display">
\begin{array}{rl}
&\min_{\mathbf{w}} -\mathbf{w}^T\mathbf{S_b} \mathbf{w} \\
&s.t.\ \mathbf{w}^T\mathbf{S_w} \mathbf{w}=1 \\
\text{use Langrange Multiplexer: }&\mathbf{S_b}\mathbf{w}=\lambda\mathbf{S_w}\mathbf{w} \\
\text{Aware that } &\mathbf{S_b}\mathbf{w} \text{ always has same direnction as } (\mathbf{\mu_0}-\mathbf{\mu_1}) \\
\text{Let }&\mathbf{S_b}\mathbf{w} = \lambda (\mathbf{\mu_0}-\mathbf{\mu_1}) \\
\therefore&\mathbf{w}=\mathbf{S_w}^{-1} (\mathbf{\mu_0}-\mathbf{\mu_1})
\end{array}</script><blockquote>
<p>In practice, itâ€™s more likely to represent $\mathbf{S_w}$ as form of Singularity Decomposition: $\mathbf{U}\mathbf{\Sigma}\mathbf{V}^T$.</p>
<p>So that we can get $\mathbf{S_w}^{-1}$ by computing $\mathbf{S_w}^{-1}= \mathbf{V}\mathbf{\Sigma}^{-1}\mathbf{U}^T$</p>
</blockquote>
<ul>
<li>This method is also practical in multi-classification task<ul>
<li>by computing $\mathbf{W}\in \mathbb{R}^{d\times (N-1)}$</li>
<li>Objective function: $\max_{W} \large\frac{tr(W^T S_b W)}{tr(W^T S_w W)}$</li>
</ul>
</li>
</ul>
<h2 id="Support-Vector-Machine"><a href="#Support-Vector-Machine" class="headerlink" title="Support Vector Machine"></a>Support Vector Machine</h2><ul>
<li>Basic idea: margin maximization<ul>
<li>the <font color="red">minimum</font> distance between a data point to the decision boundary is <font color="red">maximized</font>.</li>
<li>intuitively, the safest and most robust</li>
<li><font color="red">support vectors:</font> datapoints the margin pushes up</li>
</ul>
</li>
</ul>
<p><img src="/2025/01/01/Artificial-Intelligence/ai502.png" style="zoom:50%"></p>
<ul>
<li>decision boundary: $&lt;\mathbf{w}, \mathbf{x}&gt; +b = 0$</li>
</ul>
<p><img src="/2025/01/01/Artificial-Intelligence/ai503.png"></p>
<ul>
<li>Kernel SVM: for non-linearlity<ul>
<li>RBF</li>
<li>Polynomial</li>
<li>Sigmoid</li>
</ul>
</li>
<li>Soft Margin SVM<ul>
<li>Even with kernel trick, it is hardly to guarantee that the training data are linearly separable, thus a soft margin rather than hard margin is used in practice.</li>
</ul>
</li>
</ul>
<p><img src="/2025/01/01/Artificial-Intelligence/ai504.png"></p>
<h2 id="Artificial-Neural-Networks"><a href="#Artificial-Neural-Networks" class="headerlink" title="Artificial Neural Networks"></a>Artificial Neural Networks</h2><ul>
<li>A highly nonlinear function that mimic the structure of biological NN.</li>
</ul>
<p><img src="/2025/01/01/Artificial-Intelligence/ai505.png"></p>
<h3 id="Training-NN"><a href="#Training-NN" class="headerlink" title="Training NN"></a>Training NN</h3><ul>
<li>Optimize weights to minimize the Loss function</li>
</ul>
<script type="math/tex; mode=display">
J(w)=\frac{1}{2} \sum_{k=1}^{c}(y_k-z_k)^2=\frac{1}{2} ||\mathbf{y}-\mathbf{z} ||^{2}</script><ul>
<li>Training algorithm: gradient descent, with Back Propagation(BP) algorithm as a representative example.</li>
</ul>
<p><strong>BP</strong></p>
<ul>
<li>Update weights between output and hidden layers</li>
</ul>
<script type="math/tex; mode=display">
\nabla w_{ji}=-\eta\frac{\partial{J}}{ \partial{w_{ji}}}</script><ul>
<li>Update weights between input and hidden layers</li>
</ul>
<script type="math/tex; mode=display">
\frac{\partial{J}}{ \partial{w_{ki}}}=\frac{\partial{J}}{ \partial{net_{k}}} \cdot \frac{ \partial{net_{k}}}{ \partial{w_{ki}}} = -\delta_{k}\frac{ \partial{net_{k}}}{ \partial{w_{ki}}}</script><ul>
<li>Apply in BP algorithm<ul>
<li>initial $D=\{ (\mathbf{x_1},y_1), \cdots, (\mathbf{x_m}, y_m) \}$ and learning rate $\eta$</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">while</span> Optimality conditions are <span class="keyword">not</span> satisfied:</span><br><span class="line">  <span class="keyword">for</span> (x, y) <span class="keyword">in</span> D:</span><br><span class="line">    calc current output by current param</span><br><span class="line">    calc grad <span class="keyword">for</span> output-layer neurons</span><br><span class="line">    calc grad <span class="keyword">for</span> hidden-layer neurons</span><br><span class="line">    update weight <span class="keyword">and</span> thresholds</span><br><span class="line">end</span><br></pre></td></tr></table></figure>
<h3 id="Some-issues"><a href="#Some-issues" class="headerlink" title="Some issues"></a>Some issues</h3><ul>
<li>Universal Approximation Theory</li>
<li>Fully connected NN (MLP) with more than 1 hidden layer is very difficult to train</li>
<li>etc.</li>
</ul>
<h2 id="Decision-Tree"><a href="#Decision-Tree" class="headerlink" title="Decision Tree"></a>Decision Tree</h2><ul>
<li>A natural way to handle nonmetric data (also applicable to real-valued data).</li>
<li>Tree searching metrics<ul>
<li>Entropy: $i(N) = -\sum_{i}p(w_i)\log{p(w_i)}$</li>
<li>Variance: $i(N) = 1 - \sum_{i}p^2(w_i)$</li>
<li>Misclassification rate: $i(N) = 1 - \max_{i}p(w_i)$</li>
</ul>
</li>
</ul>
<blockquote>
<p>How to contruct a DT ?</p>
</blockquote>
<ol>
<li>Start from the root, keep searching for a rule to branch a node.</li>
<li>At each node, select the rule that leads to the most significant decrease in <strong>impurity</strong> (similar to gradient descent).<ul>
<li>$\Delta i(N) = i(N) - p_L i(N_L) - (1-p_L)i(N_R)$ </li>
</ul>
</li>
<li>When the process terminates, assign class label to the leaf nodes. <ul>
<li>label a leaf node with the label of majority instances that fall into it.</li>
</ul>
</li>
</ol>
<blockquote>
<p>How to control the complexity ?</p>
</blockquote>
<ul>
<li>Setting the maximum height of the tree (early stopping)</li>
<li>Introduce the tree height (or any other complexity measure as a penalty)</li>
<li>Fully grow the tree first, and then prune it (post processing)</li>
</ul>
<h1 id="Lecture-6-Performance-Evaluation-for-Machine-Learning"><a href="#Lecture-6-Performance-Evaluation-for-Machine-Learning" class="headerlink" title="Lecture 6. Performance Evaluation for Machine Learning"></a>Lecture 6. Performance Evaluation for Machine Learning</h1><h2 id="Outline-5"><a href="#Outline-5" class="headerlink" title="Outline"></a>Outline</h2><ul>
<li>Brief view</li>
<li>Performance Metrics</li>
<li>Estimating the Generalization</li>
</ul>
<h2 id="Brief-view"><a href="#Brief-view" class="headerlink" title="Brief view"></a>Brief view</h2><ul>
<li>Be careful when choosing your objective function, two principles:<ul>
<li>Consistent with the user requirements?</li>
<li>Existing easy-to-use algorithm to optimize it (to train the model)?</li>
</ul>
</li>
<li>Do internal tests as much as possible<ul>
<li>estimate the generalization performance as accurate as possible.</li>
</ul>
</li>
<li>Can only reduce rather than remove risk. There is no guarantee in life.</li>
</ul>
<h2 id="Performance-Metrics"><a href="#Performance-Metrics" class="headerlink" title="Performance Metrics"></a>Performance Metrics</h2><blockquote>
<p>Review MA234.</p>
</blockquote>
<ul>
<li>T &amp; F : represents truth of label (æ ‡ç­¾æ˜¯å¦çœŸå®)</li>
<li>P &amp; N : represents aspect of label (æ ‡ç­¾çš„æ­£åä¸¤é¢)</li>
<li>And thereâ€™re 4 cases: TP, TN, FP, FN</li>
<li>Several metrics:<ul>
<li>accuracy ğŸ‘‰ bad when samples are imbalanced</li>
<li>precision</li>
<li>Recall</li>
<li>F-measure ($F_1$) $=\large\frac{2\times \text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}$</li>
</ul>
</li>
</ul>
<blockquote>
<p>ç»†èŠ‚è¯·å‚è€ƒå¤§æ•°æ®å¯¼è®ºä¸å®è·µï¼ˆäºŒï¼‰</p>
</blockquote>
<ul>
<li>ROC ğŸ‘‰ TPR / FPR</li>
<li>AUC : slope of ROC, good PF when $AUC\gt 0.75$</li>
</ul>
<h2 id="Estimating-the-Generalization"><a href="#Estimating-the-Generalization" class="headerlink" title="Estimating the Generalization"></a>Estimating the Generalization</h2><ul>
<li>Generalization performance is a random variable. </li>
<li>Split the data in hand into training and testing subsets.<ul>
<li>Random Split</li>
<li>Cross-validation</li>
<li>Bootstrap</li>
</ul>
</li>
<li>Collecting the test performance for many times, calculate the average and standard deviation. </li>
<li>Do statistical tests (check your textbook on statistics)</li>
</ul>
<h1 id="Lecture-7-Unsupervised-Learning"><a href="#Lecture-7-Unsupervised-Learning" class="headerlink" title="Lecture 7. Unsupervised Learning"></a>Lecture 7. Unsupervised Learning</h1><h2 id="Outline-6"><a href="#Outline-6" class="headerlink" title="Outline"></a>Outline</h2><ul>
<li>Why Unsupervised ?</li>
<li>Clustering</li>
<li>K-Means</li>
<li>Dimensionality Reduction</li>
</ul>
<h2 id="Why-Unsupervised"><a href="#Why-Unsupervised" class="headerlink" title="Why Unsupervised ?"></a>Why Unsupervised ?</h2><ul>
<li>In practice, it might neither be tractable to collect sufficient labelled data</li>
<li>Instead, it is relatively easy to accumulate large amount of unlabeled data.</li>
</ul>
<p><strong>Supervised vs. Unsupervised</strong></p>
<ul>
<li>Share the same key factors, i.e., representation + algorithm + evaluation</li>
<li>For supervised learning, since ground-truth is available for the training data, the evaluation (objective function) can be said as <font color="red">objective</font>.</li>
<li>For unsupervised learning, the evaluation is usually less specific and <font color="red">more subjective</font>.</li>
<li>It is more likely that an unsupervised learning problem is ill-defined and the learning output deviate from our intuition.</li>
</ul>
<h2 id="Clustering"><a href="#Clustering" class="headerlink" title="Clustering"></a>Clustering</h2><ul>
<li><strong>Def.</strong> a typical ill-defined problem as there is no unique definition of the similarity between clusters.</li>
<li>Idea: gathering similar data into one class<ul>
<li>e.g. Objective Function (to minimize distance)</li>
</ul>
</li>
</ul>
<script type="math/tex; mode=display">
\begin{array}{}
J= \underset{i=1}{\overset{k}{\sum}} \underset{x \in D_i }{\sum} || \mathbf{x} - \mathbf{m_i} ||^2 \\
i.e. J = \frac{1}{2} \underset{i=1}{\overset{k}{\sum}} n_i \underset{x,x' \in D_i }{\sum} || \mathbf{x}-\mathbf{x'} ||^2
\end{array}</script><p><strong>Naive Approach</strong></p>
<ul>
<li><font color="dodgerblue">Top-down:</font> following the decision tree idea to split the data recursively. </li>
<li><font color="dodgerblue">Bottom-up:</font> recursively put two instances (or â€œmeta-instancesâ€) into the same group</li>
<li>Basically you need to define <font color="red">similarity metric</font> (e.g., Euclidean distance) first.</li>
</ul>
<blockquote>
<p>å±‚æ¬¡èšç±»ï¼Ÿ</p>
</blockquote>
<h2 id="K-Means"><a href="#K-Means" class="headerlink" title="K-Means"></a>K-Means</h2><h3 id="Algorithm"><a href="#Algorithm" class="headerlink" title="Algorithm"></a>Algorithm</h3><ul>
<li>Given a predefined $K$<ol>
<li>Randomly initialize $K$ cluster centers</li>
<li>Assign each instance to the nearest center</li>
<li>Update the each center as the mean of all the instances in the cluster</li>
<li>Repeat Step 1-3 until the centers do not change any more</li>
</ol>
</li>
</ul>
<blockquote>
<p>Not only similarity metric, but also needs calculating of the average.</p>
</blockquote>
<h3 id="Application-Clustering-for-Graph-Data"><a href="#Application-Clustering-for-Graph-Data" class="headerlink" title="Application: Clustering for Graph Data"></a>Application: Clustering for Graph Data</h3><p><img src="/2025/01/01/Artificial-Intelligence/ai701.png"></p>
<h2 id="Dimensionality-Reduction"><a href="#Dimensionality-Reduction" class="headerlink" title="Dimensionality Reduction"></a>Dimensionality Reduction</h2><h3 id="Principle-Component-Analysis"><a href="#Principle-Component-Analysis" class="headerlink" title="Principle Component Analysis"></a>Principle Component Analysis</h3><ul>
<li>Given a n-by-d data set, can we map it into a lower dimensional space with a <font color="red">linear</font> transformation, while only introduce the minimum information loss?</li>
<li>Suppose we want to reduce data dimension from $n$ to $k$<ol>
<li>Init a dataset: $X=\{x_1, x_2, \cdots , x_m\}$</li>
<li>Calculate the mean value and minus it (decentralize)</li>
<li>Calculate the covariance matrix by $C= \frac{1}{n}XX^T$</li>
<li>Calculate the eigenvalues and corresponding eigenvectors</li>
<li>Sort the eigenvectors by eigenvalues (large to small) and select the top $k$ as eigenvector matrix $P$</li>
<li>$Y=PX$ to get new data.</li>
</ol>
</li>
</ul>
<h3 id="Locally-Linear-Embedding"><a href="#Locally-Linear-Embedding" class="headerlink" title="Locally Linear Embedding"></a>Locally Linear Embedding</h3><p><img src="/2025/01/01/Artificial-Intelligence/ai702.png"></p>
<ul>
<li>Idea flow:<ol>
<li>Identify nearest neighbors for each instance</li>
<li>Calculate the linear weights for each instances to be reconstructed by its neighbors<ul>
<li>$\varepsilon(W)=\underset{i}{\sum}|X_i-\underset{j}{\sum} W_{ij} X_j|^2$</li>
</ul>
</li>
<li>Use W as the local structure information to be preserved (i.e., fix $W$), find the optimal values (say $Y$) for $X$ in the lower dimensional space.<ul>
<li>$\Phi (Y)=\underset{i}{\sum} |Y_i - \underset{j}{\sum} W_{ij} Y_j|^2$</li>
</ul>
</li>
</ol>
</li>
</ul>
<h1 id="Lecture-8-Recommender-System"><a href="#Lecture-8-Recommender-System" class="headerlink" title="Lecture 8. Recommender System"></a>Lecture 8. Recommender System</h1><h2 id="Outline-7"><a href="#Outline-7" class="headerlink" title="Outline"></a>Outline</h2><ul>
<li>Overview of recommender system (RS)</li>
<li>How does RS do recommendation?</li>
<li>How to build a RS?</li>
</ul>
<h2 id="Overview-of-recommender-system-RS"><a href="#Overview-of-recommender-system-RS" class="headerlink" title="Overview of recommender system (RS)"></a>Overview of recommender system (RS)</h2><ul>
<li>Recommender System recommend new items to its user.</li>
<li>Based on ?<ul>
<li>The items that the user has been interacted. [æ ¹æ®ç›¸ä¼¼ç‰©å“]</li>
<li>The users who have been interacted with same items which this user also been interacted. [æ ¹æ®ç›¸ä¼¼ç”¨æˆ·]</li>
</ul>
</li>
<li>The recommendation is <font color="red">personalized</font>. </li>
<li>The key of Recommender System is a <font color="red">score function</font>.<ul>
<li>Input: a user and an item.</li>
<li>Return value: a score, indicating how likely the user would be interested in the item.</li>
</ul>
</li>
</ul>
<h2 id="How-does-RS-do-recommendation"><a href="#How-does-RS-do-recommendation" class="headerlink" title="How does RS do recommendation?"></a>How does RS do recommendation?</h2><p><img src="/2025/01/01/Artificial-Intelligence/ai801.png"></p>
<ul>
<li>RS basically estimate the probability of interaction between a user and an item, </li>
<li>The score function is essentially a <fotn color="red">model trained with data&lt;/font&gt;.</fotn></li>
<li>In practice, the score function could be very complicated since<ul>
<li>The RS needs to be efficient (make recommendations in seconds)</li>
<li>In many applications, we may have millions of users and items</li>
<li>There is always a trade-off between efficiency and accuracy</li>
</ul>
</li>
</ul>
<h2 id="How-to-build-a-RS"><a href="#How-to-build-a-RS" class="headerlink" title="How to build a RS?"></a>How to build a RS?</h2><h3 id="Problem-Formulation"><a href="#Problem-Formulation" class="headerlink" title="Problem Formulation"></a>Problem Formulation</h3><ul>
<li><strong>Input:</strong> Historical user-item interaction records or additional side information (e.g. userâ€™s social relations, itemâ€™s knowledge, etc.)</li>
<li><strong>Output:</strong> The score function</li>
</ul>
<p><img src="/2025/01/01/Artificial-Intelligence/ai802.png"></p>
<h3 id="Typical-methods"><a href="#Typical-methods" class="headerlink" title="Typical methods"></a>Typical methods</h3><ul>
<li><strong>Content-based method</strong>:<ul>
<li>The very basic idea: build a regression/classification model for each user<ul>
<li>Focusing on the side information of the items (i.e., attributes, features of items)</li>
<li>Suggesting items by comparing their features to a userâ€™s past behaviors</li>
</ul>
</li>
</ul>
</li>
<li><strong>Collaborative Filtering method</strong>: <ul>
<li>Predicting user preferences based on the behaviors of other users. </li>
<li>Based on the historical user-item interaction data </li>
</ul>
</li>
<li><strong>Hybrid method</strong>: Combination of CF-based and Content-based method</li>
</ul>
<h3 id="CF-based-method"><a href="#CF-based-method" class="headerlink" title="CF-based method"></a>CF-based method</h3><ul>
<li>Attributes/features of users and items are not available, <ul>
<li>How to build the regression/classification model (as the score function)?</li>
<li>Learning representation of users and items</li>
</ul>
</li>
</ul>
<p><img src="/2025/01/01/Artificial-Intelligence/ai803.png"></p>
<h3 id="Represented-by-correlation"><a href="#Represented-by-correlation" class="headerlink" title="Represented by correlation"></a>Represented by correlation</h3><ul>
<li>Represent the user/item by its correlation with the other users/items.<ul>
<li>Users with similar historical interactions are likely to have the same preferences.</li>
<li>Items that are interacted by similar users are likely to have hidden commonalities (å…±æ€§).</li>
</ul>
</li>
<li>A user/item is represented by a vector that consists of all the correlation between itself and all the users/items.</li>
</ul>
<blockquote>
<font color="red">Q: How to define the correlation between 2 users or items?</font>
<br>
<font color="green">A: Pearson Correlation Coefficient, a normalized measurement of the covariance</font>


</blockquote>
<script type="math/tex; mode=display">
c_{u_1u_2}=\large\frac{\underset{i\in M}{\sum} (r_{u_1,i} - \bar{r}_{u_1}) (r_{u_2,i} - \bar{r}_{u_2}) }{\sqrt{\underset{i\in M}{\sum} (r_{u_1,i} - \bar{r}_{u_1})^2} \sqrt{\underset{i\in M}{\sum} (r_{u_2,i} - \bar{r}_{u_2})^2}}</script><ul>
<li>An example of userâ€™s Pearson Correlation Coefficient</li>
<li>$M$: The item set</li>
<li>$r_{u,i}$: Interaction record between user $u$ and item $i$</li>
<li>$\bar{r}_u$: Mean value of all the interaction records of user $u$</li>
</ul>
<p><img src="/2025/01/01/Artificial-Intelligence/ai804.png"></p>
<ul>
<li><strong>Advantage</strong>: high interpretability<ul>
<li>It is easy to explain why the system recommend the item to the user.</li>
</ul>
</li>
<li><strong>Disadvantage</strong>: low scalability<ul>
<li>What if there are millions of users and millions of items?</li>
<li>High-dimensional, sparse feature representation</li>
</ul>
</li>
</ul>
<h3 id="Represent-by-matrix-factorization"><a href="#Represent-by-matrix-factorization" class="headerlink" title="Represent by matrix factorization"></a>Represent by matrix factorization</h3><ul>
<li>A matrix $R\in \mathbb{R}^{n\times m}$ approximate to the product of two matrix:</li>
</ul>
<script type="math/tex; mode=display">
R\approx PQ^T ,\ P\in \mathbb{R}^{n\times d},\ Q\in \mathbb{R}^{m\times d}</script><ul>
<li>Representing the user and item as a $d$-dimension vector</li>
<li>Matrix $P$, $Q$ consist of the representation vectors of all the users and items.</li>
<li>The low-dimension vector representation is also called as <strong>embedding vector</strong>.</li>
</ul>
<script type="math/tex; mode=display">
\underset{P,Q}{\min} \underset{r_{u,i} \in R'}{\sum} ||r_{u,i} - r'_{u,i} ||,\ \text{where } r'_{u,i} = P_u Q_i^T</script><ul>
<li>In this â€œobjective functionâ€, $P_u$ is user $u$â€™s embedding vector, $Q_i$ is item $i$â€™s embedding vector<ul>
<li>$râ€™_{u,i} = f(P_u, Q_i) = P_uQ_i^T$ is a simple example for this function.</li>
</ul>
</li>
<li>If we replace the matrix multiplication with a complex model $M$, such as MLP<ul>
<li>objective function will be : $\large\underset{P,Q,M}{\min} \underset{r_{u,i}\in Râ€™}{\sum} ||r_{u,i}-f(P_u, Q_i, M)||$</li>
<li>The model with higher complexity may have better prediction performance in <strong>big data scenario</strong> (as an optimization)</li>
</ul>
</li>
</ul>
<h1 id="Lecture-9-Automated-Machine-Learning"><a href="#Lecture-9-Automated-Machine-Learning" class="headerlink" title="Lecture 9. Automated Machine Learning"></a>Lecture 9. Automated Machine Learning</h1><h2 id="Tuning-Hyper-parameters"><a href="#Tuning-Hyper-parameters" class="headerlink" title="Tuning Hyper-parameters"></a>Tuning Hyper-parameters</h2><blockquote>
<p>How to tune the hyper-parameters?</p>
</blockquote>
<p><img src="/2025/01/01/Artificial-Intelligence/ai901.png"></p>
<ul>
<li>Grid Search<ul>
<li>Too costly</li>
</ul>
</li>
<li>More efficient ways?<ul>
<li>Use heuristic Search (e.g., using Black-Box optimization algorithms)</li>
<li>Sometimes, good surrogate of generalization is available to accelerate the evaluation</li>
</ul>
</li>
</ul>
<blockquote>
<p>Too short ? Sorry, my lecture slides is only 6 pages.</p>
</blockquote>
<h1 id="Lecture-10-Logical-Agents"><a href="#Lecture-10-Logical-Agents" class="headerlink" title="Lecture 10. Logical Agents"></a>Lecture 10. Logical Agents</h1><h2 id="Outline-8"><a href="#Outline-8" class="headerlink" title="Outline"></a>Outline</h2><ul>
<li>Knowledge-based Agents</li>
<li>Represent Knowledge with Logic</li>
<li>(Propositional) Logic</li>
<li>Inference with Propositional Logic</li>
</ul>
<h2 id="Knowledge-based-Agents"><a href="#Knowledge-based-Agents" class="headerlink" title="Knowledge-based Agents"></a>Knowledge-based Agents</h2><p><strong>Agent Components</strong></p>
<ul>
<li>Intelligent agents need <font color="red">knowledge</font> about the world to choose good actions/decisions.</li>
<li>Knowledge = {sentences} in a knowledge representation language (formal language).</li>
<li>A sentence is an assertion about the world.</li>
<li>A knowledge-based agent is composed of:<ol>
<li><font color="dodgerblue">Knowledge base</font>: domain-specific content.</li>
<li><font color="dodgerblue">Inference mechanism</font>: domain-independent algorithms.</li>
</ol>
</li>
</ul>
<p><strong>Agent Requirements</strong></p>
<ul>
<li>Represent states, actions, etc.</li>
<li>Incorporate new percepts</li>
<li>Update internal representations of the world</li>
<li>Deduce hidden properties of the world</li>
<li>Deduce appropriate actions</li>
</ul>
<p><strong>Declarative approach to building an agent</strong></p>
<ul>
<li>Add new sentences: <em>Tell</em> it what it needs to know</li>
<li>Query what is known: <em>Ask</em> itself what to do - answers should follow from the KB</li>
</ul>
<blockquote>
<p>Use a game as an example:</p>
</blockquote>
<p><img src="/2025/01/01/Artificial-Intelligence/ai1001.png" style="zoom:60%"></p>
<ul>
<li>Actuators:<ul>
<li>Left turn, Right turn, Forward, Grab, Release, Shoot </li>
</ul>
</li>
<li>Sensors:<ul>
<li>Stench, Breeze, Glitter, Bump, Scream</li>
<li>Represented as a 5-element list</li>
<li>Example: [Stench, Breeze, None, None, None]</li>
</ul>
</li>
</ul>
<h2 id="Represent-Knowledge-with-Logic"><a href="#Represent-Knowledge-with-Logic" class="headerlink" title="Represent Knowledge with Logic"></a>Represent Knowledge with Logic</h2><ul>
<li><font color="dodgerblue">Knowledge base</font>: a set of sentences in a formal representation</li>
<li><font color="dodgerblue">Syntax</font>: defines well-formed sentences in the language</li>
<li><font color="dodgerblue">Semantic</font>: defines the truth or meaning of sentences in a world</li>
<li><font color="dodgerblue">Inference</font>: a procedure to derive a new sentence from other ones.</li>
</ul>
<table>
<tr>
    <td><img src="/2025/01/01/Artificial-Intelligence/ai1002.png"></td>
    <td><img src="/2025/01/01/Artificial-Intelligence/ai1003.png"></td>
</tr>
</table>

<h3 id="Inference-1"><a href="#Inference-1" class="headerlink" title="Inference"></a>Inference</h3><ul>
<li>Inference: the procedure of deriving a sentence from another sentence</li>
<li><font color="red">Model Checking</font>: A basic (and general) idea to inference</li>
</ul>
<p><img src="/2025/01/01/Artificial-Intelligence/ai1004.png" style="zoom:50%"></p>
<h2 id="Propositional-Logic"><a href="#Propositional-Logic" class="headerlink" title="Propositional Logic"></a>Propositional Logic</h2><blockquote>
<p>Most have been learnt in CS201 Discrete Mathemetics</p>
</blockquote>
<p><strong>Def.</strong> A proposition is a declarative statement thatâ€™s either True or False.</p>
<ul>
<li><font color="green">Recall:</font><ul>
<li>Negation</li>
<li>AND</li>
<li>OR</li>
<li>Implication</li>
<li>Biconditional, etc.</li>
</ul>
</li>
</ul>
<h2 id="Inference-with-Propositional-Logic"><a href="#Inference-with-Propositional-Logic" class="headerlink" title="Inference with Propositional Logic"></a>Inference with Propositional Logic</h2><ul>
<li>Our inference algorithm target:</li>
<li><strong>Sound</strong>: oes not infer false formulas, that is, derives only entailed sentences.<ul>
<li>$\{ \alpha | KB \vdash \alpha \} \subseteq \{ \alpha | KB \models \alpha \}$</li>
</ul>
</li>
<li><strong>Complete</strong>: derives ALL entailed sentences.<ul>
<li>$\{ \alpha | KB \vdash \alpha \} \supseteq \{ \alpha | KB \models \alpha \}$</li>
</ul>
</li>
<li>That is, we want a <strong>Logical Equivalent</strong>: $p\equiv q$</li>
</ul>
<blockquote>
<p>Go review some Inferences instance:</p>
<p>e.g. Modus Ponens, Modus Tollens, etc.</p>
</blockquote>
<h3 id="Inference-as-a-search-problem"><a href="#Inference-as-a-search-problem" class="headerlink" title="Inference as a search problem"></a>Inference as a search problem</h3><ul>
<li><font color="red">Initial state:</font> The initial KB</li>
<li><font color="red">Actions:</font> all inference rules applied to all sentences that match the top of the inference rule</li>
<li><font color="red">Results:</font> add the sentence in the bottom half of the inference rule</li>
<li><font color="red">Goal:</font> a state containing the sentence we are trying to prove.</li>
<li><font color="dodgerblue">Completeness Issue:</font> if the inference rules to use are not sufficient, the goal can not be obtained.</li>
</ul>
<blockquote>
<p>How to ensure soundness ?</p>
</blockquote>
<ul>
<li>The <strong>idea of inference</strong> is to repeat applying inference rules to the KB.</li>
<li>Inference can be applied whenever suitable premises are found in the KB.</li>
</ul>
<blockquote>
<p>What aboud completeness ?</p>
</blockquote>
<ul>
<li>Two ways to ensure completeness:<ul>
<li><strong>Proof by resolution</strong>: use powerful inference rules (resolution rule)</li>
<li><strong>Forward or Backward chaining</strong>: use of modus ponens on a restricted form of propositions (Horn clauses)</li>
</ul>
</li>
</ul>
<h3 id="Proof-by-resolution"><a href="#Proof-by-resolution" class="headerlink" title="Proof by resolution"></a>Proof by resolution</h3><p><img src="/2025/01/01/Artificial-Intelligence/ai1005.png" style="zoom:60%"></p>
<ul>
<li>Two cases to end loop:<ul>
<li>there are no new clauses that can be added, in which case $KB$ doesnâ€™t ential $\alpha$; or,</li>
<li>two clauses resolve to yield the empty clause, in which case $KB$ entails $\alpha$</li>
</ul>
</li>
</ul>
<h3 id="Forward-chaining"><a href="#Forward-chaining" class="headerlink" title="Forward chaining"></a>Forward chaining</h3><p><img src="/2025/01/01/Artificial-Intelligence/ai1006.png" style="zoom:60%"></p>
<ul>
<li><strong>Idea</strong>: Find any rule whose premises are satisfied in the $KB$, add its conclusion to the KB, until query is found</li>
</ul>
<table>
<tr>
    <td><img src="/2025/01/01/Artificial-Intelligence/ai1007.png"></td>
    <td><img src="/2025/01/01/Artificial-Intelligence/ai1008.png"></td>
    <td><img src="/2025/01/01/Artificial-Intelligence/ai1009.png"></td>
    <td><img src="/2025/01/01/Artificial-Intelligence/ai1010.png"></td>
</tr>
<tr>
    <td><img src="/2025/01/01/Artificial-Intelligence/ai1011.png"></td>
    <td><img src="/2025/01/01/Artificial-Intelligence/ai1012.png"></td>
    <td><img src="/2025/01/01/Artificial-Intelligence/ai1013.png"></td>
    <td><img src="/2025/01/01/Artificial-Intelligence/ai1014.png"></td>
</tr>
</table>

<h3 id="Backward-chaining"><a href="#Backward-chaining" class="headerlink" title="Backward chaining"></a>Backward chaining</h3><ul>
<li><strong>Idea:</strong> Works backwards from the query $q$</li>
<li>To prove $q$ by Backward Chaining:<ul>
<li>Check if $q$ is known already, or</li>
<li>Prove by Backward Chaining all premises of some rule concluding $q$.</li>
</ul>
</li>
<li>Avoid loops: check if new subgoal is already on the goal stack</li>
<li>Avoid repeated work: check if new subgoal<ul>
<li>has already been proved true, or</li>
<li>has already failed</li>
</ul>
</li>
</ul>
<table>
<tr>
    <td><img src="/2025/01/01/Artificial-Intelligence/ai1015.png"></td>
    <td><img src="/2025/01/01/Artificial-Intelligence/ai1016.png"></td>
    <td><img src="/2025/01/01/Artificial-Intelligence/ai1017.png"></td>
    <td><img src="/2025/01/01/Artificial-Intelligence/ai1018.png"></td>
    <td><img src="/2025/01/01/Artificial-Intelligence/ai1019.png"></td>
</tr>
<tr>
    <td><img src="/2025/01/01/Artificial-Intelligence/ai1020.png"></td>
    <td><img src="/2025/01/01/Artificial-Intelligence/ai1021.png"></td>
    <td><img src="/2025/01/01/Artificial-Intelligence/ai1022.png"></td>
    <td><img src="/2025/01/01/Artificial-Intelligence/ai1023.png"></td>
    <td><img src="/2025/01/01/Artificial-Intelligence/ai1024.png"></td>
</tr>
</table>

<ul>
<li>Explanation:<ul>
<li>start from query $Q$, and $A$, $B$ has been known.</li>
<li>check recursively each node that â€œshould be proved rightâ€</li>
<li>for one node:<ul>
<li>if its â€œsuccessorsâ€ wait to be proved (e.g. L ğŸ‘ˆ <strong>P</strong>, A)</li>
<li>or itâ€™s unknown (neither â€œgreenâ€ nor â€œredâ€), then avoid it</li>
</ul>
</li>
<li>else this node is proved (turn â€œredâ€)</li>
</ul>
</li>
<li>Suppose: B is unknown<ul>
<li>then step 5 (want to prove L ğŸ‘ˆ A, <strong>B</strong>) failed</li>
<li>and L cannot be proved, and query $Q$ failed immediately too.</li>
</ul>
</li>
</ul>
<blockquote>
<p><strong>Forward vs. Backward</strong></p>
</blockquote>
<ul>
<li>Forward chaining:<ul>
<li>Data-driven, automatic, unconscious processing,</li>
<li>May do lots of work that is irrelevant to the goal</li>
</ul>
</li>
<li>Backward chaining:<ul>
<li>Goal-driven, appropriate for problem-solving,</li>
<li>Complexity of BC can be much less than linear in size of KB</li>
</ul>
</li>
</ul>
<h3 id="DPLL"><a href="#DPLL" class="headerlink" title="DPLL"></a>DPLL</h3><blockquote>
<p>The <strong>DPLL algorithm</strong> is similar to <strong>Backtracking</strong> for CSP, but using various problem dependent information/heuristics, such as Early Termination, Pure symbol heuristic and Unit clause heuristic.</p>
</blockquote>
<p><img src="/2025/01/01/Artificial-Intelligence/ai1025.png" style="zoom:60%"></p>
<blockquote>
<p>æ¦‚å¿µä»‹ç»ï¼šå¦‚ä¸‹çš„å¼å­è¢«ç§°ä¸ºåˆå–èŒƒå¼ï¼ˆCNFï¼‰ï¼Œå¼å­ä¸­åªåŒ…å«é€»è¾‘ä¸ï¼Œé€»è¾‘æˆ–å’Œé€»è¾‘éï¼Œä¸”æ¯ä¸ªéƒ¨åˆ†ç”±<strong>é€»è¾‘ä¸</strong>è¿æ¥</p>
<p>$(a\vee b\vee \neg c)\wedge \cdots \wedge (a\vee d \vee \neg d)$</p>
<ul>
<li>æ‹¬å·éƒ¨åˆ†ä¸ºè¯¥å…¬å¼çš„<strong>å­å¥(clause)</strong>ï¼Œæ¯ä¸ªå­å¥ä¸­çš„å˜é‡æˆ–å˜é‡çš„å¦å®šä¸º<strong>æ–‡å­—(literal/symbol)</strong></li>
<li>è¦ä½¿æ•´ä¸ªå…¬å¼ä¸º Trueï¼Œåˆ™æ¯ä¸ªå­å¥éƒ½å¿…é¡»ä¸º Trueï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œæ¯ä¸ªå­å¥ä¸­è‡³å°‘æœ‰ä¸€ä¸ªæ–‡å­—ä¸º True</li>
<li>DPLL ç®—æ³•ç®€åŒ–æ­¥éª¤å®é™…ä¸Šå°±æ˜¯<font color="hotpink">ç§»é™¤æ‰€æœ‰åœ¨èµ‹å€¼åå€¼ä¸º True çš„å­å¥ï¼Œä»¥åŠæ‰€æœ‰åœ¨èµ‹å€¼åå€¼ä¸º False çš„æ–‡å­—</font>ã€‚<ul>
<li>ç®€åŒ–æ­¥éª¤åˆ†ä¸¤æ­¥ï¼šå­¤ç«‹æ–‡å­—æ¶ˆå»ï¼ˆPure Symbolï¼‰å’Œå•ä½å­å¥ä¼ æ’­ï¼ˆUnit Clauseï¼‰</li>
</ul>
</li>
</ul>
</blockquote>
<ul>
<li>In <strong>pure symbol elimination</strong>, we try to find <font color="red">symbols</font> that only appear <font color="red">once in all clauses</font>.<ul>
<li>If the symbol is in form $a$ (positive), then itâ€™s assigned to <font color="limegreen">True</font> ;</li>
<li>If the symbol is in form $\neg a$ (negative), then itâ€™s assigned to <font color="orangered">False</font> ;</li>
<li>then we check the clause containing this symbol if itâ€™s true or false. <em>(try to eliminate)</em></li>
</ul>
</li>
<li>In <strong>unit clause propagation</strong>, we try to find <font color="red">clauses with only one literal</font>, or <font color="red">clauses with one literal that is unknown</font> (and it must cause the whole clause unknown).<ul>
<li>E.g. $(a\vee b\vee c\vee \neg d)\wedge (\neg a\vee c)\wedge (\neg c\vee d)\wedge (a)$<ul>
<li>find $a$ as unit clause, then we say $a$ must be <font color="limegreen">True</font>, and reduce the sentence $\to (c)\wedge (\neg c\vee d)\wedge (a)$ ;</li>
<li>then find $c$ as unit clause, same process $\to (c)\wedge(d)\wedge(a)$ ;</li>
</ul>
</li>
</ul>
</li>
<li>At last, we got a <code>model</code> with some assigned literal. Thatâ€™s the solution we want.</li>
</ul>
<h3 id="Summary-1"><a href="#Summary-1" class="headerlink" title="Summary"></a>Summary</h3><ul>
<li><strong>Inference with Propositional Logic</strong> ğŸ‘‰ we want an inference algorithm that is:<ul>
<li>sound (does not infer false formulas), and</li>
<li>ideally, complete too (derives all true formulas).</li>
</ul>
</li>
<li>Limits ?<ul>
<li>PL is not expressive enough to describe all the world around us. It canâ€™t express information about different object and the relation between objects.</li>
<li>PL is not compact. It canâ€™t express a fact for a set of objects without enumerating all of them which is sometimes <strong>impossible</strong>.</li>
</ul>
</li>
</ul>
<blockquote>
<p>Review: First Order Logic (learnt in Discrete Mathematics)</p>
<ul>
<li>Concept of Syntax, Semantics, Entailment(necessary truth of one sentence given another), etc.</li>
<li><p>Forward, backward chaining are linear in time, complete for horn clauses. Resolution is complete for propositional logic.</p>
</li>
<li><p>Pros</p>
<ul>
<li>Intelligibility of models: models are encoded explicitly</li>
</ul>
</li>
<li>Cons<ul>
<li>Do not handle uncertainty</li>
<li>Rule-based and do not use data (Machine Learning)</li>
<li>It is hard to model every aspect of the world</li>
</ul>
</li>
</ul>
</blockquote>
<h1 id="Lecture-11-First-Order-Logic"><a href="#Lecture-11-First-Order-Logic" class="headerlink" title="Lecture 11. First Order Logic"></a>Lecture 11. First Order Logic</h1><h2 id="Inference-with-FOL"><a href="#Inference-with-FOL" class="headerlink" title="Inference with FOL"></a>Inference with FOL</h2><blockquote>
<p><strong>Basic concept of FOL</strong></p>
<p>Three basic component: Objects, Relations, Functions</p>
</blockquote>
<p><img src="/2025/01/01/Artificial-Intelligence/ai1101.png" style="zoom:60%"></p>
<ul>
<li><font color="green">Recall</font>:<ul>
<li>Universal Instantiation, Existential Instantiation, etc.</li>
<li>Reduce FOL to simple format</li>
</ul>
</li>
<li>Better Ideas to Inference with FOL: Unification<ul>
<li>Resolution</li>
<li>Chaining Algorithms (In lec 10.)</li>
</ul>
</li>
</ul>
<h1 id="Lecture-12-Representing-and-Inference-with-Uncertainty"><a href="#Lecture-12-Representing-and-Inference-with-Uncertainty" class="headerlink" title="Lecture 12. Representing and Inference with Uncertainty"></a>Lecture 12. Representing and Inference with Uncertainty</h1><h2 id="Outline-9"><a href="#Outline-9" class="headerlink" title="Outline"></a>Outline</h2><ul>
<li>Uncertainty and Rational Decisions</li>
</ul>
<h2 id="Uncertainty-and-Rational-Decisions"><a href="#Uncertainty-and-Rational-Decisions" class="headerlink" title="Uncertainty and Rational Decisions"></a>Uncertainty and Rational Decisions</h2><ul>
<li>Alternative to Logic<ul>
<li>Utility theory: Assign utility to each state/actions</li>
<li>Probability theory: Summarize the uncertainty associated with each state</li>
<li>Rational Decisions: Maximize the expected utility (Probability + Utility) </li>
<li>Thus we need to represent states in the language of probability</li>
</ul>
</li>
<li><font color="red">In a word, use probability to replace logic.</font>



</li>
</ul>
<h2 id="Basic-Probability-Theory-and-Usage"><a href="#Basic-Probability-Theory-and-Usage" class="headerlink" title="Basic Probability Theory and Usage"></a>Basic Probability Theory and Usage</h2><table>
<tr>
    <td><img src="/2025/01/01/Artificial-Intelligence/ai1201.png"></td>
    <td><img src="/2025/01/01/Artificial-Intelligence/ai1202.png"></td>
</tr>
</table>

<blockquote>
<p><font color="green">Recall:</font> MA212 æ¦‚ç‡è®ºä¸æ•°ç†ç»Ÿè®¡</p>
<p>è´å¶æ–¯å…¬å¼ï¼Œæ¡ä»¶æ¦‚ç‡ï¼Œè”åˆæ¦‚ç‡ç­‰</p>
</blockquote>
<h2 id="Bayesian-Networks"><a href="#Bayesian-Networks" class="headerlink" title="Bayesian Networks"></a>Bayesian Networks</h2><ul>
<li>What is a BN ?<ul>
<li>A Directed Acyclic Graph (DAG).</li>
<li>Each node is a random variable, associated with conditional distribution. </li>
<li>Each arc (link) represent <font color="red">direct influence</font> of a parent node to a child node.</li>
</ul>
</li>
</ul>
<p><img src="/2025/01/01/Artificial-Intelligence/ai1203.png" style="zoom:60%"></p>
<ul>
<li>In the above exmaple, a Conditional Probability Table (CPT) is construct for each node<ul>
<li>Easier to utilize independence and conditional dependence relations to define the joint distribution.</li>
</ul>
</li>
<li>How to construct a <strong>CPT for BN</strong>?</li>
</ul>
<p><img src="/2025/01/01/Artificial-Intelligence/ai1204.png" style="zoom:60%"></p>
<h3 id="Inference-with-BN"><a href="#Inference-with-BN" class="headerlink" title="Inference with BN"></a>Inference with BN</h3><ul>
<li>Given a Bayesian Network, and an (or some) observed events, which specifies the value for <font color="red">evidence variables</font>, we want to know the probability distribution of one (or several) <font color="red">query variables</font> $\color{red}X$, i.e. $P(X | \text{events})$</li>
<li>First we try enumeration (calc all possible cases)</li>
</ul>
<p><img src="/2025/01/01/Artificial-Intelligence/ai1205.png" style="zoom:70%"></p>
<ul>
<li>and itâ€™s time consuming.</li>
<li>A way to simplify: Enumeration by Variable Elimination</li>
</ul>
<p><img src="/2025/01/01/Artificial-Intelligence/ai1206.png" style="zoom:70%"></p>
<h3 id="Approximate-Inference-with-BN"><a href="#Approximate-Inference-with-BN" class="headerlink" title="Approximate Inference with BN"></a>Approximate Inference with BN</h3><ul>
<li>Basic Idea:<ol>
<li>Draw N samples from a sampling distribution $S$</li>
<li>Compute an approximate posterior probability (åéªŒæ¦‚ç‡) $\hat{P}$</li>
<li>Show this converge to the true probability $P$</li>
</ol>
</li>
<li>Outline<ul>
<li>Sampling from an empty network</li>
<li>Rejection sampling: reject samples disagreeing with evidence</li>
<li>Likelihood weighting: use evidenve to weight samples</li>
<li>Markov Chain Monte Carlo (MCMC): sample from a stochastic process (éšæœºè¿‡ç¨‹) whose stationary distribution is the true posterior.</li>
</ul>
</li>
</ul>
<h4 id="Sampling-from-an-empty-network"><a href="#Sampling-from-an-empty-network" class="headerlink" title="Sampling from an empty network"></a>Sampling from an empty network</h4><p><img src="/2025/01/01/Artificial-Intelligence/ai1207.png" style="zoom:60%"></p>
<h4 id="Rejection-Sampling"><a href="#Rejection-Sampling" class="headerlink" title="Rejection Sampling"></a>Rejection Sampling</h4><p><img src="/2025/01/01/Artificial-Intelligence/ai1208.png" style="zoom:80%"></p>
<h4 id="Likelihood-Weighting"><a href="#Likelihood-Weighting" class="headerlink" title="Likelihood Weighting"></a>Likelihood Weighting</h4><p><img src="/2025/01/01/Artificial-Intelligence/ai1209.png" style="zoom:80%"></p>
<h4 id="MCMC"><a href="#MCMC" class="headerlink" title="MCMC"></a>MCMC</h4><p><img src="/2025/01/01/Artificial-Intelligence/ai1210.png" style="zoom:70%"></p>
<h3 id="How-to-construct-a-BN-or-KB-in-general"><a href="#How-to-construct-a-BN-or-KB-in-general" class="headerlink" title="How to construct a BN (or KB in general) ?"></a>How to construct a BN (or KB in general) ?</h3><ul>
<li>Challenge<ul>
<li>Big Data</li>
</ul>
</li>
<li>Methods<ul>
<li>Structural Learning</li>
<li>Parameter Estimation</li>
</ul>
</li>
<li>Similar to Neural Networks<ul>
<li>Structural Learning: Identify the network structure</li>
<li>Parameter Estimation: find VALUEs for parameters associated with an edge<ul>
<li>Depending on how you define the relationship between events/nodes<ul>
<li>values in a CPT</li>
<li>parameters of a probability density function</li>
</ul>
</li>
</ul>
</li>
<li>A machine learning or search problem again.</li>
</ul>
</li>
</ul>
<h1 id="Lecture-13-Knowledge-Graph"><a href="#Lecture-13-Knowledge-Graph" class="headerlink" title="Lecture 13. Knowledge Graph"></a>Lecture 13. Knowledge Graph</h1><h2 id="Overview-of-Knowledge-Graph-KG"><a href="#Overview-of-Knowledge-Graph-KG" class="headerlink" title="Overview of Knowledge Graph (KG)"></a>Overview of Knowledge Graph (KG)</h2><blockquote>
<p>What is Knowledge Graph?</p>
</blockquote>
<ul>
<li>To make a knowledge base (KB) of <strong>practical significance</strong>, we need to:<ul>
<li>Set a proper boundary for â€œknowledgeâ€, which means:<ul>
<li>bound the scope of the KB (and thus its representation)</li>
<li>bound the utility (application) of the KB</li>
</ul>
</li>
</ul>
</li>
<li>The idea of KG stems from <strong>Semantic Network</strong>.<ul>
<li>Knowledge Graph: Large-scale semantic network</li>
</ul>
</li>
<li>SN/KG uses vertexes and edges to represent knowledge graphically.<ul>
<li><strong>Vertexes</strong>: entities and concepts</li>
<li><strong>Edges</strong>: relations and properties</li>
</ul>
</li>
</ul>
<p><img src="/2025/01/01/Artificial-Intelligence/ai1301.png" style="zoom:90%"></p>
<h2 id="How-to-construct-Knowledge-Graphï¼Ÿ"><a href="#How-to-construct-Knowledge-Graphï¼Ÿ" class="headerlink" title="How to construct Knowledge Graphï¼Ÿ"></a>How to construct Knowledge Graphï¼Ÿ</h2><ul>
<li>Heterogeneous directed graphs.<ul>
<li>The KG can be represented as a graph $\mathcal{G}=(V,E)$ , $V$ is vertex set (entities set), $E$ is the edge set (relations set).</li>
</ul>
</li>
<li>RDFï¼šResource Description Framework, an XML Document standard from W3C<ul>
<li>use relation triplet <code>&lt;head entity, relation type, tail entity&gt;</code> to describe a relation.</li>
<li><strong>Head entity</strong>: the subject of this relation</li>
<li><strong>Relation type</strong>: the category of this relation</li>
<li><strong>Tail entity</strong>: the object of this relation</li>
</ul>
</li>
</ul>
<p><strong>The General (Semi-)Automatic Viewpoint</strong></p>
<p><img src="/2025/01/01/Artificial-Intelligence/ai1302.png" style="zoom:60%"></p>
<h3 id="Automatic-Entity-Recognition"><a href="#Automatic-Entity-Recognition" class="headerlink" title="Automatic Entity Recognition"></a>Automatic Entity Recognition</h3><ul>
<li>Identify meaningful entities based on the statistical metrics of vocabulary across various texts.<ul>
<li>Input: Documents (text)</li>
<li>Output: A set of entities</li>
</ul>
</li>
<li><strong>TF-IDF</strong> (Term Frequencyâ€“Inverse Document Frequency):<ul>
<li><font color="dodgerblue">Idea:</font> If a word appears frequently in one document but infrequently in others, it is more likely to be a meaningful entity.</li>
<li>For a corpus of documents:<ul>
<li>Term Frequency (TF): $P(w|d)$</li>
<li>Inverse Document Frequency (IDF): $\log{\left(\frac{|D|}{|\{ d\in D|w\in d \}|}\right)}$</li>
<li>TF-IDF: TF $\times$ IDF</li>
</ul>
</li>
</ul>
</li>
<li><strong>Entropy</strong> :<ul>
<li><font color="dodgerblue">Idea:</font> If a word has a rich variety of <font color="red">neighboring words</font>, it is likely be a meaningful entity<ul>
<li>$H(u) = - \sum_{x\in \mathcal{X}} p(x) \log{p(x)}$</li>
<li>$p(x)$ is the probability of a certain left neighbor (right neighbor) word, $\mathcal{X}$ is the set of all left neighbor (right neighbor) characters of $u$.</li>
<li>The larger $H(u)$ is, more abundant the set of $u$â€™s neighbors is.</li>
</ul>
</li>
</ul>
</li>
</ul>
<blockquote>
<p>Also, some ML techniques can solve the NER(Name Entity Recognition) tasks. Considering <strong>input</strong> is a sentence, <strong>output</strong> is the label of each word in the sentence.</p>
</blockquote>
<p><img src="/2025/01/01/Artificial-Intelligence/ai1303.png" style="zoom:80%"></p>
<h3 id="Automatic-Relation-Extraction"><a href="#Automatic-Relation-Extraction" class="headerlink" title="Automatic Relation Extraction"></a>Automatic Relation Extraction</h3><blockquote>
<p>By recognizing entities, now AI should â€œlearnâ€ about relations.</p>
</blockquote>
<ul>
<li>Using machine learning techniques, model the Relation Extraction process as a Text Classification Problem.<ul>
<li>Itâ€™s also a supervised learning task.</li>
</ul>
</li>
<li>Input is a sentence that contains 2 entities. Output is the category of the relation that the sentence express.<ul>
<li>Input: <font color="red">Zihan Zhang</font> will join the <font color="green">ICPC</font>.</li>
<li>Output: participate in</li>
</ul>
</li>
<li><strong>Relation extraction task</strong> can be solved by the following technologies:<ul>
<li>RNN, Transformers, â€¦</li>
</ul>
</li>
</ul>
<h3 id="Knowledge-Graph-Completion"><a href="#Knowledge-Graph-Completion" class="headerlink" title="Knowledge Graph Completion"></a>Knowledge Graph Completion</h3><p><img src="/2025/01/01/Artificial-Intelligence/ai1304.png" style="zoom:80%"></p>
<ul>
<li>2 ways for completion task<ul>
<li>Path-based method</li>
<li>Embedding-based method</li>
</ul>
</li>
</ul>
<ul>
<li>Path-based is interpretable, so we skip it.</li>
<li>Embedding-based methods represent the entities and relation types in the KG as a <strong>low-dimensional real value vector</strong> (also called embedding).<ul>
<li>Design a score function $\mathcal{g}(h,r,t)$. Get suitable embedding for entities and relation types.<ul>
<li>$h$, $r$, and $t$ are embeddings of head entity $h$, relation type $r$, and tail entity $t$ respectively.</li>
<li>Higher $\mathcal{g}(h,r,t)$ means that the relation is more possible to be true.</li>
</ul>
</li>
</ul>
</li>
<li>How to get suitable embedding for entities and relation types?<ul>
<li>Consider: All the relations in the KG should have higher score than any relation that is not in the KG.</li>
<li>Objective Function: $\min \underset{(h,r,t)\in \mathcal{g}}{\sum} \underset{(hâ€™,râ€™,tâ€™)\notin \mathcal{g}}{\sum} \left[\mathcal{g}(hâ€™,râ€™,tâ€™) - \mathcal{g}(h,r,t)\right]_{+}$</li>
<li>Get suitable embedding by <strong>gradient descent</strong>.</li>
</ul>
</li>
</ul>
<h2 id="KG-Based-Recommender-System"><a href="#KG-Based-Recommender-System" class="headerlink" title="KG-Based Recommender System"></a>KG-Based Recommender System</h2><p><img src="/2025/01/01/Artificial-Intelligence/ai1305.png" style="zoom:80%"><br><img src="/2025/01/01/Artificial-Intelligence/ai1306.png" style="zoom:80%"><br><img src="/2025/01/01/Artificial-Intelligence/ai1307.png" style="zoom:80%"><br><img src="/2025/01/01/Artificial-Intelligence/ai1308.png" style="zoom:80%"></p>
<ul>
<li>We can get the <strong>feature of the user and item</strong> from the new graph that is mixed by KG and interaction records.</li>
<li>A typical method is GNN (Graph Neural Network):<ul>
<li>There is an initial embedding for each node in the graph.</li>
<li>The final embedding of each node is calculated by the embeddings of its neighborhood.</li>
<li>Result of $f(u,w)$ is calculated according to the final embeddings of user<br>$u$ and item $w$ by a model $M$, such as MLP or matrix multiplication.</li>
</ul>
</li>
</ul>
<h1 id="Review-and-Semester-Summary"><a href="#Review-and-Semester-Summary" class="headerlink" title="Review and Semester Summary"></a>Review and Semester Summary</h1><blockquote>
<p>I can build a knowledge base here to tell you what weâ€™ve learnt in AI course. ğŸ˜‚ </p>
<p>Just a framework.</p>
</blockquote>
<ul>
<li>Problem-solving<ul>
<li>Classical search</li>
<li>Beyondclassical search</li>
<li>Problem-Specific Search</li>
</ul>
</li>
<li>MachineLearning<ul>
<li>Supervised Learning</li>
<li>Performance Evaluation</li>
<li>Unsupervised Learning</li>
<li>Automated Machine Learning</li>
</ul>
</li>
<li>Knowledge and Reasoning <ul>
<li>Representing and Inference with logic</li>
<li>Representing and Inference with Uncertainty </li>
<li>Knowledge Graph andRecommender System </li>
</ul>
</li>
</ul>
<h2 id="Connection-with-Previous-Courses"><a href="#Connection-with-Previous-Courses" class="headerlink" title="Connection with Previous Courses"></a>Connection with Previous Courses</h2><ul>
<li>In searching module, we use algorithm of graph, which weâ€™ve learnt in <strong>DSAA</strong>.</li>
<li>In ML module, we use knowledge in <strong>Big Data</strong> Course.<ul>
<li>Also we talked about FOL â€¦ which is in <strong>Discrete Mathemetic</strong>.</li>
</ul>
</li>
<li>In KG-RS module, we use knowledge in <strong>Probability Theory and Mathemetic Statistics</strong>.</li>
<li>And the whole AI Course has strong connection to <strong>Calculus</strong> and <strong>Linear Algebra</strong>.</li>
</ul>
<blockquote>
<p>Therefore, if you want to learn AI well, these courses should be premises.</p>
<p>(Also said to me, a foolish student â€¦)</p>
</blockquote>
]]></content>
      <categories>
        <category>2024 Fall</category>
      </categories>
      <tags>
        <tag>CSE Learning</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>PlACo User Document</title>
    <url>/2025/06/17/Placo/</url>
    <content><![CDATA[<h1 id="PlACo-Document"><a href="#PlACo-Document" class="headerlink" title="PlACo Document"></a>PlACo Document</h1><ul>
<li><a href="#Introduction">Introduction</a></li>
<li><a href="#Installation">Installation</a></li>
<li><p><a href="#Usages">Usages</a></p>
<ul>
<li><a href="#Login">Login</a></li>
<li><p><a href="#Users">Users</a></p>
<ul>
<li><a href="#Course-Intructor">Instructor</a></li>
<li><a href="#Course-Student">Student</a></li>
</ul>
</li>
<li><p><a href="#Administrater">Administrater</a></p>
</li>
</ul>
</li>
<li><p><a href="#Contributing">Contributing</a></p>
</li>
<li><a href="#License">License</a></li>
</ul>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><ul>
<li><strong>PlACo</strong> (<strong>Pl</strong>atform of <strong>A</strong>ssignment and <strong>Co</strong>ding) is an integrated platform with a streamlined user interface</li>
<li>Our design combines the functions of Blackboard(an assignment submission platform) and Online Judge(a programming judge platform)</li>
<li>Our supported functions include (details seen in <a href="#usage">Usage</a>):<ul>
<li>Customized settings</li>
<li>Assignment submission</li>
<li>Programming problem submission</li>
<li>Online judge</li>
</ul>
</li>
</ul>
<h2 id="Installation"><a href="#Installation" class="headerlink" title="Installation"></a>Installation</h2><h3 id="By-source-code"><a href="#By-source-code" class="headerlink" title="By source code"></a>By source code</h3><ol>
<li>Clone frontend source code</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> [repo-address] -b frontend/main</span><br></pre></td></tr></table></figure>
<ol>
<li>Install necessary packages</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm install</span><br></pre></td></tr></table></figure>
<ol>
<li>Run in develop mode</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm run dev</span><br></pre></td></tr></table></figure>
<ol>
<li>Build the project (or you can run it in a Docker container)<ul>
<li>we use normal next.js framework, so you can view next.js deployment for this deployment</li>
</ul>
</li>
</ol>
<h2 id="Usages"><a href="#Usages" class="headerlink" title="Usages"></a>Usages</h2><h3 id="Login"><a href="#Login" class="headerlink" title="Login"></a>Login</h3><ul>
<li>In <code>Login</code> page, users can input <strong>Username</strong> and <strong>Password</strong> for login.</li>
<li>If you are a new user, feel free to sign in via Github, and we will register a new user for you!</li>
</ul>
<p><img src="/2025/06/17/Placo/login.png"></p>
<h3 id="Users"><a href="#Users" class="headerlink" title="Users"></a>Users</h3><p><strong>Intro</strong></p>
<ul>
<li>Users have normal authority in <em>PlACo</em>. Also, they may have different authorities according to their <code>role</code> in a specific course</li>
</ul>
<p><img src="/2025/06/17/Placo/mainPage.png"></p>
<h4 id="Schedule-and-Settings"><a href="#Schedule-and-Settings" class="headerlink" title="Schedule and Settings"></a>Schedule and Settings</h4><ul>
<li>There is a <code>Tab</code> at the Header of :house:main page (after you login). Click the <code>Schedule</code> to enter :calendar:schedule page.</li>
<li>You can check <strong>all the upcoming assignments</strong> of all courses that you attend in a table.</li>
<li>There is a button â€œView Calendarâ€ to see the assignment DDL in a calendar.</li>
<li>There is a button â€œAdd Entryâ€ that you can add your own schedule<ul>
<li>Input entryâ€™s name and due time to create a new entry</li>
</ul>
</li>
</ul>
<hr>
<ul>
<li>There is a <code>Menu</code> at the up-right of main page. Click the <code>Setting</code> to enter setting page</li>
<li>You can change your <code>username</code> and <code>password</code> of your account. Just input a new one and click <code>update</code>.</li>
<li>There is a switch that you can turn to dark mode. The default mode is light, but we will keep your customized setting.</li>
</ul>
<h4 id="Course-Intructor"><a href="#Course-Intructor" class="headerlink" title="Course Intructor"></a>Course Intructor</h4><blockquote>
<p>:fountain_pen: <strong>IMPORTANT!</strong> In a specific course, you will have a â€œroleâ€, a teacher (<code>INSTRUCTOR</code>) or a student (<code>STUDENT</code>).</p>
<p>:fountain_pen: <strong>IMPORTANT!</strong> Your role is specified by the administrater, and you can view your role of a course on the â€œcourse cardâ€ in :house:main page.</p>
</blockquote>
<ul>
<li>If you are <strong>INSTRUCTOR</strong> of a course, you can create assignments (following steps) at the first page you enter a course.<ul>
<li>Click the <code>Create Assignment</code> button</li>
<li>Input all necessary items (e.g. assignment title, type, due date, full mark and max attempts)<ul>
<li>you can set assignment type to<code>TEXT</code> or <code>CODE</code>. You are given different operations on different mode.</li>
</ul>
</li>
<li>You can submit files as assignment documents, you can also add document after create this assignment.</li>
<li>You can enable OCR service to check students submission after convert them from hand-written version to type-version.</li>
</ul>
</li>
<li>A <strong>navbar</strong> is offered to select assignment that you can view details and operate.</li>
<li>For a <strong>TEXT</strong> assignment, you can:<ul>
<li>click <code>Modify</code> button to change publish time, due time, full mark and enable-OCR state.</li>
<li>preview your submitted documents by clicking <code>Preview</code> button of each file</li>
<li>click <code>Add documents</code> or <code>Delete documents</code> to add or delete document files.</li>
<li>:fountain_pen: <strong>IMPORTANT!</strong> check studentsâ€™ submissions information:<ul>
<li>click link <code>View Details</code> to preview files that students submit (if exists)</li>
<li>input scores and click <code>save</code> button to score for this submission</li>
<li>click <code>Publish Scores</code> to make them available to students if <strong>Due time is expired</strong> and <strong>all studentsâ€™ submissions are scored</strong>.</li>
</ul>
</li>
</ul>
</li>
<li>For a <strong>CODE</strong> assignment, you can:<ul>
<li><strong>also</strong> modify assignment information and add/delete documents</li>
<li>You can add testcases by clicking <code>Add Testcases</code> button:<ul>
<li>then set all necessary configuration of a testcase (detailed description inside this page)</li>
<li>you can upload an input file and an expected output file as â€œtestcaseâ€</li>
<li>then add this testcase to the <strong>testcase list</strong> (<strong>you can add multiple testcases!</strong>)</li>
<li>at last, you can click <code>Confirm All</code> to upload all testcases at a time</li>
</ul>
</li>
<li>You can click <code>View Testcases</code> button to delete a testcase or view details like:<ul>
<li>CPU time limit, global time limit, memory limit, stack limit</li>
<li>Input file content, output file content, enabled attributes</li>
</ul>
</li>
<li>there is also a table showing studentsâ€™ submissions. You can view files that students submit, <strong>BUT</strong> you canâ€™t score because we have a judge service to score it automatically.</li>
</ul>
</li>
</ul>
<p><img src="/2025/06/17/Placo/assignment-instructor.png"></p>
<h4 id="Course-Student"><a href="#Course-Student" class="headerlink" title="Course Student"></a>Course Student</h4><ul>
<li>As a student in a course, you can <strong>submit assignment or code</strong> and <strong>check out your scores</strong>.</li>
<li>For a <strong>TEXT</strong> assignment, you can:<ul>
<li>click <code>Pick files</code> to upload file for a submission</li>
<li>this page will only show your latest submission (view submit time on the right)</li>
<li>You can <strong>view your score</strong> if teacher publish it. (on the right)</li>
</ul>
</li>
<li>For a <strong>CODE</strong> assignment, you can:<ul>
<li>click <code>Pick files</code> and <strong>Choose programming language</strong> to make submission</li>
<li>this page will show all your submissions ordered by submit time (desc.)</li>
<li>you can click link <code>View Details</code> to see each of your submissions and check results of all testcases (if exists)</li>
</ul>
</li>
</ul>
<blockquote>
<p>Code assighments are judged by auto service, so you <strong>MUST</strong> choose programming language before submitting</p>
</blockquote>
<p><img src="/2025/06/17/Placo/assignment-student.png"></p>
<h3 id="Administrater"><a href="#Administrater" class="headerlink" title="Administrater"></a>Administrater</h3><p><strong>Intro</strong></p>
<ul>
<li>ADMINs have all authority that users have. And they also have authority to register new users and new courses.</li>
<li>Compared to Users, administraters have 2 more tabs on hearder.</li>
</ul>
<p><img src="/2025/06/17/Placo/header.png"></p>
<h4 id="Manage-Courses"><a href="#Manage-Courses" class="headerlink" title="Manage Courses"></a>Manage Courses</h4><ul>
<li>Click <code>Courses</code> tab to manage courses</li>
<li>You can:<ul>
<li>click one existed course to add/delete members as instructor/student (all enable to search and choose)</li>
<li>click <code>Create Course</code> button to create new course<ul>
<li>You can initialize course attributes (name, instructors, students) to create one single course</li>
<li>You can also upload a <strong>CSV</strong> file in formal format &amp; order to create multiple courses.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="Manage-Users"><a href="#Manage-Users" class="headerlink" title="Manage Users"></a>Manage Users</h4><ul>
<li>Click <code>Users</code> tab to manage users</li>
<li>You can:<ul>
<li>check a userâ€™s information and deactivate it (after that, this user cannot login)</li>
<li>register a new user by clicking <code>New</code> button:<ul>
<li>You can initialize user attributes (email, username, password, role) to create one single user</li>
<li>You can also upload a <strong>CSV</strong> file in formal format &amp; order to create multiple users.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="Contributing"><a href="#Contributing" class="headerlink" title="Contributing"></a>Contributing</h2><h3 id="Contributors"><a href="#Contributors" class="headerlink" title="Contributors"></a>Contributors</h3><ul>
<li><p>Now our group have 4 members: <a href="https://github.com/fest6">fest6</a>, <a href="https://github.com/LatiosInAltoMare">LatiosInAltoMare</a>, <a href="https://github.com/zxx3312">zxx3312</a>, <a href="https://github.com/HQJ2221">HQJ2221</a>.</p>
</li>
<li><p>Two of us working for backend, and the other two for frontend. We all do part of testing, and our PM complete deployment.</p>
</li>
<li><p>If you want to contribute to our code, please refer to Developer Document(wait for publishment).</p>
</li>
</ul>
<h2 id="License"><a href="#License" class="headerlink" title="License"></a>License</h2><p><a href="https://mit-license.org/">MIT License</a></p>
]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>CSE Learning</tag>
        <tag>React</tag>
        <tag>Java</tag>
        <tag>Springboot</tag>
      </tags>
  </entry>
</search>
