<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>概率论与数理统计</title>
    <url>/2024/08/19/Probability-Theory-and-Mathematical-Statistics/</url>
    <content><![CDATA[<h1 id="第一章-概率"><a href="#第一章-概率" class="headerlink" title="第一章 概率"></a>第一章 概率</h1><h2 id="记数方法"><a href="#记数方法" class="headerlink" title="记数方法"></a>记数方法</h2><ul>
<li>古典概型<ul>
<li>$\Omega$ 只含有限个样本点</li>
<li>每个样本点出现是等可能的</li>
</ul>
</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>P(A)=\frac{A \text{的有利场合数}}{\text{样本点总数}}=\frac{k}{n}<br>$</p>

</blockquote>
<ul>
<li>几何概型<ul>
<li>对比古典概型有无限个样本点</li>
</ul>
</li>
</ul>
<h2 id="全概率定律"><a href="#全概率定律" class="headerlink" title="全概率定律"></a>全概率定律</h2><p><strong>Def.</strong> 设 $\Omega$ 为样本空间，若事件 $B_1,B_2,\cdots ,B_n$ 满足：</p>
<ol>
<li>$B_1,B_2,\cdots ,B_n$ 两两不相容</li>
<li>$B_1 \cup B_2 \cup \cdots \cup B_n = \Omega$</li>
</ol>
<p>则称 $B_1,B_2,\cdots ,B_n$ 为样本空间的一个<font color="red">划分</font>。</p>
<p>由此推出全概率公式：</p>
<blockquote class="blockquote-center">
<p>$<br>P(A)=\sum_{i=1}^{n} P(A|B_i) \cdot P(B_i)<br>$</p>

</blockquote>
<p>由全概率公式和条件概率的乘法公式推导出 <font color="red">Bayes 公式</font>：</p>
<blockquote class="blockquote-center">
<p>$<br>P(B_i|A)=\frac{P(A|B_i)P(B_i)}{\sum_{j=1}^{n} P(A|B_j)P(B_j)}<br>$</p>

</blockquote>
<p>Bayes 公式的实际意义：</p>
<p>假定 $B_1,B_2,\cdots ,B_n$ 为导致实验结果的“原因”，称 $P(B_i) (i=1,2,\cdots ,n)$ 为<font color="red">先验概率</font>。</p>
<p>若试验产生事件 A ，则要探讨事件发生的“原因”：称 $P(B_i|A)$ 为<font color="red">后验概率</font>，称 $P(A|B_i)$ 为<font color="red">原因概率</font></p>
<h1 id="第二章-随机变量"><a href="#第二章-随机变量" class="headerlink" title="第二章 随机变量"></a>第二章 随机变量</h1><h2 id="离散随机变量"><a href="#离散随机变量" class="headerlink" title="离散随机变量"></a>离散随机变量</h2><p>定义：</p>
<blockquote class="blockquote-center">
<p>$<br>P\{ X=x_k \}= p(x_k),\ \ (k=1,2,3,\cdots)<br>$</p>

</blockquote>
<p>为离散型 r.v. X 的概率质量函数 (PMF)</p>
<blockquote class="blockquote-center">
<p>$<br>F(x)=P\{ X \le x \}, -\infty \lt x \lt \infty<br>$</p>

</blockquote>
<p>为离散型 r.v. X 的累计分布函数 (CDF)</p>
<p><strong>泊松定理</strong></p>
<p>设 $\lambda \gt 0$，$n$ 为正整数，$\lim_{n \to \infty} np_n=\lambda$，则有</p>
<blockquote class="blockquote-center">
<p>$<br>\lim_{n\to \infty} C^k_n p^k_n(1-p_n)^{n-k}=\frac{\lambda^{k}e^{-\lambda}}{k!}<br>$</p>

</blockquote>
<h2 id="连续随机变量"><a href="#连续随机变量" class="headerlink" title="连续随机变量"></a>连续随机变量</h2><p>定义：</p>
<blockquote class="blockquote-center">
<p>$<br>F(x)=\int_{-\infty}^{x} f(t)\text{d}t,\ -\infty \lt x \lt \infty<br>$</p>

</blockquote>
<p>其中 $f(t)$ 为连续型 r.v. X 的概率密度函数 (PDF)</p>
<p><strong>标准正态分布</strong></p>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{l}<br>&amp;\Phi(x)=\int_{-\infty}^{x} \psi(x)\text{d}x \\<br>&amp;\psi(x)=\frac{1}{\sqrt{2\pi}\sigma} e^{-\frac{(x-\mu)^2}{2\sigma^2}} \\<br>&amp;s.t.\ \mu=0,\ \sigma^2=1<br>\end{array}<br>$</p>

</blockquote>
<h2 id="随机变量的函数"><a href="#随机变量的函数" class="headerlink" title="随机变量的函数"></a>随机变量的函数</h2><p>例：设随机变量 $X$，$Y$，满足 $Y=aX+b$，如何通过 $X$ 的概率密度分布求出 $Y$ 的 PDF？</p>
<p>解：令 $x=g(y)=\frac{y-b}{a}$，可得 $F_Y(y)=P\{ Y\le y \}=P\{ X\le\frac{y-b}{a} \}=F_X(\frac{y-b}{a})$。</p>
<p>化简得：$f_Y(y)=F_{X}’(g(y))=(g(y))’f_X(g(y))$</p>
<p>如正态分布 $X\sim N(\mu,\sigma^2)$ 的线性函数 $aX+b \sim N(a\mu +b,(a\sigma)^2)$ 也是正态分布</p>
<h1 id="第三章-联合分布"><a href="#第三章-联合分布" class="headerlink" title="第三章 联合分布"></a>第三章 联合分布</h1><h2 id="联合随机变量"><a href="#联合随机变量" class="headerlink" title="联合随机变量"></a>联合随机变量</h2><p>定义：</p>
<blockquote class="blockquote-center">
<p>$<br>F(X,Y)\triangleq P\{ X\le x,Y\le y \}\ \ s.t.\ \{x,y\}\in \mathbb{R}<br>$</p>

</blockquote>
<p>为 $X$ 与 $Y$ 的联合累积分布函数。</p>
<blockquote class="blockquote-center">
<p>$<br>F_X(x)= P\{ X\le x,Y\le \infty \}\ \ s.t.\ x\in \mathbb{R}<br>$</p>

</blockquote>
<p>称为 $X$ 的边际分布，$Y$ 同理。</p>
<p><strong>概率密度函数</strong></p>
<blockquote class="blockquote-center">
<p>$<br>F(x,y)=\int_{-\infty}^{x} \int_{-\infty}^{y} f(u,v)\text{d}u\text{d}v,\ s.t.\ \{ x,y\}\in\mathbb{R}<br>$</p>

</blockquote>
<p>则 $f(x,y)$ 为 $X$，$Y$ 的概率密度函数(joint PDF)</p>
<p><strong>边际密度</strong></p>
<blockquote class="blockquote-center">
<p>$<br>f_X(u)=\int_{-\infty}^{\infty} f(u,y)\text{d}y<br>$</p>

</blockquote>
<p>称为 $X$ 的边际密度，$Y$ 同理。</p>
<h2 id="独立随机变量"><a href="#独立随机变量" class="headerlink" title="独立随机变量"></a>独立随机变量</h2><blockquote class="blockquote-center">
<p>$<br>f(x,y)=f_X(x)\cdot f_Y(y)<br>$</p>

</blockquote>
<p>当上式成立时，$X$，$Y$ 相互独立，即相关系数 $\rho=0$。</p>
<h2 id="条件分布"><a href="#条件分布" class="headerlink" title="条件分布"></a>条件分布</h2><p>（只看连续，离散情况容易推导）</p>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{l}<br>P(X\le x|y\le Y\le y+\epsilon) &amp;=\frac{P\{X\le x,y\le Y\le y+\epsilon\}}{P\{ y\le Y\le y+\epsilon\ \}} \\<br>&amp;=\frac{\int_{-\infty}^{x}\int_{y}^{y+\epsilon} f(u,v)\text{d}u\text{d}v}{\int_{y}^{y+\epsilon} f_Y(v)\text{d}v} \\<br>&amp;=\frac{\epsilon\int_{-\infty}^{x}f(u,y_\epsilon)\text{d}u}{\epsilon f_Y(\tilde{y}_{\epsilon})} \\<br>&amp;= \int_{-\infty}^{x}\frac{f(u,y)}{f_Y(y)} \text{d}u\ \ (\epsilon\to 0)<br>\end{array}<br>$</p>

</blockquote>
<p>定义 $\frac{f(u,y)}{f_Y(y)} \triangleq f_{X|Y}(x|y)$ 为 $Y=y$ 下 $X$ 的<font color="red">条件密度</font></p>
<h2 id="联合分布随机变量的函数"><a href="#联合分布随机变量的函数" class="headerlink" title="联合分布随机变量的函数"></a>联合分布随机变量的函数</h2><p>1 . $Z=X+Y$</p>
<p>利用卷积公式 (可写作 $f_X * f_Y$)：</p>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{l}<br>&amp;f_Z(z)=\int_{-\infty}^{\infty}f_X(z-y)f_Y(y)\text{d}y \\<br>\text{or } &amp;f_Z(z)=\int_{-\infty}^{\infty}f_X(x)f_Y(z-x)\text{d}x<br>\end{array}<br>$</p>

</blockquote>
<font color="red">前提：</font> 

<p>$X$，$Y$ 相互独立（如不独立，可利用联合分布、条件分布求得，或变换成独立变量再求解）。</p>
<p>2 . $Z=\frac{X}{Y}$</p>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{l}<br>&amp;\text{由于 }F_Z(z)=P\{ X/Y\le z \}=\underset{\frac{x}{y}\le z}{\int\int} f(x,y)\text{d}x \text{d}y \text{ 积分区域可能不是矩形} \\<br>&amp;\text{为简化积分计算，使用 }\textbf{J}=\frac{\partial{(x,y)}}{\partial{(u, v)}}= \Large{\left| \begin{array}{c} \frac{\partial{x}}{\partial{u}} &amp; \frac{\partial{x}}{\partial{v}} \\ \frac{\partial{y}}{\partial{u}} &amp; \frac{\partial{y}}{\partial{v}} \end{array} \right|} \\<br>&amp;\text{得 }F_Z(z)=\underset{\Omega}{\int\int} f[x(u,v),y(u,v)] |\textbf{J}|\text{d}u \text{d}v<br>\end{array}<br>$</p>

</blockquote>
<h2 id="顺序统计量"><a href="#顺序统计量" class="headerlink" title="顺序统计量"></a>顺序统计量</h2><p>设 $X_i\sim f(x)$ 是独立同分布的连续型 r.v.，则对于顺序统计量 $X_{(1)}(\min),\cdots ,X_{(n)}(\max)$ ，如何求 $X_{(k)}$ 的密度？</p>
<p>解：对于充分小的空间 $[x,x+\text{d}x]$，有</p>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{l}<br>&amp;P\{ x\lt X_{(k)} \lt x+\text{d}x \}=\left(\begin{array}{c}n \\ k-1 \end{array} \right) F(x)^{k-1} \left(\begin{array}{c}n-k+1 \\ 1 \end{array} \right) [F(x+\text{d}x)-F(x)] \left(\begin{array}{c}n-k \\ n-k  \end{array} \right) [1-F(x+\text{d}x)^{n-k}] \\<br>\therefore\ \ &amp;f_k(x)=\frac{\text{d}P\{ x\lt X_{(k)} \lt x+\text{d}x \}}{\text{d}x}=\frac{n!}{(k-1)!(n-k)!}F(x)^{k-1} f(x)[1-F(x)]^{n-k}<br>\end{array}<br>$</p>

</blockquote>
<p>称此为 Veta 分布，记为 $X\sim Beta(k, n-k+1)$</p>
<p>Beta 密度用于刻画 [0, 1] 上的随机变量：</p>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{l}<br>&amp;f(u)=\frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)}u^{a-1}(1-u)^{b-1} \\<br>s.t.\ &amp;\Gamma(x)=(x-1)! ,\ 0\le u\le 1<br>\end{array}<br>$</p>

</blockquote>
<h1 id="第四章-随机变量的数字特征"><a href="#第四章-随机变量的数字特征" class="headerlink" title="第四章 随机变量的数字特征"></a>第四章 随机变量的数字特征</h1><h2 id="协方差"><a href="#协方差" class="headerlink" title="协方差"></a>协方差</h2><p>定义：</p>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{l}<br>&amp;Cov(X,Y)\triangleq E[(X-E(X))\cdot (Y-E(Y))]<br>\end{array}<br>$</p>

</blockquote>
<p>称为 X，Y 的协方差，其相关系数表示为：</p>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{l}<br>&amp;\rho_{XY}\triangleq Cov(X^{*},Y^{*})=\frac{Cov(X,Y)}{\sqrt{D(X)}\sqrt{E(Y)}}<br>\end{array}<br>$</p>

</blockquote>
<p>利用这个属性进行 X，Y 线性拟合的计算：</p>
<p>记均方误差为 $e=E[(Y-\hat{Y})^2]=E[(Y-(aX+b))^2]$</p>
<p>令 $\left\{ \begin{array}{l} &amp;\frac{\partial{e}}{\partial{b}}=2b+2aE(X)-2E(Y)=0 \\ &amp;\frac{\partial{e}}{\partial{a}}=2aE(X^2)-2E(XY)+2bE(X)=0 \end{array} \right.$</p>
<p>解得 $\left\{ \begin{array}{l} &amp;b_0=\frac{Cov(X,Y)}{D(X)} \\ &amp;a_0=E(Y)-E(X)\cdot b_0 \end{array} \right.$</p>
<p>进一步得 $\underset{a,b}{\min e}=D(Y)(1-\frac{Cov^2(X,Y)}{D(X)D(Y)})=D(Y)(1-\rho^2_{XY})$</p>
<font color="red">注意：</font>$\rho_{XY}=0$ 并不意味着 X，Y 相互独立！（但正态分布能证明 不相关 = 独立）



定义：

对 r.v. X，Y，

$E(X^k)\ \ \ (k=1,2,\cdots)$ 为 <font color="red">k 阶原点矩</font>

<p>$E[(X-E(X))^k]\ \ \ (k=1,2,\cdots)$ 为 <font color="red">k 阶中心矩</font></p>
<p>$E[(X-E(X))^k(Y-E(Y))^l]\ \ \ (k,l=1,2,\cdots)$ 为 <font color="red">k+l 阶混合中心矩</font></p>
<blockquote>
<p>因此，r.v. 的期望是一阶原点矩，方差是2阶中心矩，协方差是2阶混合中心矩。</p>
</blockquote>
<h2 id="条件期望"><a href="#条件期望" class="headerlink" title="条件期望"></a>条件期望</h2><p>定义：</p>
<blockquote class="blockquote-center">
<p>$<br>\left\{\begin{array}{rl}<br>&amp;E(h(Y)|X=x)=\sum_{y}h(y)p_{Y|X}(y|x) &amp;\text{（离散）} \\<br>&amp;E(h(Y)|X=x)=\int_{y}h(y)f_{Y|X}(y|x)\text{d}y &amp;\text{（连续）}<br>\end{array}\right.<br>$</p>

</blockquote>
<blockquote>
<p>特殊情况下，$h(y)=y$</p>
</blockquote>
<p><font color="green">回顾泊松分布：</font> $X\sim P(\lambda t)$</p>
<p>$P(X=k)=\frac{(\lambda t)^k}{k!}e^{-\lambda t}\ \ \ k\in\mathbb{N}$  称为泊松强度。</p>
<p>例：考虑 [0, 1] 区间上均值为 $\lambda$ 的泊松流，令 N 是 [0, 1] 上点的个数。对于 $p\lt 1$，令 X 是 [0, p] 上点的个数。计算给定 N = n 的情况下，X 的条件分布和条件期望。</p>
<p>解：联合分布</p>
<p>$P\{X=x,N=n \}=\frac{(p\lambda)^xe^{-p\lambda}}{x!}\cdot \frac{((1-p)\lambda)^{(n-x)}e^{-(1-p)\lambda}}{(n-x)!}$</p>
<p>而 $N\sim P(\lambda)$</p>
<p>因此 $P\{X=x|N=n \}=\frac{n!}{x!(n-x)!}p^x(1-p)^{(n-x)}\sim b(n,p)$</p>
<p>从而 $X$ 的条件期望为 $np$。</p>
<h1 id="第五章-数理统计（入门）"><a href="#第五章-数理统计（入门）" class="headerlink" title="第五章 数理统计（入门）"></a>第五章 数理统计（入门）</h1><h2 id="大数定律"><a href="#大数定律" class="headerlink" title="大数定律"></a>大数定律</h2><p>（伯努利版）设 $P(A)=p$，则对任意 $\epsilon\gt 0$，有 $\color{red} \underset{n\to \infty}{\lim}=P\{|\frac{n_A}{n}-p|\ge \epsilon \}=0$</p>
<p>（切比雪夫版）$\{X_n\}$ 为独立随机变量列，且期望方差相同，则对任意 $\epsilon\gt 0$，有 $\color{red} \underset{n\to \infty}{\lim}=P\{|\frac{1}{n}\sum_{i=1}^{n}X_i-\mu|\ge \epsilon \}=0$</p>
<p>（这意味着样本量足够大时，期望可被样本的算术均值替代）</p>
<h2 id="中心极限定理"><a href="#中心极限定理" class="headerlink" title="中心极限定理"></a>中心极限定理</h2><p>若 $X_n$ 的分布 $F_n(x)$ 对任意 $x$ 满足</p>
<blockquote class="blockquote-center">
<p>$<br>\color{red}<br>\begin{array}{l}<br>&amp;\underset{n\to \infty}{\lim} F_n(x)=\underset{n\to \infty}{\lim}P\{ \frac{\sum_{i=1}^{n}(X_i-\mu_i)}{\sqrt{\sum_{i=1}^{n}\sigma_i^2}}\le x \}=\psi(x)<br>\end{array}<br>$</p>

</blockquote>
<p>则称 $\{X_n \}$ 服从中心极限定理（$\psi(x)$ 为标准正态）</p>
<p>特别当 $X_n$ 独立同分布，则有 $\underset{n\to \infty}{\lim}P\{ \frac{\sum_{i=1}^{n}X_i-n\mu_i}{\sqrt{n}\sigma_i}\le x \}=\psi(x)$</p>
<blockquote>
<p>德莫夫-拉普拉斯中心极限定理：对 $\eta_n\sim b(n,p)$</p>
<p>$\frac{\eta_n-np}{\sqrt{np(1-p)}}\sim N(0,1)$</p>
<p>参考高尔顿钉板</p>
</blockquote>
<h1 id="第六章-数理统计（基础）"><a href="#第六章-数理统计（基础）" class="headerlink" title="第六章 数理统计（基础）"></a>第六章 数理统计（基础）</h1><h2 id="抽样分布"><a href="#抽样分布" class="headerlink" title="抽样分布"></a>抽样分布</h2><p>1 . $\chi^2$ - 分布</p>
<p>设 $X_1-X_n$ 是来自总体 $X\sim N(0,1)$ 的样本，令</p>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{l}<br>\chi^2=X_1^2+X_2^2+\cdots +X_n^2<br>\end{array}<br>$</p>

</blockquote>
<p>称 $\chi^2$ 服从自由度为 $n$ 的 $\chi^2$ - 分布（也称卡方分布），记为 $\chi^2(n)$。</p>
<blockquote>
<p><font color="blue">自由度：</font>自由度是二次型 $\chi^2=X_1^2+X_2^2+\cdots +X_n^2$ 的秩，即可独立变化的变量个数。</p>
</blockquote>
<p>数字特征：</p>
<ul>
<li>$E(\chi^2)=n$</li>
<li>$D(\chi^2)=2n$</li>
</ul>
<p>2 . t - 分布</p>
<p>设 $X\sim N(0,1)$，$Y\sim \chi^2(n)$，且 $X$，$Y$ 独立，令</p>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{l}<br>t=X/\sqrt{Y/n}<br>\end{array}<br>$</p>

</blockquote>
<p>称 $t$ 为服从自由度为 n 的 t - 分布，记为 $t(n)$。</p>
<p>性质：</p>
<ul>
<li>数字特征<ul>
<li>$E(t)=0$</li>
<li>$D(t)=\frac{n}{n+2}$</li>
</ul>
</li>
<li>当 n 充分大时，T 近似服从 N(0, 1)，即趋近标准正态分布<ul>
<li>可证明 $\underset{n\to\infty}{\lim}f(x)=(2\pi)^{-\frac{1}{2}}e^{-\frac{x^2}{2}}$</li>
</ul>
</li>
</ul>
<p>3 . F - 分布</p>
<p>设 $U\sim \chi^2(n_1)$，$V\sim \chi^2(n_2)$，且 $U$，$V$ 独立，令</p>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{l}<br>F=\Large\frac{U/n_1}{V/n_2}<br>\end{array}<br>$</p>

</blockquote>
<p>称 F 为服从自由度为 $(n_1,n_2)$ 的 F - 分布，记为 $F(n_1,n_2)$。</p>
<p>二级结论：</p>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{l}<br>&amp;T\sim t(n) \Rightarrow T^2\sim F(1,n) \\<br>\text{证：} &amp;T=\frac{X}{\sqrt{Y/n}} \Rightarrow T^2=\frac{X^2/1}{Y/n}, \\<br>\text{ 且 }&amp;X^2,Y\text{ 仍相互独立}<br>\end{array}<br>$</p>

</blockquote>
<h2 id="抽样分布定理"><a href="#抽样分布定理" class="headerlink" title="抽样分布定理"></a>抽样分布定理</h2><p>1 . 设 $X_1\sim X_n$ 是来自总体 $X\sim N(\mu,\sigma^2)$ 的样本，则</p>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{l}<br>\bar{X}\sim N(\mu,\frac{\sigma^2}{n})<br>\end{array}<br>$</p>

</blockquote>
<p>因为 $\bar{X}=(X_1+\cdots +X_n)/n$ ，而线性组合仍服从正态分布。</p>
<p>因此，$E(\bar{X})=\mu$，$D(\bar{X})=\frac{\sigma^2}{n}$</p>
<p>2 . 设 $X_1\sim X_n$ 是来自总体 $X\sim N(\mu,\sigma^2)$ 的样本，$\bar{X}$ 、$S^2$ 分别是样本均值和样本方差，则有</p>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{lr}<br>&amp;\frac{(n-1)S^2}{\sigma^2}\sim \chi^2(n-1) &amp;(1) \\<br>&amp;\bar{X},S^2\text{ 相互独立} &amp;(2)<br>\end{array}<br>$</p>

</blockquote>
<p>3 . waiting…</p>
<p>4 . </p>
<p>5 . </p>
<h1 id="第七章-参数估计"><a href="#第七章-参数估计" class="headerlink" title="第七章 参数估计"></a>第七章 参数估计</h1><h2 id="点估计"><a href="#点估计" class="headerlink" title="点估计"></a>点估计</h2><p>定义：设总体分布函数 $F(x,\theta)$ ， $X_1\sim X_n$ 为样本，构造一个统计量 $\theta=\theta(X_1,\cdots ,X_n)$ 来估计参数 $\theta$ ，则称为参数 $\theta$ 的<strong>估计量</strong>。</p>
<p>将观测值 $x_1,\cdots ,x_n$ 带入 $\theta(X_1,\cdots ,X_n)$ ，得到的 $\theta(x_1,\cdots ,x_n)$ 称为参数 $\theta$ 的<strong>估计值</strong>。</p>
<p>常用点估计法：</p>
<ul>
<li>矩估计：设总体 $X\sim F(x;\theta)$ ，$\theta_1\sim \theta_m$ 未知，设对 n 个样本，总体矩都存在（即 $\alpha_k \triangleq E(X^k),(k=1,2,\cdots,m)$ ），由辛钦大数定律得</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{l}<br>&amp;A_k=\frac{1}{n}\sum_{i=1}^{n}X^k_i \overset{P}{\longrightarrow}E(X^k)=\alpha_k\ \ (n\to\infty,k=1,2,\cdots,m) \\<br>\text{可认为 }&amp;A_k\approx E(X^k)=\int{x^k}\text{d}F \triangleq \alpha_k(\theta_1,\cdots, \theta_m) &amp; \\<br>\therefore &amp; \left\{\begin{array}{l}<br>&amp;\alpha_1(\theta_1,\cdots, \theta_m)=E(X) \approx A_1 \\<br>&amp;\alpha_2(\theta_1,\cdots, \theta_m)=E(X^2) \approx A_2 \\<br>&amp;\vdots \\<br>&amp;\alpha_m(\theta_1,\cdots, \theta_m)=E(X^m) \approx A_m<br>\end{array}\right.<br>\end{array}<br>$</p>

</blockquote>
<p>解上述方程组得：</p>
<blockquote class="blockquote-center">
<p>$<br>\left\{<br>\begin{array}{l}<br>&amp;\hat{\theta}_1=\hat{\theta}_1(A_1,A_2,\cdots,A_m) \\<br>&amp;\vdots \\<br>&amp;\hat{\theta}_m=\hat{\theta}_m(A_1,A_2,\cdots,A_m) \\<br>\end{array}<br>\right.<br>$</p>

</blockquote>
<ul>
<li>最大似然估计：构造似然函数 $L(\theta)$ ，通过求极大值点得到参数值</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>L(\theta)=<br>\left\{<br>\begin{array}{lr}<br>&amp;p(x_1,x_2,\cdots,x_n;\theta)=\prod_{i=1}^{n}p(x_i;\theta) &amp;(\text{离散}) \\<br>&amp;f(x_1,x_2,\cdots,x_n;\theta)=\prod_{i=1}^{n}f(x_i;\theta) &amp;(\text{连续}) \\<br>\end{array}<br>\right.<br>$</p>

</blockquote>
<p>取对数便于求偏导（对每个参数 $\theta_i$ 求偏导）：$\large\frac{\partial{\ln{L}}}{\partial{\theta_i}}=0$</p>
<p><strong>参数评价标准</strong></p>
<ul>
<li>无偏性：$E(\hat\theta)=\theta$</li>
<li>有效性：$E(\hat\theta_1)=E(\hat\theta_2)=\theta$ 且 $D(\hat\theta_1)\le D(\hat\theta_2)$，则称 $\hat\theta_1$ 较 $\hat\theta_2$ 有效。</li>
<li>相合性（一致性）：设 $\hat\theta_n=\hat\theta(X_1,X_2,\cdots,X_n)$ 是 $\theta$ 的点估计，若 $\forall \theta\in\Theta$ 满足对 $\forall\epsilon\gt 0$ 有 $\color{red}\underset{n\to\infty}{\lim}P\{|\hat\theta_n -\theta|\ge \epsilon \}=0$ ，则称 $\hat\theta_n$ 是 $\theta$ 的<font color="red">相合估计</font>，记作 $\hat\theta_n\overset{P}{\longrightarrow}\theta(n\to\infty)$ 。</li>
</ul>
<h2 id="区间估计"><a href="#区间估计" class="headerlink" title="区间估计"></a>区间估计</h2><blockquote>
<p>区别：点估计构造一个参数统计量，而区间估计构造两个并将 $(\theta_1,\theta_2)$ 以一定的置信度作为 $\theta$ 的估算区间。</p>
</blockquote>
<p>定义：设总体 $X\sim F(x;\theta)$ ，若存在 2 个统计量</p>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{lr}<br>&amp;\underline{\theta}=\underline{\theta}(X_1,\cdots,X_n),\ \ \ \overline{\theta}=\overline{\theta}(X_1,\cdots,X_n) &amp;(\underline{\theta}\lt\overline{\theta})<br>\end{array}<br>$</p>

</blockquote>
<p>使得 $\forall\theta\in\Theta$ 有 $P\{\underline{\theta}\le\theta\le\overline{\theta}\}\ge 1-\alpha$ ，则称随机区间 $(\underline{\theta},\overline{\theta})$ 为 $\theta$ 的<font color="red">置信水平</font>为 $1-\alpha$ 的<font color="red">置信区间</font>，$\underline{\theta}$ 和 $\overline{\theta}$ 分别称为置信下限和置信上限。</p>
<ul>
<li>区间估计一般方法<ul>
<li>枢轴法（对应 t-分布的应用）</li>
<li>波动理论（对应卡方分布的应用）</li>
</ul>
</li>
</ul>
<p><strong>二级结论总结</strong></p>
<ol>
<li>$\sigma^2$ 已知，对 $\mu$ 估计：$\color{red}(\bar{X}-u_{1-\frac{\alpha}{2}}\frac{\sigma}{\sqrt{n}},\bar{X}+u_{1-\frac{\alpha}{2}}\frac{\sigma}{\sqrt{n}})$</li>
<li>$\sigma^2$ 未知，对 $\mu$ 估计：$\color{red}(\bar{X}-\frac{S}{\sqrt{n}}t_{1-\frac{\alpha}{2}}(n-1),\bar{X}+\frac{S}{\sqrt{n}}t_{1-\frac{\alpha}{2}}(n-1))$</li>
<li>$\mu$ 未知，对 $\sigma^2$ 估计：$\large\color{red}(\frac{(n-1)S^2}{\chi^2_{1-\frac{\alpha}{2}}(n-1)}, \frac{(n-1)S^2}{\chi^2_{\frac{\alpha}{2}}(n-1)})$</li>
</ol>
<p><em>后两条的推导式：</em></p>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{c}<br>&amp;P\left\{ \frac{|\bar{X}-\mu|}{S/\sqrt{n}}\lt t_{1-\frac{\alpha}{2}}(n-1) \right\}=1-\alpha \\<br>&amp;P\left\{\chi^2_{\frac{\alpha}{2}}(n-1)\lt \frac{(n-1)S^2}{\sigma^2}\lt\chi^2_{1-\frac{\alpha}{2}}(n-1) \right\}=1-\alpha<br>\end{array}<br>$</p>

</blockquote>
]]></content>
      <categories>
        <category>2023 Fall</category>
      </categories>
      <tags>
        <tag>CSE Learning</tag>
        <tag>Maths</tag>
      </tags>
  </entry>
  <entry>
    <title>NUS 夏令营日记</title>
    <url>/2024/06/30/Summer-Workshop-Diary/</url>
    <content><![CDATA[<h1 id="2024-6-29-Sat"><a href="#2024-6-29-Sat" class="headerlink" title="2024-6-29 (Sat.)"></a>2024-6-29 (Sat.)</h1><p>　　经过 4 小时左右的飞行，我于新加坡当地时间（其实就是北京时间）16:50 左右抵达新加坡的樟宜机场(Changi Airport)。然后第一个难题就来了。</p>
<p>　　因为提前在淘宝买了流量网卡，所以我取完行李后还需要先去领取窗口取我的网卡，然后才能在 SG 上网。所以我在这里足足拖了 10-15 分钟。不过好在大部分跟我同一班机的同学都遇到了类似的情况，我们最终在差不多的时间里找到了领队，将我们带回了 NUS。</p>
<p>　　比较庆幸的是，这样的开局算是比较一帆风顺，至此唯一的遗憾就是我到达的时间是下午，所以在樟宜机场的商场拍摄到的大喷泉显得嘈杂且无趣。我的另一位同学似乎拍到了夜景，那张照片我没要到，只能暂且拿一张“日中的喷泉”来献丑了。</p>
<div align="center"><img src="/2024/06/30/Summer-Workshop-Diary/ft.jpg" alt="SG机场喷泉" style="width:700px">Fountain in Changi Airport</div>

<p>　　令我感到无奈的是，开局的一帆风顺并不能掩盖接下来在我身上的种种窘态。目前来看，最令我感到不适应的，反而是我在国内最习以为常甚至感到一丝嫌弃的方面：人口。可能是在大学小区内，也可能是周末的原因，当我收拾好行李打算找个餐厅吃晚饭的时候，就只能看着周围空荡荡的街头，盘算着什么时候来个人问问路。这边的人口（至少在这段时间）实在是少得超出我的想象</p>
<blockquote>
<font color="red">为什么不看地图呢？</font>
<br>
<font color="green">其实 NUS 校区内是有校巴可以通向大部分校内区域的，甚至还能去到地铁站。</font>

</blockquote>
<p>　　但是这又涉及到第二个问题：网络。来到这边后，我才发现 NUS 校内的 WiFi 是很不稳定的。具体表现为坐公交车的时候基本上只有停靠站点的时候才能连上 WiFi（后来我们发现似乎每个公交车站确实装了一台路由器）。</p>
<p>　　于是在这种找不到人问路，又只能干等 WiFi 信号的情况下，我终于想办法来到了 University Town（也称 U-Town）。毕竟我也没想到找了好几个教学区的食堂发现都没开放，我真的哭死。</p>
<div align="center"><img src="/2024/06/30/Summer-Workshop-Diary/night01.jpg" alt="U-Town 夜景" style="width:700px">Night Scene of U-Town</div>

<p>　　大约在晚上 8 点，我终于在 U-Town 吃上了 SG 落地后的第一顿晚饭。我进了 U-Town 的一家韩菜餐馆，点了个不记得叫什么的东西（我一开始以为是炒饭），一共 4.4 SGD，折合人民币大约 23.6 块。然后等端上来了才发现，这就是个加了半熟鸡蛋的方便面。</p>
<p>　　Emmm……( ó × ò)</p>
<p>　　接下来的一段时间我需要以此为基础重塑我的消费观。我在国内生活在一线城市，自认为消费水平也不算低了，不过 SG 的物价依旧令人震惊。</p>
<p>　　上面讲的都是些槽点，但是我对此并不讨厌。所有讲到的槽点几乎都来源于我对于新环境的不适应。包括 NUS 缺少宿舍饮水机和洗衣机，出行不便等等，这些基本都是基于我原来的大学环境作出的直接比较。一方面我的大学我肯定已经熟悉了，另一方面我的大学面积比较小，确实也不存在什么出行问题。</p>
<p>　　我希望我能尽快适应，毕竟我还得在这里待一个月。不过像网购，点外卖这种事情，虽然能解决我的用餐问题，但我也不在这里长期居住，我自己感觉不太需要为此特地去搞个 paynow 之类的账号来满足这些需求。再怎么说我来这里的主要任务还是交流学习，如果以后想来这里的话，那线上支付什么的迟早会解决的。</p>
<p>　　今天先聊到这，以下奉上一些出到 NUS 的小攻略（仅仅基于我第一天的体验，后面可能会推翻）。</p>
<blockquote>
<ol>
<li><p>必须下载 NUS NextBus app，在 NUS 交流基本可以解决大部分出行问题。</p>
</li>
<li><p>网购可选择 Shopee；点外卖可选择 Grab，foodpanda 或 Deliveroo。但网上大部分攻略支持优先选 Grab（功能集成，还能打车）。</p>
</li>
<li><p>不太需要担心英语交流问题。这边大部分的餐饮人员只要会说中文的，基本能一眼看出你是中国学生。</p>
</li>
<li><p>这边的饭堂不太好找，而且不容易在线上获取开放信息。所以刚到 SG 时不妨大胆一点直接去 U-Town 获取稳定食物来源。</p>
</li>
<li><p>SG 的餐饮费用毋庸置疑比国内贵得多，不过也有一些区别。一般性价比较高的大概是在 4.4 - 7 SGD 这个价位上，至少对于我一个成年人来说，这个价位完全能吃饱 + 吃好。</p>
</li>
</ol>
</blockquote>
<hr>
<h1 id="2024-6-30-Sun"><a href="#2024-6-30-Sun" class="headerlink" title="2024-6-30 (Sun.)"></a>2024-6-30 (Sun.)</h1><p>　　不得不说 NUS 的宿舍单人间住的极其舒适，虽然床小了点，只能刚好睡下一个人，但是单人间舒服啊，狠狠地满足了我的私人空间需求。</p>
<p>　　中午我的两位朋友也到了。因为这两天都是给我们办入住的，所以我早一天到的相当于多了一天的适应期（适应期指的是晚上玩新加坡服直接当了一回 4 ping 战士 ´｡✪ω✪｡｀）。</p>
<p>　　本来打算是在宿舍 PGPR 附近找个餐厅吃的（这个展开简直和昨天一模一样），结果又双叒叕没找到，所以又只能去 U-Town 。不过这回去了个挺不错的餐厅 FineFood ，可以说很符合当代大学生的饭堂风格。</p>
<div align="center"><img src="/2024/06/30/Summer-Workshop-Diary/FineFood.jpg" alt="FineFood" style="width:700px">FineFood Canteen</div>

<p>　　这里面有自选餐也有套餐，还有饮料，而且总的来说价格也能接受。反正我点了自选餐，一份菜、一份番茄炒蛋（算作肉）、一份黑椒炒牛肉一共 6.2 SGD 。份量是很够的，就算我没吃早饭，午饭也吃得挺饱。</p>
<p>　　晚上在我们宿舍区的一个小卖部买了点东西草草了事（居然也花了 4.4 SGD）。今天应该就是最后的比较自由的一天了。明天有助理带队参观学校和欢迎晚宴，可以期待一下。</p>
<hr>
<h1 id="2024-7-1-Mon"><a href="#2024-7-1-Mon" class="headerlink" title="2024-7-1 (Mon.)"></a>2024-7-1 (Mon.)</h1><p>　　今天主要有两个活动：Campus Tour 和 Welcome Dinner 。早上随意参观，有学生助理介绍引导。然后到晚上就是去 USC(University Sport Center) 参加欢迎晚宴。</p>
<div align="center"><img src="/2024/06/30/Summer-Workshop-Diary/com-3.jpg" alt="com3" style="width:700px">SoC COM 3</div>

<p>　　由于想更好地休息，我没有花太多时间在参观校园上。我大概了解了我接下来一个月的上课教室、图书馆的大致位置、饭堂和餐厅等，其实前两天已经看得差不多了。</p>
<p>　　至于欢迎晚宴也没什么特别的地方，虽然是自助，不过体量不算大，以至于当我晚上开始写日记时已经感到有些饿了。我能预感到在未来的 4-5 天内，饮食仍然会成为我的一个困扰之处。不过参考几位同学（大佬）的餐饮习惯，应该会好很多。</p>
<div align="center"><img src="/2024/06/30/Summer-Workshop-Diary/welcome-dinner.jpg" alt="welcome dinner" style="width:700px">Place of Welcome Dinner</div>

<p>　　值得一提的是，在晚宴结束后，我和几位同学一起去了肯特岗（地铁站，公交车可达）。地铁站的附近有一个超市叫 Fair Price ，里面的商品可以解决大部分初到新加坡的生活不便问题。（这个超市在 2 楼，想找到可能要花些功夫）</p>
<p>　　在超市里可以找到一些小吃、饮品、面包，还有生活用品如水桶、枕头、纸巾、洗漱用品等。这里甚至还有新鲜的水果，但是普遍很贵———新加坡的水果似乎都很贵，可能跟依赖进口有关。不过我们有幸发现了国内卖 5、6 块钱（RMB）的一种椰子水，在新加坡居然只需要 1 SGD，意味着这里的椰子水几乎和国内的价钱一样！！我们当时就决定大规模购买，不得不说这对于新加坡的夏天非常适用。</p>
<div align="center"><img src="/2024/06/30/Summer-Workshop-Diary/fruit.jpg" alt="fruit" style="width:700px">Fruit in Fair Price</div>

<p>　　以上就是今天的一些感受。从明天开始就是正式上课和写项目了，日记应该也不会天天写，可能隔一段时间写一次学习心得吧（学习笔记另外写）。回见！</p>
<h1 id="2024-7-2-Tue"><a href="#2024-7-2-Tue" class="headerlink" title="2024-7-2 (Tue.)"></a>2024-7-2 (Tue.)</h1><p>　　今天早上开课了，基本上我就要开始习惯课程安排的时间。像一些 deep learning 之类的课程是早上和下午都有课的，一般早上 9 点半到 12 点半，下午两点到五点上课，强度比较高，项目比较难也比较累。像我的课程是实时 3D 渲染的话只有下午有课，从下午一点上到下午四点，剩下的时间自由安排。相对来说我的课程是非常轻松的，而且课程难度本身不高（前提是很多老师上课不讲的代码内容要自己学会）。这样宽裕的时间安排也给了刚来新加坡的我不少到处走的机会。比如今晚就去了新加坡的夜间动物园———— Night Safari。</p>
<p>　　我是和几位朋友一起去的 Night Safari，有一些是老朋友了，还有一些刚认识不久，不过我们之间氛围还算挺好。夜间动物园带来的体验与其他动物园有很大不同。我们先是坐游行电瓶车绕了动物园一圈，看到了不少夜间生活的动物如猫头鹰、豹猫、一些大象等，后来觉得意犹未尽又从步行道走了一段路。一边夜间散步一边还能和朋友们闲聊，这对我这个 i 人来说也是一种奇妙的体验（和外向的人交流真的完全没有心理负担！）。</p>
<div align="center"><img src="/2024/06/30/Summer-Workshop-Diary/nightzoo.jpg" alt="zoo" style="width:700px">Night Safari</div>

<p>　　总的来说我已经开始适应这边的生活了。虽然这两天可能因为水土不服（新加坡饮食类型多样，我吃的也基本是中国菜，完全不应该拉肚子）让我会有些难受，不过调养一段时间就会好很多。我听一些老家在重庆，浙江的同学都说新加坡这边的环境和条件比国内好，可能是我住一线城市的原因吧，我还是比较喜欢我的家乡，不过新加坡环境好确实是客观的，至少这边平均绿植覆盖面广，街道干净。该说不说小国家有小国家的优势，像这种问题治理起来确实方便（我怎么开始突发感慨了？）。</p>
<h1 id="2024-7-5-（Fri-）"><a href="#2024-7-5-（Fri-）" class="headerlink" title="2024-7-5 （Fri.）"></a>2024-7-5 （Fri.）</h1><p>　　今天是第一周上课的最后一天，关于课程的时间安排已经完全适应。我和我的队友基本上在早上九点到十点醒，吃点东西补充下然后去教室预习或复习上课内容，下午四点上完课去 Kent Ridge MRT(肯特岗) 吃晚饭，有时买点夜宵带回宿舍。晚上如果没有小组作业基本就是各自在宿舍干活或放松。</p>
<p>　　今天我们去了肯特的一家餐厅，吃到了我来新加坡这么多天以来最好吃的一顿饭（但是爆了 9.9 SGD 的金币）。真的非常推荐去试试！他们那家的炸鸡，鸡肉真的特别多，而且不柴，9.9 SGD 一顿管饱而且好吃，血赚！</p>
<p>　　By the way，刚进肯特岗地铁站左手边的食阁，两边有两家面包店。两家面包店做的华夫饼也是超级好吃！现做现卖，有蘸酱的一个 2.3 SGD，还算是比较合适的价格了（已经逐渐适应新加坡的物价）。</p>
<p>　　个人感觉除了这两点以外，肯特岗的食阁就没什么推荐的了，基本比不上国内的餐饮，不过这两家真的是，绝了。</p>
<div align="center"><img src="/2024/06/30/Summer-Workshop-Diary/fried-chi.jpg" alt="fried-chicken" style="width:700px">Food in Kent Ridge MRT</div>



<h1 id="2024-7-7-Sun"><a href="#2024-7-7-Sun" class="headerlink" title="2024-7-7 (Sun.)"></a>2024-7-7 (Sun.)</h1><p>　　今天我要收回前面的一个暴论———— U-Town 跟肯特岗比也不是这么缺少美食。今天中午去了趟 U-Town ，本来是想简单在 FineFood 吃一下的，结果在一些奇特指引下，我找到了一个新地方。</p>
<div align="center"><img src="/2024/06/30/Summer-Workshop-Diary/u-town-dine.jpg" alt="u-town-dine" style="width:700px">More in U-Town</div>

<p>　　这地方好吃的东西也挺多的，至少我吃上了质量较高的白切鸡。这个餐厅其实就是在 FineFood 的那栋楼继续往里走的地方，不算难找，而且里面卖的东西还算比较多样。除了我吃的中国菜，还有水果、饮品、和一些其他国家的菜式。个人感觉比 FineFood 大多数套餐实惠。</p>
<p>　　由于今天几乎一天都在下雨，原本我除了中午雨停那会吃了个午饭，就计划一直待在宿舍里了。结果十分意外地，大约在下午 6 点左右，我发现雨停了好一会儿了，于是当即产生了一个出游的想法，并且立即付诸行动。</p>
<div align="center"><img src="/2024/06/30/Summer-Workshop-Diary/raffle.jpg" alt="raffle" style="width:700px">Raffle Place</div>

<p>　　我的想法来得仓促，没来得及叫上其他人，所以独自一人就坐地铁去了 Raffle Place 地铁站，并从那边穿过一栋栋建筑，最终来到了海湾边。</p>
<p>　　这里，就是新加坡的地标级景点————鱼尾狮公园 (Merlion Park)。在鱼尾狮公园的海湾岸边，可以直接看见对岸的金沙空中花园酒店 (Marina Bay Sands Hotel)，也只有在这边才能看到这个三栋建筑的全貌。</p>
<div align="center"><img src="/2024/06/30/Summer-Workshop-Diary/tri-hotel.jpg" alt="MBS Hotel" style="width:700px">MBS Hotel</div>

<p>　　当然了，还有新加坡最著名的景点之一————鱼尾狮雕像。</p>
<div align="center"><img src="/2024/06/30/Summer-Workshop-Diary/merlion.jpg" alt="merlion" style="width:700px">the Merlion</div>

<p>　　不得不说，哪怕是星期天，这里的人依然很多，可见这里确实是不负盛名。因为新加坡临近国庆，所以每周六晚上都会在这个海湾放烟花，我昨天没来可惜了，但今天来这边依然有一些惊喜的收获。</p>
<div align="center"><img src="/2024/06/30/Summer-Workshop-Diary/Jazz.jpg" alt="jazz" style="width:700px">Jazz Band Performance</div>

<p>　　最大的惊喜莫过于当我走过鱼尾狮公园，经过一座步行桥，又绕过了滨海艺术中心（一个榴莲形状的剧场）后，我意外发现了一个爵士乐队在 Esplanade Mall 演奏。现场可以说是坐满了人，连很多经过的游客都停下来，围在了场地外面，站着听他们的演奏。可以说在这样的一个场景下，爵士乐拥有无与伦比的吸引力。无论是华人，欧洲游客，还是印度人，黑人，几乎都能被这样的演奏吸引过来。更有意思的是，我注意到一位站着的华人大叔，掏出了他的一个小本本，用签字笔给每个 solo 的乐手画写生。虽说画的不太像，而且是站着随手画的，但是神态确实到位了，也算是别有一番风格。</p>
<p>　　最后这支乐队还专门演奏了一首中国乐曲，《万水千山总是情》，现场反响非常好。</p>
<div align="center"><img src="/2024/06/30/Summer-Workshop-Diary/tri-hotel-night.jpg" alt="MBS Hotel" style="width:700px">MBS Hotel(night)</div>

<p>　　等我意识到我在那里听了将近半个小时时，天已经几乎黑透了。于是我开始往回走，走时路过了鱼尾狮雕像，又拍了几张鱼尾狮和空中花园酒店和傍晚的时候做对比。在往地铁站走的途中，我特地拐到对岸去看了看莱弗士教堂。据说莱弗士 (Raffle) 是英国人，来到新加坡殖民后，有效促进了这一带的经济发展，所以后人为了纪念他，为他在这里建了一座教堂。而现在，教堂外的草地上，有不少人铺开了毯子，趁着晚风清凉在草地上休息、野炊，甚至有人拿着小音箱忘我地唱歌，颇有一种国内广场的烟火气息。在这里，我算是真正体会到了新加坡的百姓生活的一角。</p>
<p>　　当我回到宿舍，时间也才九点半，明天还要继续上课，今天就先写到这吧。</p>
<h1 id="2024-7-13-Sat"><a href="#2024-7-13-Sat" class="headerlink" title="2024-7-13 (Sat.)"></a>2024-7-13 (Sat.)</h1><p>　　上周不是自己跑去了鱼尾狮公园嘛，还是星期天没碰上烟花。这星期一听说</p>
]]></content>
      <categories>
        <category>Summer Camp</category>
      </categories>
      <tags>
        <tag>Exchange</tag>
        <tag>Dairy</tag>
      </tags>
  </entry>
  <entry>
    <title>NUS Soc SWS3005  实时 3D 图形渲染</title>
    <url>/2024/06/27/Real-Time-Rendering/</url>
    <content><![CDATA[<h1 id="I-Pre-Knowledge-Phase-1"><a href="#I-Pre-Knowledge-Phase-1" class="headerlink" title="I. Pre-Knowledge (Phase 1)"></a>I. Pre-Knowledge (Phase 1)</h1><h2 id="Image-Formation"><a href="#Image-Formation" class="headerlink" title="Image Formation"></a>Image Formation</h2><blockquote>
<p>How does a realistic graphic form? </p>
</blockquote>
<h3 id="Elements-of-Image-Formation"><a href="#Elements-of-Image-Formation" class="headerlink" title="Elements of Image Formation"></a>Elements of Image Formation</h3><ul>
<li>Objects</li>
<li>Viewer</li>
<li>Light sources</li>
<li>Materials (材质)<ul>
<li>Attributes that govern how light interacts with the materials in the scene</li>
</ul>
</li>
</ul>
<h3 id="Models"><a href="#Models" class="headerlink" title="Models"></a>Models</h3><p><strong>Know about Pinhole Camera</strong></p>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr1.png" alt="Pinhole Camera" style="zoom:60%"></div>

<p>Use trigonometry(三角几何) to find <strong>projection</strong> of 3D point at $(x, y, z)$</p>
<blockquote class="blockquote-center">
<p>$<br>x_p=-dx/z\ \ \ \ y_p=-dy/z\ \ \ \ z_p=-d<br>$</p>

</blockquote>
<p><strong>Synthetic Camera Model (合成相机模型)</strong></p>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr2.png" alt="Synthetic Camera Model
" style="zoom:60%"></div>

<p><strong>Luminance and Color Images (光线与颜色的映射)</strong></p>
<ul>
<li>Luminance Image<ul>
<li>Monochromatic(单色)<ul>
<li>Values are gray levels</li>
<li>Analogous to working with black and white film or television</li>
</ul>
</li>
</ul>
</li>
<li>Color Image<ul>
<li>Has perceptional attributes of hue(色相), saturation(饱和度), and lightness</li>
</ul>
</li>
</ul>
<p>↓</p>
<ul>
<li>Representation of Color<ul>
<li><font color="red">Additive color</font>: Form a color by adding amounts of three primaries<font color="grey">(RGB)</font><ul>
<li>E.g. CRTs, projection systems, positive film</li>
</ul>
</li>
<li><font color="red">Subtractive color</font>: Form a color by filtering white light with <font color="cyan">Cyan (C)</font>, <font color="magenta">Magenta (M)</font>, and <font color="deyellow">Yellow (Y)</font> filters<ul>
<li><font color="blue">Noted:</font> Cyan = –Red; Magenta = –Green; Yellow = –Blue</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<h2 id="Graphics-System-Design"><a href="#Graphics-System-Design" class="headerlink" title="Graphics System Design"></a>Graphics System Design</h2><font size="4">A graphics system has two main components</font>

<ol>
<li>Application Programmer Interface (API)<ul>
<li>For specifying the <font color="red"><b>scene</b></font><ul>
<li>objects, materials, viewer, lights</li>
</ul>
</li>
<li>For <font color="red">configuring/controlling</font> the system</li>
</ul>
</li>
<li>Renderer<ul>
<li>Renders the images<ul>
<li>Using scene info and system configuration</li>
</ul>
</li>
</ul>
</li>
</ol>
<h3 id="Rendering-Approaches"><a href="#Rendering-Approaches" class="headerlink" title="Rendering Approaches"></a>Rendering Approaches</h3><ol>
<li><strong>Ray tracing:</strong> follow rays of light from center of projection until they are absorbed by objects or go off to infinity<ul>
<li>符合物理解释，泛用性广；但是速度慢，性能低</li>
</ul>
</li>
<li>Radiosity: Energy based approach<ul>
<li>非常慢且不泛用</li>
</ul>
</li>
</ol>
<p><strong>Practical Approach</strong></p>
<ol>
<li><font coklor="red"><b>Polygon Rasterization</b></font>(多边形光栅)</li>
</ol>
<blockquote>
<p>3D 物体可以近似地表示为平面多边形刻面 (planar polygonal facets) 的网或网格</p>
</blockquote>
<table>
<tr>
<td><img src="/2024/06/27/Real-Time-Rendering/rtr3.png" alt="polygon rasterization
" style="zoom:60%"></td>
<td><img src="/2024/06/27/Real-Time-Rendering/rtr4.png" alt="polygon rasterization
" style="zoom:40%"></td>
</tr>
</table>

<font color="blue">Pipeline architecture</font>

<blockquote>
<p>The pipeline consists of stages that each primitive (e.g. polygon) must go through</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Vertices -&gt; |Vertex processor| -&gt; |Clipper and primitive assembler| -&gt; |Rasterizer| </span><br><span class="line">-&gt; |Fragment processor| -&gt; Pixels</span><br></pre></td></tr></table></figure>
<p>(i) Vertex Processing</p>
<ul>
<li>Much of the work in the pipeline is in converting object representations from one coordinate system to another<ul>
<li>Object coordinates</li>
<li>Camera (eye) coordinates</li>
<li>Screen coordinates</li>
</ul>
</li>
<li>Also computes vertex colors</li>
</ul>
<p>(ii) Projection</p>
<ul>
<li>Projection is the process that combines the <strong>3D</strong> viewer with the <strong>3D</strong> objects to produce the <strong>2D</strong> image<ul>
<li>Perspective projections: all projectors meet at the center of projection</li>
<li>Parallel projection: projectors are parallel, center of projection is replaced by a direction of projection</li>
</ul>
</li>
</ul>
<p>(iii) Clipping</p>
<ul>
<li>Simulate a <font color="red">virtual camera</font> to clip the images</li>
</ul>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr5.png" alt="clip" style="zoom:70%"></div>



<p>(iv) <font color="red">Rasterization</font></p>
<ul>
<li>Rasterizer produces a set of <a href="#fragment">fragments</a> for each object</li>
<li><a name="fragment">Fragments</a> are “potential pixels”<ul>
<li>Have a location in frame bufffer</li>
<li>Color and depth attributes</li>
</ul>
</li>
</ul>
<blockquote>
<p>Fragment Processing</p>
<ul>
<li>Fragments are processed to determine the color of the corresponding pixel in the frame buffer</li>
<li>Colors can be determined by texture mapping or interpolation(插值) of vertex colors</li>
<li>Fragments may be blocked/occluded(阻塞) by other fragments closer to the camera<ul>
<li>Using Hidden-surface removal</li>
</ul>
</li>
</ul>
</blockquote>
<hr>
<h2 id="API-Contents"><a href="#API-Contents" class="headerlink" title="API Contents"></a>API Contents</h2><ul>
<li><font color="green">Recall: Functions that specify what we need to form an image</font><ul>
<li>Objects</li>
<li>Viewer</li>
<li>Light Source(s)</li>
<li>Materials</li>
</ul>
</li>
</ul>
<h3 id="Object-Specifications"><a href="#Object-Specifications" class="headerlink" title="Object Specifications"></a>Object Specifications</h3><ul>
<li>Most APIs support a limited set of primitives including<ul>
<li>Points (0D object)</li>
<li>Line segments (1D objects)</li>
<li>Polygons (2D objects)</li>
<li>Some curves and surfaces<ul>
<li>Quadrics</li>
<li>Parametric polynomials</li>
</ul>
</li>
</ul>
</li>
<li>All are defined through locations in space or vertices</li>
</ul>
<h3 id="Camera-Specification"><a href="#Camera-Specification" class="headerlink" title="Camera Specification"></a>Camera Specification</h3><ul>
<li>Six degrees of freedom<ul>
<li>Position of center of lens</li>
<li>Orientation</li>
</ul>
</li>
<li>Lens</li>
<li>Film size</li>
<li>Orientation of film plane</li>
</ul>
<h3 id="Lights-and-Materials"><a href="#Lights-and-Materials" class="headerlink" title="Lights and Materials"></a>Lights and Materials</h3><ul>
<li>Types of lights<ul>
<li>Point sources vs distributed sources</li>
<li>Spot lights</li>
<li>Near and far sources</li>
<li>Color properties</li>
</ul>
</li>
<li>Material properties<ul>
<li>Absorption: color properties</li>
<li>Scattering<ul>
<li>Diffuse</li>
<li>Specular</li>
</ul>
</li>
</ul>
</li>
</ul>
<div align="center"><font color="grey" size="5">----- <font face="Segoe Script">Let's start Phase 2!</font> -----</font></div>

<h1 id="II-Elementary-OpenGL-Programming"><a href="#II-Elementary-OpenGL-Programming" class="headerlink" title="II. Elementary OpenGL Programming"></a>II. Elementary OpenGL Programming</h1><h2 id="OpenGL-Libraries"><a href="#OpenGL-Libraries" class="headerlink" title="OpenGL Libraries"></a>OpenGL Libraries</h2><h3 id="Core-Library"><a href="#Core-Library" class="headerlink" title="Core Library"></a>Core Library</h3><ul>
<li>OpenGL core library<ul>
<li>OpenGL32 on Windows</li>
<li>GL on most unix/linux systems ( <code>libGL.a</code> )</li>
</ul>
</li>
<li>OpenGL Utility Library ( GLU )<ul>
<li>Provides functionality in OpenGL core but avoids having to rewrite code</li>
</ul>
</li>
<li>Links with window system<ul>
<li><code>GLX</code> for X window systems</li>
<li><code>WGL</code> for Windows</li>
<li><code>AGL</code> for Macintosh</li>
</ul>
</li>
</ul>
<h3 id="GLUT-FreeGLUT-Libraries"><a href="#GLUT-FreeGLUT-Libraries" class="headerlink" title="GLUT / FreeGLUT Libraries"></a>GLUT / FreeGLUT Libraries</h3><ul>
<li><strong>GLUT = OpenGL Utility Toolkit</strong><ul>
<li><font color="red"><b>Not</b></font> part of OpenGL</li>
<li>Provides functionality common to all window systems<ul>
<li>Open a window</li>
<li>Get input from mouse and keyboard</li>
<li>Menus</li>
<li>Event-driven</li>
</ul>
</li>
<li>Code is portable but GLUT lacks the functionality of a good  toolkit for a specific platform<ul>
<li>No slide bars</li>
</ul>
</li>
</ul>
</li>
<li><a href="http://freeglut.sourceforge.net/">FreeGLUT</a></li>
</ul>
<h3 id="Software-Organization"><a href="#Software-Organization" class="headerlink" title="Software Organization"></a>Software Organization</h3><div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr6.png" alt="GL Organ" style="zoom:70%"></div>



<h2 id="Basic-OpenGL-Rendering-Pipeline"><a href="#Basic-OpenGL-Rendering-Pipeline" class="headerlink" title="Basic OpenGL Rendering Pipeline"></a>Basic OpenGL Rendering Pipeline</h2><ul>
<li>To render a primitive using OpenGL, the primitive goes through the following main stages: <ul>
<li><font color="green">Goal:</font> Turning primitive into pixels</li>
</ul>
</li>
</ul>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr7.png" alt="stage 1" style="zoom:70%"></div>



<h3 id="OpenGL-Functions"><a href="#OpenGL-Functions" class="headerlink" title="OpenGL Functions"></a>OpenGL Functions</h3><ul>
<li>Specify primitives<ul>
<li>E.g. points, line segments, triangles, quadrilaterals, polygons </li>
</ul>
</li>
<li>Specify vertex attributes<ul>
<li>E.g. color, normal vector, material, texture coordinates</li>
</ul>
</li>
<li>Specify transformations<ul>
<li>E.g. modeling, viewing</li>
</ul>
</li>
<li>Control (<code>GLUT</code>)</li>
<li>Input (<code>GLUT</code>)</li>
<li>Query: “ask for the state of object” etc.</li>
</ul>
<h3 id="OpenGL-State"><a href="#OpenGL-State" class="headerlink" title="OpenGL State"></a>OpenGL State</h3><ul>
<li><font color="red">OpenGL is a <b>state machine</b></font>
</li>
<li><p>OpenGL functions are <font color="red">of two types</font></p>
<ul>
<li>Primitive generating<ul>
<li>Can cause output if primitive is visible</li>
<li>How vertices are processed and appearance of primitive are controlled by the state</li>
</ul>
</li>
<li>State changing<ul>
<li>Transformation functions</li>
<li>Attribute functions</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="Simple-Concept"><a href="#Simple-Concept" class="headerlink" title="Simple Concept"></a>Simple Concept</h2><h3 id="Examples"><a href="#Examples" class="headerlink" title="Examples"></a>Examples</h3><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;GL/glut.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">mydisplay</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="built_in">glClear</span>(GL_COLOR_BUFFER_BIT); </span><br><span class="line">    <span class="built_in">glBegin</span>(GL_POLYGON); </span><br><span class="line">    <span class="built_in">glVertex2f</span>(<span class="number">-0.5</span>, <span class="number">-0.5</span>); </span><br><span class="line">    <span class="built_in">glVertex2f</span>(<span class="number">-0.5</span>, <span class="number">0.5</span>); </span><br><span class="line">    <span class="built_in">glVertex2f</span>(<span class="number">0.5</span>, <span class="number">0.5</span>); </span><br><span class="line">    <span class="built_in">glVertex2f</span>(<span class="number">0.5</span>, <span class="number">-0.5</span>); </span><br><span class="line">    <span class="built_in">glEnd</span>();</span><br><span class="line">    <span class="built_in">glFlush</span>(); </span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span>** argv)</span> </span>&#123;</span><br><span class="line">    <span class="built_in">glutInit</span>(&amp;argc, argv);</span><br><span class="line">    <span class="built_in">glutCreateWindow</span>(<span class="string">&quot;simple&quot;</span>); </span><br><span class="line">    <span class="built_in">glutDisplayFunc</span>(mydisplay); </span><br><span class="line">    <span class="built_in">glutMainLoop</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>This code is to draw a white square in black background.</p>
</blockquote>
<h3 id="Event-Loop"><a href="#Event-Loop" class="headerlink" title="Event Loop"></a>Event Loop</h3><p>Note that the program defines a <font color="red">display callback</font> function named <code>mydisplay</code></p>
<ul>
<li>Every GLUT program <font color="red"><b>must</b></font> have a display callback</li>
<li>The display callback is executed whenever OpenGL decides the display must be refreshed<ul>
<li>For example, when the window is opened</li>
</ul>
</li>
<li>The <strong>main function ends</strong> with the program entering an event loop</li>
</ul>
<h2 id="Program-Structure"><a href="#Program-Structure" class="headerlink" title="Program Structure"></a>Program Structure</h2><ul>
<li>Most OpenGL programs have a similar structure that consists of the following functions<ul>
<li><code>main()</code>: <ul>
<li>defines the callback functions </li>
<li>opens one or more windows with the required properties</li>
<li>enters event loop (last executable statement)</li>
</ul>
</li>
<li><code>init()</code>: sets the state variables<ul>
<li>Viewing</li>
<li>Attributes</li>
</ul>
</li>
<li>callbacks<ul>
<li>Display callback function</li>
<li>Input and window functions</li>
</ul>
</li>
</ul>
</li>
</ul>
<blockquote>
<p>Then we’re going to see an explicit form of <code>Example</code></p>
</blockquote>
<h3 id="main"><a href="#main" class="headerlink" title="main()"></a><code>main()</code></h3><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;GL/glut.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span>** argv)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="built_in">glutInit</span>(&amp;argc, argv); </span><br><span class="line">	<span class="built_in">glutInitDisplayMode</span>(GLUT_SINGLE | GLUT_RGB); </span><br><span class="line">	<span class="built_in">glutInitWindowSize</span>(<span class="number">500</span>, <span class="number">500</span>); </span><br><span class="line">	<span class="built_in">glutInitWindowPosition</span>(<span class="number">0</span>, <span class="number">0</span>); </span><br><span class="line">	<span class="built_in">glutCreateWindow</span>(<span class="string">&quot;simple2&quot;</span>); </span><br><span class="line">	<span class="built_in">glutDisplayFunc</span>(mydisplay); </span><br><span class="line">	<span class="built_in">init</span>(); </span><br><span class="line">	<span class="built_in">glutMainLoop</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li><code>glutInit</code> —— allows application to get command line arguments and initializes system</li>
<li><code>gluInitDisplayMode</code> —— requests properties for the window (the rendering context)<ul>
<li>RGB color</li>
<li>Single buffering</li>
<li>Properties logically ORed together</li>
</ul>
</li>
<li><code>glutWindowSize</code> —— in pixels</li>
<li><code>glutWindowPosition</code> —— from top-left corner of display</li>
<li><code>glutCreateWindow</code> —— create window with title “simple”</li>
<li><code>glutDisplayFunc</code> —— display callback</li>
<li><code>glutMainLoop</code> —— enter infinite event loop</li>
</ul>
<h3 id="init"><a href="#init" class="headerlink" title="init()"></a><code>init()</code></h3><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">init</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="built_in">glClearColor</span>(<span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">1.0</span>); </span><br><span class="line">	<span class="comment">// black clear color with opaque window</span></span><br><span class="line">	<span class="built_in">glColor3f</span>(<span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>); <span class="comment">// white fill color</span></span><br><span class="line">	<span class="built_in">glMatrixMode</span>(GL_PROJECTION); </span><br><span class="line">	<span class="built_in">glLoadIdentity</span>(); </span><br><span class="line">	<span class="built_in">glOrtho</span>(<span class="number">-1.0</span>, <span class="number">1.0</span>, <span class="number">-1.0</span>, <span class="number">1.0</span>, <span class="number">-1.0</span>, <span class="number">1.0</span>); <span class="comment">// viewing volume</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>Coordinate Systems (have a rough knowing)<ul>
<li>object coordinates (3D)</li>
<li>world coordinates (camera)</li>
<li>window coordinates</li>
</ul>
</li>
<li>About OpenGL Camera</li>
</ul>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr8.png" alt="opengl camera" style="zoom:50%"></div>

<ul>
<li>Orthographic Viewing and Transformation<ul>
<li>In the default orthographic view, points are projected forward along the $z$ axis onto the plane $z = 0$</li>
<li>In OpenGL, projection is carried out by a projection matrix (transformation)</li>
<li>There is only one set of transformation functions so we must set the matrix mode first<ul>
<li><code>glMatrixMode(GL_PROJECTION)</code></li>
</ul>
</li>
<li>Transformation functions are incremental so we start with an identity matrix and alter it with a projection matrix that gives the view volume<ul>
<li><code>glLoadIdentity();</code></li>
<li><code>glOrtho(-1.0, 1.0, -1.0, 1.0, -1.0, 1.0);</code></li>
</ul>
</li>
<li><code>glOrtho(left, right, bottom, top, near, far)</code> is used to determine the projection area.</li>
<li>If the application is in 2D, we can use the function <code>gluOrtho2D(left, right, bottom, top)</code></li>
</ul>
</li>
</ul>
<blockquote>
<p>Here is an example of how to draw a projection on 2D windows. </p>
<p>Because a projection from 3D to 2D is in <strong>OpenGL-Primitives</strong> (I show below), so we only need to paint it out.</p>
</blockquote>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">mydisplay</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="built_in">glClear</span>(GL_COLOR_BUFFER_BIT); </span><br><span class="line">	<span class="built_in">glBegin</span>(GL_POLYGON); </span><br><span class="line">	<span class="comment">// define as polygon</span></span><br><span class="line">	<span class="built_in">glVertex2f</span>(<span class="number">-0.5</span>, <span class="number">-0.5</span>); </span><br><span class="line">	<span class="built_in">glVertex2f</span>(<span class="number">-0.5</span>, <span class="number">0.5</span>); </span><br><span class="line">	<span class="built_in">glVertex2f</span>(<span class="number">0.5</span>, <span class="number">0.5</span>); </span><br><span class="line">	<span class="built_in">glVertex2f</span>(<span class="number">0.5</span>, <span class="number">-0.5</span>); </span><br><span class="line">	<span class="comment">// set 4 vertex to form 4-edges polygon</span></span><br><span class="line">	<span class="built_in">glEnd</span>();</span><br><span class="line">	<span class="built_in">glFlush</span>(); </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr11.png" alt="opengl primitives" style="zoom:70%"></div>



<h3 id="Other-methods-of-OpenGL"><a href="#Other-methods-of-OpenGL" class="headerlink" title="Other methods of OpenGL"></a>Other methods of OpenGL</h3><ol>
<li><code>glShadeModel()</code> to set the color rendering to be <code>GL_SMOOTH</code> (渐变) or <code>GL_FLAT</code> (单色).</li>
<li><code>glViewport(x, y, w, h)</code> to set the viewport of windows.</li>
</ol>
<h2 id="3D-OpenGL"><a href="#3D-OpenGL" class="headerlink" title="3D OpenGL"></a>3D OpenGL</h2><h3 id="Three-Dimensional-Applications"><a href="#Three-Dimensional-Applications" class="headerlink" title="Three-Dimensional Applications"></a>Three-Dimensional Applications</h3><ul>
<li>In OpenGL, 2D applications are a special case of 3D graphics</li>
<li>Going to 3D<ul>
<li>Not much changes</li>
<li>Use <code>glVertex3*()</code></li>
<li>Have to worry about the order in which polygons are drawn or use <strong>hidden-surface removal</strong> (occlusion problem)</li>
<li>Polygons should be simple, convex, flat</li>
</ul>
</li>
</ul>
<h3 id="Gasket-Program"><a href="#Gasket-Program" class="headerlink" title="Gasket Program"></a>Gasket Program</h3><div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr9.png" alt="triangle division" style="zoom:50%"></div>

<ul>
<li>Consider the filled area (black) and the perimeter (the length of all the lines around the filled triangles)</li>
<li>As we continue subdividing<ul>
<li>the area goes to zero (&lt; 2D)</li>
<li>but the perimeter goes to infinity (&gt; 1D)</li>
</ul>
</li>
<li>This is not an ordinary geometric object<ul>
<li>It is neither one- nor two-dimensional</li>
</ul>
</li>
<li>It is a fractal (fractional dimension) object<ul>
<li>Approximately 1.585 D</li>
</ul>
</li>
</ul>
<blockquote>
<font color="red">How to do in program?</font>

<font color="green">Using algorithm of Recursion!</font>


</blockquote>
<ul>
<li>Design <code>display()</code> and <code>myinit()</code></li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">display</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">glClear</span>(GL_COLOR_BUFFER_BIT);</span><br><span class="line">    <span class="built_in">glBegin</span>(GL_TRIANGLES);</span><br><span class="line">    <span class="built_in">divide_triangle</span>(v[<span class="number">0</span>], v[<span class="number">1</span>], v[<span class="number">2</span>], n);</span><br><span class="line">    <span class="built_in">glEnd</span>();</span><br><span class="line">    <span class="built_in">glFlush</span>();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">myinit</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">glMatrixMode</span>(GL_PROJECTION);</span><br><span class="line">    <span class="built_in">glLoadIdentity</span>();</span><br><span class="line">    <span class="built_in">gluOrtho2D</span>(<span class="number">-2.0</span>, <span class="number">2.0</span>, <span class="number">-2.0</span>, <span class="number">2.0</span>);</span><br><span class="line">    <span class="built_in">glMatrixMode</span>(GL_MODELVIEW);</span><br><span class="line">    <span class="built_in">glClearColor</span> (<span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>);</span><br><span class="line">    <span class="built_in">glColor3f</span>(<span class="number">0.0</span>,<span class="number">0.0</span>,<span class="number">0.0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>Then set parameter and callback function in <code>main()</code></li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span> **argv)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    n = <span class="number">4</span>;</span><br><span class="line">    <span class="built_in">glutInit</span>(&amp;argc, argv);</span><br><span class="line">    <span class="built_in">glutInitDisplayMode</span>(GLUT_SINGLE | GLUT_RGB);</span><br><span class="line">    <span class="built_in">glutInitWindowSize</span>(<span class="number">500</span>, <span class="number">500</span>);</span><br><span class="line">    <span class="built_in">glutCreateWindow</span>(<span class="string">&quot;Sierpinski Gasket&quot;</span>);</span><br><span class="line">    <span class="built_in">glutDisplayFunc</span>(display);</span><br><span class="line">    <span class="built_in">myinit</span>();</span><br><span class="line">    <span class="built_in">glutMainLoop</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="Move-to-3D-triangle"><a href="#Move-to-3D-triangle" class="headerlink" title="Move to 3D triangle"></a>Move to 3D triangle</h3><ul>
<li>Add an extra vertex to form tetrahedra</li>
<li>Then we can do like 2D triangle subdivision</li>
</ul>
<font color="red">But we have to deal with <b>Hidden-Surface Removal</b> !!</font>

<ul>
<li><ul>
<li>OpenGL uses a hidden-surface removal method called the z-buffer algorithm that saves depth information as objects are rendered so that only the front objects appear in the image.</li>
</ul>
</li>
</ul>
<blockquote class="blockquote-center">
<p><strong>Using the z-buffer Algorithm</strong></p>

</blockquote>
<p>Requested in <code>main()</code></p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="built_in">glutInitDisplayMode</span>(GLUT_SINGLE | GLUT_RGB | GLUT_DEPTH)</span><br></pre></td></tr></table></figure>
<p>Enabled in <code>init()</code></p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="built_in">glEnable</span>(GL_DEPTH_TEST)</span><br></pre></td></tr></table></figure>
<p>Cleared in the display callback</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="built_in">glClear</span>(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT)</span><br></pre></td></tr></table></figure>
<blockquote class="blockquote-center">
<p><strong>Surface vs. Volume Subdivision</strong></p>

</blockquote>
<ul>
<li>In our example, we subdivided the <strong>surface</strong> of each face</li>
<li>We could also subdivide the volume using the same midpoints</li>
<li>The midpoints define four smaller tetrahedrons, one for each vertex</li>
<li>Keeping only these tetrahedrons removes a volume in the middle</li>
<li>Good programming exercise</li>
</ul>
<hr>
<h1 id="III-Input-amp-Interaction"><a href="#III-Input-amp-Interaction" class="headerlink" title="III. Input &amp; Interaction"></a>III. Input &amp; Interaction</h1><h2 id="Concept"><a href="#Concept" class="headerlink" title="Concept"></a>Concept</h2><ul>
<li>Graphical Input<ul>
<li>Devices can be described either by<ul>
<li>Physical properties<ul>
<li>Mouse, Keyboard, Trackball, etc.</li>
</ul>
</li>
<li>Logical properties: What is returned to program via API<ul>
<li>A position</li>
<li>An object identifier</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>Trigger and Measure</p>
<ul>
<li>Input devices contain a <font color="red">trigger</font> which can be used to send a signal to the operating system<ul>
<li>Button on mouse</li>
<li>Pressing or releasing a key</li>
</ul>
</li>
<li>When triggered, input devices return information (their <font color="red">measure</font>) to the system<ul>
<li>Mouse returns position information</li>
<li>Keyboard returns ASCII code</li>
</ul>
</li>
</ul>
</li>
<li><p>Event Mode</p>
<ul>
<li>Each trigger generates an event whose measure is put in an event queue which can be examined by the user program</li>
</ul>
</li>
</ul>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr10.png" alt="procedure" style="zoom:70%"></div>

<ul>
<li><p>Event Type</p>
<ul>
<li>Window: resize, expose, minimize</li>
<li>Mouse: click one or more buttons</li>
<li>Motion: move mouse</li>
<li>Keyboard: press or release a key</li>
<li>Idle: non-event (无输入时的活动)<ul>
<li>Define what should be done if no other event is in queue</li>
</ul>
</li>
</ul>
</li>
<li><p><font color="green">Recall:</font> callbacks</p>
<ul>
<li>Define a callback function for <strong>each type of event</strong> the graphics system recognizes</li>
<li>E.g. <code>glutMouseFunc(mymouse)</code> where <code>mymouse</code> is a mouse callback function.</li>
</ul>
</li>
<li><font color="red">GLUT  recognizes a subset of the events recognized by any particular operation system</font> : <ul>
<li><code>glutDisplayFunc</code></li>
<li><code>glutMouseFunc</code></li>
<li><code>glutReshapeFunc</code></li>
<li><code>glutKeyboardFunc</code></li>
<li><code>glutIdleFunc</code></li>
<li><code>glutMotionFunc</code>, <code>glutPassiveMotionFunc</code> </li>
</ul>
</li>
</ul>
<h2 id="GLUT-Event-Loop"><a href="#GLUT-Event-Loop" class="headerlink" title="GLUT Event Loop"></a>GLUT Event Loop</h2><ul>
<li><font color="green">Recall:</font> the last statement in <code>main()</code> for a program using GLUT must be <code>glutMainLoop();</code></li>
<li>In each pass through the event loop, GLUT <ul>
<li>looks at the events in the <strong>queue</strong></li>
<li>execute each event if the corresponding callback function is defined.</li>
</ul>
</li>
</ul>
<font color="purple">Important before talking about callbacks:</font> 

<ul>
<li>The form of all GLUT callbacks is fixed</li>
<li>So we must use <strong>globals</strong> (全局变量) to pass information to callbacks</li>
</ul>
<h3 id="Display-Callback"><a href="#Display-Callback" class="headerlink" title="Display Callback"></a>Display Callback</h3><ul>
<li>When windows are refreshed, apply display callbacks<ul>
<li><code>glutDisplayFunc(mydisplay)</code> in <code>main()</code></li>
<li><code>glutPostRedisplay()</code> to <font color="red">avoid multiple display</font> in one single pass through the event loop<ul>
<li>set a <strong>“flag”</strong> at the end of the event loop.</li>
<li>GLUT checks it and display callback function is executed.</li>
</ul>
</li>
</ul>
</li>
<li>Then what’s inside <code>mydisplay</code>?<ul>
<li><code>glClear()</code> to clear the window</li>
<li>Use <font color="red"><b>Double Buffer</b></font> to avoid <font color="blue">partial drawn</font> <ul>
<li><strong>Front Buffer</strong>: one that is <strong>displayed</strong> but not written to</li>
<li><strong>Back Buffer</strong>: one that is <strong>written</strong> to but not displayed</li>
</ul>
</li>
<li><code>glutInitDisplayMode(GLUT_RGB | GLUT_DOUBLE)</code> declare in <code>main()</code> to request a <font color="red">double buffer</font></li>
<li>At the end of display callback buffers are swapped.</li>
</ul>
</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">mydisplay</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"> <span class="built_in">glClear</span>(GL_COLOR_BUFFER_BIT|…)</span><br><span class="line"> ...</span><br><span class="line"> <span class="comment">/* draw graphics here */</span></span><br><span class="line"> ...</span><br><span class="line"> <span class="built_in">glutSwapBuffers</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="Idle-Callback"><a href="#Idle-Callback" class="headerlink" title="Idle Callback"></a>Idle Callback</h3><ul>
<li>The idle callback is executed whenever there are <font color="red">no events</font> in the event queue<ul>
<li><code>glutIdleFunc(myidle)</code> in <code>main()</code></li>
<li><font color="blue">Useful for animation</font> 

</li>
</ul>
</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">myidle</span><span class="params">()</span> </span>&#123;</span><br><span class="line"> <span class="comment">/* change something */</span></span><br><span class="line"> t += dt</span><br><span class="line"> <span class="built_in">glutPostRedisplay</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="Mouse-and-Keyboard-Callbacks"><a href="#Mouse-and-Keyboard-Callbacks" class="headerlink" title="Mouse and Keyboard Callbacks"></a>Mouse and Keyboard Callbacks</h3><ul>
<li><code>glutMouseFunc(mymouse)</code> in <code>main()</code></li>
<li><code>void mymouse(GLint button, GLint state,  GLint x, GLint y)</code> to define mouse callbacks<ul>
<li>Buttons: <code>GLUT_LEFT_BUTTON</code>, <code>GLUT_MIDDLE_BUTTON</code> or <code>GLUT_RIGHT_BUTTON</code></li>
<li>States: <code>GLUT_UP</code> or <code>GLUT_DOWN</code></li>
<li>Cursor Position: top-left corner is (0,0) <font color="gray">[Others depend on winsize]</font></li>
</ul>
</li>
</ul>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr12.png" alt="position" style="zoom:50%"></div>

<blockquote class="blockquote-center">
<p>$<br>y_{\text{OpenGL}}= h-1-y_{text{win}}<br>$</p>

</blockquote>
<font color="blue">E.g. To draw a square when mouse click</font>

<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">mymouse</span><span class="params">(<span class="type">int</span> btn, <span class="type">int</span> state, <span class="type">int</span> x, <span class="type">int</span> y)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"> <span class="keyword">if</span> (btn==GLUT_RIGHT_BUTTON &amp;&amp; state==GLUT_DOWN) <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line"> <span class="keyword">if</span> (btn==GLUT_LEFT_BUTTON &amp;&amp; state==GLUT_DOWN) <span class="built_in">drawSquare</span>(x, y);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">drawSquare</span><span class="params">(<span class="type">int</span> x, <span class="type">int</span> y)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"> y = w – <span class="number">1</span> - y; <span class="comment">/* invert y position */</span></span><br><span class="line"> <span class="comment">/* a random color */</span></span><br><span class="line"> <span class="built_in">glColor3ub</span>((<span class="type">char</span>)<span class="built_in">rand</span>()%<span class="number">256</span>,(<span class="type">char</span>)<span class="built_in">rand</span>()%<span class="number">256</span>,(<span class="type">char</span>)<span class="built_in">rand</span>()%<span class="number">256</span> );</span><br><span class="line"> <span class="built_in">glBegin</span>(GL_POLYGON);</span><br><span class="line"> <span class="built_in">glVertex2f</span>(x+size, y+size);</span><br><span class="line"> <span class="built_in">glVertex2f</span>(x-size, y+size);</span><br><span class="line"> <span class="built_in">glVertex2f</span>(x-size, y-size);</span><br><span class="line"> <span class="built_in">glVertex2f</span>(x+size, y-size);</span><br><span class="line"> <span class="built_in">glEnd</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<hr>
<ul>
<li>We can draw squares (or anything else) continuously as long as a mouse button is depressed by using the motion callback<ul>
<li><code>glutMotionFunc(drawSquare)</code></li>
</ul>
</li>
<li><p>We can draw squares without depressing a button using the <font color="red">passive motion</font> callback (用于鼠标没按下但在移动时的操作)</p>
<ul>
<li><code>glutPassiveMotionFunc(drawSquare)</code></li>
</ul>
</li>
<li><p><strong>Keyboard is almost the same</strong></p>
<ul>
<li><code>glutKeyboardFunc(mykey)</code></li>
<li><code>void mykey(unsigned char key,  int x, int y)</code></li>
</ul>
</li>
</ul>
<p>E.g.</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">mykey</span><span class="params">(<span class="type">unsigned</span> <span class="type">char</span> key, <span class="type">int</span> x, <span class="type">int</span> y)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"> <span class="keyword">if</span> (key == <span class="string">&#x27;Q&#x27;</span> | key == <span class="string">&#x27;q&#x27;</span>) </span><br><span class="line"> <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p><strong>Others:</strong></p>
<p>GLUT defines the <strong>special keys</strong> in <code>glut.h</code></p>
<ul>
<li>Function key 1: <code>GLUT_KEY_F1</code></li>
<li>Up arrow key: <code>GLUT_KEY_UP</code></li>
</ul>
<p>Also check <strong>modifiers</strong></p>
<ul>
<li><code>GLUT_ACTIVE_SHIFT</code>, <code>GLUT_ACTIVE_CTRL</code>, <code>GLUT_ACTIVE_ALT</code> is depressed using <code>glutGetModifiers()</code> </li>
</ul>
</blockquote>
<h3 id="Reshape-Callback"><a href="#Reshape-Callback" class="headerlink" title="Reshape Callback"></a>Reshape Callback</h3><ul>
<li><code>glutReshapeFunc(myreshape)</code> in <code>main()</code></li>
<li><code>void myreshape(int w, int h)</code></li>
</ul>
<p>E.g.</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">myReshape</span><span class="params">(<span class="type">int</span> w, <span class="type">int</span> h)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"> <span class="built_in">glViewport</span>(<span class="number">0</span>, <span class="number">0</span>, w, h);</span><br><span class="line"> <span class="built_in">glMatrixMode</span>(GL_PROJECTION); <span class="comment">/* switch matrix mode */</span></span><br><span class="line"> <span class="built_in">glLoadIdentity</span>();</span><br><span class="line"> </span><br><span class="line"> <span class="keyword">if</span> (w &lt;= h)</span><br><span class="line"> <span class="built_in">gluOrtho2D</span>( <span class="number">-2.0</span>, <span class="number">2.0</span>, <span class="number">-2.0</span> * (GLfloat) h / w,</span><br><span class="line"> <span class="number">2.0</span> * (GLfloat) h / w );</span><br><span class="line"> <span class="keyword">else</span> </span><br><span class="line"> <span class="built_in">gluOrtho2D</span>( <span class="number">-2.0</span> * (GLfloat) w / h, </span><br><span class="line"> <span class="number">2.0</span> * (GLfloat) w / h, <span class="number">-2.0</span>, <span class="number">2.0</span> );</span><br><span class="line"> <span class="built_in">glMatrixMode</span>(GL_MODELVIEW); <span class="comment">/* return to modelview mode */</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="Menu"><a href="#Menu" class="headerlink" title="Menu"></a>Menu</h3><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// main()</span></span><br><span class="line">GLint menu_id = <span class="built_in">glutCreateMenu</span>(mymenu);</span><br><span class="line"><span class="built_in">glutAddMenuEntry</span>(<span class="string">&quot;Clear&quot;</span>, <span class="number">1</span>);</span><br><span class="line"><span class="built_in">glutAddMenuEntry</span>(<span class="string">&quot;Quit&quot;</span>, <span class="number">2</span>);</span><br><span class="line"><span class="built_in">glutAttachMenu</span>(GLUT_RIGHT_BUTTON);</span><br></pre></td></tr></table></figure>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">mymenu</span><span class="params">(<span class="type">int</span> id)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"> <span class="keyword">if</span>(id == <span class="number">1</span>) <span class="built_in">glClear</span>(GL_COLOR_BUFFER_BIT);</span><br><span class="line"> <span class="keyword">if</span>(id == <span class="number">2</span>) <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="Other-Functions"><a href="#Other-Functions" class="headerlink" title="Other Functions"></a>Other Functions</h3><ul>
<li>Dynamic Windows<ul>
<li>Create and destroy during execution</li>
</ul>
</li>
<li>Subwindows</li>
<li>Multiple Windows</li>
<li>Changing callbacks during execution</li>
<li>Timers (look up glutTimerFunc)<ul>
<li>Useful for controlling speed of animation</li>
</ul>
</li>
<li>Portable fonts<ul>
<li>glutBitmapCharacter</li>
<li>glutStrokeCharacter</li>
</ul>
</li>
</ul>
<hr>
<h1 id="IV-Geometric-Objects-amp-Transformations"><a href="#IV-Geometric-Objects-amp-Transformations" class="headerlink" title="IV. Geometric Objects &amp; Transformations"></a>IV. Geometric Objects &amp; Transformations</h1><ul>
<li>Basic elements<ul>
<li>Scalars</li>
<li>Vectors</li>
<li>Points</li>
</ul>
</li>
<li>Basic primitives<ul>
<li>Line segments</li>
<li>Polygons</li>
</ul>
</li>
</ul>
<h2 id="Representation"><a href="#Representation" class="headerlink" title="Representation"></a>Representation</h2><ul>
<li>Introduce<ul>
<li><strong>coordinate systems</strong> for representing vector spaces</li>
<li>frames for representing <strong>affine spaces</strong>(仿射空间)</li>
</ul>
</li>
<li>Discuss change of frames and bases</li>
<li>Introduce homogeneous coordinates</li>
</ul>
<h3 id="Coordinate-Systems"><a href="#Coordinate-Systems" class="headerlink" title="Coordinate Systems"></a>Coordinate Systems</h3><font color="green">Recall: Linear Algebra</font>

<ul>
<li>basis: $v_1,v_2,…,v_n$</li>
<li>a vector written as $v=\alpha_1 v_1+\alpha_2 v_2 + \cdots + \alpha_n v_n$</li>
<li>the <font color="red">coordinate</font> of $v$ in this basis is $\{ \alpha_1,\alpha_2, \cdots , \alpha_n \}$</li>
</ul>
<h3 id="Frame"><a href="#Frame" class="headerlink" title="Frame"></a>Frame</h3><p><strong>Def.</strong> A <font color="red">frame</font> is a system with a single point(origin $P_0$) and a basis vector <font color="blue">in an affine space</font>.</p>
<blockquote class="blockquote-center">
<p>$<br>P=P_0 + \beta_1 v_1 + \beta_2 v_2 + \cdots + \beta_n v_n<br>$</p>

</blockquote>
<h3 id="Homogeneous-Coordinates"><a href="#Homogeneous-Coordinates" class="headerlink" title="Homogeneous Coordinates"></a>Homogeneous Coordinates</h3><p>E.g. for a 3 * 3 space, the 3 * 3 matrices cannot used for translation(平移), because vectors have no position.</p>
<ul>
<li>We extend the $3\times 3$ point to 4-dimension: $(x,y,z) \rightarrow (x,y,z,1)$</li>
<li>and a $4\times 4$ matrix can represent translation, rotation and scaling and shear</li>
<li>using matrix(a template) below, we can maintain $w=0$ for vectors and $w=1$ for points for <font color="red">orthographic viewing</font> .</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\left( \begin{array}{c}<br>a &amp; b &amp; c &amp; tx \\<br>d &amp; e &amp; f &amp; ty \\<br>g &amp; h &amp; i &amp; tz \\<br>0 &amp; 0 &amp; 0 &amp; 1<br>\end{array}\right)<br>$</p>

</blockquote>
<font color="blue">E.g. For a 3D point $(x,y,z)$ , its homogeneous coordinate is $P_h = (x,y,z,1)$ . To translate it, we define a matrix:</font>

<blockquote class="blockquote-center">
<p>$<br>\left( \begin{array}{c}<br>1 &amp; 0 &amp; 0 &amp; tx \\<br>0 &amp; 1 &amp; 0 &amp; ty \\<br>0 &amp; 0 &amp; 1 &amp; tz \\<br>0 &amp; 0 &amp; 0 &amp; 1<br>\end{array}\right)<br>\left( \begin{array}{c}<br>x \\ y \\ z \\ 1<br>\end{array}\right) =<br>\left( \begin{array}{c}<br>x+ tx \\ y+ ty \\ z+ tz \\  1<br>\end{array}\right)<br>$</p>

</blockquote>
<ul>
<li>More generally, homogeneous coordinates are represented as $p=[ wx,wy,wz,w ]^T$</li>
</ul>
<h2 id="Transformation"><a href="#Transformation" class="headerlink" title="Transformation"></a>Transformation</h2><ul>
<li>Affine Transformation: Line preserving</li>
<li><p>Translation: move points</p>
<ul>
<li>$P’=P+d$ where $d=[d_x, d_y, d_z, 0]^T$ </li>
</ul>
</li>
<li><p><font color="green">Recall for Linear Algebra:</font> Some linear transformation: </p>
<ul>
<li>Rotation (2D)</li>
<li>Scaling</li>
<li>Reflection</li>
</ul>
</li>
</ul>
<blockquote>
<p>try to remember their transformation matrices.</p>
</blockquote>
<p><strong>Inverses</strong></p>
<ul>
<li>Translation: $\textbf{T}^{-1}=\textbf{T}(-d_x, -d_y, -d_z)$</li>
<li>Rotation: $\textbf{R}^{-1}(\theta)=\textbf{R}(- \theta)$<ul>
<li>Noted that only $cos(\theta)$ on orthogonal entry</li>
</ul>
</li>
<li>Scaling: $\textbf{S}^{-1}(s_x, s_y, s_z)=\textbf{S}(1/s_x, 1/s_y, 1/s_z)$ </li>
</ul>
<p><strong>Examples</strong></p>
<p>Rotation About a Fixed Point Other than the Origin:</p>
<ol>
<li>Move fixed point to origin</li>
<li>Rotate</li>
<li>Move fixed point back</li>
</ol>
<blockquote class="blockquote-center">
<p>$<br>\textbf{M}=\textbf{T}(p_f)\textbf{R}(\theta)\textbf{T}(-p_f)<br>$</p>

</blockquote>
<p>(bu)</p>
<h2 id="OpenGL-Transformations"><a href="#OpenGL-Transformations" class="headerlink" title="OpenGL Transformations"></a>OpenGL Transformations</h2><div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr13.png" alt="procedure" style="zoom:50%"></div>

<ul>
<li><p><font color="green">Recall:</font> <code>glMatrixMode(GLenum mode)</code> to change the mode of matrix calculation</p>
<ul>
<li>when doing transformation, use <code>GL_MODELVIEW</code> state</li>
</ul>
</li>
<li><p>For all CTM(Current Transformation Matrix) Operations, our CPP Code must load identity matrix first:</p>
</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="built_in">glMatrixMode</span>(GL_MODELVIEW);</span><br><span class="line"><span class="built_in">glLoadIdentity</span>(); <span class="comment">// 重置</span></span><br><span class="line"><span class="built_in">glTranslatef</span>(<span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">-5.0</span>); <span class="comment">// 平移物体</span></span><br></pre></td></tr></table></figure>
<ul>
<li>Beware of using <strong>post-multiplications</strong> (the later operations should be multipled to result matrix $\textbf{C}$ <font color="red">earlier</font>)<ul>
<li>E.g. Rotation About a Fixed Point: $\textbf{C}=\textbf{T}^{-1}\textbf{R}\textbf{T}$</li>
</ul>
</li>
<li>Other Transformation Matrix specifying<ul>
<li>rotation: <code>glRotatef(theta, vx, vy, yz)</code></li>
<li>translation: <code>glTranslatef(dx, dy, dz)</code></li>
<li>scale: <code>glScalef(sx, sy, sz)</code> </li>
</ul>
</li>
</ul>
<hr>
<h1 id="V-Camera-amp-Viewing"><a href="#V-Camera-amp-Viewing" class="headerlink" title="V. Camera &amp; Viewing"></a>V. Camera &amp; Viewing</h1><h2 id="Computer-Viewing"><a href="#Computer-Viewing" class="headerlink" title="Computer Viewing"></a>Computer Viewing</h2><ul>
<li><font color="red">2</font> attributes to define the viewing:<ul>
<li>Positioning the camera<ul>
<li><font color="green">Setting the <b>model-view</b> matrix</font> </li>
</ul>
</li>
<li>Selecting a lens<ul>
<li><font color="green">Setting the <b>projection</b> matrix</font></li>
<li>Perspective or orthographic / view volume / clipping volume …</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="Specify-Different-Space"><a href="#Specify-Different-Space" class="headerlink" title="Specify Different Space"></a>Specify Different Space</h2><div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr13.png" style="zoom:60%"></div>

<ul>
<li>Local / Modeling / Object Space<ul>
<li>Each object model has its own local coordinate frame</li>
</ul>
</li>
<li>World Space (类似全局空间)<ul>
<li><font color="blue">Lights and Camera pose</font> are defined in this space</li>
</ul>
</li>
</ul>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr17.png" style="zoom:60%"></div>

<ul>
<li><strong>Camera Space / View Space / Eye Space</strong><ul>
<li>Camera is located at the origin</li>
<li>Looking in negative $z$ direction</li>
<li>$+y$-axis is the “up-vector”</li>
</ul>
</li>
</ul>
<blockquote>
<p>Initially the <strong>world</strong> and <strong>camera</strong> frames are the same.</p>
<p>To specify camera pose, we need to specify the camera coordinate frame with respect to the world coordinate frame.</p>
</blockquote>
<h2 id="View-Transformation"><a href="#View-Transformation" class="headerlink" title="View Transformation"></a>View Transformation</h2><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="built_in">glLookAt</span>( eyex, eyey, eyez,</span><br><span class="line">		  atx , aty , atz ,</span><br><span class="line">		  upx , upy , upz )</span><br></pre></td></tr></table></figure>
<ul>
<li>通过 eye 和 at 求出前向量</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\text{forward}=\frac{\text{at} - \text{eye}}{|\text{at} - \text{eye}|}<br>$</p>

</blockquote>
<ul>
<li>通过 forward 和 up 求出右向量</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\text{side}=\frac{\text{forward} \times \text{up}}{|\text{forward} \times \text{up}|}<br>$</p>

</blockquote>
<ul>
<li>然后就能得到修正后的上向量</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\text{up’}= \text{forward} \times \text{side}<br>$</p>

</blockquote>
<ul>
<li>求出三个向量后就能确定 camera 的位置和 pose 了</li>
</ul>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr18.png" alt="view-trans" style="zoom:60%"></div>

<ul>
<li>Suppose the camera has been moved to the location $[e_x, e_y, e_z]^T$, and its $x_c$, $y_c$, $z_c$ axes are the unit vectors $\textbf{u}$, $\textbf{v}$, $\textbf{n}$, respectively, then</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\textbf{M}_{\text{view}}=<br>\left[ \begin{array}{c}<br>u_x &amp; u_y &amp; u_z &amp; 0 \\<br>v_x &amp; v_y &amp; v_z &amp; 0 \\<br>n_x &amp; n_y &amp; n_z &amp; 0 \\<br>0 &amp; 0 &amp; 0 &amp; 1<br>\end{array}\right]<br>\cdot<br>\left[ \begin{array}{c}<br>1 &amp; 0 &amp; 0 &amp; -e_x \\<br>0 &amp; 1 &amp; 0 &amp; -e_y \\<br>0 &amp; 0 &amp; 1 &amp; -e_z \\<br>0 &amp; 0 &amp; 0 &amp; 1<br>\end{array}\right]<br>$</p>

</blockquote>
<p>▪ Note that $[e_x, e_y, e_z]^T$ and $\textbf{u}$, $\textbf{v}$, $\textbf{n}$ are all specified with respect to the world frame</p>
<h2 id="Projection-——-Defining-the-View-Volume"><a href="#Projection-——-Defining-the-View-Volume" class="headerlink" title="Projection —— Defining the View Volume"></a>Projection —— Defining the View Volume</h2><ul>
<li>For orthographic projection, use <code>glOrtho()</code></li>
<li>For perspective projection, use <code>glFrustum()</code></li>
</ul>
<h3 id="OpenGL-Orthographic-Projection"><a href="#OpenGL-Orthographic-Projection" class="headerlink" title="OpenGL Orthographic Projection"></a>OpenGL Orthographic Projection</h3><ul>
<li>The glOrtho() function then generates a matrix that linearly maps the view volume to the canonical view volume, where<ul>
<li>(left, bottom, –near) is mapped to (–1, –1, –1)</li>
<li>(right, top, – far) is mapped to (1, 1, 1)</li>
</ul>
</li>
</ul>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr14.png" alt="ortho-projection" style="zoom:60%"></div>

<blockquote>
<p>正投影，能较真实地反映物体大小，物体显示的大小不会因视角变化改变。常用于CAD设计、地图绘制、2D游戏等不需要表现深度感的场景。</p>
</blockquote>
<h3 id="OpenGL-Perspective-Projection"><a href="#OpenGL-Perspective-Projection" class="headerlink" title="OpenGL Perspective Projection"></a>OpenGL Perspective Projection</h3><ul>
<li><code>glFrustum( left, right, bottom, top, near, far )</code><ul>
<li>The <code>glFrustum()</code> function allows (off-center) non-symmetric view volume</li>
</ul>
</li>
<li>Often, we want a <strong>symmetric view volume</strong>. We can use<ul>
<li><code>gluPerspective( fovy, aspect, near, far );</code></li>
</ul>
</li>
</ul>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr15.png" alt="persp-projection" style="zoom:60%"></div>

<blockquote>
<p>透视投影，有深度感，近大远小。常用于3D游戏、虚拟现实、建筑可视化等需要真实感的场景。</p>
</blockquote>
<h4 id="Principle-of-Perspective-Projection"><a href="#Principle-of-Perspective-Projection" class="headerlink" title="Principle of Perspective Projection"></a>Principle of Perspective Projection</h4><div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr19.png" alt="persp-projection-d" style="zoom:60%"></div>

<ul>
<li>Center of projection at the origin</li>
<li>Projection plane is $z = d$, $d &lt; 0$</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>x_p=\frac{x}{z/d}\ \ \ \ y_p=\frac{y}{z/d}\ \ \ \ z_p=d<br>$</p>

</blockquote>
<ul>
<li>Consider $p=Mq$ where</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>p=<br>\left[ \begin{array}{c}<br>x \\ y \\ z \\ z/d<br>\end{array}\right] \ \ \ \ M=<br>\left[ \begin{array}{c}<br>1 &amp; 0 &amp; 0 &amp; 0 \\<br>0 &amp; 1 &amp; 0 &amp; 0 \\<br>0 &amp; 0 &amp; 1 &amp; 0 \\<br>0 &amp; 0 &amp; 1/d &amp; 0<br>\end{array}\right] \ \ \ \ q=<br>\left[ \begin{array}{c}<br>x \\ y \\ z \\ 1<br>\end{array}\right]<br>$</p>

</blockquote>
<ul>
<li>If we scale $p$ , then we get the projection point on plane $z=d$ .</li>
</ul>
<h1 id="VI-Rasterization"><a href="#VI-Rasterization" class="headerlink" title="VI. Rasterization"></a>VI. Rasterization</h1><h2 id="Recall-for-OpenGL-Rendering-Pipeline"><a href="#Recall-for-OpenGL-Rendering-Pipeline" class="headerlink" title="Recall for OpenGL Rendering Pipeline"></a>Recall for OpenGL Rendering Pipeline</h2><div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr16.png" alt="Rendering Pipeline" style="zoom:60%"></div>

<h3 id="Primitive-Assembly-etc"><a href="#Primitive-Assembly-etc" class="headerlink" title="Primitive Assembly, etc."></a>Primitive Assembly, etc.</h3><ul>
<li>Primitive assembly<ul>
<li>Vertex data is collected into complete primitives</li>
<li>Necessary for clipping and back-face culling</li>
</ul>
</li>
<li>Clipping</li>
<li>Perspective division (Object Oriented)<ul>
<li>To normalized device coordinate (NDC) space</li>
</ul>
</li>
<li>Viewport transformation (Viewer Oriented)<ul>
<li>To window space</li>
<li>Include depth range scaling</li>
</ul>
</li>
<li>Back-face culling</li>
</ul>
<h3 id="Rasterization-amp-Fragment-Processing"><a href="#Rasterization-amp-Fragment-Processing" class="headerlink" title="Rasterization &amp; Fragment Processing"></a>Rasterization &amp; Fragment Processing</h3><ul>
<li>Attribute values at fragments are computed by interpolating attribute values assigned to vertices<ul>
<li>Interpolation is performed in window space (2D)</li>
</ul>
</li>
</ul>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr20.png" alt="interpolation" style="zoom:55%"></div>

<ul>
<li>Each generated fragment is processed to determine the color of the corresponding pixel in the frame buffer</li>
<li>Fragment color can be modified by <strong>texture mapping</strong> (纹理映射)<ul>
<li>Texture access (using interpolated texture coordinates)<ul>
<li>Access texture map using texture coordinates</li>
</ul>
</li>
<li>Texture application<ul>
<li>Texture color can be combined with the fragment color of the primitive</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>Per-Fragment Operations</strong></p>
<ul>
<li><font color="blue">Fragment is discarded if it is blocked (occluded) by the corresponding pixel already in the frame buffer</font><ul>
<li>Z-buffer hidden-surface removal</li>
</ul>
</li>
<li><font color="blue">Fragment may be blended with the corresponding pixel already in the frame buffer</font> <ul>
<li>Blending</li>
</ul>
</li>
</ul>
<blockquote>
<p>Let’s talk about something important !!!</p>
</blockquote>
<h2 id="Clipping"><a href="#Clipping" class="headerlink" title="Clipping"></a>Clipping</h2><blockquote>
<p>To clip out primitives that are outside the view volume</p>
</blockquote>
<h3 id="Clipping-2D-Line-Segments"><a href="#Clipping-2D-Line-Segments" class="headerlink" title="Clipping 2D Line Segments"></a>Clipping 2D Line Segments</h3><h4 id="Cohen-Sutherland-Algorithm"><a href="#Cohen-Sutherland-Algorithm" class="headerlink" title="Cohen-Sutherland Algorithm"></a>Cohen-Sutherland Algorithm</h4><ul>
<li>Using <a name="edge-table">edge table</a></li>
</ul>
<table>
<tr>
<td><img src="/2024/06/27/Real-Time-Rendering/rtr21.png" style="zoom:50%"></td>
<td><p><li>Case 1: Both endpoints inside all four lines
<ul><li>Draw (accept) line segment as is</li></ul></li>
<li>Case 2: Both endpoints outside same line
<ul><li>Discard (reject) the line segment</li></ul></li></p></td>
</tr>
<tr>
<td><img src="/2024/06/27/Real-Time-Rendering/rtr22.png" style="zoom:50%"></td>
<td><p><li>Case 3: One endpoint inside all lines and one outside
<ul><li>Must do at least one intersection</li></ul></li>
<li>Case 4: Both outside
<ul><li>May have part inside</li>
<li>Must do at least one intersection</li></ul></li></p></td>
</tr>
</table>

<p><strong>Using Outcode</strong></p>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr23.png" alt="outcode" style="zoom:60%"></div>

<p>E.g. Suppose a line $AB$ with endpoints $A$ and $B$ .</p>
<ul>
<li>If $\text{outcode}(A)=\text{outcode}(B)=0$ , accept the segment</li>
<li>If $\text{outcode}(A)=0$ , $\text{outcode}(B)\not= 0$ , <ul>
<li>Compute intersection</li>
<li>Location of $1$ in outcode($B$) determines which edge to intersect with</li>
<li>If outcode($B$) has two $1$’s, then need to do two intersections</li>
</ul>
</li>
<li>If $\text{outcode}(A)$ &amp; $\text{outcode}(B) \not= 0$ , reject the segment</li>
<li><p>If $\text{outcode}(A)$ &amp; $\text{outcode}(B) = 0$ , but neither of them are $0$ , </p>
<ul>
<li>Shorten line segment by intersecting with one of sides of window</li>
<li>Compute outcode of intersection (new endpoint of shortened line segment)</li>
<li>Re-execute algorithm</li>
</ul>
</li>
<li><p><strong>When it goes to 3D</strong>, we can use 6-bit outcode to represent 6 faces of the window.</p>
</li>
</ul>
<h3 id="Polygon-Clipping"><a href="#Polygon-Clipping" class="headerlink" title="Polygon Clipping"></a>Polygon Clipping</h3><blockquote>
<p>Problems of polygon clipping: may generate multiple polygons.</p>
<p>Solution: For concave polygons, use tessellation function(镶嵌函数) in <code>GLU</code> to change it to multiple convex polygons.</p>
</blockquote>
<ul>
<li>simple way: set axis-aligned bounding box(AABB) for simple calculation.</li>
</ul>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr24.png" alt="outcode" style="zoom:50%"></div>



<h2 id="Rasterization"><a href="#Rasterization" class="headerlink" title="Rasterization"></a>Rasterization</h2><h3 id="Scan-Conversion-of-Line-Segments"><a href="#Scan-Conversion-of-Line-Segments" class="headerlink" title="Scan Conversion of Line Segments"></a>Scan Conversion of Line Segments</h3><p><a name="BA"><b>Bresenham’s Algorithm</b></a></p>
<ul>
<li><font color="red">Key thought</font>: A binary decision problem on how the next pixel lies based on the previous pixel.</li>
</ul>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr25.png" alt="BA" style="zoom:50%"></div>

<ul>
<li>On the next point: $y=m(x_k + 1) + b$</li>
<li>$d_\text{lower} = y-y_k$</li>
<li>$d_\text{upper}=(y_k+1)-y$</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\begin{align}<br>p_k&amp;=\Delta x(d_\text{lower} - d_\text{upper}) \\<br>&amp;=2x_k \Delta y - 2y_k \Delta x + c<br>\end{align}<br>$</p>

</blockquote>
<p>where $c=2\Delta y + \Delta x (2b - 1)$ is an <font color="red">integer constant</font> .</p>
<ul>
<li>If $p_k &gt; 0$ , plot upper pixel</li>
<li><p>If $p_k &lt; 0$ , plot lower pixel</p>
</li>
<li><p>We can incrementally compute $p_{k+1}$ from $p_k$</p>
<ul>
<li>If $p_k &gt; 0$ ,  $p_{k + 1} = p_k + 2\Delta y – 2\Delta x$</li>
<li>If $p_k &lt; 0$, $p_{k + 1} = p_k + 2\Delta y$</li>
<li>where $p_0=2\Delta y - \Delta x$</li>
</ul>
</li>
</ul>
<h3 id="Scan-Conversion-of-Polygons"><a href="#Scan-Conversion-of-Polygons" class="headerlink" title="Scan Conversion of Polygons"></a>Scan Conversion of Polygons</h3><p><strong>Scan-Line Fill — Interpolation</strong></p>
<ul>
<li>$C_1$ $C_2$ $C_3$ specified by glColor or by vertex shading (lighting computation)</li>
<li>$C_4$ determined by interpolating between $C_1$ and $C_3$</li>
<li>$C_5$ determined by interpolating between $C_2$ and $C_3$</li>
<li>Interpolate between $C_4$ and $C_5$ along span</li>
</ul>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr26.png" alt="scPolygon" style="zoom:50%"></div>

<blockquote>
<p>So what we need to do in this algorithm is calculating : </p>
<ol>
<li>points intersact with scan-line (Recall <a href="#BA">Bresenham’s Algorithm</a>)</li>
<li>which polygons lie on this pixel (多边形扫描转换，<a href="#edge-table">边表</a>，活动边表)</li>
</ol>
</blockquote>
<h3 id="Hidden-Surface-Removal"><a href="#Hidden-Surface-Removal" class="headerlink" title="Hidden-Surface Removal"></a>Hidden-Surface Removal</h3><ul>
<li>Painter’s Algorithm<ul>
<li>Fill the objects at the back first, then cover with the front objects</li>
</ul>
</li>
<li>Depth Sorting<ul>
<li>Need $O(n^2)$ at worst</li>
</ul>
</li>
</ul>
<p><strong>Back-Face Culling</strong></p>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr27.png" alt="BFC" style="zoom:90%"></div>

<ul>
<li>Polygons is <font color="red">back-facing</font> if $\textbf{N}_p \cdot \textbf{N} &lt;0$</li>
<li><font color="blue">In OpenGL, we can simply enable culling</font><ul>
<li>By default, polygon vertices must be provided in <font color="blue">counter clockwise</font> order</li>
<li>But may not work correctly for <font color="blue">non-convex</font> polygon</li>
</ul>
</li>
</ul>
<p><strong>Z-Buffer</strong></p>
<ul>
<li>Key thought: Exchange time with space</li>
<li>Use a <font color="red">z-buffer</font> (depth buffer) to store the depth of the closest object at each pixel found so far</li>
</ul>
<h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr16.png" alt="Rendering Pipeline" style="zoom:60%"></div>

<ul>
<li>Viewing this pipeline again:</li>
<li>Using back-face culling to remove hidden-surface</li>
<li>Using scan conversion to do rasterization</li>
<li>Using z-buffer to test the per-fragment</li>
<li>At the end, output frame buffer.</li>
</ul>
<hr>
<h1 id="VII-Illumination"><a href="#VII-Illumination" class="headerlink" title="VII. Illumination"></a>VII. Illumination</h1><p><strong>Local Reflection vs Global Illumination</strong></p>
<ul>
<li>Local reflection<ul>
<li>Considers relationship between a light source, a single surface point, and a view point</li>
<li>No interaction with other objects</li>
</ul>
</li>
<li>Global illumination<ul>
<li>Considers all light sources and surfaces</li>
<li>Inter-reflections and shadows</li>
</ul>
</li>
</ul>
<h2 id="Phong-Illumination-Equation"><a href="#Phong-Illumination-Equation" class="headerlink" title="Phong Illumination Equation"></a>Phong Illumination Equation</h2><blockquote class="blockquote-center">
<p>$<br>I_{\text{Phong}}=k_a i_a + \sum_{m \in \text{lights}} \left(k_d (\textbf{L}_m \cdot \textbf{N}) i_{m,d} + k_s (\textbf{R}_m \cdot \textbf{V})^{\alpha} i_{m,s}  \right)<br>$</p>

</blockquote>
<p>where :</p>
<ul>
<li>$k_a$ 表示环境光反射系数，常数</li>
<li>$k_d$ 表示漫反射系数，常数</li>
<li>$k_s$ 表示镜面高光反射系数，常数</li>
<li>$\alpha$ 表示物体材质光滑程度，由材质决定（材质越光滑系数越大），常量</li>
<li>$\textbf{L}_m$ 表示相对于 $L$ 的反射光线方向</li>
<li>$\textbf{N}$ 表示该点的法线 [Normal Vector]</li>
<li>$\textbf{R}_m$ 表示反射光的方向</li>
<li>$\textbf{V}$ 表示摄像机的方向</li>
<li>$i_{m,d}$ 表示光源$m$的漫反射反射光照，RGB</li>
<li>$i_{m,s}$ 表示光源$m$的高光反射光照，RGB</li>
<li>$i_a$ 表示环境光的光照，RGB</li>
<li>$I_p$ 表示 $p$ 的总光照，RGB</li>
<li>$m$ 表示其中一个光源</li>
</ul>
<blockquote>
<p>Sum 中的两项分别对应下图的两步（Diffuse【漫反射】是 $L \cdot N$ ，Specular 【镜面】是 $R \cdot V$），ambient 对应 $k_a \times i_a$ ，表示局部的环境色渲染。</p>
</blockquote>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr28.png" alt="PIE" style="zoom:70%"></div>


<ul>
<li>Diffuse Reflection: <strong>Lambert’s Cosine Law</strong><ul>
<li>diffuse reflection $\propto \cos{\theta} = \textbf{N} \cdot \textbf{L}$</li>
</ul>
</li>
</ul>
<h2 id="Illumination-in-OpenGL"><a href="#Illumination-in-OpenGL" class="headerlink" title="Illumination in OpenGL"></a>Illumination in OpenGL</h2><ul>
<li>Lighting Computation at <strong>Vertex Processing</strong> stage.</li>
<li>Specifying Vertex Normal Vectors<ul>
<li>Set by <code>glNormal*()</code><ul>
<li><code>glNormal3f(x, y, z)</code></li>
<li><code>glNormal3fv(p)</code></li>
</ul>
</li>
<li><code>glEnable(GL_NORMALIZE)</code> allows for auto-normalization at a performance penalty</li>
</ul>
</li>
<li>Enabling Lighting Computation<ul>
<li>Shading calculations are enabled by<ul>
<li><code>glEnable(GL_LIGHTING)</code></li>
<li>Once lighting is enabled, <code>glColor()</code> is <font color="red">ignored</font></li>
</ul>
</li>
<li>Must enable each light source individually<ul>
<li><code>glEnable(GL_LIGHTi)</code> $i = 0, 1, 2, \cdots $</li>
</ul>
</li>
<li>Can choose light model parameters<ul>
<li><code>glLightModeli(parameter, GL_TRUE)</code><ul>
<li><code>GL_LIGHT_MODEL_LOCAL_VIEWER</code> do not use simplifying distant viewer assumption in calculation</li>
<li><code>GL_LIGHT_MODEL_TWO_SIDED</code> shades both sides of polygons independently</li>
</ul>
</li>
</ul>
</li>
<li><font color="red">An example code of using light</font>:</li>
</ul>
</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">GLfloat diffuse0[] = &#123;<span class="number">1.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">1.0</span>&#125;;</span><br><span class="line">GLfloat ambient0[] = &#123;<span class="number">1.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">1.0</span>&#125;;</span><br><span class="line">GLfloat specular0[] = &#123;<span class="number">1.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">1.0</span>&#125;;</span><br><span class="line">GLfloat light0_pos[] = &#123;<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3</span>,<span class="number">0</span>, <span class="number">1.0</span>&#125;;</span><br><span class="line"></span><br><span class="line"><span class="built_in">glEnable</span>(GL_LIGHTING);</span><br><span class="line"><span class="built_in">glEnable</span>(GL_LIGHT0);</span><br><span class="line"><span class="built_in">glLightfv</span>(GL_LIGHT0, GL_POSITION, light0_pos);</span><br><span class="line"><span class="built_in">glLightfv</span>(GL_LIGHT0, GL_AMBIENT, ambient0);		<span class="comment">// def ambient</span></span><br><span class="line"><span class="built_in">glLightfv</span>(GL_LIGHT0, GL_DIFFUSE, diffuse0);		<span class="comment">// def diffuse</span></span><br><span class="line"><span class="built_in">glLightfv</span>(GL_LIGHT0, GL_SPECULAR, specular0);	<span class="comment">// def spec</span></span><br></pre></td></tr></table></figure>
<ul>
<li>Or using <strong>Global Ambient Light</strong> : <code>glLightModelfv(GL_LIGHT_MODEL_AMBIENT, global_ambient)</code></li>
</ul>
<blockquote>
<p>设置材质和设置光源的参数很像，用 <code>glMaterialfv()</code> 函数，第一个参数改成 <code>GL_FRONT, GL_BACK, GL_FRONT_AND_BACK</code> 表示内外渲染</p>
</blockquote>
<h2 id="Shading"><a href="#Shading" class="headerlink" title="Shading"></a>Shading</h2><h3 id="Gouraud-Shading-vs-Phong-Shading"><a href="#Gouraud-Shading-vs-Phong-Shading" class="headerlink" title="Gouraud Shading vs. Phong Shading"></a>Gouraud Shading vs. Phong Shading</h3><ul>
<li>Flat shading is “bad”</li>
<li>Gouraud Shading<ol>
<li>For each vertex, compute the <font color="red">average normal vector</font> of the polygons that share the vertex</li>
<li>Apply <font color="red">PIE</font> at the vertex using its <font color="blue">average normal vector</font></li>
<li>Smoothly interpolate the computed colors at the vertices of the polygon to the interior of the polygon</li>
</ol>
</li>
<li>Using <font color="red">Gouraud Shading</font> in OpenGL: <code>glShadeModel(GL_SMOOTH)</code> (No Phong Shading use directly)</li>
</ul>
<ul>
<li>Phong Shading<ol>
<li>In Phong Shading, we do not compute the colors of the vertices for interpolation. Instead, for each fragment in the polygon, we interpolate the normal vectors from the vertices</li>
<li>Then, at each fragment, we apply PIE on the interpolated normal vector to compute a color for the fragment</li>
</ol>
</li>
</ul>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr30.png" alt="Gouraud-and-Phong" style="zoom:70%"></div>

<ul>
<li>Differences<ul>
<li>Highlights are produced more faithfully with Phong shading</li>
<li>Gouraud shading produces only “linear interpolation” of colors</li>
<li>Gouraud shading may even miss the highlight</li>
</ul>
</li>
<li>OpenGL does not support Phong Shading<ul>
<li>But can be done by reprogramming the rendering pipeline <font color="red">using shaders</font></li>
</ul>
</li>
</ul>
<h1 id="VIII-Modern-OpenGL-Intro"><a href="#VIII-Modern-OpenGL-Intro" class="headerlink" title="VIII. Modern OpenGL (Intro)"></a>VIII. Modern OpenGL (Intro)</h1><div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr29.png" alt="modern-opengl" style="zoom:60%"></div>

<h2 id="Example-OpenGL-Programs-The-Modern-Way"><a href="#Example-OpenGL-Programs-The-Modern-Way" class="headerlink" title="Example OpenGL Programs: The Modern Way"></a>Example OpenGL Programs: The Modern Way</h2><h3 id="New-Lib"><a href="#New-Lib" class="headerlink" title="New Lib"></a>New Lib</h3><ul>
<li><code>GLEW</code><ul>
<li><font coolr="blue">The OpenGL Extension Wrangler Library</font> </li>
<li>a cross-platform open-source C/C++ extension loading library</li>
<li>provides efficient run-time mechanisms for determining which OpenGL extensions are supported on the target platform</li>
<li><font color="red">Automatically initializes</font> the entry points of new OpenGL functions</li>
</ul>
</li>
<li><code>GLM</code><ul>
<li><font color="blue">OpenGL Mathematics</font> 


</li>
</ul>
</li>
</ul>
<h3 id="Examples-1"><a href="#Examples-1" class="headerlink" title="Examples"></a>Examples</h3><blockquote>
<p>注意：由于课程上给出的示例代码过长，这里只总结一些重要部分，不展示示例代码。OpenGL 的相关教程网上不会缺，可以自行获取。</p>
</blockquote>
<h1 id="IX-Shading-Language"><a href="#IX-Shading-Language" class="headerlink" title="IX. Shading Language"></a>IX. Shading Language</h1><blockquote>
<p>This section is all about coding.</p>
<p>Some basis(Data Type, Data Structure, etc.) is ignored.</p>
</blockquote>
<p><strong>Storage Quantifiers</strong></p>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr31.png" style="zoom:60%"></div>

<p><strong>Function Parameter Qualifiers</strong></p>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr32.png" style="zoom:60%"></div>

<ul>
<li>GLSL has no concepts of pointer or reference</li>
<li>Functions are called by <font color="red">value-return</font></li>
</ul>
<p><strong>Vertex and Fragment Built-in Variables</strong></p>
<table>
<tr>
<td><img src="/2024/06/27/Real-Time-Rendering/rtr33.png"></td>
<td><img src="/2024/06/27/Real-Time-Rendering/rtr34.png"></td>
</tr>
</table>



<ul>
<li><code>gl_FragCoord</code> contains window relative coordinates $(x, y, z, 1/w)$<ul>
<li>$z$ is the depth value (after depth range scaling)</li>
<li>$w$ is $–z_e$ where $z_e$ is the $z$-coordinate of the fragment in the eye space</li>
</ul>
</li>
<li>If <code>gl_FragDepth</code> is not written to, <code>gl_FragCoord.z</code> is used as fragment’s depth</li>
</ul>
<ul>
<li>A fragment’s 2D position is the window-relative coordinates of the fragment’s center<ul>
<li>By default, for the <font color="red">bottom-left-most</font> pixel in the window<ul>
<li><code>gl_FragCoord.x == 0.5</code></li>
<li><code>gl_FragCoord.y == 0.5</code></li>
</ul>
</li>
</ul>
</li>
</ul>
<blockquote>
<p>Modern OpenGL uses <code>.vert</code> and <code>.frag</code> to describe the vertex and fragment rendering.</p>
</blockquote>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// A simple pseudo-code</span></span><br><span class="line">GLuint ShaderProjObj;</span><br><span class="line"><span class="type">const</span> <span class="type">char</span> vert[] = <span class="string">&quot;exmaple.vert&quot;</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">char</span> frag[] = <span class="string">&quot;example.frag&quot;</span>;</span><br><span class="line"><span class="type">const</span> GLfloat lightAmbient[] = &#123; <span class="number">0.0f</span>, <span class="number">0.0f</span>, <span class="number">0.0f</span>, <span class="number">1.0f</span> &#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">static</span> <span class="type">void</span> <span class="title">MyInit</span><span class="params">(<span class="type">void</span>)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// Create Gouraud Shading shader program object.</span></span><br><span class="line">  ShaderProjObj = <span class="built_in">makeShaderProgramFromFiles</span>(vert, frag, <span class="literal">NULL</span>);</span><br><span class="line">  <span class="comment">// Install Gauraud Shading shader program to the rendering pipeline first.</span></span><br><span class="line">  <span class="built_in">glUseProgram</span>(ShaderProjObj);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">static</span> <span class="type">void</span> <span class="title">MyDrawFunc</span><span class="params">(<span class="type">void</span>)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// Query locations of uniform variables.(exmaple)</span></span><br><span class="line">  GLint la = <span class="built_in">glGetUniformLocation</span>(ShaderProjObj, <span class="string">&quot;LightAmbient&quot;</span>);</span><br><span class="line">  <span class="comment">// Set Uniform variable</span></span><br><span class="line">  <span class="built_in">glUniform4fv</span>(la, <span class="number">1</span>, lightAmbient);</span><br><span class="line">  </span><br><span class="line">  objModel3D-&gt;<span class="built_in">render</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<hr>
<h1 id="X-Texture-Mapping-amp-Applications"><a href="#X-Texture-Mapping-amp-Applications" class="headerlink" title="X. Texture Mapping &amp; Applications"></a>X. Texture Mapping &amp; Applications</h1><h2 id="Surface-Parameterization"><a href="#Surface-Parameterization" class="headerlink" title="Surface Parameterization"></a>Surface Parameterization</h2><ul>
<li>Defines a mapping between the 3D surfaces and the 2D texture map<ul>
<li>Defines the mapping $(x_w, y_w, z_w) \leftrightarrow (s,t)$<ul>
<li>$(x_w, y_w, z_w)$ is the 3D coordinates of surface point</li>
<li>$(s, t )$ is the 2D texture coordinates (limited to $[0,1]^2$)</li>
</ul>
</li>
<li>Defines which <strong>“texel”</strong> maps to each surface point</li>
</ul>
</li>
<li>Difficulty<ul>
<li>Non-trivial surface topology causes severe distortion of textures (有些不正常的表面拓扑后会产生纹理混乱)</li>
</ul>
</li>
</ul>
<h1 id="XI-FBO-amp-Shadow-Mapping"><a href="#XI-FBO-amp-Shadow-Mapping" class="headerlink" title="XI. FBO &amp; Shadow Mapping"></a>XI. FBO &amp; Shadow Mapping</h1><h2 id="Framebuffer-Objects-FBO"><a href="#Framebuffer-Objects-FBO" class="headerlink" title="Framebuffer Objects(FBO)"></a>Framebuffer Objects(FBO)</h2><h3 id="Multi-Pass-Rendering"><a href="#Multi-Pass-Rendering" class="headerlink" title="Multi-Pass Rendering"></a>Multi-Pass Rendering</h3><p><strong>Def.</strong> Render 3D scene multiple times (passes), and “combine” the multiple rendered images to synthesize final frame</p>
<ul>
<li>Allows creation of non-displayable framebuffers</li>
<li>OpenGL can redirect rendering output to FBO</li>
<li>Each FBO contains a collection of rendering destinations</li>
</ul>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr37.png" style="zoom:50%"></div>



<ul>
<li>Two types of framebuffer-attachable images<ul>
<li>Texture images<ul>
<li>Render to texture</li>
</ul>
</li>
<li>Renderbuffer images<ul>
<li>Offscreen rendering</li>
</ul>
</li>
</ul>
</li>
<li>Many color attachment points allow multiple render targets (MRT)<ul>
<li>Can query the maximum number of color attachment points with <code>GL_MAX_COLOR_ATTACHMENTS</code> (usually 8)</li>
</ul>
</li>
</ul>
<h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// cpp file</span></span><br><span class="line"><span class="comment">// set up FBO</span></span><br><span class="line">GLuint fboHandle; <span class="comment">// The handle to the FBO</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Generate and bind the framebuffer</span></span><br><span class="line"><span class="built_in">glGenFramebuffers</span>(<span class="number">1</span>, &amp;fboHandle);</span><br><span class="line"><span class="built_in">glBindFramebuffer</span>(GL_FRAMEBUFFER, fboHandle);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Create first texture object</span></span><br><span class="line">GLuint renderTexA;</span><br><span class="line"><span class="built_in">glGenTextures</span>(<span class="number">1</span>, &amp;renderTexA);</span><br><span class="line"><span class="built_in">glActiveTexture</span>(GL_TEXTURE0); <span class="comment">// Use texture unit 0</span></span><br><span class="line"><span class="built_in">glBindTexture</span>(GL_TEXTURE_2D, renderTexA);</span><br><span class="line"><span class="built_in">glTexImage2D</span>(GL_TEXTURE_2D, <span class="number">0</span>, GL_RGBA8, fboWidth, fboHeight, <span class="number">0</span>,</span><br><span class="line">  GL_RGBA, GL_UNSIGNED_BYTE, <span class="literal">NULL</span>);</span><br><span class="line"><span class="comment">// ...</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Attach first texture to FBO</span></span><br><span class="line"><span class="built_in">glFramebufferTexture2D</span>(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT2,</span><br><span class="line">  GL_TEXTURE_2D, renderTexA, <span class="number">0</span>);</span><br><span class="line">  </span><br><span class="line"><span class="comment">// ... second texture object as above</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Create the depth buffer</span></span><br><span class="line">GLuint depthBuf;</span><br><span class="line"><span class="built_in">glGenRenderbuffers</span>(<span class="number">1</span>, &amp;depthBuf);</span><br><span class="line"><span class="built_in">glBindRenderbuffer</span>(GL_RENDERBUFFER, depthBuf);</span><br><span class="line"><span class="built_in">glRenderbufferStorage</span>(GL_RENDERBUFFER, GL_DEPTH_COMPONENT, </span><br><span class="line">  fboWidth, fboHeight);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Bind the depth buffer to the FBO</span></span><br><span class="line"><span class="built_in">glFramebufferRenderbuffer</span>(GL_FRAMEBUFFER, GL_DEPTH_ATTACHMENT,</span><br><span class="line">  GL_RENDERBUFFER, depthBuf);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Set the target for the fragment shader outputs</span></span><br><span class="line">GLenum drawBufs[] = &#123; GL_COLOR_ATTACHMENT2, GL_COLOR_ATTACHMENT3 &#125;;</span><br><span class="line"><span class="built_in">glDrawBuffers</span>(<span class="number">2</span>, drawBufs);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Unbind the framebuffer, and revert to default</span></span><br><span class="line"><span class="built_in">glBindFramebuffer</span>(GL_FRAMEBUFFER, <span class="number">0</span>);</span><br></pre></td></tr></table></figure>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// often in other functions</span></span><br><span class="line"><span class="comment">// DRAW TO TEXTURES</span></span><br><span class="line"><span class="comment">// Bind to texture&#x27;s FBO</span></span><br><span class="line"><span class="built_in">glBindFramebuffer</span>(GL_FRAMEBUFFER, fboHandle);</span><br><span class="line"></span><br><span class="line"><span class="built_in">glViewport</span>(<span class="number">0</span>, <span class="number">0</span>, fboWidth, fboHeight); <span class="comment">// Viewport for the texture</span></span><br><span class="line"><span class="built_in">glClear</span>(GL_DEPTH_BUFFER_BIT);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Use glClearBufferfv() to individually clear color buffers</span></span><br><span class="line"><span class="type">const</span> GLfloat lightGreen[<span class="number">4</span>] = &#123; <span class="number">0.5f</span>, <span class="number">1.0f</span>, <span class="number">0.5f</span>, <span class="number">1.0f</span> &#125;;</span><br><span class="line"><span class="type">const</span> GLfloat lightRed[<span class="number">4</span>] = &#123; <span class="number">1.0f</span>, <span class="number">0.5f</span>, <span class="number">0.5f</span>, <span class="number">1.0f</span> &#125;;</span><br><span class="line"><span class="built_in">glClearBufferfv</span>(GL_COLOR, <span class="number">0</span>, lightGreen);</span><br><span class="line"><span class="built_in">glClearBufferfv</span>(GL_COLOR, <span class="number">1</span>, lightRed);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Setup the projection matrix and view matrix</span></span><br><span class="line"><span class="comment">// for the scene to be rendered to the texture here.</span></span><br><span class="line"><span class="comment">// ...</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">renderTextureScene</span>();</span><br></pre></td></tr></table></figure>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// DRAW FINAL FRAME</span></span><br><span class="line"><span class="comment">// Unbind texture&#x27;s FBO (back to default FB)</span></span><br><span class="line"><span class="built_in">glBindFramebuffer</span>(GL_FRAMEBUFFER, <span class="number">0</span>);</span><br><span class="line"><span class="built_in">glViewport</span>(<span class="number">0</span>, <span class="number">0</span>, winWidth, winHeight); <span class="comment">// Viewport for main window</span></span><br><span class="line"><span class="built_in">glClear</span>(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Setup the projection matrix and view matrix.</span></span><br><span class="line"><span class="comment">// ...</span></span><br><span class="line"><span class="built_in">renderScene</span>();</span><br></pre></td></tr></table></figure>
<h2 id="Shadow-Mapping"><a href="#Shadow-Mapping" class="headerlink" title="Shadow Mapping"></a>Shadow Mapping</h2><table>
<tr align="center">
<td><img src="/2024/06/27/Real-Time-Rendering/rtr38.png"></td>
<td><img src="/2024/06/27/Real-Time-Rendering/rtr39.png"></td>
</tr>
</table>



<h3 id="Algorithm-Overview"><a href="#Algorithm-Overview" class="headerlink" title="Algorithm Overview"></a>Algorithm Overview</h3><ol>
<li>Render the scene using the light source as viewpoint</li>
<li>Save the depth buffer <font color="blue">(a.k.a. shadow map)</font></li>
<li>Clear the framebuffer</li>
<li>Render the scene from camera’s viewpoint<ul>
<li>For each fragment, transform it to the “light space” and compare its “light space” $z$ value with the corresponding $z$ value in the shadow map<ul>
<li>If “light space” z value is larger, the fragment is in shadow and it is lit with only ambient light</li>
<li>Otherwise, the fragment is <font color="red">not</font> in shadow and is <font color="red">fully lit</font></li>
</ul>
</li>
</ul>
</li>
</ol>
<h3 id="Shadow-Map-Coordinates"><a href="#Shadow-Map-Coordinates" class="headerlink" title="Shadow Map Coordinates"></a>Shadow Map Coordinates</h3><ul>
<li>Any 3D point in the view frustum(视图) of the light source must be transformed to the shadow map coordinates $[s, t, p]$ where $s$, $t$, $p$ are in the range $[0,1]$</li>
<li>Given a 3D point $p_M$ in modeling coordinates, its shadow map coordinates $p_L$ is</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>p_L=B \cdot P_L \cdot V_L \cdot M \cdot p_M<br>$</p>

</blockquote>
<ul>
<li>$M$ is the modeling matrix</li>
<li>$V_L$ is the light’s view transformation matrix</li>
<li>$P_L$ is the light’s projection matrix</li>
<li>and $B=\left[ \begin{array} \\<br>0.5&amp;0&amp;0&amp;0.5 \\<br>0&amp;0.5&amp;0&amp;0.5 \\<br>0&amp;0&amp;0.5&amp;0.5 \\<br>0&amp;0&amp;0&amp;1 \\<br>\end{array}\right]$</li>
</ul>
<h3 id="Issues"><a href="#Issues" class="headerlink" title="Issues"></a>Issues</h3><ul>
<li>shadow acnes(失真)<ul>
<li>Sol 1: Subtract a tolerance value from <code>ShadowCoord.z</code> in the fragment shader before the depth comparison</li>
<li>Sol 2: “Offset” the scene backwards when generating the shadow map from the light source<ul>
<li>Use OpenGL function <code>glPolygonOffset()</code></li>
</ul>
</li>
</ul>
</li>
<li>Obvious jaggies(锯齿)<ul>
<li>Percentage Closer Filtering (PCF)</li>
</ul>
</li>
</ul>
<figure class="highlight glsl"><table><tr><td class="code"><pre><span class="line"><span class="comment">// before using PCF</span></span><br><span class="line"><span class="type">void</span> shadeWithShadow()</span><br><span class="line">&#123;</span><br><span class="line">  <span class="type">vec3</span> ambient = ...; <span class="comment">// ambient</span></span><br><span class="line">  <span class="type">vec3</span> diffSpec = ...; <span class="comment">// diffuse and specular</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">// Do the shadow-map lookup</span></span><br><span class="line">  <span class="type">float</span> shadow = <span class="built_in">textureProj</span>(ShadowMap, ShadowCoord);</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// If the fragment is in shadow, use ambient light only.</span></span><br><span class="line">  FragColor = <span class="type">vec4</span>(diffSpec * shadow + ambient, <span class="number">1.0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight glsl"><table><tr><td class="code"><pre><span class="line"><span class="comment">// after using PCF</span></span><br><span class="line"><span class="type">void</span> shadeWithShadow()</span><br><span class="line">&#123;</span><br><span class="line">  <span class="type">vec3</span> ambient = ...; <span class="comment">// ambient</span></span><br><span class="line">  <span class="type">vec3</span> diffSpec = ...; <span class="comment">// diffuse and specular</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">// The sum of the comparisons with nearby texels</span></span><br><span class="line">  <span class="type">float</span> sum = <span class="number">0.0</span>;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// Sum contributions from texels around ShadowCoord</span></span><br><span class="line">  sum += <span class="built_in">textureProjOffset</span>(ShadowMap, ShadowCoord, <span class="type">ivec2</span>(<span class="number">-1</span>,<span class="number">-1</span>));</span><br><span class="line">  sum += <span class="built_in">textureProjOffset</span>(ShadowMap, ShadowCoord, <span class="type">ivec2</span>(<span class="number">-1</span>,<span class="number">1</span>));</span><br><span class="line">  sum += <span class="built_in">textureProjOffset</span>(ShadowMap, ShadowCoord, <span class="type">ivec2</span>(<span class="number">1</span>,<span class="number">1</span>));</span><br><span class="line">  sum += <span class="built_in">textureProjOffset</span>(ShadowMap, ShadowCoord, <span class="type">ivec2</span>(<span class="number">1</span>,<span class="number">-1</span>));</span><br><span class="line">  <span class="type">float</span> shadow = sum * <span class="number">0.25</span>;</span><br><span class="line">  </span><br><span class="line">  FragColor = <span class="type">vec4</span>(diffSpec * shadow + ambient, <span class="number">1.0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="XII-Image-Processing"><a href="#XII-Image-Processing" class="headerlink" title="XII. Image Processing"></a>XII. Image Processing</h1><h1 id="XIII-Ray-Tracing"><a href="#XIII-Ray-Tracing" class="headerlink" title="XIII. Ray Tracing"></a>XIII. Ray Tracing</h1><h2 id="Basic-Ray-Casting"><a href="#Basic-Ray-Casting" class="headerlink" title="Basic Ray Casting"></a>Basic Ray <font color="red">Casting</font></h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">For every pixel</span><br><span class="line">  Construct a ray from the eye</span><br><span class="line">  For every object in the scene</span><br><span class="line">    Find intersection with the ray </span><br><span class="line">    Keep if closest</span><br><span class="line">  Shade depending on light and normal vector(using Phong reflection)</span><br></pre></td></tr></table></figure>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr35.png" style="zoom:50%"></div>



<p><strong>Rasterization vs. Ray Casting</strong></p>
<ul>
<li>Rasterization<ul>
<li>Given a primitive in 3D space, determine which pixels are covered by the primitive</li>
</ul>
</li>
<li>Ray Casting<ul>
<li>At each pixel, determine which primitive covers it</li>
</ul>
</li>
</ul>
<h2 id="Ray-Tracing"><a href="#Ray-Tracing" class="headerlink" title="Ray Tracing"></a>Ray <font color="red">Tracing</font></h2><ul>
<li>From the closest intersection point, secondary rays are shot out<ul>
<li>Reflection ray</li>
<li>Refraction ray</li>
<li>Shadow rays</li>
</ul>
</li>
</ul>
<h3 id="Whitted-style-Recursive-Ray-Tracing"><a href="#Whitted-style-Recursive-Ray-Tracing" class="headerlink" title="Whitted-style(Recursive) Ray Tracing"></a>Whitted-style(Recursive) Ray Tracing</h3><blockquote class="blockquote-center">
<p>$<br>\begin{align}<br>&amp;\textbf{I}= \textbf{I}_{\text{local}}+k_{\text{rg}} \textbf{I}_{\text{reflected}}+k_{\text{tg}} \textbf{I}_{\text{transmitted}} \\<br>\text{where }&amp;\textbf{I}_{\text{local}}= \textbf{I}_{a}k_a+ \color{red}k_{\text{shadow}}\color{black}\textbf{I}_{\text{source}}\left[ k_d(\textbf{N} \cdot \textbf{L}) + k_r (\textbf{R} \cdot \textbf{V})^n + k_t (\textbf{T} \cdot \textbf{V})^m \right]<br>\end{align}<br>$</p>

</blockquote>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr36.png" style="zoom:50%"></div>

<ul>
<li>So if the material is opaque, the $k_t (\textbf{T} \cdot \textbf{V})^m$ can be omitted.</li>
<li>Also consider <font color="red">Shadow Rays</font>.</li>
</ul>
<p><strong>Scene Description</strong></p>
<ul>
<li>Camera view &amp; image resolution<ul>
<li>Camera position and orientation in world coordinate frame<ul>
<li>Similar to <code>gluLookAt()</code></li>
</ul>
</li>
<li>Field of view<ul>
<li>Similar to <code>gluPerspective()</code>, but <font color="red">no need</font> near &amp; far plane</li>
</ul>
</li>
<li>Image resolution<ul>
<li>Number of pixels in each dimension</li>
</ul>
</li>
</ul>
</li>
<li>Each point light source<ul>
<li>Position</li>
<li>Brightness and color ($\text{I}_{source}$)</li>
<li>A global ambient ($\text{I}_{a}$)</li>
<li>Spotlight is also possible</li>
</ul>
</li>
<li>Each object surface material<ul>
<li>$k$ (each is a RGB vector)</li>
<li>$n$, $m$</li>
<li>Refractive index $\mu$ if $k_{tg} \not= 0$ or $k_{t} \not= 0$</li>
</ul>
</li>
<li>Objects<ul>
<li>Implicit representations (e.g. plane, sphere, quadrics)</li>
<li>Polygon</li>
<li>Parametric (e.g. bicubic Bezier patches)</li>
<li>Volumetric</li>
</ul>
</li>
</ul>
<blockquote>
<p>Q: When to stop recursion?</p>
</blockquote>
<ul>
<li>When the surface is totally diffuse (and opaque)</li>
<li>When reflected/refracted ray hits nothing</li>
<li>When maximum recursion depth is reached</li>
<li>When the contribution of the reflected/refracted ray to the color at the top level is too small<ul>
<li>$(k_{rg1} | k_{tg1}) \times … \times (k_{rg(n−1)} | k_{tg(n−1)}) &lt; \text{threshold}$ </li>
</ul>
</li>
</ul>
<h1 id="Appendices-Reference"><a href="#Appendices-Reference" class="headerlink" title="Appendices (Reference)"></a>Appendices (Reference)</h1><p>If you want to search the reference pages of OpenGL Programming on <code>C++</code> , or use real-time 3D rendering in other field using OpenGL API, please refer to the <a href="https://registry.khronos.org/OpenGL-Refpages/gl4/">OpenGL® 4.5 Reference Pages</a> .</p>
<p>If you are just interesting in shader rendering (like only do fragment shaders), you can go to <a href="https://www.shadertoy.com/">shadertoy</a> to take a look at others’ work or create your own.</p>
<p>One of the contributor of “shadertoy”, Inigo Quilez, has published a tutorial of the skills of shadertoy, and you can learn it here → <a href="https://iquilezles.org/articles/">https://iquilezles.org/articles/</a></p>
]]></content>
      <categories>
        <category>2024 Summer</category>
      </categories>
      <tags>
        <tag>CSE Learning</tag>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title>MA234 大数据导论与实践（二）</title>
    <url>/2024/06/24/Big-Data-2/</url>
    <content><![CDATA[<h1 id="Big-Data-II"><a href="#Big-Data-II" class="headerlink" title="Big Data (II)"></a>Big Data (II)</h1><h2 id="IV-Classification"><a href="#IV-Classification" class="headerlink" title="IV. Classification"></a>IV. Classification</h2><blockquote>
<p>本章内容较多，先写下本章主要内容：</p>
<p>本章涉及分类算法，主要会提及 KNN 算法，决策树算法和朴素贝叶斯算法（是分类算法中最基础的几种）<br>其中，每种算法的应用里涵盖了一些多用概念，如剪枝操作、似然函数计算等。</p>
<p>介绍三种基本算法后，本章还涉及模型评估，讲解如何通过不同问题使用不同的算法以得到最优的结果</p>
<p>注：本章含有不亚于数据预处理章节的数学公式，要求理解公式基本内涵。</p>
</blockquote>
<h3 id="K-Nearest-Neighbor-KNN"><a href="#K-Nearest-Neighbor-KNN" class="headerlink" title="K-Nearest Neighbor (KNN)"></a>K-Nearest Neighbor (KNN)</h3><blockquote>
<p>Supervised learning method, especially useful when prior knowledge on the data is very limited.</p>
<p><font color="red">Low bias, high variance</font> : <font color="blue">just for small</font> <code>k</code> </p>
<p><strong>Advantages</strong> : not sensitive to outliers (异常值距离一般较远) , easy to implement and parallelize, good for large training set</p>
<p><strong>Drawbacks</strong> : need to tune (调节) $k$, take large storage, computationally intensive (计算缓慢，算力要求高)</p>
</blockquote>
<font size="4"><b>Algorithm</b></font>

<ul>
<li>Input : training set $D_{train} = \{(x_1, y_1),\cdots,(x_N, y_N)\}$,  a test sample $x$ without label $y$, $k$ and distance metric $d(x, y)$</li>
<li>Output : predicted label $y_{pred}$ for $x$ </li>
</ul>
<ol>
<li>Compute $d(x, x_j)$ for each $(x_j , y_j) \in D_{train}$</li>
<li>Sort the distances in an <font color="Red">ascending</font> order, choose the ﬁrst $k$ samples $(x_{(1)}, y_{(1)}),\cdots,(x_{(k)} , y_{(k)})$ </li>
<li>Make majority vote $y_{pred} = \text{Mode}(y_{(1)},\cdots, y_{(k)})$ </li>
</ol>
<p>Time Complexity : $O(mndK)$ where $n$ is the number of training samples, $m$ is the number of test samples, $d$ is the dimension, and $K$ is the number of nearest neighbors</p>
<div align="center"><img src="/2024/06/24/Big-Data-2/bd8.png" alt="bd8" style="zoom:50%"></div>



<p><strong>Similarity and Divergence</strong></p>
<ul>
<li><a href="/2024/06/22/Big-Data-1/index.html#cosine distance">Cosine similarity</a></li>
<li><a href="/2024/06/22/Big-Data-1/index.html#Jaccard">Jaccard similarity</a> for sets $A$ and $B$ : $Jaccard(A,B)=\Large{\frac{|A\cap B|}{|A\cup B|}}$ </li>
<li>Kullback-Leibler(KL) divergence : $d_{KL}(P||Q) = E_P log \large{\frac{P(x)}{Q(x)}}$ , measures the distance between two probability <font color="red">distributions</font> $P$ and $Q$ ; in discrete case, $d_{KL}(p||q) = \sum^m_{i=1} p_i log \large{\frac{p_i}{q_i}}$ (CDF of $P$ and $Q$)</li>
</ul>
<p><strong>Tuning <code>k</code></strong> </p>
<ul>
<li>Different <code>k</code> value can lead to totally different results. ( model overfit the data when <code>k = 1</code>, bad for generalization )</li>
<li><strong>M-fold Cross-validation (CV)</strong> to tune <code>k</code> : <ul>
<li>partition the dataset into M parts ( M = 5 or 10 ) , let $\kappa : \{1,\cdots, N\} \to \{1,\cdots, M\}$ be <em>randomized partition index map</em> (随机分布索引映射) . The <em>CV estimate of prediction error</em> (预测误差的CV估计) is<br> $CV(\hat f,k)=\large{\frac{1}{N}} \sum_{n=1}^{N}L(y_i,\hat f^{-\kappa(i)}(x_i,k))$</li>
</ul>
</li>
</ul>
<p><img src="/2024/06/24/Big-Data-2/bd9.png" alt="bd9"></p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">k’s value</th>
<th style="text-align:center">$k=1$ (complex model)</th>
<th style="text-align:center">$k=\infty$ (simplier model)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Bias</td>
<td style="text-align:center">decrease</td>
<td style="text-align:center">increase</td>
</tr>
<tr>
<td style="text-align:center">Variance</td>
<td style="text-align:center">increase</td>
<td style="text-align:center">$0$</td>
</tr>
<tr>
<td style="text-align:center">Generalization</td>
<td style="text-align:center">overfitting (train-set friendly)</td>
<td style="text-align:center">underfitting (test-set friendly)</td>
</tr>
</tbody>
</table>
</div>
<p><a name="Bayes"><b>Bayes Classifier (Oracle Classifier)</b></a></p>
<ul>
<li>Assume $Y \in \mathcal{Y} = \{1, 2, . . . , C\}$, the classiﬁer $f : \mathcal X → \mathcal Y$ is a piecewise (分段) constant function</li>
<li>For <a href="/2024/06/22/Big-Data-1/index.html#0-1 loss">0-1 loss</a> $L(y, f )$, the learning problem is to minimize</li>
</ul>
<script type="math/tex; mode=display">
\begin{align}
\mathcal E(f)&=E_{P(X,Y)}[L(Y,f(X))]=1-P(Y=f(X))\\
&=1-\int_{\mathcal X}P(Y=f(X)|X=x)p_X(x)\text dx
\end{align}</script><ul>
<li>Bayes rule : $f^{∗} (x) = \arg \max_c P(Y = c|X = x)$ , <font color="grey">“the most probable label under the conditional probability on x”</font></li>
<li>Bayes Error Rate (贝叶斯误差) : $\text{inf}_{f}\varepsilon (f)=$ $\color{red}\mathcal E(f^{\ast})$ $=1-P(Y=f^{\ast}(X))$</li>
<li><strong>Bayes Decision Boundary</strong> (贝叶斯决策边界) : the boundary separating the <strong>K partition</strong> domains in $\mathcal X$ on each of which $f^{ ∗ }(x) \in Y$ is constant. For binary classiﬁcation, it is the level set on which $P(Y=1|X=x)=P(Y=0|X=x)=0.5$<ul>
<li><font color="green">Recall : Decision boundary of 15NN is smoother than that of 1NN</font> 



</li>
</ul>
</li>
</ul>
<font color="red">Analysis of 1NN</font>

<ul>
<li>1NN error rate is twice the Bayes error rate<ul>
<li>Bayes error $=1-p_{c^\ast}(x)$ where $c^\ast=\arg\max_{c}p_c(x)$</li>
<li>Assume the samples are i.i.d. (独立同分布) , for any test sample $x$ and small $\delta$, there is always a training sample $z \in B(x, \delta)$ (the label of $x$ is the same as that of $z$), then 1NN error is</li>
</ul>
</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\begin{align}<br>\epsilon=\sum_{c=1}^{C}p_c(x)(1-p_c(z))\overset{\delta\to 0}{\longrightarrow}&amp;1-\sum_{c=1}^{C}p_{c}^{2}(x) \\<br>\le\ &amp;1-p_{c^\ast}^{2}(x) \\<br>\le\ &amp;2(1-p_{c^\ast}(x))<br>\end{align}<br>$</p>

</blockquote>
<ul>
<li><ul>
<li><font color="green">Remark : In fact,</font> $\color{green}\epsilon\le 2(1-p_{c^\ast}^{2}(x))-\frac{C}{C-1}(1-p_{c^\ast}^{2}(x))^2$</li>
</ul>
</li>
</ul>
<font color="blue">Case : Use kNN to diagnose breast cancer (cookdata) </font>

<ul>
<li>We have to consider its radius, texture (质地) , perimeter, area, smoothness, etc. (n-dimension)</li>
<li>Data scaling : 0-1 scaling or z-score scaling</li>
<li>Use code to assist</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line">KNeighborsClassifier(n_neighbors = <span class="number">10</span>, metric = <span class="string">&#x27;minkowski&#x27;</span>, p = <span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="Decision-Tree"><a href="#Decision-Tree" class="headerlink" title="Decision Tree"></a>Decision Tree</h3><ul>
<li>Tree structure : internal nodes indicate features, while leaf nodes represent classes.</li>
<li>Start from root, choose a suitable feature $x_i$ and its split point $c_i$ at each internal node, split the node to two child nodes depending on whether $x_i \le c_i$ , until the child nodes are pure.</li>
<li>Equivalent to rectangular partition of the region.</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th><img src="/2024/06/24/Big-Data-2/bd11.png" width="60%"></th>
<th><img src="/2024/06/24/Big-Data-2/bd12.png" width="60%"></th>
</tr>
</thead>
<tbody>
<tr>
<td><p align="center"><a name="tree">Tree structure</a></p></td>
<td><p align="center">Rectangular partition</p></td>
</tr>
</tbody>
</table>
</div>
<ul>
<li>How to choose <font color="red">features</font> and <font color="red">split points</font> ?<ul>
<li>Impurity : choose the feature and split point so that after each slit the impurity should decrease the most</li>
<li>Impurity(M0)-Impurity(M12) &gt; Impurity(M0)-Impurity(M34), choose A as split node ; otherwise choose B</li>
</ul>
</li>
</ul>
<div align="center"><img src="/2024/06/24/Big-Data-2/bd13.png" alt="bd13" style="zoom:80%"></div>

<ul>
<li>Impurity Measures<ol>
<li>GINI Index<ul>
<li>Gini index of node $t$ : $Gini(t)=1-\sum_{c=1}^C (p(c|t))^2$ where $p(c|t)$ is the proportion of class-c data in node $t$</li>
<li>Gini index of a split : $Gini_{split}=\sum_{k=1}^{K}\frac{n_k}{n}Gini(k)$ where $n_k$ is the number of samples in the child node $k$, $n=\sum_{k=1}^{K} n_k$ </li>
<li>Choose the split so that $Gini(t) − Gini_{split}$ is maximized</li>
</ul>
</li>
<li>Information Gain<ul>
<li>Entropy at $t$ : $H(t) = −\sum_{c=1}^{C}p(c|t)\log_2 p(c|t)$ , </li>
<li>where $t$ is the node and $\color{blue}c$ <font color="blue">represents that this node is chosen</font>.</li>
<li>Maximum at $log_2 C$, when $p(c|t)=\frac{1}{C}$</li>
<li>Minimum at $0$, when $p(c|t)=1$ for some $c$</li>
</ul>
</li>
<li>Misclassiﬁcation Error<ul>
<li>Misclassiﬁcation error at t : $\text{Error}(t) = 1 − \max_c p(c|t)$  (use majority vote)</li>
<li>Maximum at $1−\frac{1}{C}$, when $p(c|t) = \frac{1}{C}$</li>
<li>Minimum at $0$, when $p(c|t)=1$ for some $c$</li>
</ul>
</li>
</ol>
</li>
<li>Compare Three Measure<ul>
<li>Gini index and information gain should be used when growing the tree</li>
<li>In pruning, all three can be used (typically misclassiﬁcation error)</li>
</ul>
</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">Algorithm</th>
<th style="text-align:center">Type</th>
<th style="text-align:center">Impurity Measure</th>
<th style="text-align:center">Child Nodes</th>
<th style="text-align:center">Target Type</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">ID3</td>
<td style="text-align:center">Discrete</td>
<td style="text-align:center">Info Gain</td>
<td style="text-align:center">$k\ge 2$</td>
<td style="text-align:center">Discrete</td>
</tr>
<tr>
<td style="text-align:center">C4.5</td>
<td style="text-align:center">Discrete, Continuous</td>
<td style="text-align:center">Info Gain</td>
<td style="text-align:center">$k\ge 2$</td>
<td style="text-align:center">Discrete</td>
</tr>
<tr>
<td style="text-align:center">C5.0</td>
<td style="text-align:center">Discrete, Continuous</td>
<td style="text-align:center">Info Gain</td>
<td style="text-align:center">$k\ge 2$</td>
<td style="text-align:center">Discrete</td>
</tr>
<tr>
<td style="text-align:center">CART</td>
<td style="text-align:center">Discrete, Continuous</td>
<td style="text-align:center">Gini Index</td>
<td style="text-align:center">$k=2$</td>
<td style="text-align:center">Discrete, Continuous</td>
</tr>
</tbody>
</table>
</div>
<ul>
<li>Tree Pruning (剪枝)<ul>
<li>Too complex tree structure easily leads to <font color="red">overﬁtting</font> (分类太细，模型太复杂)</li>
<li>Prepruning : set threshold <font color="grey">(阈值)</font> $\delta$ for impurity decrease <font color="grey">(剔除杂质)</font> in splitting a node ; if $\Delta \text{Impurity}_{split} \gt \delta$, do slitting, otherwise stop</li>
<li>Postpruning : based on <u>cost function</u> (provided  $|T|$ and $\alpha$)<ul>
<li>$\color{red}\text{Cost}_{ \alpha}(T)=\sum_{t=1}^{|T|}n_t\ \text{Impurity}(t)+\alpha|T|$</li>
<li>Input: a complete tree $T$, $\alpha$</li>
<li>Output: postpruning tree $\text{T}_{\alpha}$ </li>
</ul>
<ol>
<li>Compute $\text{Impurity}(t)$ for $\forall t$</li>
<li>Iteratively merge child nodes <strong>bottom-up</strong> : Suppose $\text{T}_{A}$ and $\text{T}_{B}$ are the trees before and after merging, do merging if $\text{Cost}_{ \alpha}(\text{T}_{A}) \ge \text{Cost}_{ \alpha}(\text{T}_{B})$   <font color="grey">(剪枝前损失更大)</font></li>
</ol>
</li>
</ul>
</li>
</ul>
<ul>
<li>Pros and Cons<ul>
<li>Advantage<ul>
<li>Easy to interpret and visualize : widely used in ﬁnance, medical health, biology, etc.</li>
<li>Easy to deal with missing values (treat as new data type)</li>
<li>Could be extended to regression</li>
</ul>
</li>
<li>Disadvantage<ul>
<li>Easy to be trapped at local minimum because of greedy algorithm (贪心)</li>
<li>Simple decision boundary : parallel lines to the axes (Recall <a href="#tree">Pic above</a>)</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<h3 id="Naive-Bayes-朴素贝叶斯"><a href="#Naive-Bayes-朴素贝叶斯" class="headerlink" title="Naive Bayes (朴素贝叶斯)"></a>Naive Bayes (朴素贝叶斯)</h3><ul>
<li>Based on <strong>Bayes Theorem</strong> and conditional independency assumption on features (Recall <a href="#Bayes">Bayes Classifier</a>)</li>
<li>Bayes Theorem : $\Large{P(Y|X)=\frac{P(X|Y)P(Y)}{P(X)}}$<ul>
<li>$P(Y)$ is prior prob. distribution (先验概率分布) , $P(X|Y )$ is likelihood function (似然函数) , $P(X)$ is evidence (边际概率) , $P(Y |X)$ is posterior prob. distribution (后验概率分布).</li>
</ul>
</li>
<li>The <font color="red">core problem</font> of machine learning is to estimate $P(Y |X)$ </li>
</ul>
<ol>
<li>Let $X = \{X_1, . . . , X_d \}$, for ﬁxed sample $X = x$, $P(X = x)$ is independent of  $Y$ , by Bayes Theorem, $P(Y|X=x)\propto P(X=x|Y)P(Y)$</li>
<li>Assume conditional independency of $X_1, \cdots, X_d$ given $Y = c$ : $P(X=x|Y=c)=\prod_{i=1}^{d}P(X_i=x_i|Y=c)$</li>
<li><font color="red">Naive Bayes Model :</font>

</li>
</ol>
<blockquote class="blockquote-center">
<p>$<br>\color{red}\hat y =\arg \max_c P(Y=c)\prod_{i=1}^{d}P(X_i=x_i|Y=c)<br>$</p>

</blockquote>
<p><strong>Maximum Likelihood Estimate (MLE)</strong></p>
<ul>
<li>Estimate $P(Y = c)$ and $P(X_i = x_i |Y = c)$ from the dataset $D = \{(\textbf{x}_1, y_1), \cdots ,(\textbf{x}_n, y_n)\}$<ol>
<li><strong>MLE</strong> for $P(Y = c)$ : $P(Y = c) =\Large{\frac{ \sum_{i=1}^{n} I(y_i=c)}{n}}$</li>
<li>When $X_i$ is discrete variable with range $\{v_1, \cdots , v_K\}$, <strong>MLE</strong> for $P(X_i = v_k |Y = c) =\Large{\frac{ \sum_{i=1}^{n} I(x_i = v_k |y_i = c)}{ \sum_{i=1}^{n} I(y_i = c)}}$ <br> ( if $X_i$ is continuous, just do discretization on it and use this formula )</li>
</ol>
</li>
</ul>
<hr>
<h3 id="Model-Assessment"><a href="#Model-Assessment" class="headerlink" title="Model Assessment"></a>Model Assessment</h3><p><strong>Confusion Matrix</strong></p>
<div align="center"><img src="/2024/06/24/Big-Data-2/bd14.png" alt="bd14" style="zoom:100%"></div>



<ul>
<li>Representation<ul>
<li>T &amp; F : represents truth of label (标签是否真实)</li>
<li>P &amp; N : represents aspect of label (标签的两面)</li>
</ul>
</li>
<li><p>Two-class classification: </p>
<ul>
<li>$\text{Accuracy} =\large{\frac{\text{TP+TN}}{\text{TN+FN+FP+TP}}}$, not a good index when samples are <font color="red">imbalanced</font></li>
<li>$\text{Precision}=\large{\frac{\text{TP}}{\text{TP+FP}}}$ </li>
<li>TPR : $\text{Recall} = \large{\frac{\text{TP}}{\text{TP+FN}}}$ ; important in medical diagnosis (回收)</li>
<li>F score : $F_{\beta} = \large{\frac{(1+\beta^2)\text{Precision}\times\text{Recall}}{\beta^2 \times \text{Precision}+\text{Recall}}}$ , e.g. $F_1$ score for $\beta=1$</li>
<li>FPR : $\text{Specifity} = \large{\frac{\text{TN}}{\text{TN+FP}}}$ ; recall for negative samples</li>
</ul>
</li>
<li><p>Receiver Operating Characteristic (ROC, 受试者工作特征) and Area Under ROC (AUC)</p>
<ul>
<li>Aim to solve class distribution <font color="red">imbalance problem</font></li>
<li>Set different threshold (阈值) $t$ for continuous predicted values.</li>
<li>Compute <strong>TPR</strong> vs. <strong>FPR</strong> for all $t$ and plot ROC curve</li>
</ul>
</li>
</ul>
<div align="center"><img src="/2024/06/24/Big-Data-2/bd15.png" style="zoom:120%"></div>

<ul>
<li>Beware: Don’t view the “curve” as a function, but as a <strong>continuous set of points</strong>.<ul>
<li>Higher ROC implies better performance (How to measure ? AUC)</li>
</ul>
</li>
<li>AUC: compute the area under ROC curve. The larger the better. Model is good for test set if $AUC \gt 0.75$</li>
</ul>
<p><strong>Cohen’s Kappa Coefficient</strong></p>
<blockquote>
<p>Since ROC and AUC is complex to be quantified, we need a <code>coe</code> to indicate it.</p>
<p>We use an example to explain how to quantified it.</p>
</blockquote>
<blockquote class="blockquote-center">
<p>$<br>\begin{align}<br>&amp;\text{Cohen’s Kappa Coefficient: }&amp; &amp;\kappa=\frac{p_o-p_e}{1-p_e}=1-\frac{1-p_o}{1-p_e} \\<br>&amp;&amp; &amp;p_e=\sum_{c=1}^{C}\frac{n_c^{pred}}{N}\frac{n_c^{true}}{N}<br>\end{align}<br>$</p>

</blockquote>
<ul>
<li>$p_o$ is the accuracy</li>
<li>$p_e$ is the hypothetical probability of chance agreement</li>
</ul>
<div align="center"><img src="/2024/06/24/Big-Data-2/bd16.png" alt="bd16" style="zoom:100%"></div>

<p>E.g.  $\large{p_o=\frac{20+15}{50}=0.7}$, $\large{p_e=\frac{25}{50}\times\frac{20}{50}+\frac{25}{50}=0.5}$, then $\large{\kappa=0.4}$</p>
<ul>
<li>$\kappa \in [-1,1]$, $\kappa\ge 0.75$ for good performance and $\kappa\lt 0.4$ for bad one.</li>
</ul>
<hr>
<h2 id="V-Regression"><a href="#V-Regression" class="headerlink" title="V. Regression"></a>V. Regression</h2><h3 id="Linear-Model"><a href="#Linear-Model" class="headerlink" title="Linear Model"></a>Linear Model</h3><p><strong>Linear model</strong> : </p>
<ul>
<li>For <strong>Univariate</strong> linear model,  $y = w_0 + w_1x + \epsilon$, where $w_0$ and $w_1$ are regression coeﬃcients, $\epsilon$ is the error or noise</li>
</ul>
<p>Assume $\epsilon ∼ \mathcal N (0, \sigma^2)$, where $σ^2$ is a ﬁxed but unknown variance; then $y|x ∼ \mathcal N (w_0 + w_1x, σ^2)$</p>
<script type="math/tex; mode=display">
(\hat{w}_0,\hat{w}_1)= \arg \min_{w_0,w_1}\sum_{i=1}^{n}(y_i-w_0-w_1x_i)^2</script><p>which means $L(\hat w_0,\hat w_1)$ is minimized (残差最小).</p>
<ul>
<li>For <strong>multivariate</strong> linear model, $y=f(\textbf{x})=w_0+w_1x_1+w_2x_2+\cdots+w_px_p + \epsilon$ <ul>
<li>where $w_0, w_1,\cdots, w_p$ are <font color="red">regression coefficients</font>, $\textbf{x} = (x_1,\cdots, x_p)^T$ is the input vector whose components are independent variables or attribute values, $\epsilon \thicksim \mathcal N(0, σ^2)$ is the noise.</li>
<li>For the size n samples $\{(\textbf{x}_i, y_i)\}$, let $\textbf{y} = (y_1, \cdots , y_n)^T$ be the response or dependent variables, $\textbf{w} = (w_0, w_1, \cdots, w_p)^T$,  we construct a matrix $\textbf{X}=[\textbf{1}_n, (\textbf{x}_1, \cdots,\textbf{x}_n)^T]\in \mathbb R^{n \times(p+1)}$ , and $\textbf{\varepsilon}=(\epsilon_1,\cdots,\epsilon_n)^T \thicksim \mathcal N(\textbf{0},\sigma^2\textbf{l}_n)$ </li>
</ul>
</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\begin{align}<br>&amp;\textbf{y}=\textbf{X}\textbf{w} + \varepsilon\\ \\<br>&amp;\textbf{X}=<br>\begin{pmatrix}<br>1 &amp; x_{11} &amp; \cdots &amp; x_{1p} \\<br>1 &amp; x_{21} &amp; \cdots &amp; x_{2p} \\<br>\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\<br>1 &amp; x_{n1} &amp; \cdots &amp; x_{np}<br>\end{pmatrix}<br>\end{align}<br>$</p>

</blockquote>
<p><strong>Least Square (LS)</strong> <font color="grey" size="3">最小二乘法</font></p>
<div><img src="/2024/06/24/Big-Data-2/bd17.png" style="zoom:60%"></div>

<ul>
<li>From geometry aspect, we should <strong>minimize the residual sum-of-square (残差平方和)</strong>: <br>$\text{RSS}(\textbf{w})=\sum_{i=1}^{n} (y_i-w_0-w_1x_1-\cdots-w_px_p)^2=|\textbf{y} - \textbf{X} \textbf{w}|_{2}^2$<ul>
<li>When $\textbf{X}^T\textbf{X}$ is invertible, the <strong>minimizer</strong> $\hat{\textbf{w}}$ satisfy :  （可证明 $\hat w$ 是无偏估计）</li>
</ul>
</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\nabla_{\textbf{w}}\text{RSS}(\hat{\textbf{w}})=0 \Rightarrow \hat{\textbf{w}}=(\textbf{X}^T \textbf{X})^{-1}\textbf{X}^T \textbf{y}<br>$</p>

</blockquote>
<ul>
<li><ul>
<li>Then prediction $\hat{\textbf{y}}=\textbf{X}(\textbf{X}^T \textbf{X})^{-1}\textbf{X}^T \textbf{y}= \textbf{P} \textbf{y}$ is a projection of $\textbf{y}$ onto the linear space spanned by the column vectors of $\textbf{X}$; (As Pic 15 show)<ul>
<li>$\textbf{P}=\textbf{X}(\textbf{X}^T \textbf{X})^{-1}\textbf{X}^T$ is the projection matrix satisfying $\textbf{P}^2 = \textbf{P}$ <font color="green">(Recall: Linear Algebra)</font></li>
</ul>
</li>
</ul>
</li>
</ul>
<blockquote>
<p>Optimal Method: Ordinary least square (<strong>OLS</strong>)</p>
<ol>
<li>Get mean values from sample set: $\bar y=\frac{1}{n}\sum_{i=1}^{n}y_i$ , $\bar{\textbf{x}}=\frac{1}{n}\sum_{i=1}^{n}{ \textbf{x}_i}$</li>
<li>Centralize data (minus by $\bar y$ and $\bar{\textbf{x}}$) and calculate $RSS(\tilde{\textbf{w}})$ </li>
<li>Prediction $\hat{\textbf{y}}= \textbf{P} \textbf{y}$ is the projection (投影) of $\textbf{y}$ on the <em>linear space spanned</em> by the columns of $\textbf{X}$. <br>$\mathcal X= \text{Span} \{ \textbf{x}_{\cdot ,0}, \textbf{x}_{\cdot ,1},\cdots,  \textbf{x}_{\cdot ,p}\}$ , recall that $ \textbf{x}_{\cdot ,0}= \textbf{1}_n$</li>
<li>If $\{ \textbf{x}_{\cdot ,0}, \textbf{x}_{\cdot ,1},\cdots,  \textbf{x}_{\cdot ,p}\}$ forms a set of orthonormal basis (标准正交基) , then $\hat{\textbf{y}}=\sum_{i=0}^{p}&lt;\textbf{y}, \textbf{x}_{\cdot ,i}&gt; \textbf{x}_{\cdot ,i}$</li>
<li>If not, do orthogonalization by Gram-Schmidt procedure for the set $\{ \textbf{x}_{\cdot ,0}, \textbf{x}_{\cdot ,1},\cdots,  \textbf{x}_{\cdot ,p}\}$ </li>
</ol>
</blockquote>
<ul>
<li>From mathemetic aspect, it’s about <strong>MLE</strong> (Result the same)<ol>
<li>Likelihood function: $L((\textbf{w},\textbf{X}),\textbf{y})=P(\textbf{y}|(\textbf{X}, \textbf{w}))=\prod_{i=1}^{n}P(y_i|(\textbf{x}_i, \textbf{w}))$ </li>
<li>Find <strong>MLE</strong>: $\hat{\textbf{w}}=\arg \max_{\textbf{w}} L(\textbf{w} ; \textbf{X}, \textbf{y})$ (E.g. For $P(y_i|(\textbf{x}_i, \textbf{w}))=\frac{1}{\sqrt{2\pi}\sigma} \Large{e^{-\frac{(y_i-w_0-w_1x_{i1}-\cdots-w_px_{ip})^2}{2\sigma^{2}}}}$)</li>
<li><font color="blue">(2.) is equivalent to its log-function:</font><br> E.g.  $l(\textbf{w} ; \textbf{X}, \textbf{y})= \log{L(\textbf{w} ; \textbf{X}, \textbf{y})}=-n\log(\sqrt{2\pi}\sigma)-\frac{1}{2\sigma^{2}} \sum_{i=1}^{n} (y_i-w_0-w_1x_{i1}-\cdots-w_px_{ip})^2$ </li>
<li>Then get the same minimizer as <strong>LS</strong> : $\hat{\textbf{w}}=(\textbf{X}^T \textbf{X})^{-1}\textbf{X}^T \textbf{y}$</li>
</ol>
</li>
</ul>
<p><strong>Shortcomings of Fitting Nonlinear Data</strong> (上述方法仅适合线性回归)</p>
<ul>
<li>Evaluating the model by Coefficient of Determination $R^2$<ul>
<li>$R^2 := 1-\frac{ \text{SS}_{res}}{ \text{SS}_{tot}}$ ($=\frac{ \text{SS}_{reg}}{ \text{SS}_{tot}}$ only for linear regression), where<ul>
<li>$ \text{SS}_{tot} = \sum_{i=1}^{n} (y_i-\bar y)^2$ is the total sum of squares</li>
<li>$ \text{SS}_{reg} = \sum_{i=1}^{n} (\hat y_i-\bar y)^2$ is the regression sum of squares</li>
<li>$ \text{SS}_{res} = \sum_{i=1}^{n} (y_i-\hat y_i)^2$ is the residual sum of squares.</li>
</ul>
</li>
<li>The larger the $R^2$, the better the model !</li>
</ul>
</li>
<li><strong>Multicolinearity</strong> [多重共线性]<ul>
<li>If the columns of $\textbf{X}$ are almost linearly dependent (multicolinearity), then $\det(\textbf{X}^{T}\textbf{X})\approx 0$, the diagonal entries in $(\textbf{X}^{T}\textbf{X})^{-1}$ is quite large, leading to a large variances of $\hat{\textbf{w}}$ (inaccurate).</li>
<li>Remedies (补救措施): ridge regression (岭回归), principal component regression (主属性回归), partial least squares regression (部分最小二乘回归), etc.</li>
</ul>
</li>
<li>Overfitting<ul>
<li>Linear regression easily to be overfitted when introducing more variables.</li>
<li>Solution: <a href="#regul">Regularization</a></li>
</ul>
</li>
</ul>
<p><strong>Bias-Variance Decomposition</strong></p>
<ul>
<li>Bias (偏差): $\text{Bias}(\hat f(\textbf{x}))=\text{E}_\text{train}\hat f(\textbf{x})-f(\textbf{x})$ , average <strong>accuracy</strong> of prediction for the model (deviation from the truth)</li>
<li>Variance (方差): $\text{Var}(\hat f(\textbf{x}))=\text{E}_\text{train}(\hat f(\textbf{x})-\text{E}_\text{train}\hat f(\textbf{x}))^2$ , <strong>variability</strong> of the model prediction due to different data set (stability)</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\color{red}<br>\text{E}_\text{train}\text{R}_\text{exp}(\hat f(\textbf{x}))=\text{E}_\text{train}\text{E}_\text{P}[(y-\hat f(\textbf{x}))^2|\textbf{x}] = \underbrace{\text{Var}(\hat f(\textbf{x}))}_{\text{variance}}+\underbrace{\text{Bias}^2(\hat f(\textbf{x}))}_{\text{bias}}+\underbrace{\sigma^2}_{\text{noise}}<br>$</p>

</blockquote>
<div><img src="/2024/06/24/Big-Data-2/bd19.png" style="zoom:80%"></div>

<ul>
<li>The more complicated the model, the lower the bias, but the higher the variance.</li>
</ul>
<div><img src="/2024/06/24/Big-Data-2/bd18.png" style="zoom:90%"></div>

<ul>
<li>kNN Regression<ul>
<li>kNN can be used to do regression if the mode (majority vote) is replaced by mean : $\hat f(x)=\frac{1}{k} \sum_{ x_{(i)} \in N_{k}(x)} y_{(i)}$</li>
<li>Generalization error of kNN regression is</li>
</ul>
</li>
</ul>
<div><img src="/2024/06/24/Big-Data-2/bd20.png" style="zoom:80%"></div>

<p>where we have used the fact that $E_{ \text{train}} y_{i} = f(\textbf{x}_{i})$ and $\text{Var}(y_i)=\sigma^2$</p>
<ul>
<li>For small $k$, overfitting, bias ↓, variance ↑</li>
<li>For large $k$, underfitting, bias ↑, variance ↓</li>
</ul>
<hr>
<h3 id="Regularization-正则化"><a href="#Regularization-正则化" class="headerlink" title="Regularization (正则化)"></a><a name="regul">Regularization</a> (正则化)</h3><blockquote>
<p>Why we need Regularization ?</p>
<ul>
<li>In <strong>high dimensions</strong>, the more the input attributes, the larger the <strong>variance</strong></li>
<li>Shrinking some coefficients or setting them to zero can reduce the <strong>overfitting</strong></li>
<li>Using less input variables also help interpretation with the most important variables</li>
<li>Subset selectionµretaining only a subset of the variables, while eliminating the rest variables from the model</li>
</ul>
</blockquote>
<h4>Best-Subset Selection</h4>

<ul>
<li>find for each $k ∈ \{0, 1, \cdots , p\}$ the subset $S_k \subset \{1,\cdots, p\}$ of size $k$ that gives the smallest $\text{RSS}(\textbf{w}) = \sum_{i=1}^n (y_i − w_0 − \sum_{j\in S_k} w_j x_{ij})^2$ </li>
<li>Noted that the best subset of size $k + 1$ may not include the the variables in the best subset of size $k$</li>
<li>Choose $k$ based on <strong>bias-variance tradeoff</strong>, usually by <strong>AIC</strong> and <strong>BIC</strong>(贝叶斯信息量), or practically by <strong>cross-validation</strong></li>
</ul>
<h5>Forward-stepwise selection</h5>

<ul>
<li>Start with the intercept (截距?) $\bar y$ , then sequentially add into the model the variables that improve the fit most (reduce RSS most)</li>
<li><font color="red">QR factorization</font> helps search the candidate variables to add </li>
<li><font color="red">Greedy algorithm</font> : the solution could be sub-optimal</li>
</ul>
<h5>Backward-stepwise selection</h5>

<ul>
<li>Start with the <font color="red">full model</font>, then sequentially delete from the model the variables that has the least impact on the fit most </li>
<li>The candidate for dropping is the variable with the smallest <a href="/2024/06/22/Big-Data-1/index.html#z-score">Z-score</a> </li>
<li>Can only be used when $n &gt; p$ in order to fit the full model by <strong>OLS</strong></li>
</ul>
<h5><font color="red">Regularization by Penalties</font></h5>

<ul>
<li>Add a penalty term, in general $l_q$ - norm</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\sum_{i=1}^{n}(y_i-w_0-w_1x_1-\cdots-w_px_p)^2+\lambda |\textbf{w}|^q_q=|\textbf{y}-\textbf{X}\textbf{w}|^2+\lambda |\textbf{w}|^q_q<br>$</p>

</blockquote>
<ul>
<li>By arranging $\lambda$ , we can correct the overfitting (bias inc. &amp; var dec.)</li>
<li><code>q = 2</code> for Ridge Regression &amp; <code>q = 1</code> for LASSO Regression</li>
</ul>
<div align="center"><img src="/2024/06/24/Big-Data-2/bd26.png" style="zoom:60%"></div>



<h4>Ridge Regression</h4>

<font color="#ff44ff">$\hat w=\arg \underset{w}\min {\|y-Xw\|_2^2}+\lambda\|w\|_2^2$</font> 

<div align="center"><img src="/2024/06/24/Big-Data-2/bd21.png" style="zoom:50%"></div>

<blockquote>
<p>Solving Ridge Regression</p>
</blockquote>
<div align="center"><img src="/2024/06/24/Big-Data-2/bd22.png" style="zoom:50%"></div>



<blockquote>
<p>Bayesian Viewpoint of Ridge Regression</p>
</blockquote>
<div align="center"><img src="/2024/06/24/Big-Data-2/bd23.png" style="zoom:60%"></div>

<hr>
<h4>LASSO Regression</h4>

<blockquote>
<p>Can be used to estimate the coefficients and select the important variables simultaneously</p>
<p>Reduce the model complexity, avoid overfitting, and improve the generalization ability</p>
</blockquote>
<font color="#ff44ff">$\hat w=\arg \underset{w}\min {\|y-Xw\|_2^2}+\lambda\|w\|_1$</font> 

<p>Two Rpoperties : </p>
<ul>
<li>Shrinkage (将所有点收缩)</li>
<li>Selection (将近点归零，远点收缩)</li>
</ul>
<table>
    <tr>
        <td><img align="center" src="/2024/06/24/Big-Data-2/bd24.png" style="zoom:50%"></td>
        <td><img align="center" src="/2024/06/24/Big-Data-2/bd25.png" style="zoom:50%"></td>
    </tr>
    <tr>
        <td colspan="2"><center><font size="2">LASSO Regression</font></center></td>
    </tr>
</table>

<blockquote class="blockquote-center">
<p>$<br>\hat w_i^{\text{lasso}} = (|\hat w^{OLS}_i| − \lambda)+\text{sign}(\hat w^{OLS}_i)<br>$</p>

</blockquote>
<ul>
<li>Solving LASSO by <strong>LARS</strong> (最小角回归算法)<ol>
<li>Start with all coefficients $w_i$ equal to zero</li>
<li>Find the predictor $x_i$ most correlated with $y$ (一般认为夹角最小的即是)</li>
<li>Increase the coefficient $w_i$ in the direction of the sign of its correlation with $y$. Take residuals $r = y − \hat y$ along the way. Stop when some other predictor $x_k$ has as much correlation with $r$ as $x_i$ has (调整参数 $w$ 直至下一个分量夹角最小)</li>
<li>Increase $(w_i, w_k)$ in their joint <strong>least squares direction</strong>, until some other predictor $x_m$ has as much correlation with the residual $r$</li>
<li>Continue until all predictors are in the model</li>
</ol>
</li>
</ul>
<center><img src="/2024/06/24/Big-Data-2/bd27.png" style="zoom:70%"><font size="2">Pic 19. LARS</font></center>



<blockquote>
<p>Optional: Maximum A Posteriori (<strong>MAP</strong>) Estimation</p>
<ul>
<li><p>Given $\theta$ , the conditional distribution of $\textbf{y}$ is $P(\textbf{y}|\theta)$</p>
</li>
<li><p><strong>MAP</strong> choose the point of maximal posterior probability :</p>
<p> $\hat{\theta}^{MAP}=\arg \underset{\theta}\max{(\log P(\textbf{y}|\theta)+\log P(\theta))}$</p>
</li>
<li><p>If $\theta=\textbf{w}$, and we choose the log-prior <font color="grey">[对数先验]</font> (i.e. normal prior  $\mathcal N(0, \frac{\sigma^2}{\lambda} \textbf{I})$ ) , we revocer the ridge regression.</p>
</li>
<li><p><font color="#ff7575">Different log-prior lead to different penalties</font> (Not general case. Some penalties may not be the logarithms[对数] of probability distributions, some other penalties depend on the data)</p>
</li>
</ul>
<p>Related Regularization Models</p>
<ul>
<li>Elastic net (混合回归) : $\hat{\textbf{w}}=\arg\min_w|y-Xw|_2^2+\lambda_1|\textbf{w}|^2_2+\lambda_2|\textbf{w}|_1$ </li>
<li>Group LASSO (对不同分组进行回归) : $\hat{\textbf{w}}=\arg\min_w|y-Xw|_2^2+\sum_{g=1}^{G}\lambda_{g}|\textbf{w}_{g}|_2$ , where $\textbf{w}=(w_1,\cdots,w_G)$ is the <strong>group partition</strong> of $\textbf{w}$. </li>
<li>Dantzig Selector : …</li>
<li>Smoothly clipped absolute deviation (<strong>SCAD</strong>) penalty</li>
<li>Adaptive LASSO</li>
</ul>
</blockquote>
<h4>ADMM Used in LASSO Problem</h4>

<p><strong>Altinating Direction Method of Multipliers (ADMM)</strong></p>
<ul>
<li>ADMM [交替方向乘子法] often used to solve problems with two optimized variables which only has equality constraint. </li>
<li><p>Normal Form as below :</p>
<script type="math/tex; mode=display">
\min_{x,z} f(x)+g(z)\\ s.t.\ Ax+Bz=c</script></li>
<li><p>where $x\in R^{n}$ and $z\in R^{m}$ are optimized variables, and in the equality constraint, $A\in R^{p\times n}$ , $B\in R^{p\times m}$ , $c\in R^{p}$ , and $f$ and $g$ are <font color="red">convex functions (凸函数)</font></p>
</li>
</ul>
<center>------ Solution ------</center>

<ol>
<li>Define Augmented Lagrangian (增广拉格朗日函数)</li>
</ol>
<script type="math/tex; mode=display">
L_{\rho}(x,z,u)=f(x)+g(z)+u^{T}(Ax+Bz-c)+\frac{\rho}{2}\|Ax+Bz-c\|^2</script><ul>
<li>If we let $w=\frac{u}{\rho}$ , then we can get simplified form of Augmented Lagrangian</li>
</ul>
<script type="math/tex; mode=display">
L_{\rho}(x,z,u)=f(x)+g(z)+\frac{\rho}{2}\|Ax+Bz-c+w\|_2^2-\frac{\rho}{2}\|w\|_2^2</script><ol>
<li>Algorithm : fixed other variables and update only one of them (Here $\rho\gt 0$ is a penalty parameter)</li>
</ol>
<script type="math/tex; mode=display">
\begin{align}
&\text{for }k=1,2,3,...\\
&\text{step 1: } x^{(k)}=\arg\min_{x}L_{\rho}(x,z^{(k-1)},w^{(k-1)})=\arg\min_{x} f(x)+\frac{\rho}{2}\|Ax+Bz^{(k-1)}-c+w^{(k-1)}\|_2^2 \\
&\text{step 2: } z^{(k)}=\arg\min_{z}L_{\rho}(x^{(k)},z,w^{(k-1)})=\arg\min_{z} g(z)+\frac{\rho}{2}\|Ax^{(k)}+Bz-c+w^{(k-1)}\|_2^2 \\
&\text{step 3: } w^{(k)}=w^{(k-1)}+Ax^{(k)}+Bz^{(k)}-c
\end{align}</script><ol>
<li><strong>Consider LASSO Problem</strong> <ul>
<li>To find $\min_{w} \frac{1}{2}|y-Xw|^2_2+\lambda|w|_1$ </li>
<li>Let $w=\beta$ (the constraint : $w-\beta=0$) and rewrite the Augmented Lagrangian : $L_{\rho}(w,\beta,u)=\frac{1}{2}|y-Xw|^2_2+\lambda|\beta|_1+u^T(w-\beta)+\frac{\rho}{2}|w-\beta|_2^2$</li>
</ul>
</li>
</ol>
<h3 id="Model-Assessment-1"><a href="#Model-Assessment-1" class="headerlink" title="Model Assessment"></a>Model Assessment</h3><ul>
<li>Mean absolute error (MAE) : $MAE =\frac{1}{n} \sum_{i=1}^{n} |y_i - \hat y_i|$</li>
<li>Mean square error (MSE) : $MSE =\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat y_i)^2$ </li>
<li>Root mean square error (RMSE) : $RMSE = \sqrt{\frac{1}{n} (y_i - \hat y_i)^2}$</li>
<li><p>Coefficient of Determination [决定系数] <font color="green">(Recall)</font> : $R^2:=1-\frac{\text{SS}_{\text{res}}}{\text{SS}_{\text{tot}}}$ , <br>where $\text{SS}_{\text{tot}}=\sum_{i=1}^n (y_i-\bar y_i)^2$  and  $\text{SS}_{\text{res}}=\sum_{i=1}^n (y_i-\hat y_i)^2$ </p>
<ul>
<li>Normally $R^2\in[0,1]$ , but it can be negative (a wrong model making residual too large). </li>
<li><font color="red">The larger the $R^2$ , the better the model.</font>
</li>
</ul>
</li>
<li><p>Adjusted Coefficient of Determination</p>
</li>
</ul>
<script type="math/tex; mode=display">
R_{\text{adj}}^2=1-\frac{(1-R^2)(n-1)}{n-p-1}</script><ul>
<li>$n$ is  the number of samples, $p$ is the dimensionality (or the number of attributes)</li>
<li><font color="red">The larger the $\text{R}_{\text{adj}}^2$ value, the better performance the model</font></li>
<li>When adding important variables into the model, $\text{R}_{\text{adj}}^2$ gets larger and $\text{SS}_{\text{res}}$ is reduced</li>
</ul>
<hr>
<h2 id="VI-Classification-II"><a href="#VI-Classification-II" class="headerlink" title="VI. Classification II"></a>VI. Classification II</h2><blockquote>
<p>Why talk about Regression first ?</p>
<ul>
<li>Naive Bayes uses Probability and Mathemetic methods, which is the core of Regression</li>
<li>Regression all apply <strong>MLE</strong>, which is connected with Bayes rules.</li>
</ul>
</blockquote>
<h3 id="Logistic-Regression"><a href="#Logistic-Regression" class="headerlink" title="Logistic Regression"></a>Logistic Regression</h3><blockquote>
<p>逻辑回归是一种分类方法（不是回归）</p>
</blockquote>
<font color="green">Recall: Linear Regression</font>

<ul>
<li>$E(y|x)=P(y=1|x)=w_0+w_1x$ , but $w_0+w_1x$ may be not probability</li>
<li>Use <strong>Sigmoid function</strong> to map it to $\left[0,1\right]$ : $g(z)=\frac{1}{1+e^{-z}}$ , where $z=w_0+w_1x_1+\cdots+w_dx_d$</li>
<li><font color="red">Equivalently</font>, $\log{\frac{P(y=1|x)}{1-P(y=1|x)}}=w_0+w_1x_1+\cdots+w_dx_d$</li>
</ul>
<script type="math/tex; mode=display">
\text{logit}(z)=\log\frac{z}{1-z}</script><p><strong>MLE for Logistic Regression</strong></p>
<ul>
<li>The prob. distribution for two-class logistic regression model is <ul>
<li>$Pr(y=1|X=x)=\frac{\exp(\textbf{w}^T \textbf{x})}{1+\exp(\textbf{w}^T \textbf{x})}$</li>
<li>$Pr(y=0|X=x)=\frac{1}{1+\exp(\textbf{w}^T \textbf{x})}$</li>
</ul>
</li>
<li>Let $P(y=k|X=x)=p_k(\textbf{x};\textbf{w})$, $k=0,1$. The <font color="red">likelihood function</font> is $L(\textbf{w})=\prod_{i=1}^{n} p_{y_i}(\textbf{x}_i;\textbf{w})$</li>
<li>MLE of $\textbf{w}$ : $\hat{\textbf{w}}=\arg \underset{\textbf{w}}\max L(\textbf{w})$</li>
<li>Solve $\color{red}\nabla_{\textbf{w}}\log L(\textbf{w})=0$ by Newton-Raphson method</li>
</ul>
<blockquote>
<p>用 MLE 计算 $\hat{\textbf{w}}$ ，需要提前知道 $x$ 的分布，所以逻辑回归是一种分类算法。</p>
</blockquote>
<h3 id="Linear-Discriminant-Analysis-LDA"><a href="#Linear-Discriminant-Analysis-LDA" class="headerlink" title="Linear Discriminant Analysis (LDA)"></a>Linear Discriminant Analysis (LDA)</h3><blockquote>
<p>线性判别分析，是一种监督学习的降维方法（无监督学习一般用<strong>PCA</strong>，主成分分析来降维）</p>
</blockquote>
<font color="green">Recall: Naive Bayes</font>

<ul>
<li>By <strong>Bayes Theorem</strong>: $P(Y|X=x)\propto f_k(\textbf{x})\pi_{k}$ , where $f_k(\textbf{x})=P(\textbf{X}=\textbf{x}|Y=k)$ is be the <font color="red">density function</font> of samples in each class $Y=k$, $\pi_k=P(Y=k)$ is the <font color="red">prior probability</font>.</li>
<li>Assume $f_k (\textbf{x})$ is multivariate Gaussian (多元高斯分布) : $f_k(x)=\large{\frac{1}{(2\pi)^{p/2} |\Sigma_k}^{1/2}|e^{\frac{1}{2}(x-\mu_k)^T\Sigma_k^{-1}(x-\mu_k)}}$ , with a common covariance matrix (协方差矩阵) $\Sigma_k$ <font color="grey">(注：多元高斯可以表示为向量和矩阵乘积的形式，如上)</font></li>
<li>For the decision boundary between class $k$ and $l$, the <strong>log-ratio</strong> of their posteriors (后验) $P(Y|X)$ is</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\log{\frac{P(Y=k|\textbf{X}=\textbf{x})}{P(Y=l|\textbf{X}=\textbf{x})}}=\log{\frac{\pi_k}{\pi_l}}-\frac{1}{2}(\mu_k+\mu_l)^T\Sigma_k^{-1}(\mu_k-\mu_l)+\textbf{x}^T \Sigma^{-1}(\mu_k-\mu_l)<br>$</p>

</blockquote>
<ol>
<li><p>From log-ratio, we can get <font color="red">Linear discriminant functions</font>(e.g. for class $k$) : $\delta_k(\textbf{x})=\textbf{x}^T\Sigma^{-1}\mu_k-\frac{1}{2}\mu_k^T\Sigma^{-1}\mu_k+\log\pi_k$ </p>
</li>
<li><p>Then the log-ratio become : $\log{\frac{P(Y=k|\textbf{X}=\textbf{x})}{P(Y=l|\textbf{X}=\textbf{x})}}=\delta_k(\textbf{x})-\delta_l(\textbf{x})$ </p>
<blockquote>
<p>相减结果是一个一次方程（线性）</p>
</blockquote>
</li>
<li><p>Decision Rule(分类依据) : $k^{\ast}=\arg\max_k \delta_k(\textbf{x})$</p>
</li>
</ol>
<p><strong>Two-class LDA</strong></p>
<ul>
<li>LDA rule classifies to <strong>class 2</strong> if</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>(\textbf{x}-\frac{\hat\mu_1+\hat\mu_2}{2})^T \Sigma^{-1}(\hat\mu_2-\hat\mu_1)+\log{\frac{\hat\pi_2}{\hat\pi_1}}\gt 0<br>$</p>

</blockquote>
<ul>
<li>Discriminant direction : $\beta=\Sigma^{-1}(\hat\mu_2-\hat\mu_1)$ </li>
</ul>
<center><img src="/2024/06/24/Big-Data-2/bd28.png" style="zoom:50%"><font size="2">Pic 20. Two-class LDA</font></center>

<blockquote>
<p>$\hat\mu$ 看作图中椭圆的中心，图中的 $w$ 为投影方向。由上述公式计算可得到样本在投影基向量上的方向，从而判断其类别</p>
<p>从定性上看，投影的作用是降维，选择的投影空间应当是能将不同类数据点在映射后尽可能分开（或同类的点尽可能紧凑）。</p>
</blockquote>
<h3 id="Neural-Network"><a href="#Neural-Network" class="headerlink" title="Neural Network"></a>Neural Network</h3><center><img src="/2024/06/24/Big-Data-2/bd29.png" style="zoom:70%"><font size="2">Pic 21. NN</font></center>

<script type="math/tex; mode=display">
\hat y=g(w_0+\sum_{i=1}^{m} x_iw_i)</script><ul>
<li>$\hat y$ is Output</li>
<li>$g$ is a <font color="red">Non-linear activation function</font> (非线性激活函数)</li>
<li>$w_0$ is the Bias</li>
</ul>
<center><img src="/2024/06/24/Big-Data-2/bd30.png" style="zoom:70%"><font size="2">Pic 22. Common Activation Functions</font></center>

<ul>
<li><strong>Single Hidden Layer Neural Network</strong><ul>
<li><font color="red">$z_i=w_{0,i}^{(1)}+\sum_{j=1}^{m}x_jw_{j,i}^{(1)}$</font> </li>
<li><font color="red">$\hat y_i=w_{0,i}^{(2)}+\sum_{j=1}^{d_1}g(z_j)w_{j,i}^{(2)}$</font></li>
<li>$x_i\to z_k\to y_j$ , where $z_k$ is the hidden layer</li>
<li>Hidden Layer can be <font color="red">multiple</font> </li>
</ul>
</li>
</ul>
<center><img src="/2024/06/24/Big-Data-2/bd31.png" style="zoom:50%"></center>



<ul>
<li><strong>Thm: Universal Approximation Theorem</strong> —— Any function can be approximated by a <font color="blue">three-layer</font> neural network within sufficiently high accuracy.<ul>
<li>Why not effective ?</li>
<li>The <strong>width</strong> of each layer may be too much (Large calculation !!)</li>
<li><font color="green">Now we’re trying to replace <b>width</b> with <b>depth</b> and find the same Theorem</font> <font color="grey">(即增加层数，减少每层的神经元)</font>



</li>
</ul>
</li>
</ul>
<h4>Loss Optimization</h4>

<blockquote>
<p>Find $\textbf{W}=\{w^{(0)},w^{(1)},…,w^{(n)}\}$ with lowest loss function</p>
</blockquote>
<blockquote class="blockquote-center">
<p>$<br>\textbf{W}^{\ast}=\underset{\textbf{W}} {\arg\min} \frac{1}{n}\sum_{i=1}^{n}L(f(x^{(i)};\textbf{W}),y^{(i)})=\underset{\textbf{W}} {\arg\min}\ C(\textbf{W})<br>$</p>

</blockquote>
<ul>
<li>But for most cases, we should calculate <font color="red">gradient</font> to find $\textbf{W}^{\ast}$ </li>
<li><font color="red">Use <b>gradient decent</b> to solve:</font> $\frac{\partial{C}}{\partial{\textbf{W}}}$</li>
</ul>
<blockquote>
<p>How to calculate ? (More detail)</p>
</blockquote>
<center><img src="/2024/06/24/Big-Data-2/bd33.png" style="zoom:60%"></center>

<ul>
<li>$w_{jk}^{l}$ is the weight for the connection from the $k^{th}$ neuron in the $(l − 1)^{th}$ layer to the $j^{th}$ neuron in the $l^{th}$ layer.</li>
<li>More briefly, <font color="red">$b_{j}^{l}=w_{j0}^l$</font> is the <font color="red">bias</font> of the $j^{th}$ neuron in the $l^{th}$ layer.</li>
<li><p>$a^l_j$ for the <font color="red">activation</font> of the $j^{th}$ neuron in the $l^{th}$ layer $z_j^l$  : <font color="red">$a^l_j=g(z^l_j)=g(\sum_k w_{jk}^{l}a_k^{l-1} + b_j^l)$</font> </p>
</li>
<li><p>We have define $C(\textbf{W})=\frac{1}{n}\sum_{i=1}^{n}L(f(x^{(i)};\textbf{W}),y^{(i)})$ </p>
</li>
</ul>
<center><img src="/2024/06/24/Big-Data-2/bd32.png" style="zoom:40%"></center>

<blockquote>
<p>Proof (暂略)</p>
</blockquote>
<h4>Gradient Descent</h4>

<p><strong>Algorithm</strong> :</p>
<ol>
<li>Initialize weights randomly  $\thicksim\mathcal N(0, \sigma^{2})$ </li>
<li>Loop until convergence : <ol>
<li>Pick single data point $i$</li>
<li>Compute <strong>gradient</strong>  $\frac{\partial J_i(\textbf{W})}{\partial \textbf{W}}$ </li>
<li>Update weights, $\textbf{W} \leftarrow (\textbf{W}-\eta \frac{\partial J(\textbf{W})}{\partial \textbf{W}})$ </li>
</ol>
</li>
<li>Return weights</li>
</ol>
<ul>
<li>Mini-batches lead to fast training ! (need not to calculate all gradient for trainset $x$)</li>
<li>Can parallelize computation + achieve significant speed increases on GPUs.</li>
</ul>
<h3 id="Support-Vector-Machine-SVM"><a href="#Support-Vector-Machine-SVM" class="headerlink" title="Support Vector Machine (SVM)"></a>Support Vector Machine (SVM)</h3><p><strong>About SVM</strong></p>
<ul>
<li>Use <strong>hyperplane</strong> [超平面] to separate data : maximize <strong>margin</strong></li>
<li>Can deal with <font color="red">low-dimensional data</font> that are not linearly separated by using kernel functions</li>
<li>Decision boundary only depends on some samples (support vectors)</li>
</ul>
<p><strong>How to train</strong></p>
<ul>
<li>Training data: $\{(\textbf{x}_1,y_1),(\textbf{x}_2,y_2),…,(\textbf{x}_n, y_n) \}, y_i\in \{-1, 1\}$</li>
<li>Hyperplane: $S=\textbf{w}^T\textbf{x} + b$ ;     Decision function: $f(\textbf{x})=\text{sign}(\textbf{w}^T\textbf{x} + b)$</li>
<li>Geometric <strong>margin</strong> between a point and hyperplane : $\large{r_i=\frac{y_i(\textbf{w}^T\textbf{x} + b)}{|\textbf{w}|_2}}$</li>
<li>Margin between dataset and hyperplane : $\underset{i}\min r_i$</li>
<li>Maximize margin : $\underset{\textbf{w}, b}\max \underset{i}\min r_i$</li>
</ul>
<p><strong>Optimization</strong></p>
<ul>
<li>Without loss of generality, let $\underset{i}\min y_i(\textbf{w}^T\textbf{x} + b)=1$</li>
<li>Maximize margin is equivalent to $\underset{\textbf{w}, b}\max \frac{1}{|\textbf{w}|_2}$  ,  $s.t.\ y_i(\textbf{w}^T\textbf{x} + b)\ge 1,\ i=1,…,n$</li>
<li>Further reduce to $\underset{\textbf{w}, b} \min \frac{1}{2}|\textbf{w}|_2^2$  ,  $s.t.\ y_i(\textbf{w}^T\textbf{x} + b)\ge 1,\ i=1,…,n$</li>
<li>This is <strong>primal problem</strong> : quadratical programming with linear constraints, computational complexity is $O(p^3)$ where $p$ is dimension</li>
</ul>
<blockquote>
<p>But we use <strong>Dual problem optimization</strong>(对偶问题优化) most.</p>
</blockquote>
<ul>
<li>When slater condition is satisfied, $\min \max ⇔ \max \min$</li>
<li>Dual problem : $\underset{\alpha}\max \underset{\textbf{w}, b}\min L(\textbf{w},b,\alpha)$ —— $L$ is Lagrange function(拉格朗日函数)</li>
<li><p>Solve for inner minimization problem : </p>
<ul>
<li>$\nabla_{\textbf{w}}L=0 \Longrightarrow \textbf{w}^\ast=\sum_i \alpha_iy_i \textbf{x}_i$</li>
<li>$\frac{\partial L}{\partial b}=0 \Longrightarrow \sum_i\alpha_iy_i=0$</li>
</ul>
</li>
<li><p>Plug into $L$: $L(\textbf{w}^\ast,b^\ast,\alpha)=\sum_i\alpha_i-\frac{1}{2}\sum_i\sum_j\alpha_i\alpha_jy_iy_j(\textbf{x}_i^T \textbf{x}_j)$ </p>
</li>
<li><font color="red">Dual Optimization: </font>

</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\begin{align}<br>&amp;\min_\alpha\frac{1}{2}\sum_i\sum_j\alpha_i\alpha_jy_iy_j(\textbf{x}_i^T \textbf{x}_j)-\sum_i\alpha_i, \\<br>&amp;\text{s.t. }\alpha_i\ge0,\ i=1,…,n,\ \sum_i\alpha_iy_i=0<br>\end{align}<br>$</p>

</blockquote>
<p><strong>KKT Condition</strong></p>
<ul>
<li>Three more conditions from the equivalence of primal and minimax problems</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\left\{ \begin{array}{l}<br>\alpha_i^{\ast}\ge 0\\<br>y_i((\textbf{w}^{\ast})^T \textbf{x}_i+b^{\ast})-1 \ge 0\\<br>\alpha_i^{\ast}[y_i((\textbf{w}^{\ast})^T \textbf{x}_i+b^{\ast})-1]=0<br>\end{array}\right.<br>$</p>

</blockquote>
<ul>
<li>These together with two zero derivative conditions form KKT conditions</li>
<li>$\alpha_i^{\ast}\gt 0 \Rightarrow y_i((\textbf{w}^{\ast})^T \textbf{x}_i+b^{\ast})=1$</li>
<li>Index set of <font color="red">support vectors</font> : $S=\{i|\ \alpha_i \gt 0\}$</li>
<li>$b=y_s-\textbf{w}^T\textbf{x}_s=y_s-\sum_{i\in S}\alpha_i y_i \textbf{x}^T_i\textbf{x}_s$</li>
<li>More stable solution : </li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\color{red} b=\frac{1}{|S|}\sum_{s\in S}\left(y_s-\sum_{i\in S}\alpha_i y_i \textbf{x}^T_i\textbf{x}_s\right)<br>$</p>

</blockquote>
<p><strong>Soft Margin</strong></p>
<ul>
<li>When data are not linear separable, introduce slack variables (tolerance control of fault) $\xi_i \gt 0$</li>
<li>Relax constraint to $y_i(\textbf{w}^T\textbf{x} + b) \ge 1-\xi_i$ </li>
<li>Primal problem :</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\begin{align}<br>&amp;\underset{\textbf{w}, b} \min \frac{1}{2}|\textbf{w}|_2^2+C\sum_{i=1}^{n}\xi_i\\<br>&amp;\text{s.t. }y_i(\textbf{w}^T\textbf{x} + b)\ge 1-\xi_i,\ \xi_i \ge 0,\ i=1,…,n<br>\end{align}<br>$</p>

</blockquote>
<ul>
<li>Similar derivation to dual problem : (Difference: add the error coe $C$ as a bound)</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\begin{align}<br>&amp;\min_{\alpha}\frac{1}{2}\sum_i \sum_j \alpha_i \alpha_j y_i y_j (\textbf{x}_i^T \textbf{x}_j)-\sum_i \alpha_i \\<br>&amp;\text{s.t. }0\le \alpha_i \le C,\ i=1,…,n,\ \sum_i\alpha_iy_i=0<br>\end{align}<br>$</p>

</blockquote>
<h4 id="Nonlinear-SVM"><a href="#Nonlinear-SVM" class="headerlink" title="Nonlinear SVM"></a>Nonlinear SVM</h4><ul>
<li>Nonlinear decision boundary could be mapped to linear boundary in <font color="red">high-dimensional space</font></li>
</ul>
<center><img src="/2024/06/24/Big-Data-2/bd34.png" style="zoom:60%"></center>

<ul>
<li>Modify objective function in dual problem : $\color{red}\frac{1}{2}\sum_i \sum_j \alpha_i \alpha_j y_i y_j (\phi(\textbf{x}_i)^T \phi(\textbf{x}_j))-\sum_i \alpha_i$</li>
<li>Kernel function as inner product : $K(\textbf{x}_i, \textbf{x}_j)=\phi(\textbf{x}_i)^T \phi(\textbf{x}_j)$</li>
<li><font color="grey">Q: How to choose <b>Kernel Functions</b> ?</font>      <font color="green">A: Arbitrary</font>

</li>
</ul>
<center><img src="/2024/06/24/Big-Data-2/bd35.png" style="zoom:50%"></center>

<hr>
]]></content>
      <categories>
        <category>2024 Spring</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>CSE Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>MA234 大数据导论与实践（一）</title>
    <url>/2024/06/22/Big-Data-1/</url>
    <content><![CDATA[<h1 id="Big-Data-I"><a href="#Big-Data-I" class="headerlink" title="Big Data (I)"></a>Big Data (I)</h1><h2 id="I-Pre-Knowledge"><a href="#I-Pre-Knowledge" class="headerlink" title="I. Pre-Knowledge"></a>I. Pre-Knowledge</h2><h3 id="Recall-for-Linear-Algebra"><a href="#Recall-for-Linear-Algebra" class="headerlink" title="Recall for Linear Algebra"></a>Recall for Linear Algebra</h3><p><strong>1. Linear Combination and Linear Function</strong></p>
<p><strong>Def.</strong> Suppose $\vec\alpha_1,\vec\alpha_2,\cdots, \vec\alpha_e$ are finite vector from <font color="red">linear space</font> $\textbf{V}$. If any vector from $\textbf{V}$ can be represented as $\vec\alpha = k_1\vec\alpha_1+k_2\vec\alpha_2+\cdots + k_e \vec\alpha_e$ , we say that $\vec\alpha$ can be linearly represented by vector group $\{\vec\alpha_1,\vec\alpha_2,\cdots, \vec\alpha_e\}$ , or $\alpha$ is a Linear Combination of $\{\vec\alpha_1,\vec\alpha_2,\cdots, \vec\alpha_e\}$. </p>
<blockquote class="blockquote-center">
<p>$<br>\begin{align}<br>&amp;\text{Set }A=\{\vec\alpha_1,\vec\alpha_2,\cdots, \vec\alpha_e\}\\<br>&amp;V=\text{Span}(A)=\{k_1\vec\alpha_1+k_2\vec\alpha_2+\cdots + k_e \vec\alpha_e | k_i\in \mathbb R, 1\le i\le e\}<br>\end{align}<br>$</p>

</blockquote>
<blockquote>
<p>In a <strong>matrix</strong> (i.e. $A$), set all rows as a vector group, and it span a space called <strong>Row Space</strong> (Noted: $R(A)$). All columns span a space called <strong>Column Space</strong> (Noted: $\text{Col}(A)$).</p>
<p>Linear Function $Ax=b$ is solutable <font color="red">if and only if</font> $b$ is a linear combination of $\text{Col}(A)$ (or $b \in \text{Col}(A)$).</p>
<p>Specially, if $b=0$ ($Ax=0$), then all solution of $x$ group as a vector space called <strong>Null Space</strong> (Noted: $\text{Nul}(A)$)</p>
</blockquote>
<hr>
<p><strong>2. Basis and Orthogonal</strong></p>
<ul>
<li>About <strong>Rank</strong><ul>
<li><font color="green">Recall: </font>$\color{green}LU$ <font color="green">factorization</font><ul>
<li>$\color{green}PA=LDU$, where $P$ is row exchange matrix (避免 A 主元为 0), $L$ is lower-triangle matrix with diagonal is all 1, $D$ is the coefficient matrix and $U$ is upper-triangle matrix.</li>
</ul>
</li>
<li>For a $m\times n$ matrix ranked $r$, there are $(n-r)$ particular solution of $Ax=b$ in the solution space of $A$ ($\text{Nul}(A)$).</li>
<li>For $Ax=b$ , $Ux=c$ or $Rx=d$ , there must be $\color{red}(m-r)$ <font color="red">conditions</font> for formula to be solutable.</li>
</ul>
</li>
</ul>
<ul>
<li>About <strong>Linear Independent</strong><ul>
<li><strong>Def.</strong> Suppose $A=\{v_1,v_2,\cdots, v_n\}$ is vector set of $\mathbb R^n$. If $\exists v_i \in A, v_i=\sum_{j\neq i} \lambda_j v_j, \lambda_j \in \mathcal R$ , then we say $A$ is <strong>linear dependent</strong>. <font color="red">If not, we say it’s <strong>Linear Independent</strong>.</font></li>
<li><strong>Thm.</strong> $A$ is linear independent <font color="red">if and only if</font> $\lambda_1 \vec{v_1}+\lambda_2\vec{v_2}+\cdots +\lambda_k\vec{v_k}=0$ only holds when $\lambda_1=\lambda_2=\cdots =\lambda_k=0$</li>
</ul>
</li>
</ul>
<blockquote>
<p>Then we can talk about <strong>Basis</strong>(基)</p>
</blockquote>
<p><strong>Def.</strong> For vector space $V$ , if vector group $A=\{v_1,v_2,\cdots, v_k\}$ satisfies that $V=\text{Span}(A)$ , and $A$ is <font color="red">linear independent</font> , then we say that $\color{red}A$ <font color="red">is one of the <strong>basis</strong> of</font> $\color{red}V$.</p>
<ul>
<li>If $A$ is a basis of $V$ , then $\forall \vec{w} \in V$ , there must be unique array $[a_1, a_2,\cdots,a_k]$ such that $\vec{w}=a_1v_1+a_2v_2+\cdots +a_kv_k$ . Then we call this array a <font color="red">coordinate</font> of $\vec w$ in $A$ , noted $[\vec w]_{A}$</li>
</ul>
<h3 id="Recall-for-Calculus"><a href="#Recall-for-Calculus" class="headerlink" title="Recall for Calculus"></a>Recall for Calculus</h3><p><strong>1. Langrange Multiplier</strong> [拉格朗日乘数法]</p>
<h3 id="Other-Prepared-Knowledge"><a href="#Other-Prepared-Knowledge" class="headerlink" title="Other Prepared Knowledge"></a>Other Prepared Knowledge</h3><p><strong>1. Norm</strong></p>
<p>On vectors :</p>
<ul>
<li>1-Norm: $|x|_1 = \sum_{i=1}^{N}{|x_i|}$</li>
<li>2-Norm: $|\textbf{x}|_2= \sqrt{\sum_{i=1}^{N} x_i^2}$</li>
<li>$\pm\infty$-Norm: $|\textbf{x}|_{\infty}=\underset{i}\max{|x_i|}$  ;  $|\textbf{x}|_{-\infty}=\underset{i}\min{|x_i|}$</li>
<li>p-Norm: $|\textbf{x}|_p=(\sum_{i=1}^{N}{|x_i|}^p)^{\frac{1}{p}}$</li>
</ul>
<p>On matrix :</p>
<ul>
<li>1-Norm(列和范数) : $|A|_1=\underset{j}\max \sum_{i=1}^{m}{|a_{i,j}|}$  , maximum among <font color="red">absolute sum of column vector</font>.</li>
<li>2-Norm: $|A|_2=\sqrt{\lambda_1}$  , where $\lambda_1$ is the maximum eigenvalue(特征值) of $A^TA$</li>
<li>$\infty$-Norm(行和范数) : $|A|_\infty=\underset{i}\max \sum_{j=1}^{n}{|a_{i,j}|}$  , maximum among <font color="red">absolute sum of row vector</font>.</li>
<li>F-Norm(核范数) : $|A|_*=\sum_{i=1}^{n}\lambda_i$  , where $\lambda_i$ is singular value(奇异值) of $A$</li>
</ul>
<h2 id="II-Intro"><a href="#II-Intro" class="headerlink" title="II. Intro"></a>II. Intro</h2><h3 id="About-Big-Data"><a href="#About-Big-Data" class="headerlink" title="About Big Data"></a>About Big Data</h3><ul>
<li><font color="Red"><strong>4 Big “V”</strong></font> required in Big Data<ul>
<li><strong>Volume</strong>: KB, MB, GB ($10^9$ bytes), TB, PB, EB ($10^{18}$ bytes), ZB, YB<ul>
<li>Data of Baidu: several ZB</li>
</ul>
</li>
<li><strong>Variety</strong>: diﬀerent sources from business to industry, diﬀerent types</li>
<li><strong>Value</strong>: redundant information contained in the data, need to retrieve useful information</li>
<li><strong>Velocity</strong> (速度): fast speed for information transfer</li>
</ul>
</li>
<li><em>Two perspectives of data sciences</em> :<ul>
<li>Study science with the help of data : bioinformatics, astrophysics, geosciences, etc.</li>
<li>Use scientiﬁc methods to exploit (利用) data : statistics, machine learning, data mining, pattern recognition, data base, etc.</li>
</ul>
</li>
<li><em>Data Analysis</em><ul>
<li>Ordinary data types :<ul>
<li>Table : classical data (could be treated as matrix)</li>
<li>Set of points : mathematical description</li>
<li>Time series : text, audio, stock prices, DNA sequences, etc.</li>
<li>Image : 2D signal (or matrix equivalently, e.g., pixels), MRI, CT, supersonic imaging</li>
<li>Video : Totally 3D, with 2D in space and 1D in time (another kind of time series)</li>
<li>Webpage and newspaper : time series with spacial structure</li>
<li>Network : relational data, graph (nodes and edges)</li>
</ul>
</li>
<li>Basic assumption : the data are generated from an underlying model, which is unknown in practice<ul>
<li>Set of points : probability distribution</li>
<li>Time series : stochastic processes, e.g., Hidden Markov Model (HMM)</li>
<li>Image : random ﬁelds, e.g., Gibbs random ﬁelds</li>
<li>Network : graphical models, Beyesian models</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>Difficulties of Data Analysis</strong></p>
<ul>
<li>Huge <font color="#921aff">volume</font> of data</li>
<li>Extremely high dimensions<ul>
<li>Solutions: <ul>
<li>Make use of prior information</li>
<li>Restrict to simple models</li>
<li>Make use of special structures, e.g., sparsity, low rank, smoothness</li>
<li>Dimensionality reduction, e.g., PCA, LDA, etc.</li>
</ul>
</li>
</ul>
</li>
<li>Complex <font color="#921aff">variety</font> of data</li>
<li>Large noise (噪点, <font color="#921aff">values</font>) : data are always contaminated with noises</li>
</ul>
<h3 id="Representation-of-Data"><a href="#Representation-of-Data" class="headerlink" title="Representation of Data"></a>Representation of Data</h3><ul>
<li>Input space $\mathcal X = \{\text{All possible samples}\}$ ; $\textbf{x} \in \mathcal{X}$ is an input vector, also called feature, predictor, independent variable, etc; <strong>typically multi-dimension</strong>. For multi-dimension, $\textbf{x} \in \mathbb R^p$ is a weight vector (权重向量，每一维度所占权重可调整) or coding vector (编码向量，e.g. 矢量图).</li>
<li>Output space $\mathcal{Y} = \{\text{All possible results}\}$ ; $y \in \mathcal{Y}$ is an output vector, also called response, dependent variable, etc; <strong>typically one dimension</strong>. E.g. $y = 0\ \text{or}\ 1$ for classiﬁcation problems, $y \in \mathbb{R}$ for regression problems.</li>
<li>For supervised learning, assume that $(\textbf{x},y)\sim \mathcal P$, a joint distribution on the sample space $\mathcal X \times \mathcal Y$</li>
</ul>
<hr>
<font size="4"><b>Supervised Learning (监督学习) —— <font color="Grey">given labels of data</font></b></font>

<ul>
<li>Training : ﬁnd the optimal parameters (or model) to minimize the error between the prediction and target</li>
<li>Classiﬁcation <font color="Grey">(if output is discrete)</font>: SVM (支持向量机), KNN (K-Nearest Neighbor), Desicion tree, etc.</li>
<li>Regression <font color="Grey">(if output is continuous)</font>: linear regression, CART, etc.</li>
</ul>
<p>Maths method about Supervised Learning </p>
<ul>
<li>Goal: Find the conditional distribution $\mathcal P(y|\textbf{x})$ of $y$ given $\textbf{x}$ </li>
<li>Training dataset: $\{(\textbf{x}_i, y_i)\}_{i=1}^{n} \overset{\text{i.i.d}}{\sim} \mathcal P$, used to learn an approximation $\hat{f}(\textbf{x})$ or $\hat{\mathcal P}(y|\textbf{x})$</li>
<li>Test dataset: $\{(\textbf{x}_j, y_j)\}_{j=n+1}^{n+m} \overset{\text{i.i.d}}{\sim} \mathcal P$, used to test</li>
</ul>
<div align="center">
<img src="/2024/06/22/Big-Data-1/bd2.png" alt="bd2" width="80%">
</div>

<blockquote>
<p>So we can conclude that a predictor must be developed from a Supervised Learning Model.</p>
</blockquote>
<font size="4"><b>Unsupervised Learning (无监督学习) —— <font color="Grey">no labels</font></b></font>

<ul>
<li>Optimize the parameters based on some <font color="#ce0000">natural rules</font>, e.g., cohesion (收敛) or divergence (发散)</li>
<li>Clutering : K-Means, SOM (Self-Organizing Map)</li>
</ul>
<div align="center">
<img src="/2024/06/22/Big-Data-1/bd3.png" alt="bd3" width="80%">
</div>


<p>Maths method about Unsupervised Learning</p>
<ul>
<li>Goal : in probabilistic settings, find the distribution (PDF) $\mathcal P(\textbf{x})$ of $\textbf{x}$ and approximate it (there is no y)</li>
<li>Training dataset : $\{(x_i)\}_{i=1}^{n} \overset{\text{i.i.d}}{\sim} \mathcal P$ , used to learn an approximation $\hat{\mathcal P}(\textbf{x})$ (no test data in general)</li>
</ul>
<font size="4"><b>Semi-supervised learning:</b></font> 

<ul>
<li>with missing data, e.g., EM; self-supervised learning, learn the missing part of images, inpainting.</li>
</ul>
<font size="4"><b>Reinforcement learning (强化学习):</b></font>  

<ul>
<li><font color="red">No label, but have target</font>. Play games, e.g., Go, StarCraft; robotics; auto-steering.</li>
</ul>
<h3 id="Modeling-and-Analysis"><a href="#Modeling-and-Analysis" class="headerlink" title="Modeling and Analysis"></a>Modeling and Analysis</h3><ul>
<li>Decision function (hypothesis) space : <ul>
<li>$\mathcal{F}=\{\mathcal{f_\theta}=\mathcal{f_\theta}(x), \theta \in \Theta \}$ </li>
<li>or $\mathcal{F}=\{\mathcal{P_\theta}=\mathcal{P_\theta}(y|x), \theta \in \Theta \}$</li>
</ul>
</li>
<li><font color="red">Loss function :</font> a measure for the “goodness” of the prediction, $L(y, \mathcal{f}(x))$ <ul>
<li><a name="0-1 loss"><i>0-1 loss</i></a>: $L(y, \mathcal{f}(x))=\textbf{l}_{y\not{=}f(x)}=1-\textbf{l}_{y=f(x)}$ （个人理解一般是用于二元项预测的误差判断）</li>
<li><i>Square loss</i>: $L(y, \mathcal{f}(x))=(y-f(x))^2$ （比绝对值误差更泛用）</li>
<li><i>Absolute loss</i>: $L(y, \mathcal{f}(x))={|y-f(x)|}$ </li>
<li><i>Cross-entropy (交叉熵) loss</i>: <br>   $\color{red}L(y, \mathcal{f}(x))=-y\log{f(x)}-(1-y)\log{(1-f(x))}$</li>
</ul>
</li>
<li><strong>Risk</strong> : in average sense,<br> $\mathcal{R}(f)=E_{\mathcal P} [L(y, f(x))]=\underset{\mathcal X \times \mathcal Y}{\int}L(y, f(x))\mathcal{P}(x,y)\text d x \text d y$ </li>
<li><font color="Red"><b>Target of Learning</b></font> : minimize $\mathcal R_{exp}(f)$ to get $f^{\ast}$ ( $\text{即} f^{\ast}=\underset{f}{min}\ \mathcal{R}_{exp}(f)$ )</li>
</ul>
<p><strong>Risk Minimize Strategy :</strong> </p>
<ul>
<li>Empirical risk minimization (<strong>ERM</strong>) : <ul>
<li>given training set $\{(\textbf{x}_i,y_i)\}_{i=1}^{n}$ , $R_{emp}(f)=\frac{1}{n}\sum_{i=1}^{n}L(y_i,f(\textbf{x}_i))$ <font color="grey">(Loss function 的均值定义为预测模型 f 的经验风险)</font> .<ul>
<li>By law of large number, $\underset{n\to\infty}{\lim} R_{emp}(f)=R_{exp}(f)$ . <font color="Grey">(即经验风险趋近于预测风险)</font></li>
<li>Optimization problem <font color="red">(What Machine Learning truly do)</font> : $\underset{f\in\mathcal F}{\min}\frac{1}{n}\sum_{i=1}^{n}L(y_i,f(\textbf{x}_i))$ </li>
<li><font color="Green">Now we only need to know</font>  $\color{green}f$ <font color="Green">and training set</font>  $\color{green}\textbf{x}_i$ </li>
</ul>
</li>
</ul>
</li>
<li>Structural risk minimization (<strong>SRM</strong>) : <ul>
<li>given training set $\{(\textbf{x}_i,y_i)\}_{i=1}^{n}$ , and a complexity function $J=J(f)$ , $R_{SRM}(f)=\frac{1}{n}\sum_{i=1}^{n}L(y_i,f(\textbf{x}_i))+\lambda J(f)$ <ul>
<li>$J(f)$ measures how complex the model $f$ is, typically the degree of complexity</li>
<li>$λ\ge 0$ is a tradeoff(平衡项) between the empirical risk and model complexity</li>
<li>Optimization problem <font color="red">(What Machine Learning truly do)</font> : $\underset{f\in\mathcal F}{\min}\frac{1}{n}\sum_{i=1}^{n}L(y_i,f(\textbf{x}_i))+\lambda J(f)$ </li>
<li><font color="Green">We need to know</font> $\color{green}f$ <font color="Green">and training set</font> $\color{green}{\textbf{x}_i}$ <font color="Green">, and need to</font> <font color="#00CD00">adjust the parameter</font>  $\color{green}{\lambda}$</li>
</ul>
</li>
</ul>
</li>
</ul>
<blockquote>
<p>We see that <font color="#c6a300">Optimization Method</font> is essencial in machine learning. Here are some of them: </p>
<ul>
<li>Gradient descent method (梯度下降), including coordinate descent, sequential minimal optimization (SMO), etc.</li>
<li>Newton’s method and quasi-Newton’s method (拟牛顿法)</li>
<li>Combinatorial optimization (组合优化)</li>
<li>Genetic algorithms (遗传算法)</li>
<li>Monte Carlo methods (随机算法)</li>
</ul>
</blockquote>
<p><strong>Model assessment :</strong></p>
<ul>
<li>Training error: $R_{emp}(\hat f)=\frac{1}{n}\sum_{i=1}^{n}L(y_i,\hat f(\textbf{x}_i))$ , tells the diﬃculty of learning problem</li>
<li>Test error: $e_{test}(\hat f)=\frac{1}{m}\sum_{j=n+1}^{n+m}L(y_j,\hat f(\textbf{x}_j))$ , tells the capability of prediction ;<br> In particular, if 0-1 loss is used (below)<ul>
<li>Error rate : $e_{test}(\hat f) = \frac{1}{m}\sum_{j=n+1}^{n+m}\textbf{l}_{y_j\ne\hat f(\textbf{x}_j)}$</li>
<li>Accuracy : $r_{test}(\hat f) = \frac{1}{m}\sum_{j=n+1}^{n+m}\textbf{l}_{y_j=\hat f(\textbf{x}_j)}$</li>
<li>$e_{test}+ r_{test} = 1$ </li>
</ul>
</li>
<li><p>Generalization error (泛化误差——模型对新样本的预测性的度量)</p>
<ul>
<li>$R_{exp}(\hat f)=E_{\mathcal P}[L(y,\hat f(\textbf{x}))]=\underset{\mathcal X\times\mathcal Y}{\int}L(y,\hat f(\textbf{x}))\mathcal P(\textbf{x},y)\text d\textbf{x} \text d y$ <br>tells the capability for predicting <font color="#9f4d95">unknown data</font> from the same distribution</li>
<li>Its upper bound $M$ deﬁnes the generalization ability (负相关)<ul>
<li>As $n\to\infty$, $M\to 0$ (which means almost no error)</li>
<li>As $\mathcal F$ becomes larger, $M$ increases.</li>
</ul>
</li>
</ul>
</li>
<li><p><em>Overfitting</em></p>
<ul>
<li>Too many model paramters （模型太复杂）</li>
<li>Better for training set, but worse for test set</li>
</ul>
</li>
<li><em>Underfitting</em><ul>
<li>Better for test set, but worse for training set</li>
</ul>
</li>
</ul>
<p><strong>Model Selection :</strong> choose the most proper model.</p>
<ul>
<li><a name="cross validation">Cross-validation</a> (交叉验证) : split the training set into training subset and validation subset, use training set to train diﬀerent models repeatedly, use validation set to select the best model with the smallest (validation) error<ul>
<li>Simple CV : randomly split the data into two subsets</li>
<li>K-fold CV : randomly split the data into $K$ disjoint subsets with the same size, treat the union of $K − 1$ subsets as training set, the other one as validation set, do this repeatedly and select the best model with smallest mean (validation) error</li>
<li>Leave-one-out CV : $K = n$ in the previous case</li>
</ul>
</li>
</ul>
<h3>Data Science vs. Other Techniques</h3>

<div align="center">
<img src="/2024/06/22/Big-Data-1/bd1.png" alt="bd1" width="60%">
</div>

<hr>
<h2 id="III-Data-Preprocessing"><a href="#III-Data-Preprocessing" class="headerlink" title="III. Data Preprocessing"></a>III. Data Preprocessing</h2><h3 id="Data-Type"><a href="#Data-Type" class="headerlink" title="Data Type"></a>Data Type</h3><ul>
<li>Types of Attributes  <font size="2">(每门课几乎都离不开这个)</font><ul>
<li>Discrete: $x \in \text{some countable sets}$, e.g., $\mathbb N$ <ul>
<li><a name="nominal">Nominal (列举名义)</a> </li>
<li><a name="boolean">Boolean (0 or 1) </a> </li>
<li><a name="ordinal">Ordinal (基数等级, e.g. A+, A-, B+,…) </a> </li>
</ul>
</li>
<li>Continuous: $x \in \text{some subset in }\mathbb R$ </li>
</ul>
</li>
</ul>
<ol>
<li><strong>Basic Statistics</strong> (统计量)<ul>
<li>Mean</li>
<li>Median (中位数)</li>
<li>extremum (极值)</li>
<li>Quantile (分位数) </li>
<li>Variance, Standard deviation (标准差)</li>
<li>Mode (众数)</li>
</ul>
</li>
</ol>
<div align="center">
<img src="/2024/06/22/Big-Data-1/bd4.png" alt="bd4" width="90%">
</div>

<blockquote>
<p>Empiricism:  Mean − Mode = 3 $\times$ (Mean − Median)</p>
</blockquote>
<ul>
<li>Box Plot (箱线图) —— used to describe statistics</li>
</ul>
<div align="center">
<img src="/2024/06/22/Big-Data-1/bd5.png" alt="bd5" width="40%">
</div>



<ol>
<li><strong>Metrics</strong> (度量——亦称距离函数，是度量空间中满足特定条件的特殊函数。度量空间由欧几里得空间的距离概念抽象化定义而来。)<ul>
<li>Proximity :<ul>
<li>Similarity : range is $[0, 1]$ </li>
<li>Dissimilarity : range is $[0, \infty]$ , sometimes <a href="#distance">distance</a> (noted by <code>d</code>)</li>
</ul>
</li>
<li>For <a href="#nominal">nominal data</a>, $d(\textbf{x}_i,\textbf{x}_j)=\frac{\sum_{k}\textbf{l}(\textbf{x}_{i,k}\neq\textbf{x}_{j,k})}{p}$ ,or one-hot encoding into Boolean data</li>
<li>For <a href="#boolean">Boolean data</a>, <strong>symmetric distance</strong> (rand disrance) $\text d(\textbf{x}_i,\textbf{x}_j) =\frac {r+s}{q+r+s+t}$ or <strong>Rand index</strong> $\text{Sim}_{\text{Rand}}(\textbf{x}_i,\textbf{x}_j)=\frac{q+t}{q+r+s+t}$ ; <strong>non-symmetric distance</strong> (<a name="Jaccard"><font color="black"> Jaccard distance </font></a>) $\text d(\textbf{x}_i,\textbf{x}_j)=\frac{r+s} {q+r+s}$ or <strong>Jaccard index</strong> $\text{Sim}_{\text{Jaccard}}(\textbf{x}_i,\textbf{x}_j)=\frac {q} {q+r+s}$ </li>
</ul>
</li>
</ol>
<div align="center">
<img src="/2024/06/22/Big-Data-1/bd6.png" alt="bd6" width="40%">
</div>



<p><a name="distance"><font color="Red"><strong>Distance :</strong></font></a></p>
<p><strong>Def.</strong> Distance <code>d</code> is the difference between two samples.</p>
<ul>
<li>Properties of Distance : <ul>
<li>Non-negative: $\text{d}(x,y)\ge 0$</li>
<li>Identity: $\text d(x,y)=0\Leftrightarrow x=y$ </li>
<li>Symmetric: $\text d(x,y)=\text d(y,x)$ </li>
<li>Basic Vector Attributes : e.g. $\text d(x,y)\le \text d(x,z)+\text d(z,y)$ </li>
</ul>
</li>
<li>距离度量分为Space Distance (e.g. Euclidean) 、String Distance (e.g. Hamming distance) 、Set Proximity (e.g. Jaccard distance) 和 Distribution Distance (e.g. Chi-square measure)</li>
</ul>
<font color="blue">以下简单介绍几种距离，更多请参考<a href="https://blog.csdn.net/hy592070616/article/details/121723169?spm=1001.2014.3001.5501">此处 (csdn note)</a></font><br>



<font color="blue">1 .  Minkowski distance (闵可夫斯基距离)</font>

<blockquote class="blockquote-center">
<p>$<br>\begin{align}<br>&amp;\text d(\textbf{x}_i,\textbf{x}_j)=\sqrt[h]{\sum_{k=1}^{p}|\text x_{ik}-\text x_{jk}|^h}&amp;<br>\end{align}<br>$</p>

</blockquote>
<blockquote>
<p>Parameter <code>h</code> is to <font color="blue">emphasize the character of the data</font>. By changing the value of <code>h</code> , Minkowski distance can cover many Distance Metrics.</p>
</blockquote>
<font color="blue">2 .  Manhattan distance (曼哈顿距离) </font>


<blockquote>
<p>Minkowski distance where $h = 1$</p>
</blockquote>
<blockquote class="blockquote-center">
<p>$<br>\text d(\textbf{x}_i,\textbf{x}_j)=\sum_{k=1}^{p}|\text x_{ik}-\text x_{jk}|<br>$</p>

</blockquote>
<font color="blue">3 .  Euclidean distance (欧氏距离)</font>

<blockquote>
<p>Minkowski distance where $h = 2$ </p>
</blockquote>
<blockquote class="blockquote-center">
<p>$<br>\text d(\textbf{x}_i,\textbf{x}_j)=\sqrt{\sum_{k=1}^{p}(\text x_{ik}-\text x_{jk})^2}<br>$</p>

</blockquote>
<font color="blue">4 .  Supremum distance (or Chebyshev distance, 切比雪夫距离)</font>

<blockquote>
<p>Minkowski distance where $h \to \infty$ </p>
</blockquote>
<blockquote class="blockquote-center">
<p>$<br>\text d(\textbf{x}_i,\textbf{x}_j)=\max_{k=1}^{p}|\text x_{ik}-\text x_{jk}|<br>$</p>

</blockquote>
<p><a name="cosine distance"><font color="blue">5 .  Cosine distance (余弦距离)</font></a> </p>
<blockquote class="blockquote-center">
<p>$<br>\cos(\textbf{x}_i,\textbf{x}_j)=\frac{\sum_{k=1}^{p}\text x_{ik}\text x_{jk}}{\sqrt{\sum_{k=1}^{p}\text x_{ik}^2}\sqrt{\sum_{k=1}^{p}\text x_{ik}^2}}=\frac{\textbf{x}_i\cdot\textbf{x}_j}{\left|\textbf{x}_i\right|\left|\textbf{x}_j\right|}<br>$</p>

</blockquote>
<p><strong>Other Distance:</strong></p>
<ul>
<li>For <a href="#ordinal">ordinal data</a>, mapping the data to numerical data : $X=\{x_{(1)}, x_{(2)},…, x_{(n)}\}, x_{(i)} \mapsto \frac{i−1} {n−1}\in [0, 1]$ </li>
<li>For mixed type, use weighed distance (加权) with prescribed weights :</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\text d(\textbf{x}_i,\textbf{x}_j)=\frac{\sum_{g=1}^{G}w_{ij}^{(g)}\text d_{ij}^{(g)}}{\sum_{g=1}^{G}w_{ij}^{(g)}}<br>$</p>

</blockquote>
<h3 id="Data-Preprocessing-Lecture"><a href="#Data-Preprocessing-Lecture" class="headerlink" title="Data Preprocessing (Lecture)"></a>Data Preprocessing (Lecture)</h3><div align="center">
<img src="/2024/06/22/Big-Data-1/bd7.png" alt="bd7" width="90%">
</div>

<ul>
<li>Data Scaling (归一化，标准化)<ul>
<li>Why scaling?<ul>
<li>For better performance or normalize diﬀerent dimensions</li>
</ul>
</li>
<li><a name="z-score"><b>Z-score scaling</b></a>:   <font size="5">$x_i^\ast=\frac{x_i-\hat\mu}{\hat\sigma}$ </font> ,<br>applicable when max and min unknown and data distributes well (e.g. normal distribution)</li>
<li><strong>0-1 scaling</strong> (Min-Max scaling) :   <font size="5">$x_i^\ast=\frac{x_i-\min_k x_k}{\max_k x_k-\min_k x_k}$ </font> ,<br>applicable for bounded data sets, and need to <font color="red">recompute</font> max and min when new data added</li>
<li>Decimal scaling: $x_{i}^{\ast}=\frac{x_i}{10^k}$, applicable for data varying across many magnitudes (分布太广)</li>
<li>Logistic scaling: $x_i^{\ast}=\frac{1}{1+e^{-x_i}}$ , applicable for data concentrating nearby origin (分布太窄)</li>
</ul>
</li>
<li>Data Discretization (离散化)<ul>
<li>Why discretization?<ul>
<li>Improve the robustness : removing the outliers by putting them into certain intervals</li>
<li>For better interpretation</li>
<li>Reduce the storage and computational power</li>
</ul>
</li>
<li><strong>Unsupervised discretization</strong>: equal-distance discretization (等距，数据分布可能不均), equal-frequency discretization, clustering-based discretization (聚类), 3$\sigma$-based discretization</li>
<li><strong>Supervised discretization</strong>: information gain based discretization (e.g. 决策树), $\mathcal X^2$-based discretization (Chi-Merge)</li>
</ul>
</li>
<li>Data Redundancy <ul>
<li>Why redundancy exists?<ul>
<li>Correlations exist among different attributes (E.g. Age, birthday and current time), <font color="green">recalling the linear dependency for vectors</font></li>
</ul>
</li>
<li><strong>Continuous variables:</strong> compute the correlation coefficient (相关系数) <font size="4">$\rho_{A,B}=\frac{\sum_{i=1}^{k}{(a_i-\bar A)(b_i-\bar B)}}{k\hat\sigma_{A}\hat\sigma_{B}}\in[-1,1]$ </font></li>
<li><strong>Discrete variables:</strong> compute the $\mathcal X^{2}$ statistics : large $\hat{\mathcal{X}^{2}}$ value implies small correlation.</li>
</ul>
</li>
</ul>
<blockquote>
<p>About missing data: (<code>NA</code>, \<Empty>, <code>NaN</code>)</Empty></p>
<p>Delete or Pad </p>
<ul>
<li>Pad (or filling)<ul>
<li>fill with <font color="blue">0</font>, with <font color="blue">mean value</font>, with <font color="blue">similar variables</font> (auto-correlation is introduced), with <font color="blue">past data</font>, with <font color="blue">Expectation-Maximization</font> or by K-Means</li>
</ul>
</li>
</ul>
<p>In Python, <code>NaN</code> means missing values (Not a Number, missing float values)</p>
<p><code>None</code> is a Python object, representing missing values of the object type</p>
<p>For some multi-classifications (e.g. “Male” and “Female”) model, we should refer to <strong>Dummy Variables</strong> to describe. (We usually set “Unknown” as reference variable <code>00</code>, and describe “Male” and “Female” as <code>01</code> &amp; <code>10</code>)</p>
</blockquote>
<ul>
<li>Random filling : <ul>
<li>Bayesian Bootstrap : for discrete data with range $\{x_i\}^k_{i=1}$, randomly sample $k − 1$ numbers from $U(0, 1)$ as $\{a_{(i)}\}^k_{i=0}$ with $a_{(0)} = 0$ and $a_{(k)} = 1$ ; then randomly sample from $\{x_i\}^k_{i=1}$ with probability distribution $\{a_{(i)} − a_{(i−1)}\}^k_{i=1} $accordingly to fill in the missing values</li>
<li>Approximate Bayesian Bootstrap : Sample with replacement from $\{x_i\}^k_{i=1}$ to form new data set $X^\ast = \{x^\ast_{i} \}^{k^\ast}_{i=1}$ ; then randomly sample $n$ values from $X^\ast$ to fill in the missing values, allowing for repeatedly filling missing values</li>
</ul>
</li>
<li>Model based methods : treat missing variable as <code>y</code>, other variables as <code>x</code> ; take the  data without missing values as out training set to train a <font color="#009100">classification</font> or <font color="#009100">regression</font> model ; take those with missing values as test set to predict the missing values.</li>
</ul>
<h3 id="Outlier-异常值"><a href="#Outlier-异常值" class="headerlink" title="Outlier (异常值)"></a>Outlier (异常值)</h3><ul>
<li><p>Outlier Detection</p>
<ul>
<li>Statistics Based Methods</li>
<li>Local Outlier Factor</li>
</ul>
</li>
<li><p>Computing Density by Distance</p>
<ul>
<li>$d(A, B)$ : distance between $A$ and $B$ </li>
<li>$d_k (A)$ : k-distance of $A$, or the distance between $A$ and the <font color="red">k-th nearest point</font> from $A$ ;</li>
<li>$N_k (A)$ : Set of k-distance neighborhood of $A$, or the points within $d_k (A)$ from $A$ ;</li>
<li>$rd_k (B, A)$ : k-reach distance from $A$ to $B$, the repulsive distance from $A$ to $B$ as if $A$ has a hard-core with radius $d_k (A)$, $rd_k (B, A) = max\{d_k (A), d(A, B)\}$ ; k-reach-distance is not symmetric. [ $rd_k (B, A)\neq rd_k(A,B)$ ]  <br><font color="Grey">Personal understanding: It’s like adding a weight at two edge between two nodes in a directed graph.</font></li>
</ul>
</li>
</ul>
<blockquote>
<p>如果 $B$ 在 $A$ 的 $k$ 邻近点以外，则取 $A$, $B$ 距离，如果 $B$ 在 $A$ 的 $k$ 邻近点以内，则取 $A$ 与其 $k$ 邻近点的距离</p>
</blockquote>
<ul>
<li>Local Outlier Factor (Some definition)<ul>
<li>$lrd_k (A)$ : <font color="red">local reachability density</font> is inversely proportional (成反比) to the average distance</li>
<li>$lrd_k (A)=1/\left(\frac{ \sum_{O\in N_k (A)} rd_k (A,O) }{| N_k (A)|}\right)$ <font color="blue">(Definition)</font> </li>
<li>If for most $O\in N_k (A)$ , more than $k$ points are closer to $O$ than $A$ is, then the denominator (分母) is much larger than $d_k(A)$ , and $lrd_k(A)$ is small (e.g. $k=3$ in following Pic)</li>
<li><font color="red">Local Outlier Factor</font> : $LOF_k(A)=\Large{\frac{ \sum_{O\in N_k(A)} \frac{lrd_k(O)}{lrd_k(A)}}{|N_k(A)|}}$ </li>
<li>$LOF_k(A) \ll 1$ , the density of $A$ is locally higher ; $LOF_k(A)\gg 1$ , the density of $A$ is locally lower, probably <font color="#ff359a">outlier</font> </li>
</ul>
</li>
</ul>
<div align="center">
<img src="/2024/06/22/Big-Data-1/bd10.png" alt="bd10" width="40%">
</div>

<blockquote>
<font face="华文楷体" size="4">注：</font>$LOF$ <font face="华文楷体" size="4">主要用于检测点</font> $A$ <font face="华文楷体" size="4">的邻近点密度，并由此推测该点是否异常值</font>

</blockquote>
]]></content>
      <categories>
        <category>2024 Spring</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>CSE Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>CS202 计算机组成原理</title>
    <url>/2024/06/25/Computer-Organization/</url>
    <content><![CDATA[<h1 id="Computer-Organization"><a href="#Computer-Organization" class="headerlink" title="Computer Organization"></a>Computer Organization</h1>]]></content>
      <categories>
        <category>2024 Spring</category>
      </categories>
      <tags>
        <tag>CSE Learning</tag>
        <tag>Verilog</tag>
      </tags>
  </entry>
  <entry>
    <title>Introduction to Hexo and Github Page</title>
    <url>/2024/06/07/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is the very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
  </entry>
</search>
