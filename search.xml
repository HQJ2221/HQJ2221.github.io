<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>MA234 大数据导论与实践（一）</title>
    <url>/2024/06/22/Big-Data-1/</url>
    <content><![CDATA[<h1 id="Big-Data-I"><a href="#Big-Data-I" class="headerlink" title="Big Data (I)"></a>Big Data (I)</h1><h2 id="I-Pre-Knowledge"><a href="#I-Pre-Knowledge" class="headerlink" title="I. Pre-Knowledge"></a>I. Pre-Knowledge</h2><h3 id="Recall-for-Linear-Algebra"><a href="#Recall-for-Linear-Algebra" class="headerlink" title="Recall for Linear Algebra"></a>Recall for Linear Algebra</h3><p><strong>1. Linear Combination and Linear Function</strong></p>
<p><strong>Def.</strong> Suppose $\vec\alpha_1,\vec\alpha_2,\cdots, \vec\alpha_e$ are finite vector from <font color="red">linear space</font> $\textbf{V}$. If any vector from $\textbf{V}$ can be represented as $\vec\alpha = k_1\vec\alpha_1+k_2\vec\alpha_2+\cdots + k_e \vec\alpha_e$ , we say that $\vec\alpha$ can be linearly represented by vector group $\{\vec\alpha_1,\vec\alpha_2,\cdots, \vec\alpha_e\}$ , or $\alpha$ is a Linear Combination of $\{\vec\alpha_1,\vec\alpha_2,\cdots, \vec\alpha_e\}$. </p>
<blockquote class="blockquote-center">
<p>$<br>\begin{align}<br>&amp;\text{Set }A=\{\vec\alpha_1,\vec\alpha_2,\cdots, \vec\alpha_e\}\\<br>&amp;V=\text{Span}(A)=\{k_1\vec\alpha_1+k_2\vec\alpha_2+\cdots + k_e \vec\alpha_e | k_i\in \mathbb R, 1\le i\le e\}<br>\end{align}<br>$</p>

</blockquote>
<blockquote>
<p>In a <strong>matrix</strong> (i.e. $A$), set all rows as a vector group, and it span a space called <strong>Row Space</strong> (Noted: $R(A)$). All columns span a space called <strong>Column Space</strong> (Noted: $\text{Col}(A)$).</p>
<p>Linear Function $Ax=b$ is solutable <font color="red">if and only if</font> $b$ is a linear combination of $\text{Col}(A)$ (or $b \in \text{Col}(A)$).</p>
<p>Specially, if $b=0$ ($Ax=0$), then all solution of $x$ group as a vector space called <strong>Null Space</strong> (Noted: $\text{Nul}(A)$)</p>
</blockquote>
<hr>
<p><strong>2. Basis and Orthogonal</strong></p>
<ul>
<li>About <strong>Rank</strong><ul>
<li><font color="green">Recall: </font>$\color{green}LU$ <font color="green">factorization</font><ul>
<li>$\color{green}PA=LDU$, where $P$ is row exchange matrix (避免 A 主元为 0), $L$ is lower-triangle matrix with diagonal is all 1, $D$ is the coefficient matrix and $U$ is upper-triangle matrix.</li>
</ul>
</li>
<li>For a $m\times n$ matrix ranked $r$, there are $(n-r)$ particular solution of $Ax=b$ in the solution space of $A$ ($\text{Nul}(A)$).</li>
<li>For $Ax=b$ , $Ux=c$ or $Rx=d$ , there must be $\color{red}(m-r)$ <font color="red">conditions</font> for formula to be solutable.</li>
</ul>
</li>
</ul>
<ul>
<li>About <strong>Linear Independent</strong><ul>
<li><strong>Def.</strong> Suppose $A=\{v_1,v_2,\cdots, v_n\}$ is vector set of $\mathbb R^n$. If $\exists v_i \in A, v_i=\sum_{j\neq i} \lambda_j v_j, \lambda_j \in \mathcal R$ , then we say $A$ is <strong>linear dependent</strong>. <font color="red">If not, we say it’s <strong>Linear Independent</strong>.</font></li>
<li><strong>Thm.</strong> $A$ is linear independent <font color="red">if and only if</font> $\lambda_1 \vec{v_1}+\lambda_2\vec{v_2}+\cdots +\lambda_k\vec{v_k}=0$ only holds when $\lambda_1=\lambda_2=\cdots =\lambda_k=0$</li>
</ul>
</li>
</ul>
<blockquote>
<p>Then we can talk about <strong>Basis</strong>(基)</p>
</blockquote>
<p><strong>Def.</strong> For vector space $V$ , if vector group $A=\{v_1,v_2,\cdots, v_k\}$ satisfies that $V=\text{Span}(A)$ , and $A$ is <font color="red">linear independent</font> , then we say that $\color{red}A$ <font color="red">is one of the <strong>basis</strong> of</font> $\color{red}V$.</p>
<ul>
<li>If $A$ is a basis of $V$ , then $\forall \vec{w} \in V$ , there must be unique array $[a_1, a_2,\cdots,a_k]$ such that $\vec{w}=a_1v_1+a_2v_2+\cdots +a_kv_k$ . Then we call this array a <font color="red">coordinate</font> of $\vec w$ in $A$ , noted $[\vec w]_{A}$</li>
</ul>
<h3 id="Recall-for-Calculus"><a href="#Recall-for-Calculus" class="headerlink" title="Recall for Calculus"></a>Recall for Calculus</h3><p><strong>1. Langrange Multiplier</strong> [拉格朗日乘数法]</p>
<h3 id="Other-Prepared-Knowledge"><a href="#Other-Prepared-Knowledge" class="headerlink" title="Other Prepared Knowledge"></a>Other Prepared Knowledge</h3><p><strong>1. Norm</strong></p>
<p>On vectors :</p>
<ul>
<li>1-Norm: $|x|_1 = \sum_{i=1}^{N}{|x_i|}$</li>
<li>2-Norm: $|\textbf{x}|_2= \sqrt{\sum_{i=1}^{N} x_i^2}$</li>
<li>$\pm\infty$-Norm: $|\textbf{x}|_{\infty}=\underset{i}\max{|x_i|}$  ;  $|\textbf{x}|_{-\infty}=\underset{i}\min{|x_i|}$</li>
<li>p-Norm: $|\textbf{x}|_p=(\sum_{i=1}^{N}{|x_i|}^p)^{\frac{1}{p}}$</li>
</ul>
<p>On matrix :</p>
<ul>
<li>1-Norm(列和范数) : $|A|_1=\underset{j}\max \sum_{i=1}^{m}{|a_{i,j}|}$  , maximum among <font color="red">absolute sum of column vector</font>.</li>
<li>2-Norm: $|A|_2=\sqrt{\lambda_1}$  , where $\lambda_1$ is the maximum eigenvalue(特征值) of $A^TA$</li>
<li>$\infty$-Norm(行和范数) : $|A|_\infty=\underset{i}\max \sum_{j=1}^{n}{|a_{i,j}|}$  , maximum among <font color="red">absolute sum of row vector</font>.</li>
<li>F-Norm(核范数) : $|A|_*=\sum_{i=1}^{n}\lambda_i$  , where $\lambda_i$ is singular value(奇异值) of $A$</li>
</ul>
<h2 id="II-Intro"><a href="#II-Intro" class="headerlink" title="II. Intro"></a>II. Intro</h2><h3 id="About-Big-Data"><a href="#About-Big-Data" class="headerlink" title="About Big Data"></a>About Big Data</h3><ul>
<li><font color="Red"><strong>4 Big “V”</strong></font> required in Big Data<ul>
<li><strong>Volume</strong>: KB, MB, GB ($10^9$ bytes), TB, PB, EB ($10^{18}$ bytes), ZB, YB<ul>
<li>Data of Baidu: several ZB</li>
</ul>
</li>
<li><strong>Variety</strong>: diﬀerent sources from business to industry, diﬀerent types</li>
<li><strong>Value</strong>: redundant information contained in the data, need to retrieve useful information</li>
<li><strong>Velocity</strong> (速度): fast speed for information transfer</li>
</ul>
</li>
<li><em>Two perspectives of data sciences</em> :<ul>
<li>Study science with the help of data : bioinformatics, astrophysics, geosciences, etc.</li>
<li>Use scientiﬁc methods to exploit (利用) data : statistics, machine learning, data mining, pattern recognition, data base, etc.</li>
</ul>
</li>
<li><em>Data Analysis</em><ul>
<li>Ordinary data types :<ul>
<li>Table : classical data (could be treated as matrix)</li>
<li>Set of points : mathematical description</li>
<li>Time series : text, audio, stock prices, DNA sequences, etc.</li>
<li>Image : 2D signal (or matrix equivalently, e.g., pixels), MRI, CT, supersonic imaging</li>
<li>Video : Totally 3D, with 2D in space and 1D in time (another kind of time series)</li>
<li>Webpage and newspaper : time series with spacial structure</li>
<li>Network : relational data, graph (nodes and edges)</li>
</ul>
</li>
<li>Basic assumption : the data are generated from an underlying model, which is unknown in practice<ul>
<li>Set of points : probability distribution</li>
<li>Time series : stochastic processes, e.g., Hidden Markov Model (HMM)</li>
<li>Image : random ﬁelds, e.g., Gibbs random ﬁelds</li>
<li>Network : graphical models, Beyesian models</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>Difficulties of Data Analysis</strong></p>
<ul>
<li>Huge <font color="#921aff">volume</font> of data</li>
<li>Extremely high dimensions<ul>
<li>Solutions: <ul>
<li>Make use of prior information</li>
<li>Restrict to simple models</li>
<li>Make use of special structures, e.g., sparsity, low rank, smoothness</li>
<li>Dimensionality reduction, e.g., PCA, LDA, etc.</li>
</ul>
</li>
</ul>
</li>
<li>Complex <font color="#921aff">variety</font> of data</li>
<li>Large noise (噪点, <font color="#921aff">values</font>) : data are always contaminated with noises</li>
</ul>
<h3 id="Representation-of-Data"><a href="#Representation-of-Data" class="headerlink" title="Representation of Data"></a>Representation of Data</h3><ul>
<li>Input space $\mathcal X = \{\text{All possible samples}\}$ ; $\textbf{x} \in \mathcal{X}$ is an input vector, also called feature, predictor, independent variable, etc; <strong>typically multi-dimension</strong>. For multi-dimension, $\textbf{x} \in \mathbb R^p$ is a weight vector (权重向量，每一维度所占权重可调整) or coding vector (编码向量，e.g. 矢量图).</li>
<li>Output space $\mathcal{Y} = \{\text{All possible results}\}$ ; $y \in \mathcal{Y}$ is an output vector, also called response, dependent variable, etc; <strong>typically one dimension</strong>. E.g. $y = 0\ \text{or}\ 1$ for classiﬁcation problems, $y \in \mathbb{R}$ for regression problems.</li>
<li>For supervised learning, assume that $(\textbf{x},y)\sim \mathcal P$, a joint distribution on the sample space $\mathcal X \times \mathcal Y$</li>
</ul>
<hr>
<font size="4"><b>Supervised Learning (监督学习) —— <font color="Grey">given labels of data</font></b></font>

<ul>
<li>Training : ﬁnd the optimal parameters (or model) to minimize the error between the prediction and target</li>
<li>Classiﬁcation <font color="Grey">(if output is discrete)</font>: SVM (支持向量机), KNN (K-Nearest Neighbor), Desicion tree, etc.</li>
<li>Regression <font color="Grey">(if output is continuous)</font>: linear regression, CART, etc.</li>
</ul>
<p>Maths method about Supervised Learning </p>
<ul>
<li>Goal: Find the conditional distribution $\mathcal P(y|\textbf{x})$ of $y$ given $\textbf{x}$ </li>
<li>Training dataset: $\{(\textbf{x}_i, y_i)\}_{i=1}^{n} \overset{\text{i.i.d}}{\sim} \mathcal P$, used to learn an approximation $\hat{f}(\textbf{x})$ or $\hat{\mathcal P}(y|\textbf{x})$</li>
<li>Test dataset: $\{(\textbf{x}_j, y_j)\}_{j=n+1}^{n+m} \overset{\text{i.i.d}}{\sim} \mathcal P$, used to test</li>
</ul>
<div align="center">
<img src="/2024/06/22/Big-Data-1/bd2.png" alt="bd2" width="80%">
</div>

<blockquote>
<p>So we can conclude that a predictor must be developed from a Supervised Learning Model.</p>
</blockquote>
<font size="4"><b>Unsupervised Learning (无监督学习) —— <font color="Grey">no labels</font></b></font>

<ul>
<li>Optimize the parameters based on some <font color="#ce0000">natural rules</font>, e.g., cohesion (收敛) or divergence (发散)</li>
<li>Clutering : K-Means, SOM (Self-Organizing Map)</li>
</ul>
<div align="center">
<img src="/2024/06/22/Big-Data-1/bd3.png" alt="bd3" width="80%">
</div>


<p>Maths method about Unsupervised Learning</p>
<ul>
<li>Goal : in probabilistic settings, find the distribution (PDF) $\mathcal P(\textbf{x})$ of $\textbf{x}$ and approximate it (there is no y)</li>
<li>Training dataset : $\{(x_i)\}_{i=1}^{n} \overset{\text{i.i.d}}{\sim} \mathcal P$ , used to learn an approximation $\hat{\mathcal P}(\textbf{x})$ (no test data in general)</li>
</ul>
<font size="4"><b>Semi-supervised learning:</b></font> 

<ul>
<li>with missing data, e.g., EM; self-supervised learning, learn the missing part of images, inpainting.</li>
</ul>
<font size="4"><b>Reinforcement learning (强化学习):</b></font>  

<ul>
<li><font color="red">No label, but have target</font>. Play games, e.g., Go, StarCraft; robotics; auto-steering.</li>
</ul>
<h3 id="Modeling-and-Analysis"><a href="#Modeling-and-Analysis" class="headerlink" title="Modeling and Analysis"></a>Modeling and Analysis</h3><ul>
<li>Decision function (hypothesis) space : <ul>
<li>$\mathcal{F}=\{\mathcal{f_\theta}=\mathcal{f_\theta}(x), \theta \in \Theta \}$ </li>
<li>or $\mathcal{F}=\{\mathcal{P_\theta}=\mathcal{P_\theta}(y|x), \theta \in \Theta \}$</li>
</ul>
</li>
<li><font color="red">Loss function :</font> a measure for the “goodness” of the prediction, $L(y, \mathcal{f}(x))$ <ul>
<li><a name="0-1 loss"><i>0-1 loss</i></a>: $L(y, \mathcal{f}(x))=\textbf{l}_{y\not{=}f(x)}=1-\textbf{l}_{y=f(x)}$ （个人理解一般是用于二元项预测的误差判断）</li>
<li><i>Square loss</i>: $L(y, \mathcal{f}(x))=(y-f(x))^2$ （比绝对值误差更泛用）</li>
<li><i>Absolute loss</i>: $L(y, \mathcal{f}(x))={|y-f(x)|}$ </li>
<li><i>Cross-entropy (交叉熵) loss</i>: <br>   $\color{red}L(y, \mathcal{f}(x))=-y\log{f(x)}-(1-y)\log{(1-f(x))}$</li>
</ul>
</li>
<li><strong>Risk</strong> : in average sense,<br> $\mathcal{R}(f)=E_{\mathcal P} [L(y, f(x))]=\underset{\mathcal X \times \mathcal Y}{\int}L(y, f(x))\mathcal{P}(x,y)\text d x \text d y$ </li>
<li><font color="Red"><b>Target of Learning</b></font> : minimize $\mathcal R_{exp}(f)$ to get $f^{\ast}$ ( $\text{即} f^{\ast}=\underset{f}{min}\ \mathcal{R}_{exp}(f)$ )</li>
</ul>
<p><strong>Risk Minimize Strategy :</strong> </p>
<ul>
<li>Empirical risk minimization (<strong>ERM</strong>) : <ul>
<li>given training set $\{(\textbf{x}_i,y_i)\}_{i=1}^{n}$ , $R_{emp}(f)=\frac{1}{n}\sum_{i=1}^{n}L(y_i,f(\textbf{x}_i))$ <font color="grey">(Loss function 的均值定义为预测模型 f 的经验风险)</font> .<ul>
<li>By law of large number, $\underset{n\to\infty}{\lim} R_{emp}(f)=R_{exp}(f)$ . <font color="Grey">(即经验风险趋近于预测风险)</font></li>
<li>Optimization problem <font color="red">(What Machine Learning truly do)</font> : $\underset{f\in\mathcal F}{\min}\frac{1}{n}\sum_{i=1}^{n}L(y_i,f(\textbf{x}_i))$ </li>
<li><font color="Green">Now we only need to know</font>  $\color{green}f$ <font color="Green">and training set</font>  $\color{green}\textbf{x}_i$ </li>
</ul>
</li>
</ul>
</li>
<li>Structural risk minimization (<strong>SRM</strong>) : <ul>
<li>given training set $\{(\textbf{x}_i,y_i)\}_{i=1}^{n}$ , and a complexity function $J=J(f)$ , $R_{SRM}(f)=\frac{1}{n}\sum_{i=1}^{n}L(y_i,f(\textbf{x}_i))+\lambda J(f)$ <ul>
<li>$J(f)$ measures how complex the model $f$ is, typically the degree of complexity</li>
<li>$λ\ge 0$ is a tradeoff(平衡项) between the empirical risk and model complexity</li>
<li>Optimization problem <font color="red">(What Machine Learning truly do)</font> : $\underset{f\in\mathcal F}{\min}\frac{1}{n}\sum_{i=1}^{n}L(y_i,f(\textbf{x}_i))+\lambda J(f)$ </li>
<li><font color="Green">We need to know</font> $\color{green}f$ <font color="Green">and training set</font> $\color{green}{\textbf{x}_i}$ <font color="Green">, and need to</font> <font color="#00CD00">adjust the parameter</font>  $\color{green}{\lambda}$</li>
</ul>
</li>
</ul>
</li>
</ul>
<blockquote>
<p>We see that <font color="#c6a300">Optimization Method</font> is essencial in machine learning. Here are some of them: </p>
<ul>
<li>Gradient descent method (梯度下降), including coordinate descent, sequential minimal optimization (SMO), etc.</li>
<li>Newton’s method and quasi-Newton’s method (拟牛顿法)</li>
<li>Combinatorial optimization (组合优化)</li>
<li>Genetic algorithms (遗传算法)</li>
<li>Monte Carlo methods (随机算法)</li>
</ul>
</blockquote>
<p><strong>Model assessment :</strong></p>
<ul>
<li>Training error: $R_{emp}(\hat f)=\frac{1}{n}\sum_{i=1}^{n}L(y_i,\hat f(\textbf{x}_i))$ , tells the diﬃculty of learning problem</li>
<li>Test error: $e_{test}(\hat f)=\frac{1}{m}\sum_{j=n+1}^{n+m}L(y_j,\hat f(\textbf{x}_j))$ , tells the capability of prediction ;<br> In particular, if 0-1 loss is used (below)<ul>
<li>Error rate : $e_{test}(\hat f) = \frac{1}{m}\sum_{j=n+1}^{n+m}\textbf{l}_{y_j\ne\hat f(\textbf{x}_j)}$</li>
<li>Accuracy : $r_{test}(\hat f) = \frac{1}{m}\sum_{j=n+1}^{n+m}\textbf{l}_{y_j=\hat f(\textbf{x}_j)}$</li>
<li>$e_{test}+ r_{test} = 1$ </li>
</ul>
</li>
<li><p>Generalization error (泛化误差——模型对新样本的预测性的度量)</p>
<ul>
<li>$R_{exp}(\hat f)=E_{\mathcal P}[L(y,\hat f(\textbf{x}))]=\underset{\mathcal X\times\mathcal Y}{\int}L(y,\hat f(\textbf{x}))\mathcal P(\textbf{x},y)\text d\textbf{x} \text d y$ <br>tells the capability for predicting <font color="#9f4d95">unknown data</font> from the same distribution</li>
<li>Its upper bound $M$ deﬁnes the generalization ability (负相关)<ul>
<li>As $n\to\infty$, $M\to 0$ (which means almost no error)</li>
<li>As $\mathcal F$ becomes larger, $M$ increases.</li>
</ul>
</li>
</ul>
</li>
<li><p><em>Overfitting</em></p>
<ul>
<li>Too many model paramters （模型太复杂）</li>
<li>Better for training set, but worse for test set</li>
</ul>
</li>
<li><em>Underfitting</em><ul>
<li>Better for test set, but worse for training set</li>
</ul>
</li>
</ul>
<p><strong>Model Selection :</strong> choose the most proper model.</p>
<ul>
<li><a name="cross validation">Cross-validation</a> (交叉验证) : split the training set into training subset and validation subset, use training set to train diﬀerent models repeatedly, use validation set to select the best model with the smallest (validation) error<ul>
<li>Simple CV : randomly split the data into two subsets</li>
<li>K-fold CV : randomly split the data into $K$ disjoint subsets with the same size, treat the union of $K − 1$ subsets as training set, the other one as validation set, do this repeatedly and select the best model with smallest mean (validation) error</li>
<li>Leave-one-out CV : $K = n$ in the previous case</li>
</ul>
</li>
</ul>
<h3>Data Science vs. Other Techniques</h3>

<div align="center">
<img src="/2024/06/22/Big-Data-1/bd1.png" alt="bd1" width="60%">
</div>

<hr>
<h2 id="III-Data-Preprocessing"><a href="#III-Data-Preprocessing" class="headerlink" title="III. Data Preprocessing"></a>III. Data Preprocessing</h2><h3 id="Data-Type"><a href="#Data-Type" class="headerlink" title="Data Type"></a>Data Type</h3><ul>
<li>Types of Attributes  <font size="2">(每门课几乎都离不开这个)</font><ul>
<li>Discrete: $x \in \text{some countable sets}$, e.g., $\mathbb N$ <ul>
<li><a name="nominal">Nominal (列举名义)</a> </li>
<li><a name="boolean">Boolean (0 or 1) </a> </li>
<li><a name="ordinal">Ordinal (基数等级, e.g. A+, A-, B+,…) </a> </li>
</ul>
</li>
<li>Continuous: $x \in \text{some subset in }\mathbb R$ </li>
</ul>
</li>
</ul>
<ol>
<li><strong>Basic Statistics</strong> (统计量)<ul>
<li>Mean</li>
<li>Median (中位数)</li>
<li>extremum (极值)</li>
<li>Quantile (分位数) </li>
<li>Variance, Standard deviation (标准差)</li>
<li>Mode (众数)</li>
</ul>
</li>
</ol>
<div align="center">
<img src="/2024/06/22/Big-Data-1/bd4.png" alt="bd4" width="90%">
</div>

<blockquote>
<p>Empiricism:  Mean − Mode = 3 $\times$ (Mean − Median)</p>
</blockquote>
<ul>
<li>Box Plot (箱线图) —— used to describe statistics</li>
</ul>
<div align="center">
<img src="/2024/06/22/Big-Data-1/bd5.png" alt="bd5" width="40%">
</div>



<ol>
<li><strong>Metrics</strong> (度量——亦称距离函数，是度量空间中满足特定条件的特殊函数。度量空间由欧几里得空间的距离概念抽象化定义而来。)<ul>
<li>Proximity :<ul>
<li>Similarity : range is $[0, 1]$ </li>
<li>Dissimilarity : range is $[0, \infty]$ , sometimes <a href="#distance">distance</a> (noted by <code>d</code>)</li>
</ul>
</li>
<li>For <a href="#nominal">nominal data</a>, $d(\textbf{x}_i,\textbf{x}_j)=\frac{\sum_{k}\textbf{l}(\textbf{x}_{i,k}\neq\textbf{x}_{j,k})}{p}$ ,or one-hot encoding into Boolean data</li>
<li>For <a href="#boolean">Boolean data</a>, <strong>symmetric distance</strong> (rand disrance) $\text d(\textbf{x}_i,\textbf{x}_j) =\frac {r+s}{q+r+s+t}$ or <strong>Rand index</strong> $\text{Sim}_{\text{Rand}}(\textbf{x}_i,\textbf{x}_j)=\frac{q+t}{q+r+s+t}$ ; <strong>non-symmetric distance</strong> (<a name="Jaccard"><font color="black"> Jaccard distance </font></a>) $\text d(\textbf{x}_i,\textbf{x}_j)=\frac{r+s} {q+r+s}$ or <strong>Jaccard index</strong> $\text{Sim}_{\text{Jaccard}}(\textbf{x}_i,\textbf{x}_j)=\frac {q} {q+r+s}$ </li>
</ul>
</li>
</ol>
<div align="center">
<img src="/2024/06/22/Big-Data-1/bd6.png" alt="bd6" width="40%">
</div>



<p><a name="distance"><font color="Red"><strong>Distance :</strong></font></a></p>
<p><strong>Def.</strong> Distance <code>d</code> is the difference between two samples.</p>
<ul>
<li>Properties of Distance : <ul>
<li>Non-negative: $\text{d}(x,y)\ge 0$</li>
<li>Identity: $\text d(x,y)=0\Leftrightarrow x=y$ </li>
<li>Symmetric: $\text d(x,y)=\text d(y,x)$ </li>
<li>Basic Vector Attributes : e.g. $\text d(x,y)\le \text d(x,z)+\text d(z,y)$ </li>
</ul>
</li>
<li>距离度量分为Space Distance (e.g. Euclidean) 、String Distance (e.g. Hamming distance) 、Set Proximity (e.g. Jaccard distance) 和 Distribution Distance (e.g. Chi-square measure)</li>
</ul>
<font color="blue">以下简单介绍几种距离，更多请参考<a href="https://blog.csdn.net/hy592070616/article/details/121723169?spm=1001.2014.3001.5501">此处 (csdn note)</a></font><br>



<font color="blue">1 .  Minkowski distance (闵可夫斯基距离)</font>

<blockquote class="blockquote-center">
<p>$<br>\begin{align}<br>&amp;\text d(\textbf{x}_i,\textbf{x}_j)=\sqrt[h]{\sum_{k=1}^{p}|\text x_{ik}-\text x_{jk}|^h}&amp;<br>\end{align}<br>$</p>

</blockquote>
<blockquote>
<p>Parameter <code>h</code> is to <font color="blue">emphasize the character of the data</font>. By changing the value of <code>h</code> , Minkowski distance can cover many Distance Metrics.</p>
</blockquote>
<font color="blue">2 .  Manhattan distance (曼哈顿距离) </font>


<blockquote>
<p>Minkowski distance where $h = 1$</p>
</blockquote>
<blockquote class="blockquote-center">
<p>$<br>\text d(\textbf{x}_i,\textbf{x}_j)=\sum_{k=1}^{p}|\text x_{ik}-\text x_{jk}|<br>$</p>

</blockquote>
<font color="blue">3 .  Euclidean distance (欧氏距离)</font>

<blockquote>
<p>Minkowski distance where $h = 2$ </p>
</blockquote>
<blockquote class="blockquote-center">
<p>$<br>\text d(\textbf{x}_i,\textbf{x}_j)=\sqrt{\sum_{k=1}^{p}(\text x_{ik}-\text x_{jk})^2}<br>$</p>

</blockquote>
<font color="blue">4 .  Supremum distance (or Chebyshev distance, 切比雪夫距离)</font>

<blockquote>
<p>Minkowski distance where $h \to \infty$ </p>
</blockquote>
<blockquote class="blockquote-center">
<p>$<br>\text d(\textbf{x}_i,\textbf{x}_j)=\max_{k=1}^{p}|\text x_{ik}-\text x_{jk}|<br>$</p>

</blockquote>
<p><a name="cosine distance"><font color="blue">5 .  Cosine distance (余弦距离)</font></a> </p>
<blockquote class="blockquote-center">
<p>$<br>\cos(\textbf{x}_i,\textbf{x}_j)=\frac{\sum_{k=1}^{p}\text x_{ik}\text x_{jk}}{\sqrt{\sum_{k=1}^{p}\text x_{ik}^2}\sqrt{\sum_{k=1}^{p}\text x_{ik}^2}}=\frac{\textbf{x}_i\cdot\textbf{x}_j}{\left|\textbf{x}_i\right|\left|\textbf{x}_j\right|}<br>$</p>

</blockquote>
<p><strong>Other Distance:</strong></p>
<ul>
<li>For <a href="#ordinal">ordinal data</a>, mapping the data to numerical data : $X=\{x_{(1)}, x_{(2)},…, x_{(n)}\}, x_{(i)} \mapsto \frac{i−1} {n−1}\in [0, 1]$ </li>
<li>For mixed type, use weighed distance (加权) with prescribed weights :</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\text d(\textbf{x}_i,\textbf{x}_j)=\frac{\sum_{g=1}^{G}w_{ij}^{(g)}\text d_{ij}^{(g)}}{\sum_{g=1}^{G}w_{ij}^{(g)}}<br>$</p>

</blockquote>
<h3 id="Data-Preprocessing-Lecture"><a href="#Data-Preprocessing-Lecture" class="headerlink" title="Data Preprocessing (Lecture)"></a>Data Preprocessing (Lecture)</h3><div align="center">
<img src="/2024/06/22/Big-Data-1/bd7.png" alt="bd7" width="90%">
</div>

<ul>
<li>Data Scaling (归一化，标准化)<ul>
<li>Why scaling?<ul>
<li>For better performance or normalize diﬀerent dimensions</li>
</ul>
</li>
<li><a name="z-score"><b>Z-score scaling</b></a>:   <font size="5">$x_i^\ast=\frac{x_i-\hat\mu}{\hat\sigma}$ </font> ,<br>applicable when max and min unknown and data distributes well (e.g. normal distribution)</li>
<li><strong>0-1 scaling</strong> (Min-Max scaling) :   <font size="5">$x_i^\ast=\frac{x_i-\min_k x_k}{\max_k x_k-\min_k x_k}$ </font> ,<br>applicable for bounded data sets, and need to <font color="red">recompute</font> max and min when new data added</li>
<li>Decimal scaling: $x_{i}^{\ast}=\frac{x_i}{10^k}$, applicable for data varying across many magnitudes (分布太广)</li>
<li>Logistic scaling: $x_i^{\ast}=\frac{1}{1+e^{-x_i}}$ , applicable for data concentrating nearby origin (分布太窄)</li>
</ul>
</li>
<li>Data Discretization (离散化)<ul>
<li>Why discretization?<ul>
<li>Improve the robustness : removing the outliers by putting them into certain intervals</li>
<li>For better interpretation</li>
<li>Reduce the storage and computational power</li>
</ul>
</li>
<li><strong>Unsupervised discretization</strong>: equal-distance discretization (等距，数据分布可能不均), equal-frequency discretization, clustering-based discretization (聚类), 3$\sigma$-based discretization</li>
<li><strong>Supervised discretization</strong>: information gain based discretization (e.g. 决策树), $\mathcal X^2$-based discretization (Chi-Merge)</li>
</ul>
</li>
<li>Data Redundancy <ul>
<li>Why redundancy exists?<ul>
<li>Correlations exist among different attributes (E.g. Age, birthday and current time), <font color="green">recalling the linear dependency for vectors</font></li>
</ul>
</li>
<li><strong>Continuous variables:</strong> compute the correlation coefficient (相关系数) <font size="4">$\rho_{A,B}=\frac{\sum_{i=1}^{k}{(a_i-\bar A)(b_i-\bar B)}}{k\hat\sigma_{A}\hat\sigma_{B}}\in[-1,1]$ </font></li>
<li><strong>Discrete variables:</strong> compute the $\mathcal X^{2}$ statistics : large $\hat{\mathcal{X}^{2}}$ value implies small correlation.</li>
</ul>
</li>
</ul>
<blockquote>
<p>About missing data: (<code>NA</code>, \<Empty>, <code>NaN</code>)</Empty></p>
<p>Delete or Pad </p>
<ul>
<li>Pad (or filling)<ul>
<li>fill with <font color="blue">0</font>, with <font color="blue">mean value</font>, with <font color="blue">similar variables</font> (auto-correlation is introduced), with <font color="blue">past data</font>, with <font color="blue">Expectation-Maximization</font> or by K-Means</li>
</ul>
</li>
</ul>
<p>In Python, <code>NaN</code> means missing values (Not a Number, missing float values)</p>
<p><code>None</code> is a Python object, representing missing values of the object type</p>
<p>For some multi-classifications (e.g. “Male” and “Female”) model, we should refer to <strong>Dummy Variables</strong> to describe. (We usually set “Unknown” as reference variable <code>00</code>, and describe “Male” and “Female” as <code>01</code> &amp; <code>10</code>)</p>
</blockquote>
<ul>
<li>Random filling : <ul>
<li>Bayesian Bootstrap : for discrete data with range $\{x_i\}^k_{i=1}$, randomly sample $k − 1$ numbers from $U(0, 1)$ as $\{a_{(i)}\}^k_{i=0}$ with $a_{(0)} = 0$ and $a_{(k)} = 1$ ; then randomly sample from $\{x_i\}^k_{i=1}$ with probability distribution $\{a_{(i)} − a_{(i−1)}\}^k_{i=1} $accordingly to fill in the missing values</li>
<li>Approximate Bayesian Bootstrap : Sample with replacement from $\{x_i\}^k_{i=1}$ to form new data set $X^\ast = \{x^\ast_{i} \}^{k^\ast}_{i=1}$ ; then randomly sample $n$ values from $X^\ast$ to fill in the missing values, allowing for repeatedly filling missing values</li>
</ul>
</li>
<li>Model based methods : treat missing variable as <code>y</code>, other variables as <code>x</code> ; take the  data without missing values as out training set to train a <font color="#009100">classification</font> or <font color="#009100">regression</font> model ; take those with missing values as test set to predict the missing values.</li>
</ul>
<h3 id="Outlier-异常值"><a href="#Outlier-异常值" class="headerlink" title="Outlier (异常值)"></a>Outlier (异常值)</h3><ul>
<li><p>Outlier Detection</p>
<ul>
<li>Statistics Based Methods</li>
<li>Local Outlier Factor</li>
</ul>
</li>
<li><p>Computing Density by Distance</p>
<ul>
<li>$d(A, B)$ : distance between $A$ and $B$ </li>
<li>$d_k (A)$ : k-distance of $A$, or the distance between $A$ and the <font color="red">k-th nearest point</font> from $A$ ;</li>
<li>$N_k (A)$ : Set of k-distance neighborhood of $A$, or the points within $d_k (A)$ from $A$ ;</li>
<li>$rd_k (B, A)$ : k-reach distance from $A$ to $B$, the repulsive distance from $A$ to $B$ as if $A$ has a hard-core with radius $d_k (A)$, $rd_k (B, A) = max\{d_k (A), d(A, B)\}$ ; k-reach-distance is not symmetric. [ $rd_k (B, A)\neq rd_k(A,B)$ ]  <br><font color="Grey">Personal understanding: It’s like adding a weight at two edge between two nodes in a directed graph.</font></li>
</ul>
</li>
</ul>
<blockquote>
<p>如果 $B$ 在 $A$ 的 $k$ 邻近点以外，则取 $A$, $B$ 距离，如果 $B$ 在 $A$ 的 $k$ 邻近点以内，则取 $A$ 与其 $k$ 邻近点的距离</p>
</blockquote>
<ul>
<li>Local Outlier Factor (Some definition)<ul>
<li>$lrd_k (A)$ : <font color="red">local reachability density</font> is inversely proportional (成反比) to the average distance</li>
<li>$lrd_k (A)=1/\left(\frac{ \sum_{O\in N_k (A)} rd_k (A,O) }{| N_k (A)|}\right)$ <font color="blue">(Definition)</font> </li>
<li>If for most $O\in N_k (A)$ , more than $k$ points are closer to $O$ than $A$ is, then the denominator (分母) is much larger than $d_k(A)$ , and $lrd_k(A)$ is small (e.g. $k=3$ in following Pic)</li>
<li><font color="red">Local Outlier Factor</font> : $LOF_k(A)=\Large{\frac{ \sum_{O\in N_k(A)} \frac{lrd_k(O)}{lrd_k(A)}}{|N_k(A)|}}$ </li>
<li>$LOF_k(A) \ll 1$ , the density of $A$ is locally higher ; $LOF_k(A)\gg 1$ , the density of $A$ is locally lower, probably <font color="#ff359a">outlier</font> </li>
</ul>
</li>
</ul>
<div align="center">
<img src="/2024/06/22/Big-Data-1/bd10.png" alt="bd10" width="40%">
</div>

<blockquote>
<font face="华文楷体" size="4">注：</font>$LOF$ <font face="华文楷体" size="4">主要用于检测点</font> $A$ <font face="华文楷体" size="4">的邻近点密度，并由此推测该点是否异常值</font>

</blockquote>
]]></content>
      <categories>
        <category>2024 Spring</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>CSE Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>CS202 计算机组成原理</title>
    <url>/2024/06/25/Computer-Organization/</url>
    <content><![CDATA[<h1 id="Computer-Organization"><a href="#Computer-Organization" class="headerlink" title="Computer Organization"></a>Computer Organization</h1>]]></content>
      <categories>
        <category>2024 Spring</category>
      </categories>
      <tags>
        <tag>CSE Learning</tag>
        <tag>Verilog</tag>
      </tags>
  </entry>
  <entry>
    <title>MA234 大数据导论与实践（二）</title>
    <url>/2024/06/24/Big-Data-2/</url>
    <content><![CDATA[<h1 id="Big-Data-II"><a href="#Big-Data-II" class="headerlink" title="Big Data (II)"></a>Big Data (II)</h1><h2 id="IV-Classification"><a href="#IV-Classification" class="headerlink" title="IV. Classification"></a>IV. Classification</h2><blockquote>
<p>本章内容较多，先写下本章主要内容：</p>
<p>本章涉及分类算法，主要会提及 KNN 算法，决策树算法和朴素贝叶斯算法（是分类算法中最基础的几种）<br>其中，每种算法的应用里涵盖了一些多用概念，如剪枝操作、似然函数计算等。</p>
<p>介绍三种基本算法后，本章还涉及模型评估，讲解如何通过不同问题使用不同的算法以得到最优的结果</p>
<p>注：本章含有不亚于数据预处理章节的数学公式，要求理解公式基本内涵。</p>
</blockquote>
<h3 id="K-Nearest-Neighbor-KNN"><a href="#K-Nearest-Neighbor-KNN" class="headerlink" title="K-Nearest Neighbor (KNN)"></a>K-Nearest Neighbor (KNN)</h3><blockquote>
<p>Supervised learning method, especially useful when prior knowledge on the data is very limited.</p>
<p><font color="red">Low bias, high variance</font> : <font color="blue">just for small</font> <code>k</code> </p>
<p><strong>Advantages</strong> : not sensitive to outliers (异常值距离一般较远) , easy to implement and parallelize, good for large training set</p>
<p><strong>Drawbacks</strong> : need to tune (调节) $k$, take large storage, computationally intensive (计算缓慢，算力要求高)</p>
</blockquote>
<font size="4"><b>Algorithm</b></font>

<ul>
<li>Input : training set $D_{train} = \{(x_1, y_1),\cdots,(x_N, y_N)\}$,  a test sample $x$ without label $y$, $k$ and distance metric $d(x, y)$</li>
<li>Output : predicted label $y_{pred}$ for $x$ </li>
</ul>
<ol>
<li>Compute $d(x, x_j)$ for each $(x_j , y_j) \in D_{train}$</li>
<li>Sort the distances in an <font color="Red">ascending</font> order, choose the ﬁrst $k$ samples $(x_{(1)}, y_{(1)}),\cdots,(x_{(k)} , y_{(k)})$ </li>
<li>Make majority vote $y_{pred} = \text{Mode}(y_{(1)},\cdots, y_{(k)})$ </li>
</ol>
<p>Time Complexity : $O(mndK)$ where $n$ is the number of training samples, $m$ is the number of test samples, $d$ is the dimension, and $K$ is the number of nearest neighbors</p>
<div align="center"><img src="/2024/06/24/Big-Data-2/bd8.png" alt="bd8" style="zoom:50%"></div>



<p><strong>Similarity and Divergence</strong></p>
<ul>
<li><a href="/2024/06/22/Big-Data-1/index.html#cosine distance">Cosine similarity</a></li>
<li><a href="/2024/06/22/Big-Data-1/index.html#Jaccard">Jaccard similarity</a> for sets $A$ and $B$ : $Jaccard(A,B)=\Large{\frac{|A\cap B|}{|A\cup B|}}$ </li>
<li>Kullback-Leibler(KL) divergence : $d_{KL}(P||Q) = E_P log \large{\frac{P(x)}{Q(x)}}$ , measures the distance between two probability <font color="red">distributions</font> $P$ and $Q$ ; in discrete case, $d_{KL}(p||q) = \sum^m_{i=1} p_i log \large{\frac{p_i}{q_i}}$ (CDF of $P$ and $Q$)</li>
</ul>
<p><strong>Tuning <code>k</code></strong> </p>
<ul>
<li>Different <code>k</code> value can lead to totally different results. ( model overfit the data when <code>k = 1</code>, bad for generalization )</li>
<li><strong>M-fold Cross-validation (CV)</strong> to tune <code>k</code> : <ul>
<li>partition the dataset into M parts ( M = 5 or 10 ) , let $\kappa : \{1,\cdots, N\} \to \{1,\cdots, M\}$ be <em>randomized partition index map</em> (随机分布索引映射) . The <em>CV estimate of prediction error</em> (预测误差的CV估计) is<br> $CV(\hat f,k)=\large{\frac{1}{N}} \sum_{n=1}^{N}L(y_i,\hat f^{-\kappa(i)}(x_i,k))$</li>
</ul>
</li>
</ul>
<p><img src="/2024/06/24/Big-Data-2/bd9.png" alt="bd9"></p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">k’s value</th>
<th style="text-align:center">$k=1$ (complex model)</th>
<th style="text-align:center">$k=\infty$ (simplier model)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Bias</td>
<td style="text-align:center">decrease</td>
<td style="text-align:center">increase</td>
</tr>
<tr>
<td style="text-align:center">Variance</td>
<td style="text-align:center">increase</td>
<td style="text-align:center">$0$</td>
</tr>
<tr>
<td style="text-align:center">Generalization</td>
<td style="text-align:center">overfitting (train-set friendly)</td>
<td style="text-align:center">underfitting (test-set friendly)</td>
</tr>
</tbody>
</table>
</div>
<p><a name="Bayes"><b>Bayes Classifier (Oracle Classifier)</b></a></p>
<ul>
<li>Assume $Y \in \mathcal{Y} = \{1, 2, . . . , C\}$, the classiﬁer $f : \mathcal X → \mathcal Y$ is a piecewise (分段) constant function</li>
<li>For <a href="/2024/06/22/Big-Data-1/index.html#0-1 loss">0-1 loss</a> $L(y, f )$, the learning problem is to minimize</li>
</ul>
<script type="math/tex; mode=display">
\begin{align}
\mathcal E(f)&=E_{P(X,Y)}[L(Y,f(X))]=1-P(Y=f(X))\\
&=1-\int_{\mathcal X}P(Y=f(X)|X=x)p_X(x)\text dx
\end{align}</script><ul>
<li>Bayes rule : $f^{∗} (x) = \arg \max_c P(Y = c|X = x)$ , <font color="grey">“the most probable label under the conditional probability on x”</font></li>
<li>Bayes Error Rate (贝叶斯误差) : $\text{inf}_{f}\varepsilon (f)=$ $\color{red}\mathcal E(f^{\ast})$ $=1-P(Y=f^{\ast}(X))$</li>
<li><strong>Bayes Decision Boundary</strong> (贝叶斯决策边界) : the boundary separating the <strong>K partition</strong> domains in $\mathcal X$ on each of which $f^{ ∗ }(x) \in Y$ is constant. For binary classiﬁcation, it is the level set on which $P(Y=1|X=x)=P(Y=0|X=x)=0.5$<ul>
<li><font color="green">Recall : Decision boundary of 15NN is smoother than that of 1NN</font> 



</li>
</ul>
</li>
</ul>
<font color="red">Analysis of 1NN</font>

<ul>
<li>1NN error rate is twice the Bayes error rate<ul>
<li>Bayes error $=1-p_{c^\ast}(x)$ where $c^\ast=\arg\max_{c}p_c(x)$</li>
<li>Assume the samples are i.i.d. (独立同分布) , for any test sample $x$ and small $\delta$, there is always a training sample $z \in B(x, \delta)$ (the label of $x$ is the same as that of $z$), then 1NN error is</li>
</ul>
</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\begin{align}<br>\epsilon=\sum_{c=1}^{C}p_c(x)(1-p_c(z))\overset{\delta\to 0}{\longrightarrow}&amp;1-\sum_{c=1}^{C}p_{c}^{2}(x) \\<br>\le\ &amp;1-p_{c^\ast}^{2}(x) \\<br>\le\ &amp;2(1-p_{c^\ast}(x))<br>\end{align}<br>$</p>

</blockquote>
<ul>
<li><ul>
<li><font color="green">Remark : In fact,</font> $\color{green}\epsilon\le 2(1-p_{c^\ast}^{2}(x))-\frac{C}{C-1}(1-p_{c^\ast}^{2}(x))^2$</li>
</ul>
</li>
</ul>
<font color="blue">Case : Use kNN to diagnose breast cancer (cookdata) </font>

<ul>
<li>We have to consider its radius, texture (质地) , perimeter, area, smoothness, etc. (n-dimension)</li>
<li>Data scaling : 0-1 scaling or z-score scaling</li>
<li>Use code to assist</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line">KNeighborsClassifier(n_neighbors = <span class="number">10</span>, metric = <span class="string">&#x27;minkowski&#x27;</span>, p = <span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="Decision-Tree"><a href="#Decision-Tree" class="headerlink" title="Decision Tree"></a>Decision Tree</h3><ul>
<li>Tree structure : internal nodes indicate features, while leaf nodes represent classes.</li>
<li>Start from root, choose a suitable feature $x_i$ and its split point $c_i$ at each internal node, split the node to two child nodes depending on whether $x_i \le c_i$ , until the child nodes are pure.</li>
<li>Equivalent to rectangular partition of the region.</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th><img src="/2024/06/24/Big-Data-2/bd11.png" width="60%"></th>
<th><img src="/2024/06/24/Big-Data-2/bd12.png" width="60%"></th>
</tr>
</thead>
<tbody>
<tr>
<td><p align="center"><a name="tree">Tree structure</a></p></td>
<td><p align="center">Rectangular partition</p></td>
</tr>
</tbody>
</table>
</div>
<ul>
<li>How to choose <font color="red">features</font> and <font color="red">split points</font> ?<ul>
<li>Impurity : choose the feature and split point so that after each slit the impurity should decrease the most</li>
<li>Impurity(M0)-Impurity(M12) &gt; Impurity(M0)-Impurity(M34), choose A as split node ; otherwise choose B</li>
</ul>
</li>
</ul>
<div align="center"><img src="/2024/06/24/Big-Data-2/bd13.png" alt="bd13" style="zoom:80%"></div>

<ul>
<li>Impurity Measures<ol>
<li>GINI Index<ul>
<li>Gini index of node $t$ : $Gini(t)=1-\sum_{c=1}^C (p(c|t))^2$ where $p(c|t)$ is the proportion of class-c data in node $t$</li>
<li>Gini index of a split : $Gini_{split}=\sum_{k=1}^{K}\frac{n_k}{n}Gini(k)$ where $n_k$ is the number of samples in the child node $k$, $n=\sum_{k=1}^{K} n_k$ </li>
<li>Choose the split so that $Gini(t) − Gini_{split}$ is maximized</li>
</ul>
</li>
<li>Information Gain<ul>
<li>Entropy at $t$ : $H(t) = −\sum_{c=1}^{C}p(c|t)\log_2 p(c|t)$ , </li>
<li>where $t$ is the node and $\color{blue}c$ <font color="blue">represents that this node is chosen</font>.</li>
<li>Maximum at $log_2 C$, when $p(c|t)=\frac{1}{C}$</li>
<li>Minimum at $0$, when $p(c|t)=1$ for some $c$</li>
</ul>
</li>
<li>Misclassiﬁcation Error<ul>
<li>Misclassiﬁcation error at t : $\text{Error}(t) = 1 − \max_c p(c|t)$  (use majority vote)</li>
<li>Maximum at $1−\frac{1}{C}$, when $p(c|t) = \frac{1}{C}$</li>
<li>Minimum at $0$, when $p(c|t)=1$ for some $c$</li>
</ul>
</li>
</ol>
</li>
<li>Compare Three Measure<ul>
<li>Gini index and information gain should be used when growing the tree</li>
<li>In pruning, all three can be used (typically misclassiﬁcation error)</li>
</ul>
</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">Algorithm</th>
<th style="text-align:center">Type</th>
<th style="text-align:center">Impurity Measure</th>
<th style="text-align:center">Child Nodes</th>
<th style="text-align:center">Target Type</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">ID3</td>
<td style="text-align:center">Discrete</td>
<td style="text-align:center">Info Gain</td>
<td style="text-align:center">$k\ge 2$</td>
<td style="text-align:center">Discrete</td>
</tr>
<tr>
<td style="text-align:center">C4.5</td>
<td style="text-align:center">Discrete, Continuous</td>
<td style="text-align:center">Info Gain</td>
<td style="text-align:center">$k\ge 2$</td>
<td style="text-align:center">Discrete</td>
</tr>
<tr>
<td style="text-align:center">C5.0</td>
<td style="text-align:center">Discrete, Continuous</td>
<td style="text-align:center">Info Gain</td>
<td style="text-align:center">$k\ge 2$</td>
<td style="text-align:center">Discrete</td>
</tr>
<tr>
<td style="text-align:center">CART</td>
<td style="text-align:center">Discrete, Continuous</td>
<td style="text-align:center">Gini Index</td>
<td style="text-align:center">$k=2$</td>
<td style="text-align:center">Discrete, Continuous</td>
</tr>
</tbody>
</table>
</div>
<ul>
<li>Tree Pruning (剪枝)<ul>
<li>Too complex tree structure easily leads to <font color="red">overﬁtting</font> (分类太细，模型太复杂)</li>
<li>Prepruning : set threshold <font color="grey">(阈值)</font> $\delta$ for impurity decrease <font color="grey">(剔除杂质)</font> in splitting a node ; if $\Delta \text{Impurity}_{split} \gt \delta$, do slitting, otherwise stop</li>
<li>Postpruning : based on <u>cost function</u> (provided  $|T|$ and $\alpha$)<ul>
<li>$\color{red}\text{Cost}_{ \alpha}(T)=\sum_{t=1}^{|T|}n_t\ \text{Impurity}(t)+\alpha|T|$</li>
<li>Input: a complete tree $T$, $\alpha$</li>
<li>Output: postpruning tree $\text{T}_{\alpha}$ </li>
</ul>
<ol>
<li>Compute $\text{Impurity}(t)$ for $\forall t$</li>
<li>Iteratively merge child nodes <strong>bottom-up</strong> : Suppose $\text{T}_{A}$ and $\text{T}_{B}$ are the trees before and after merging, do merging if $\text{Cost}_{ \alpha}(\text{T}_{A}) \ge \text{Cost}_{ \alpha}(\text{T}_{B})$   <font color="grey">(剪枝前损失更大)</font></li>
</ol>
</li>
</ul>
</li>
</ul>
<ul>
<li>Pros and Cons<ul>
<li>Advantage<ul>
<li>Easy to interpret and visualize : widely used in ﬁnance, medical health, biology, etc.</li>
<li>Easy to deal with missing values (treat as new data type)</li>
<li>Could be extended to regression</li>
</ul>
</li>
<li>Disadvantage<ul>
<li>Easy to be trapped at local minimum because of greedy algorithm (贪心)</li>
<li>Simple decision boundary : parallel lines to the axes (Recall <a href="#tree">Pic above</a>)</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<h3 id="Naive-Bayes-朴素贝叶斯"><a href="#Naive-Bayes-朴素贝叶斯" class="headerlink" title="Naive Bayes (朴素贝叶斯)"></a>Naive Bayes (朴素贝叶斯)</h3><ul>
<li>Based on <strong>Bayes Theorem</strong> and conditional independency assumption on features (Recall <a href="#Bayes">Bayes Classifier</a>)</li>
<li>Bayes Theorem : $\Large{P(Y|X)=\frac{P(X|Y)P(Y)}{P(X)}}$<ul>
<li>$P(Y)$ is prior prob. distribution (先验概率分布) , $P(X|Y )$ is likelihood function (似然函数) , $P(X)$ is evidence (边际概率) , $P(Y |X)$ is posterior prob. distribution (后验概率分布).</li>
</ul>
</li>
<li>The <font color="red">core problem</font> of machine learning is to estimate $P(Y |X)$ </li>
</ul>
<ol>
<li>Let $X = \{X_1, . . . , X_d \}$, for ﬁxed sample $X = x$, $P(X = x)$ is independent of  $Y$ , by Bayes Theorem, $P(Y|X=x)\propto P(X=x|Y)P(Y)$</li>
<li>Assume conditional independency of $X_1, \cdots, X_d$ given $Y = c$ : $P(X=x|Y=c)=\prod_{i=1}^{d}P(X_i=x_i|Y=c)$</li>
<li><font color="red">Naive Bayes Model :</font>

</li>
</ol>
<blockquote class="blockquote-center">
<p>$<br>\color{red}\hat y =\arg \max_c P(Y=c)\prod_{i=1}^{d}P(X_i=x_i|Y=c)<br>$</p>

</blockquote>
<p><strong>Maximum Likelihood Estimate (MLE)</strong></p>
<ul>
<li>Estimate $P(Y = c)$ and $P(X_i = x_i |Y = c)$ from the dataset $D = \{(\textbf{x}_1, y_1), \cdots ,(\textbf{x}_n, y_n)\}$<ol>
<li><strong>MLE</strong> for $P(Y = c)$ : $P(Y = c) =\Large{\frac{ \sum_{i=1}^{n} I(y_i=c)}{n}}$</li>
<li>When $X_i$ is discrete variable with range $\{v_1, \cdots , v_K\}$, <strong>MLE</strong> for $P(X_i = v_k |Y = c) =\Large{\frac{ \sum_{i=1}^{n} I(x_i = v_k |y_i = c)}{ \sum_{i=1}^{n} I(y_i = c)}}$ <br> ( if $X_i$ is continuous, just do discretization on it and use this formula )</li>
</ol>
</li>
</ul>
<hr>
<h3 id="Model-Assessment"><a href="#Model-Assessment" class="headerlink" title="Model Assessment"></a>Model Assessment</h3><p><strong>Confusion Matrix</strong></p>
<div align="center"><img src="/2024/06/24/Big-Data-2/bd14.png" alt="bd14" style="zoom:100%"></div>



<ul>
<li>Representation<ul>
<li>T &amp; F : represents truth of label (标签是否真实)</li>
<li>P &amp; N : represents aspect of label (标签的两面)</li>
</ul>
</li>
<li><p>Two-class classification: </p>
<ul>
<li>$\text{Accuracy} =\large{\frac{\text{TP+TN}}{\text{TN+FN+FP+TP}}}$, not a good index when samples are <font color="red">imbalanced</font></li>
<li>$\text{Precision}=\large{\frac{\text{TP}}{\text{TP+FP}}}$ </li>
<li>TPR : $\text{Recall} = \large{\frac{\text{TP}}{\text{TP+FN}}}$ ; important in medical diagnosis (回收)</li>
<li>F score : $F_{\beta} = \large{\frac{(1+\beta^2)\text{Precision}\times\text{Recall}}{\beta^2 \times \text{Precision}+\text{Recall}}}$ , e.g. $F_1$ score for $\beta=1$</li>
<li>FPR : $\text{Specifity} = \large{\frac{\text{TN}}{\text{TN+FP}}}$ ; recall for negative samples</li>
</ul>
</li>
<li><p>Receiver Operating Characteristic (ROC, 受试者工作特征) and Area Under ROC (AUC)</p>
<ul>
<li>Aim to solve class distribution <font color="red">imbalance problem</font></li>
<li>Set different threshold (阈值) $t$ for continuous predicted values.</li>
<li>Compute <strong>TPR</strong> vs. <strong>FPR</strong> for all $t$ and plot ROC curve</li>
</ul>
</li>
</ul>
<div align="center"><img src="/2024/06/24/Big-Data-2/bd15.png" style="zoom:120%"></div>

<ul>
<li>Beware: Don’t view the “curve” as a function, but as a <strong>continuous set of points</strong>.<ul>
<li>Higher ROC implies better performance (How to measure ? AUC)</li>
</ul>
</li>
<li>AUC: compute the area under ROC curve. The larger the better. Model is good for test set if $AUC \gt 0.75$</li>
</ul>
<p><strong>Cohen’s Kappa Coefficient</strong></p>
<blockquote>
<p>Since ROC and AUC is complex to be quantified, we need a <code>coe</code> to indicate it.</p>
<p>We use an example to explain how to quantified it.</p>
</blockquote>
<blockquote class="blockquote-center">
<p>$<br>\begin{align}<br>&amp;\text{Cohen’s Kappa Coefficient: }&amp; &amp;\kappa=\frac{p_o-p_e}{1-p_e}=1-\frac{1-p_o}{1-p_e} \\<br>&amp;&amp; &amp;p_e=\sum_{c=1}^{C}\frac{n_c^{pred}}{N}\frac{n_c^{true}}{N}<br>\end{align}<br>$</p>

</blockquote>
<ul>
<li>$p_o$ is the accuracy</li>
<li>$p_e$ is the hypothetical probability of chance agreement</li>
</ul>
<div align="center"><img src="/2024/06/24/Big-Data-2/bd16.png" alt="bd16" style="zoom:100%"></div>

<p>E.g.  $\large{p_o=\frac{20+15}{50}=0.7}$, $\large{p_e=\frac{25}{50}\times\frac{20}{50}+\frac{25}{50}=0.5}$, then $\large{\kappa=0.4}$</p>
<ul>
<li>$\kappa \in [-1,1]$, $\kappa\ge 0.75$ for good performance and $\kappa\lt 0.4$ for bad one.</li>
</ul>
<hr>
<h2 id="V-Regression"><a href="#V-Regression" class="headerlink" title="V. Regression"></a>V. Regression</h2><h3 id="Linear-Model"><a href="#Linear-Model" class="headerlink" title="Linear Model"></a>Linear Model</h3><p><strong>Linear model</strong> : </p>
<ul>
<li>For <strong>Univariate</strong> linear model,  $y = w_0 + w_1x + \epsilon$, where $w_0$ and $w_1$ are regression coeﬃcients, $\epsilon$ is the error or noise</li>
</ul>
<p>Assume $\epsilon ∼ \mathcal N (0, \sigma^2)$, where $σ^2$ is a ﬁxed but unknown variance; then $y|x ∼ \mathcal N (w_0 + w_1x, σ^2)$</p>
<script type="math/tex; mode=display">
(\hat{w}_0,\hat{w}_1)= \arg \min_{w_0,w_1}\sum_{i=1}^{n}(y_i-w_0-w_1x_i)^2</script><p>which means $L(\hat w_0,\hat w_1)$ is minimized (残差最小).</p>
<ul>
<li>For <strong>multivariate</strong> linear model, $y=f(\textbf{x})=w_0+w_1x_1+w_2x_2+\cdots+w_px_p + \epsilon$ <ul>
<li>where $w_0, w_1,\cdots, w_p$ are <font color="red">regression coefficients</font>, $\textbf{x} = (x_1,\cdots, x_p)^T$ is the input vector whose components are independent variables or attribute values, $\epsilon \thicksim \mathcal N(0, σ^2)$ is the noise.</li>
<li>For the size n samples $\{(\textbf{x}_i, y_i)\}$, let $\textbf{y} = (y_1, \cdots , y_n)^T$ be the response or dependent variables, $\textbf{w} = (w_0, w_1, \cdots, w_p)^T$,  we construct a matrix $\textbf{X}=[\textbf{1}_n, (\textbf{x}_1, \cdots,\textbf{x}_n)^T]\in \mathbb R^{n \times(p+1)}$ , and $\textbf{\varepsilon}=(\epsilon_1,\cdots,\epsilon_n)^T \thicksim \mathcal N(\textbf{0},\sigma^2\textbf{l}_n)$ </li>
</ul>
</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\begin{align}<br>&amp;\textbf{y}=\textbf{X}\textbf{w} + \varepsilon\\ \\<br>&amp;\textbf{X}=<br>\begin{pmatrix}<br>1 &amp; x_{11} &amp; \cdots &amp; x_{1p} \\<br>1 &amp; x_{21} &amp; \cdots &amp; x_{2p} \\<br>\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\<br>1 &amp; x_{n1} &amp; \cdots &amp; x_{np}<br>\end{pmatrix}<br>\end{align}<br>$</p>

</blockquote>
<p><strong>Least Square (LS)</strong> <font color="grey" size="3">最小二乘法</font></p>
<div><img src="/2024/06/24/Big-Data-2/bd17.png" style="zoom:60%"></div>

<ul>
<li>From geometry aspect, we should <strong>minimize the residual sum-of-square (残差平方和)</strong>: <br>$\text{RSS}(\textbf{w})=\sum_{i=1}^{n} (y_i-w_0-w_1x_1-\cdots-w_px_p)^2=|\textbf{y} - \textbf{X} \textbf{w}|_{2}^2$<ul>
<li>When $\textbf{X}^T\textbf{X}$ is invertible, the <strong>minimizer</strong> $\hat{\textbf{w}}$ satisfy :  （可证明 $\hat w$ 是无偏估计）</li>
</ul>
</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\nabla_{\textbf{w}}\text{RSS}(\hat{\textbf{w}})=0 \Rightarrow \hat{\textbf{w}}=(\textbf{X}^T \textbf{X})^{-1}\textbf{X}^T \textbf{y}<br>$</p>

</blockquote>
<ul>
<li><ul>
<li>Then prediction $\hat{\textbf{y}}=\textbf{X}(\textbf{X}^T \textbf{X})^{-1}\textbf{X}^T \textbf{y}= \textbf{P} \textbf{y}$ is a projection of $\textbf{y}$ onto the linear space spanned by the column vectors of $\textbf{X}$; (As Pic 15 show)<ul>
<li>$\textbf{P}=\textbf{X}(\textbf{X}^T \textbf{X})^{-1}\textbf{X}^T$ is the projection matrix satisfying $\textbf{P}^2 = \textbf{P}$ <font color="green">(Recall: Linear Algebra)</font></li>
</ul>
</li>
</ul>
</li>
</ul>
<blockquote>
<p>Optimal Method: Ordinary least square (<strong>OLS</strong>)</p>
<ol>
<li>Get mean values from sample set: $\bar y=\frac{1}{n}\sum_{i=1}^{n}y_i$ , $\bar{\textbf{x}}=\frac{1}{n}\sum_{i=1}^{n}{ \textbf{x}_i}$</li>
<li>Centralize data (minus by $\bar y$ and $\bar{\textbf{x}}$) and calculate $RSS(\tilde{\textbf{w}})$ </li>
<li>Prediction $\hat{\textbf{y}}= \textbf{P} \textbf{y}$ is the projection (投影) of $\textbf{y}$ on the <em>linear space spanned</em> by the columns of $\textbf{X}$. <br>$\mathcal X= \text{Span} \{ \textbf{x}_{\cdot ,0}, \textbf{x}_{\cdot ,1},\cdots,  \textbf{x}_{\cdot ,p}\}$ , recall that $ \textbf{x}_{\cdot ,0}= \textbf{1}_n$</li>
<li>If $\{ \textbf{x}_{\cdot ,0}, \textbf{x}_{\cdot ,1},\cdots,  \textbf{x}_{\cdot ,p}\}$ forms a set of orthonormal basis (标准正交基) , then $\hat{\textbf{y}}=\sum_{i=0}^{p}&lt;\textbf{y}, \textbf{x}_{\cdot ,i}&gt; \textbf{x}_{\cdot ,i}$</li>
<li>If not, do orthogonalization by Gram-Schmidt procedure for the set $\{ \textbf{x}_{\cdot ,0}, \textbf{x}_{\cdot ,1},\cdots,  \textbf{x}_{\cdot ,p}\}$ </li>
</ol>
</blockquote>
<ul>
<li>From mathemetic aspect, it’s about <strong>MLE</strong> (Result the same)<ol>
<li>Likelihood function: $L((\textbf{w},\textbf{X}),\textbf{y})=P(\textbf{y}|(\textbf{X}, \textbf{w}))=\prod_{i=1}^{n}P(y_i|(\textbf{x}_i, \textbf{w}))$ </li>
<li>Find <strong>MLE</strong>: $\hat{\textbf{w}}=\arg \max_{\textbf{w}} L(\textbf{w} ; \textbf{X}, \textbf{y})$ (E.g. For $P(y_i|(\textbf{x}_i, \textbf{w}))=\frac{1}{\sqrt{2\pi}\sigma} \Large{e^{-\frac{(y_i-w_0-w_1x_{i1}-\cdots-w_px_{ip})^2}{2\sigma^{2}}}}$)</li>
<li><font color="blue">(2.) is equivalent to its log-function:</font><br> E.g.  $l(\textbf{w} ; \textbf{X}, \textbf{y})= \log{L(\textbf{w} ; \textbf{X}, \textbf{y})}=-n\log(\sqrt{2\pi}\sigma)-\frac{1}{2\sigma^{2}} \sum_{i=1}^{n} (y_i-w_0-w_1x_{i1}-\cdots-w_px_{ip})^2$ </li>
<li>Then get the same minimizer as <strong>LS</strong> : $\hat{\textbf{w}}=(\textbf{X}^T \textbf{X})^{-1}\textbf{X}^T \textbf{y}$</li>
</ol>
</li>
</ul>
<p><strong>Shortcomings of Fitting Nonlinear Data</strong> (上述方法仅适合线性回归)</p>
<ul>
<li>Evaluating the model by Coefficient of Determination $R^2$<ul>
<li>$R^2 := 1-\frac{ \text{SS}_{res}}{ \text{SS}_{tot}}$ ($=\frac{ \text{SS}_{reg}}{ \text{SS}_{tot}}$ only for linear regression), where<ul>
<li>$ \text{SS}_{tot} = \sum_{i=1}^{n} (y_i-\bar y)^2$ is the total sum of squares</li>
<li>$ \text{SS}_{reg} = \sum_{i=1}^{n} (\hat y_i-\bar y)^2$ is the regression sum of squares</li>
<li>$ \text{SS}_{res} = \sum_{i=1}^{n} (y_i-\hat y_i)^2$ is the residual sum of squares.</li>
</ul>
</li>
<li>The larger the $R^2$, the better the model !</li>
</ul>
</li>
<li><strong>Multicolinearity</strong> [多重共线性]<ul>
<li>If the columns of $\textbf{X}$ are almost linearly dependent (multicolinearity), then $\det(\textbf{X}^{T}\textbf{X})\approx 0$, the diagonal entries in $(\textbf{X}^{T}\textbf{X})^{-1}$ is quite large, leading to a large variances of $\hat{\textbf{w}}$ (inaccurate).</li>
<li>Remedies (补救措施): ridge regression (岭回归), principal component regression (主属性回归), partial least squares regression (部分最小二乘回归), etc.</li>
</ul>
</li>
<li>Overfitting<ul>
<li>Linear regression easily to be overfitted when introducing more variables.</li>
<li>Solution: <a href="#regul">Regularization</a></li>
</ul>
</li>
</ul>
<p><strong>Bias-Variance Decomposition</strong></p>
<ul>
<li>Bias (偏差): $\text{Bias}(\hat f(\textbf{x}))=\text{E}_\text{train}\hat f(\textbf{x})-f(\textbf{x})$ , average <strong>accuracy</strong> of prediction for the model (deviation from the truth)</li>
<li>Variance (方差): $\text{Var}(\hat f(\textbf{x}))=\text{E}_\text{train}(\hat f(\textbf{x})-\text{E}_\text{train}\hat f(\textbf{x}))^2$ , <strong>variability</strong> of the model prediction due to different data set (stability)</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\color{red}<br>\text{E}_\text{train}\text{R}_\text{exp}(\hat f(\textbf{x}))=\text{E}_\text{train}\text{E}_\text{P}[(y-\hat f(\textbf{x}))^2|\textbf{x}] = \underbrace{\text{Var}(\hat f(\textbf{x}))}_{\text{variance}}+\underbrace{\text{Bias}^2(\hat f(\textbf{x}))}_{\text{bias}}+\underbrace{\sigma^2}_{\text{noise}}<br>$</p>

</blockquote>
<div><img src="/2024/06/24/Big-Data-2/bd19.png" style="zoom:80%"></div>

<ul>
<li>The more complicated the model, the lower the bias, but the higher the variance.</li>
</ul>
<div><img src="/2024/06/24/Big-Data-2/bd18.png" style="zoom:90%"></div>

<ul>
<li>kNN Regression<ul>
<li>kNN can be used to do regression if the mode (majority vote) is replaced by mean : $\hat f(x)=\frac{1}{k} \sum_{ x_{(i)} \in N_{k}(x)} y_{(i)}$</li>
<li>Generalization error of kNN regression is</li>
</ul>
</li>
</ul>
<div><img src="/2024/06/24/Big-Data-2/bd20.png" style="zoom:80%"></div>

<p>where we have used the fact that $E_{ \text{train}} y_{i} = f(\textbf{x}_{i})$ and $\text{Var}(y_i)=\sigma^2$</p>
<ul>
<li>For small $k$, overfitting, bias ↓, variance ↑</li>
<li>For large $k$, underfitting, bias ↑, variance ↓</li>
</ul>
<hr>
<h3 id="Regularization-正则化"><a href="#Regularization-正则化" class="headerlink" title="Regularization (正则化)"></a><a name="regul">Regularization</a> (正则化)</h3><blockquote>
<p>Why we need Regularization ?</p>
<ul>
<li>In <strong>high dimensions</strong>, the more the input attributes, the larger the <strong>variance</strong></li>
<li>Shrinking some coefficients or setting them to zero can reduce the <strong>overfitting</strong></li>
<li>Using less input variables also help interpretation with the most important variables</li>
<li>Subset selectionµretaining only a subset of the variables, while eliminating the rest variables from the model</li>
</ul>
</blockquote>
<h4>Best-Subset Selection</h4>

<ul>
<li>find for each $k ∈ \{0, 1, \cdots , p\}$ the subset $S_k \subset \{1,\cdots, p\}$ of size $k$ that gives the smallest $\text{RSS}(\textbf{w}) = \sum_{i=1}^n (y_i − w_0 − \sum_{j\in S_k} w_j x_{ij})^2$ </li>
<li>Noted that the best subset of size $k + 1$ may not include the the variables in the best subset of size $k$</li>
<li>Choose $k$ based on <strong>bias-variance tradeoff</strong>, usually by <strong>AIC</strong> and <strong>BIC</strong>(贝叶斯信息量), or practically by <strong>cross-validation</strong></li>
</ul>
<h5>Forward-stepwise selection</h5>

<ul>
<li>Start with the intercept (截距?) $\bar y$ , then sequentially add into the model the variables that improve the fit most (reduce RSS most)</li>
<li><font color="red">QR factorization</font> helps search the candidate variables to add </li>
<li><font color="red">Greedy algorithm</font> : the solution could be sub-optimal</li>
</ul>
<h5>Backward-stepwise selection</h5>

<ul>
<li>Start with the <font color="red">full model</font>, then sequentially delete from the model the variables that has the least impact on the fit most </li>
<li>The candidate for dropping is the variable with the smallest <a href="/2024/06/22/Big-Data-1/index.html#z-score">Z-score</a> </li>
<li>Can only be used when $n &gt; p$ in order to fit the full model by <strong>OLS</strong></li>
</ul>
<h5><font color="red">Regularization by Penalties</font></h5>

<ul>
<li>Add a penalty term, in general $l_q$ - norm</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\sum_{i=1}^{n}(y_i-w_0-w_1x_1-\cdots-w_px_p)^2+\lambda |\textbf{w}|^q_q=|\textbf{y}-\textbf{X}\textbf{w}|^2+\lambda |\textbf{w}|^q_q<br>$</p>

</blockquote>
<ul>
<li>By arranging $\lambda$ , we can correct the overfitting (bias inc. &amp; var dec.)</li>
<li><code>q = 2</code> for Ridge Regression &amp; <code>q = 1</code> for LASSO Regression</li>
</ul>
<div align="center"><img src="/2024/06/24/Big-Data-2/bd26.png" style="zoom:60%"></div>



<h4>Ridge Regression</h4>

<font color="#ff44ff">$\hat w=\arg \underset{w}\min {\|y-Xw\|_2^2}+\lambda\|w\|_2^2$</font> 

<div align="center"><img src="/2024/06/24/Big-Data-2/bd21.png" style="zoom:50%"></div>

<blockquote>
<p>Solving Ridge Regression</p>
</blockquote>
<div align="center"><img src="/2024/06/24/Big-Data-2/bd22.png" style="zoom:50%"></div>



<blockquote>
<p>Bayesian Viewpoint of Ridge Regression</p>
</blockquote>
<div align="center"><img src="/2024/06/24/Big-Data-2/bd23.png" style="zoom:60%"></div>

<hr>
<h4>LASSO Regression</h4>

<blockquote>
<p>Can be used to estimate the coefficients and select the important variables simultaneously</p>
<p>Reduce the model complexity, avoid overfitting, and improve the generalization ability</p>
</blockquote>
<font color="#ff44ff">$\hat w=\arg \underset{w}\min {\|y-Xw\|_2^2}+\lambda\|w\|_1$</font> 

<p>Two Rpoperties : </p>
<ul>
<li>Shrinkage (将所有点收缩)</li>
<li>Selection (将近点归零，远点收缩)</li>
</ul>
<table>
    <tr>
        <td><img align="center" src="/2024/06/24/Big-Data-2/bd24.png" style="zoom:50%"></td>
        <td><img align="center" src="/2024/06/24/Big-Data-2/bd25.png" style="zoom:50%"></td>
    </tr>
    <tr>
        <td colspan="2"><center><font size="2">LASSO Regression</font></center></td>
    </tr>
</table>

<blockquote class="blockquote-center">
<p>$<br>\hat w_i^{\text{lasso}} = (|\hat w^{OLS}_i| − \lambda)+\text{sign}(\hat w^{OLS}_i)<br>$</p>

</blockquote>
<ul>
<li>Solving LASSO by <strong>LARS</strong> (最小角回归算法)<ol>
<li>Start with all coefficients $w_i$ equal to zero</li>
<li>Find the predictor $x_i$ most correlated with $y$ (一般认为夹角最小的即是)</li>
<li>Increase the coefficient $w_i$ in the direction of the sign of its correlation with $y$. Take residuals $r = y − \hat y$ along the way. Stop when some other predictor $x_k$ has as much correlation with $r$ as $x_i$ has (调整参数 $w$ 直至下一个分量夹角最小)</li>
<li>Increase $(w_i, w_k)$ in their joint <strong>least squares direction</strong>, until some other predictor $x_m$ has as much correlation with the residual $r$</li>
<li>Continue until all predictors are in the model</li>
</ol>
</li>
</ul>
<center><img src="/2024/06/24/Big-Data-2/bd27.png" style="zoom:70%"><font size="2">Pic 19. LARS</font></center>



<blockquote>
<p>Optional: Maximum A Posteriori (<strong>MAP</strong>) Estimation</p>
<ul>
<li><p>Given $\theta$ , the conditional distribution of $\textbf{y}$ is $P(\textbf{y}|\theta)$</p>
</li>
<li><p><strong>MAP</strong> choose the point of maximal posterior probability :</p>
<p> $\hat{\theta}^{MAP}=\arg \underset{\theta}\max{(\log P(\textbf{y}|\theta)+\log P(\theta))}$</p>
</li>
<li><p>If $\theta=\textbf{w}$, and we choose the log-prior <font color="grey">[对数先验]</font> (i.e. normal prior  $\mathcal N(0, \frac{\sigma^2}{\lambda} \textbf{I})$ ) , we revocer the ridge regression.</p>
</li>
<li><p><font color="#ff7575">Different log-prior lead to different penalties</font> (Not general case. Some penalties may not be the logarithms[对数] of probability distributions, some other penalties depend on the data)</p>
</li>
</ul>
<p>Related Regularization Models</p>
<ul>
<li>Elastic net (混合回归) : $\hat{\textbf{w}}=\arg\min_w|y-Xw|_2^2+\lambda_1|\textbf{w}|^2_2+\lambda_2|\textbf{w}|_1$ </li>
<li>Group LASSO (对不同分组进行回归) : $\hat{\textbf{w}}=\arg\min_w|y-Xw|_2^2+\sum_{g=1}^{G}\lambda_{g}|\textbf{w}_{g}|_2$ , where $\textbf{w}=(w_1,\cdots,w_G)$ is the <strong>group partition</strong> of $\textbf{w}$. </li>
<li>Dantzig Selector : …</li>
<li>Smoothly clipped absolute deviation (<strong>SCAD</strong>) penalty</li>
<li>Adaptive LASSO</li>
</ul>
</blockquote>
<h4>ADMM Used in LASSO Problem</h4>

<p><strong>Altinating Direction Method of Multipliers (ADMM)</strong></p>
<ul>
<li>ADMM [交替方向乘子法] often used to solve problems with two optimized variables which only has equality constraint. </li>
<li><p>Normal Form as below :</p>
<script type="math/tex; mode=display">
\min_{x,z} f(x)+g(z)\\ s.t.\ Ax+Bz=c</script></li>
<li><p>where $x\in R^{n}$ and $z\in R^{m}$ are optimized variables, and in the equality constraint, $A\in R^{p\times n}$ , $B\in R^{p\times m}$ , $c\in R^{p}$ , and $f$ and $g$ are <font color="red">convex functions (凸函数)</font></p>
</li>
</ul>
<center>------ Solution ------</center>

<ol>
<li>Define Augmented Lagrangian (增广拉格朗日函数)</li>
</ol>
<script type="math/tex; mode=display">
L_{\rho}(x,z,u)=f(x)+g(z)+u^{T}(Ax+Bz-c)+\frac{\rho}{2}\|Ax+Bz-c\|^2</script><ul>
<li>If we let $w=\frac{u}{\rho}$ , then we can get simplified form of Augmented Lagrangian</li>
</ul>
<script type="math/tex; mode=display">
L_{\rho}(x,z,u)=f(x)+g(z)+\frac{\rho}{2}\|Ax+Bz-c+w\|_2^2-\frac{\rho}{2}\|w\|_2^2</script><ol>
<li>Algorithm : fixed other variables and update only one of them (Here $\rho\gt 0$ is a penalty parameter)</li>
</ol>
<script type="math/tex; mode=display">
\begin{align}
&\text{for }k=1,2,3,...\\
&\text{step 1: } x^{(k)}=\arg\min_{x}L_{\rho}(x,z^{(k-1)},w^{(k-1)})=\arg\min_{x} f(x)+\frac{\rho}{2}\|Ax+Bz^{(k-1)}-c+w^{(k-1)}\|_2^2 \\
&\text{step 2: } z^{(k)}=\arg\min_{z}L_{\rho}(x^{(k)},z,w^{(k-1)})=\arg\min_{z} g(z)+\frac{\rho}{2}\|Ax^{(k)}+Bz-c+w^{(k-1)}\|_2^2 \\
&\text{step 3: } w^{(k)}=w^{(k-1)}+Ax^{(k)}+Bz^{(k)}-c
\end{align}</script><ol>
<li><strong>Consider LASSO Problem</strong> <ul>
<li>To find $\min_{w} \frac{1}{2}|y-Xw|^2_2+\lambda|w|_1$ </li>
<li>Let $w=\beta$ (the constraint : $w-\beta=0$) and rewrite the Augmented Lagrangian : $L_{\rho}(w,\beta,u)=\frac{1}{2}|y-Xw|^2_2+\lambda|\beta|_1+u^T(w-\beta)+\frac{\rho}{2}|w-\beta|_2^2$</li>
</ul>
</li>
</ol>
<h3 id="Model-Assessment-1"><a href="#Model-Assessment-1" class="headerlink" title="Model Assessment"></a>Model Assessment</h3><ul>
<li>Mean absolute error (MAE) : $MAE =\frac{1}{n} \sum_{i=1}^{n} |y_i - \hat y_i|$</li>
<li>Mean square error (MSE) : $MSE =\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat y_i)^2$ </li>
<li>Root mean square error (RMSE) : $RMSE = \sqrt{\frac{1}{n} (y_i - \hat y_i)^2}$</li>
<li><p>Coefficient of Determination [决定系数] <font color="green">(Recall)</font> : $R^2:=1-\frac{\text{SS}_{\text{res}}}{\text{SS}_{\text{tot}}}$ , <br>where $\text{SS}_{\text{tot}}=\sum_{i=1}^n (y_i-\bar y_i)^2$  and  $\text{SS}_{\text{res}}=\sum_{i=1}^n (y_i-\hat y_i)^2$ </p>
<ul>
<li>Normally $R^2\in[0,1]$ , but it can be negative (a wrong model making residual too large). </li>
<li><font color="red">The larger the $R^2$ , the better the model.</font>
</li>
</ul>
</li>
<li><p>Adjusted Coefficient of Determination</p>
</li>
</ul>
<script type="math/tex; mode=display">
R_{\text{adj}}^2=1-\frac{(1-R^2)(n-1)}{n-p-1}</script><ul>
<li>$n$ is  the number of samples, $p$ is the dimensionality (or the number of attributes)</li>
<li><font color="red">The larger the $\text{R}_{\text{adj}}^2$ value, the better performance the model</font></li>
<li>When adding important variables into the model, $\text{R}_{\text{adj}}^2$ gets larger and $\text{SS}_{\text{res}}$ is reduced</li>
</ul>
<hr>
<h2 id="VI-Classification-II"><a href="#VI-Classification-II" class="headerlink" title="VI. Classification II"></a>VI. Classification II</h2><blockquote>
<p>Why talk about Regression first ?</p>
<ul>
<li>Naive Bayes uses Probability and Mathemetic methods, which is the core of Regression</li>
<li>Regression all apply <strong>MLE</strong>, which is connected with Bayes rules.</li>
</ul>
</blockquote>
<h3 id="Logistic-Regression"><a href="#Logistic-Regression" class="headerlink" title="Logistic Regression"></a>Logistic Regression</h3><blockquote>
<p>逻辑回归是一种分类方法（不是回归）</p>
</blockquote>
<font color="green">Recall: Linear Regression</font>

<ul>
<li>$E(y|x)=P(y=1|x)=w_0+w_1x$ , but $w_0+w_1x$ may be not probability</li>
<li>Use <strong>Sigmoid function</strong> to map it to $\left[0,1\right]$ : $g(z)=\frac{1}{1+e^{-z}}$ , where $z=w_0+w_1x_1+\cdots+w_dx_d$</li>
<li><font color="red">Equivalently</font>, $\log{\frac{P(y=1|x)}{1-P(y=1|x)}}=w_0+w_1x_1+\cdots+w_dx_d$</li>
</ul>
<script type="math/tex; mode=display">
\text{logit}(z)=\log\frac{z}{1-z}</script><p><strong>MLE for Logistic Regression</strong></p>
<ul>
<li>The prob. distribution for two-class logistic regression model is <ul>
<li>$Pr(y=1|X=x)=\frac{\exp(\textbf{w}^T \textbf{x})}{1+\exp(\textbf{w}^T \textbf{x})}$</li>
<li>$Pr(y=0|X=x)=\frac{1}{1+\exp(\textbf{w}^T \textbf{x})}$</li>
</ul>
</li>
<li>Let $P(y=k|X=x)=p_k(\textbf{x};\textbf{w})$, $k=0,1$. The <font color="red">likelihood function</font> is $L(\textbf{w})=\prod_{i=1}^{n} p_{y_i}(\textbf{x}_i;\textbf{w})$</li>
<li>MLE of $\textbf{w}$ : $\hat{\textbf{w}}=\arg \underset{\textbf{w}}\max L(\textbf{w})$</li>
<li>Solve $\color{red}\nabla_{\textbf{w}}\log L(\textbf{w})=0$ by Newton-Raphson method</li>
</ul>
<blockquote>
<p>用 MLE 计算 $\hat{\textbf{w}}$ ，需要提前知道 $x$ 的分布，所以逻辑回归是一种分类算法。</p>
</blockquote>
<h3 id="Linear-Discriminant-Analysis-LDA"><a href="#Linear-Discriminant-Analysis-LDA" class="headerlink" title="Linear Discriminant Analysis (LDA)"></a>Linear Discriminant Analysis (LDA)</h3><blockquote>
<p>线性判别分析，是一种监督学习的降维方法（无监督学习一般用<strong>PCA</strong>，主成分分析来降维）</p>
</blockquote>
<font color="green">Recall: Naive Bayes</font>

<ul>
<li>By <strong>Bayes Theorem</strong>: $P(Y|X=x)\propto f_k(\textbf{x})\pi_{k}$ , where $f_k(\textbf{x})=P(\textbf{X}=\textbf{x}|Y=k)$ is be the <font color="red">density function</font> of samples in each class $Y=k$, $\pi_k=P(Y=k)$ is the <font color="red">prior probability</font>.</li>
<li>Assume $f_k (\textbf{x})$ is multivariate Gaussian (多元高斯分布) : $f_k(x)=\large{\frac{1}{(2\pi)^{p/2} |\Sigma_k}^{1/2}|e^{\frac{1}{2}(x-\mu_k)^T\Sigma_k^{-1}(x-\mu_k)}}$ , with a common covariance matrix (协方差矩阵) $\Sigma_k$ <font color="grey">(注：多元高斯可以表示为向量和矩阵乘积的形式，如上)</font></li>
<li>For the decision boundary between class $k$ and $l$, the <strong>log-ratio</strong> of their posteriors (后验) $P(Y|X)$ is</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\log{\frac{P(Y=k|\textbf{X}=\textbf{x})}{P(Y=l|\textbf{X}=\textbf{x})}}=\log{\frac{\pi_k}{\pi_l}}-\frac{1}{2}(\mu_k+\mu_l)^T\Sigma_k^{-1}(\mu_k-\mu_l)+\textbf{x}^T \Sigma^{-1}(\mu_k-\mu_l)<br>$</p>

</blockquote>
<ol>
<li><p>From log-ratio, we can get <font color="red">Linear discriminant functions</font>(e.g. for class $k$) : $\delta_k(\textbf{x})=\textbf{x}^T\Sigma^{-1}\mu_k-\frac{1}{2}\mu_k^T\Sigma^{-1}\mu_k+\log\pi_k$ </p>
</li>
<li><p>Then the log-ratio become : $\log{\frac{P(Y=k|\textbf{X}=\textbf{x})}{P(Y=l|\textbf{X}=\textbf{x})}}=\delta_k(\textbf{x})-\delta_l(\textbf{x})$ </p>
<blockquote>
<p>相减结果是一个一次方程（线性）</p>
</blockquote>
</li>
<li><p>Decision Rule(分类依据) : $k^{\ast}=\arg\max_k \delta_k(\textbf{x})$</p>
</li>
</ol>
<p><strong>Two-class LDA</strong></p>
<ul>
<li>LDA rule classifies to <strong>class 2</strong> if</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>(\textbf{x}-\frac{\hat\mu_1+\hat\mu_2}{2})^T \Sigma^{-1}(\hat\mu_2-\hat\mu_1)+\log{\frac{\hat\pi_2}{\hat\pi_1}}\gt 0<br>$</p>

</blockquote>
<ul>
<li>Discriminant direction : $\beta=\Sigma^{-1}(\hat\mu_2-\hat\mu_1)$ </li>
</ul>
<center><img src="/2024/06/24/Big-Data-2/bd28.png" style="zoom:50%"><font size="2">Pic 20. Two-class LDA</font></center>

<blockquote>
<p>$\hat\mu$ 看作图中椭圆的中心，图中的 $w$ 为投影方向。由上述公式计算可得到样本在投影基向量上的方向，从而判断其类别</p>
<p>从定性上看，投影的作用是降维，选择的投影空间应当是能将不同类数据点在映射后尽可能分开（或同类的点尽可能紧凑）。</p>
</blockquote>
<h3 id="Neural-Network"><a href="#Neural-Network" class="headerlink" title="Neural Network"></a>Neural Network</h3><center><img src="/2024/06/24/Big-Data-2/bd29.png" style="zoom:70%"><font size="2">Pic 21. NN</font></center>

<script type="math/tex; mode=display">
\hat y=g(w_0+\sum_{i=1}^{m} x_iw_i)</script><ul>
<li>$\hat y$ is Output</li>
<li>$g$ is a <font color="red">Non-linear activation function</font> (非线性激活函数)</li>
<li>$w_0$ is the Bias</li>
</ul>
<center><img src="/2024/06/24/Big-Data-2/bd30.png" style="zoom:70%"><font size="2">Pic 22. Common Activation Functions</font></center>

<ul>
<li><strong>Single Hidden Layer Neural Network</strong><ul>
<li><font color="red">$z_i=w_{0,i}^{(1)}+\sum_{j=1}^{m}x_jw_{j,i}^{(1)}$</font> </li>
<li><font color="red">$\hat y_i=w_{0,i}^{(2)}+\sum_{j=1}^{d_1}g(z_j)w_{j,i}^{(2)}$</font></li>
<li>$x_i\to z_k\to y_j$ , where $z_k$ is the hidden layer</li>
<li>Hidden Layer can be <font color="red">multiple</font> </li>
</ul>
</li>
</ul>
<center><img src="/2024/06/24/Big-Data-2/bd31.png" style="zoom:50%"></center>



<ul>
<li><strong>Thm: Universal Approximation Theorem</strong> —— Any function can be approximated by a <font color="blue">three-layer</font> neural network within sufficiently high accuracy.<ul>
<li>Why not effective ?</li>
<li>The <strong>width</strong> of each layer may be too much (Large calculation !!)</li>
<li><font color="green">Now we’re trying to replace <b>width</b> with <b>depth</b> and find the same Theorem</font> <font color="grey">(即增加层数，减少每层的神经元)</font>



</li>
</ul>
</li>
</ul>
<h4>Loss Optimization</h4>

<blockquote>
<p>Find $\textbf{W}=\{w^{(0)},w^{(1)},…,w^{(n)}\}$ with lowest loss function</p>
</blockquote>
<blockquote class="blockquote-center">
<p>$<br>\textbf{W}^{\ast}=\underset{\textbf{W}} {\arg\min} \frac{1}{n}\sum_{i=1}^{n}L(f(x^{(i)};\textbf{W}),y^{(i)})=\underset{\textbf{W}} {\arg\min}\ C(\textbf{W})<br>$</p>

</blockquote>
<ul>
<li>But for most cases, we should calculate <font color="red">gradient</font> to find $\textbf{W}^{\ast}$ </li>
<li><font color="red">Use <b>gradient decent</b> to solve:</font> $\frac{\partial{C}}{\partial{\textbf{W}}}$</li>
</ul>
<blockquote>
<p>How to calculate ? (More detail)</p>
</blockquote>
<center><img src="/2024/06/24/Big-Data-2/bd33.png" style="zoom:60%"></center>

<ul>
<li>$w_{jk}^{l}$ is the weight for the connection from the $k^{th}$ neuron in the $(l − 1)^{th}$ layer to the $j^{th}$ neuron in the $l^{th}$ layer.</li>
<li>More briefly, <font color="red">$b_{j}^{l}=w_{j0}^l$</font> is the <font color="red">bias</font> of the $j^{th}$ neuron in the $l^{th}$ layer.</li>
<li><p>$a^l_j$ for the <font color="red">activation</font> of the $j^{th}$ neuron in the $l^{th}$ layer $z_j^l$  : <font color="red">$a^l_j=g(z^l_j)=g(\sum_k w_{jk}^{l}a_k^{l-1} + b_j^l)$</font> </p>
</li>
<li><p>We have define $C(\textbf{W})=\frac{1}{n}\sum_{i=1}^{n}L(f(x^{(i)};\textbf{W}),y^{(i)})$ </p>
</li>
</ul>
<center><img src="/2024/06/24/Big-Data-2/bd32.png" style="zoom:40%"></center>

<blockquote>
<p>Proof (暂略)</p>
</blockquote>
<h4>Gradient Descent</h4>

<p><strong>Algorithm</strong> :</p>
<ol>
<li>Initialize weights randomly  $\thicksim\mathcal N(0, \sigma^{2})$ </li>
<li>Loop until convergence : <ol>
<li>Pick single data point $i$</li>
<li>Compute <strong>gradient</strong>  $\frac{\partial J_i(\textbf{W})}{\partial \textbf{W}}$ </li>
<li>Update weights, $\textbf{W} \leftarrow (\textbf{W}-\eta \frac{\partial J(\textbf{W})}{\partial \textbf{W}})$ </li>
</ol>
</li>
<li>Return weights</li>
</ol>
<ul>
<li>Mini-batches lead to fast training ! (need not to calculate all gradient for trainset $x$)</li>
<li>Can parallelize computation + achieve significant speed increases on GPUs.</li>
</ul>
<h3 id="Support-Vector-Machine-SVM"><a href="#Support-Vector-Machine-SVM" class="headerlink" title="Support Vector Machine (SVM)"></a>Support Vector Machine (SVM)</h3><p><strong>About SVM</strong></p>
<ul>
<li>Use <strong>hyperplane</strong> [超平面] to separate data : maximize <strong>margin</strong></li>
<li>Can deal with <font color="red">low-dimensional data</font> that are not linearly separated by using kernel functions</li>
<li>Decision boundary only depends on some samples (support vectors)</li>
</ul>
<p><strong>How to train</strong></p>
<ul>
<li>Training data: $\{(\textbf{x}_1,y_1),(\textbf{x}_2,y_2),…,(\textbf{x}_n, y_n) \}, y_i\in \{-1, 1\}$</li>
<li>Hyperplane: $S=\textbf{w}^T\textbf{x} + b$ ;     Decision function: $f(\textbf{x})=\text{sign}(\textbf{w}^T\textbf{x} + b)$</li>
<li>Geometric <strong>margin</strong> between a point and hyperplane : $\large{r_i=\frac{y_i(\textbf{w}^T\textbf{x} + b)}{|\textbf{w}|_2}}$</li>
<li>Margin between dataset and hyperplane : $\underset{i}\min r_i$</li>
<li>Maximize margin : $\underset{\textbf{w}, b}\max \underset{i}\min r_i$</li>
</ul>
<p><strong>Optimization</strong></p>
<ul>
<li>Without loss of generality, let $\underset{i}\min y_i(\textbf{w}^T\textbf{x} + b)=1$</li>
<li>Maximize margin is equivalent to $\underset{\textbf{w}, b}\max \frac{1}{|\textbf{w}|_2}$  ,  $s.t.\ y_i(\textbf{w}^T\textbf{x} + b)\ge 1,\ i=1,…,n$</li>
<li>Further reduce to $\underset{\textbf{w}, b} \min \frac{1}{2}|\textbf{w}|_2^2$  ,  $s.t.\ y_i(\textbf{w}^T\textbf{x} + b)\ge 1,\ i=1,…,n$</li>
<li>This is <strong>primal problem</strong> : quadratical programming with linear constraints, computational complexity is $O(p^3)$ where $p$ is dimension</li>
</ul>
<blockquote>
<p>But we use <strong>Dual problem optimization</strong>(对偶问题优化) most.</p>
</blockquote>
<ul>
<li>When slater condition is satisfied, $\min \max ⇔ \max \min$</li>
<li>Dual problem : $\underset{\alpha}\max \underset{\textbf{w}, b}\min L(\textbf{w},b,\alpha)$ —— $L$ is Lagrange function(拉格朗日函数)</li>
<li><p>Solve for inner minimization problem : </p>
<ul>
<li>$\nabla_{\textbf{w}}L=0 \Longrightarrow \textbf{w}^\ast=\sum_i \alpha_iy_i \textbf{x}_i$</li>
<li>$\frac{\partial L}{\partial b}=0 \Longrightarrow \sum_i\alpha_iy_i=0$</li>
</ul>
</li>
<li><p>Plug into $L$: $L(\textbf{w}^\ast,b^\ast,\alpha)=\sum_i\alpha_i-\frac{1}{2}\sum_i\sum_j\alpha_i\alpha_jy_iy_j(\textbf{x}_i^T \textbf{x}_j)$ </p>
</li>
<li><font color="red">Dual Optimization: </font>

</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\begin{align}<br>&amp;\min_\alpha\frac{1}{2}\sum_i\sum_j\alpha_i\alpha_jy_iy_j(\textbf{x}_i^T \textbf{x}_j)-\sum_i\alpha_i, \\<br>&amp;\text{s.t. }\alpha_i\ge0,\ i=1,…,n,\ \sum_i\alpha_iy_i=0<br>\end{align}<br>$</p>

</blockquote>
<p><strong>KKT Condition</strong></p>
<ul>
<li>Three more conditions from the equivalence of primal and minimax problems</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\left\{ \begin{array}{l}<br>\alpha_i^{\ast}\ge 0\\<br>y_i((\textbf{w}^{\ast})^T \textbf{x}_i+b^{\ast})-1 \ge 0\\<br>\alpha_i^{\ast}[y_i((\textbf{w}^{\ast})^T \textbf{x}_i+b^{\ast})-1]=0<br>\end{array}\right.<br>$</p>

</blockquote>
<ul>
<li>These together with two zero derivative conditions form KKT conditions</li>
<li>$\alpha_i^{\ast}\gt 0 \Rightarrow y_i((\textbf{w}^{\ast})^T \textbf{x}_i+b^{\ast})=1$</li>
<li>Index set of <font color="red">support vectors</font> : $S=\{i|\ \alpha_i \gt 0\}$</li>
<li>$b=y_s-\textbf{w}^T\textbf{x}_s=y_s-\sum_{i\in S}\alpha_i y_i \textbf{x}^T_i\textbf{x}_s$</li>
<li>More stable solution : </li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\color{red} b=\frac{1}{|S|}\sum_{s\in S}\left(y_s-\sum_{i\in S}\alpha_i y_i \textbf{x}^T_i\textbf{x}_s\right)<br>$</p>

</blockquote>
<p><strong>Soft Margin</strong></p>
<ul>
<li>When data are not linear separable, introduce slack variables (tolerance control of fault) $\xi_i \gt 0$</li>
<li>Relax constraint to $y_i(\textbf{w}^T\textbf{x} + b) \ge 1-\xi_i$ </li>
<li>Primal problem :</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\begin{align}<br>&amp;\underset{\textbf{w}, b} \min \frac{1}{2}|\textbf{w}|_2^2+C\sum_{i=1}^{n}\xi_i\\<br>&amp;\text{s.t. }y_i(\textbf{w}^T\textbf{x} + b)\ge 1-\xi_i,\ \xi_i \ge 0,\ i=1,…,n<br>\end{align}<br>$</p>

</blockquote>
<ul>
<li>Similar derivation to dual problem : (Difference: add the error coe $C$ as a bound)</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\begin{align}<br>&amp;\min_{\alpha}\frac{1}{2}\sum_i \sum_j \alpha_i \alpha_j y_i y_j (\textbf{x}_i^T \textbf{x}_j)-\sum_i \alpha_i \\<br>&amp;\text{s.t. }0\le \alpha_i \le C,\ i=1,…,n,\ \sum_i\alpha_iy_i=0<br>\end{align}<br>$</p>

</blockquote>
<h4 id="Nonlinear-SVM"><a href="#Nonlinear-SVM" class="headerlink" title="Nonlinear SVM"></a>Nonlinear SVM</h4><ul>
<li>Nonlinear decision boundary could be mapped to linear boundary in <font color="red">high-dimensional space</font></li>
</ul>
<center><img src="/2024/06/24/Big-Data-2/bd34.png" style="zoom:60%"></center>

<ul>
<li>Modify objective function in dual problem : $\color{red}\frac{1}{2}\sum_i \sum_j \alpha_i \alpha_j y_i y_j (\phi(\textbf{x}_i)^T \phi(\textbf{x}_j))-\sum_i \alpha_i$</li>
<li>Kernel function as inner product : $K(\textbf{x}_i, \textbf{x}_j)=\phi(\textbf{x}_i)^T \phi(\textbf{x}_j)$</li>
<li><font color="grey">Q: How to choose <b>Kernel Functions</b> ?</font>      <font color="green">A: Arbitrary</font>

</li>
</ul>
<center><img src="/2024/06/24/Big-Data-2/bd35.png" style="zoom:50%"></center>

<hr>
]]></content>
      <categories>
        <category>2024 Spring</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>CSE Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>Introduction to Hexo and Github Page</title>
    <url>/2024/06/07/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is the very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
  </entry>
  <entry>
    <title>NUS Soc SWS3005  实时 3D 图形渲染</title>
    <url>/2024/06/27/Real-Time-Rendering/</url>
    <content><![CDATA[<h1 id="I-Pre-Knowledge-Phase-1"><a href="#I-Pre-Knowledge-Phase-1" class="headerlink" title="I. Pre-Knowledge (Phase 1)"></a>I. Pre-Knowledge (Phase 1)</h1><h2 id="Image-Formation"><a href="#Image-Formation" class="headerlink" title="Image Formation"></a>Image Formation</h2><blockquote>
<p>How does a realistic graphic form? </p>
</blockquote>
<h3 id="Elements-of-Image-Formation"><a href="#Elements-of-Image-Formation" class="headerlink" title="Elements of Image Formation"></a>Elements of Image Formation</h3><ul>
<li>Objects</li>
<li>Viewer</li>
<li>Light sources</li>
<li>Materials (材质)<ul>
<li>Attributes that govern how light interacts with the materials in the scene</li>
</ul>
</li>
</ul>
<h3 id="Models"><a href="#Models" class="headerlink" title="Models"></a>Models</h3><p><strong>Know about Pinhole Camera</strong></p>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr1.png" alt="Pinhole Camera" style="zoom:60%"></div>

<p>Use trigonometry(三角几何) to find <strong>projection</strong> of 3D point at $(x, y, z)$</p>
<blockquote class="blockquote-center">
<p>$<br>x_p=-dx/z\ \ \ \ y_p=-dy/z\ \ \ \ z_p=-d<br>$</p>

</blockquote>
<p><strong>Synthetic Camera Model (合成相机模型)</strong></p>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr2.png" alt="Synthetic Camera Model
" style="zoom:60%"></div>

<p><strong>Luminance and Color Images (光线与颜色的映射)</strong></p>
<ul>
<li>Luminance Image<ul>
<li>Monochromatic(单色)<ul>
<li>Values are gray levels</li>
<li>Analogous to working with black and white film or television</li>
</ul>
</li>
</ul>
</li>
<li>Color Image<ul>
<li>Has perceptional attributes of hue(色相), saturation(饱和度), and lightness</li>
</ul>
</li>
</ul>
<p>↓</p>
<ul>
<li>Representation of Color<ul>
<li><font color="red">Additive color</font>: Form a color by adding amounts of three primaries<font color="grey">(RGB)</font><ul>
<li>E.g. CRTs, projection systems, positive film</li>
</ul>
</li>
<li><font color="red">Subtractive color</font>: Form a color by filtering white light with <font color="cyan">Cyan (C)</font>, <font color="magenta">Magenta (M)</font>, and <font color="deyellow">Yellow (Y)</font> filters<ul>
<li><font color="blue">Noted:</font> Cyan = –Red; Magenta = –Green; Yellow = –Blue</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<h2 id="Graphics-System-Design"><a href="#Graphics-System-Design" class="headerlink" title="Graphics System Design"></a>Graphics System Design</h2><font size="4">A graphics system has two main components</font>

<ol>
<li>Application Programmer Interface (API)<ul>
<li>For specifying the <font color="red"><b>scene</b></font><ul>
<li>objects, materials, viewer, lights</li>
</ul>
</li>
<li>For <font color="red">configuring/controlling</font> the system</li>
</ul>
</li>
<li>Renderer<ul>
<li>Renders the images<ul>
<li>Using scene info and system configuration</li>
</ul>
</li>
</ul>
</li>
</ol>
<h3 id="Rendering-Approaches"><a href="#Rendering-Approaches" class="headerlink" title="Rendering Approaches"></a>Rendering Approaches</h3><ol>
<li><strong>Ray tracing:</strong> follow rays of light from center of projection until they are absorbed by objects or go off to infinity<ul>
<li>符合物理解释，泛用性广；但是速度慢，性能低</li>
</ul>
</li>
<li>Radiosity: Energy based approach<ul>
<li>非常慢且不泛用</li>
</ul>
</li>
</ol>
<p><strong>Practical Approach</strong></p>
<ol>
<li><font coklor="red"><b>Polygon Rasterization</b></font>(多边形光栅)</li>
</ol>
<blockquote>
<p>3D 物体可以近似地表示为平面多边形刻面 (planar polygonal facets) 的网或网格</p>
</blockquote>
<table>
<tr>
<td><img src="/2024/06/27/Real-Time-Rendering/rtr3.png" alt="polygon rasterization
" style="zoom:60%"></td>
<td><img src="/2024/06/27/Real-Time-Rendering/rtr4.png" alt="polygon rasterization
" style="zoom:40%"></td>
</tr>
</table>

<font color="blue">Pipeline architecture</font>

<blockquote>
<p>The pipeline consists of stages that each primitive (e.g. polygon) must go through</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Vertices -&gt; |Vertex processor| -&gt; |Clipper and primitive assembler| -&gt; |Rasterizer| </span><br><span class="line">-&gt; |Fragment processor| -&gt; Pixels</span><br></pre></td></tr></table></figure>
<p>(i) Vertex Processing</p>
<ul>
<li>Much of the work in the pipeline is in converting object representations from one coordinate system to another<ul>
<li>Object coordinates</li>
<li>Camera (eye) coordinates</li>
<li>Screen coordinates</li>
</ul>
</li>
<li>Also computes vertex colors</li>
</ul>
<p>(ii) Projection</p>
<ul>
<li>Projection is the process that combines the <strong>3D</strong> viewer with the <strong>3D</strong> objects to produce the <strong>2D</strong> image<ul>
<li>Perspective projections: all projectors meet at the center of projection</li>
<li>Parallel projection: projectors are parallel, center of projection is replaced by a direction of projection</li>
</ul>
</li>
</ul>
<p>(iii) Clipping</p>
<ul>
<li>Simulate a <font color="red">virtual camera</font> to clip the images</li>
</ul>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr5.png" alt="clip" style="zoom:70%"></div>



<p>(iv) <font color="red">Rasterization</font></p>
<ul>
<li>Rasterizer produces a set of <a href="#fragment">fragments</a> for each object</li>
<li><a name="fragment">Fragments</a> are “potential pixels”<ul>
<li>Have a location in frame bufffer</li>
<li>Color and depth attributes</li>
</ul>
</li>
</ul>
<blockquote>
<p>Fragment Processing</p>
<ul>
<li>Fragments are processed to determine the color of the corresponding pixel in the frame buffer</li>
<li>Colors can be determined by texture mapping or interpolation(插值) of vertex colors</li>
<li>Fragments may be blocked/occluded(阻塞) by other fragments closer to the camera<ul>
<li>Using Hidden-surface removal</li>
</ul>
</li>
</ul>
</blockquote>
<hr>
<h2 id="API-Contents"><a href="#API-Contents" class="headerlink" title="API Contents"></a>API Contents</h2><ul>
<li><font color="green">Recall: Functions that specify what we need to form an image</font><ul>
<li>Objects</li>
<li>Viewer</li>
<li>Light Source(s)</li>
<li>Materials</li>
</ul>
</li>
</ul>
<h3 id="Object-Specifications"><a href="#Object-Specifications" class="headerlink" title="Object Specifications"></a>Object Specifications</h3><ul>
<li>Most APIs support a limited set of primitives including<ul>
<li>Points (0D object)</li>
<li>Line segments (1D objects)</li>
<li>Polygons (2D objects)</li>
<li>Some curves and surfaces<ul>
<li>Quadrics</li>
<li>Parametric polynomials</li>
</ul>
</li>
</ul>
</li>
<li>All are defined through locations in space or vertices</li>
</ul>
<h3 id="Camera-Specification"><a href="#Camera-Specification" class="headerlink" title="Camera Specification"></a>Camera Specification</h3><ul>
<li>Six degrees of freedom<ul>
<li>Position of center of lens</li>
<li>Orientation</li>
</ul>
</li>
<li>Lens</li>
<li>Film size</li>
<li>Orientation of film plane</li>
</ul>
<h3 id="Lights-and-Materials"><a href="#Lights-and-Materials" class="headerlink" title="Lights and Materials"></a>Lights and Materials</h3><ul>
<li>Types of lights<ul>
<li>Point sources vs distributed sources</li>
<li>Spot lights</li>
<li>Near and far sources</li>
<li>Color properties</li>
</ul>
</li>
<li>Material properties<ul>
<li>Absorption: color properties</li>
<li>Scattering<ul>
<li>Diffuse</li>
<li>Specular</li>
</ul>
</li>
</ul>
</li>
</ul>
<div align="center"><font color="grey" size="5">----- <font face="Segoe Script">Let's start Phase 2!</font> -----</font></div>

<h1 id="II-Elementary-OpenGL-Programming"><a href="#II-Elementary-OpenGL-Programming" class="headerlink" title="II. Elementary OpenGL Programming"></a>II. Elementary OpenGL Programming</h1><h2 id="OpenGL-Libraries"><a href="#OpenGL-Libraries" class="headerlink" title="OpenGL Libraries"></a>OpenGL Libraries</h2><h3 id="Core-Library"><a href="#Core-Library" class="headerlink" title="Core Library"></a>Core Library</h3><ul>
<li>OpenGL core library<ul>
<li>OpenGL32 on Windows</li>
<li>GL on most unix/linux systems ( <code>libGL.a</code> )</li>
</ul>
</li>
<li>OpenGL Utility Library ( GLU )<ul>
<li>Provides functionality in OpenGL core but avoids having to rewrite code</li>
</ul>
</li>
<li>Links with window system<ul>
<li><code>GLX</code> for X window systems</li>
<li><code>WGL</code> for Windows</li>
<li><code>AGL</code> for Macintosh</li>
</ul>
</li>
</ul>
<h3 id="GLUT-FreeGLUT-Libraries"><a href="#GLUT-FreeGLUT-Libraries" class="headerlink" title="GLUT / FreeGLUT Libraries"></a>GLUT / FreeGLUT Libraries</h3><ul>
<li><strong>GLUT = OpenGL Utility Toolkit</strong><ul>
<li><font color="red"><b>Not</b></font> part of OpenGL</li>
<li>Provides functionality common to all window systems<ul>
<li>Open a window</li>
<li>Get input from mouse and keyboard</li>
<li>Menus</li>
<li>Event-driven</li>
</ul>
</li>
<li>Code is portable but GLUT lacks the functionality of a good  toolkit for a specific platform<ul>
<li>No slide bars</li>
</ul>
</li>
</ul>
</li>
<li><a href="http://freeglut.sourceforge.net/">FreeGLUT</a></li>
</ul>
<h3 id="Software-Organization"><a href="#Software-Organization" class="headerlink" title="Software Organization"></a>Software Organization</h3><div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr6.png" alt="GL Organ" style="zoom:70%"></div>



<h2 id="Basic-OpenGL-Rendering-Pipeline"><a href="#Basic-OpenGL-Rendering-Pipeline" class="headerlink" title="Basic OpenGL Rendering Pipeline"></a>Basic OpenGL Rendering Pipeline</h2><ul>
<li>To render a primitive using OpenGL, the primitive goes through the following main stages: <ul>
<li><font color="green">Goal:</font> Turning primitive into pixels</li>
</ul>
</li>
</ul>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr7.png" alt="stage 1" style="zoom:70%"></div>



<h3 id="OpenGL-Functions"><a href="#OpenGL-Functions" class="headerlink" title="OpenGL Functions"></a>OpenGL Functions</h3><ul>
<li>Specify primitives<ul>
<li>E.g. points, line segments, triangles, quadrilaterals, polygons </li>
</ul>
</li>
<li>Specify vertex attributes<ul>
<li>E.g. color, normal vector, material, texture coordinates</li>
</ul>
</li>
<li>Specify transformations<ul>
<li>E.g. modeling, viewing</li>
</ul>
</li>
<li>Control (<code>GLUT</code>)</li>
<li>Input (<code>GLUT</code>)</li>
<li>Query: “ask for the state of object” etc.</li>
</ul>
<h3 id="OpenGL-State"><a href="#OpenGL-State" class="headerlink" title="OpenGL State"></a>OpenGL State</h3><ul>
<li><font color="red">OpenGL is a <b>state machine</b></font>
</li>
<li><p>OpenGL functions are <font color="red">of two types</font></p>
<ul>
<li>Primitive generating<ul>
<li>Can cause output if primitive is visible</li>
<li>How vertices are processed and appearance of primitive are controlled by the state</li>
</ul>
</li>
<li>State changing<ul>
<li>Transformation functions</li>
<li>Attribute functions</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="Simple-Concept"><a href="#Simple-Concept" class="headerlink" title="Simple Concept"></a>Simple Concept</h2><h3 id="Examples"><a href="#Examples" class="headerlink" title="Examples"></a>Examples</h3><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;GL/glut.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">mydisplay</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="built_in">glClear</span>(GL_COLOR_BUFFER_BIT); </span><br><span class="line">    <span class="built_in">glBegin</span>(GL_POLYGON); </span><br><span class="line">    <span class="built_in">glVertex2f</span>(<span class="number">-0.5</span>, <span class="number">-0.5</span>); </span><br><span class="line">    <span class="built_in">glVertex2f</span>(<span class="number">-0.5</span>, <span class="number">0.5</span>); </span><br><span class="line">    <span class="built_in">glVertex2f</span>(<span class="number">0.5</span>, <span class="number">0.5</span>); </span><br><span class="line">    <span class="built_in">glVertex2f</span>(<span class="number">0.5</span>, <span class="number">-0.5</span>); </span><br><span class="line">    <span class="built_in">glEnd</span>();</span><br><span class="line">    <span class="built_in">glFlush</span>(); </span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span>** argv)</span> </span>&#123;</span><br><span class="line">    <span class="built_in">glutInit</span>(&amp;argc, argv);</span><br><span class="line">    <span class="built_in">glutCreateWindow</span>(<span class="string">&quot;simple&quot;</span>); </span><br><span class="line">    <span class="built_in">glutDisplayFunc</span>(mydisplay); </span><br><span class="line">    <span class="built_in">glutMainLoop</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>This code is to draw a white square in black background.</p>
</blockquote>
<h3 id="Event-Loop"><a href="#Event-Loop" class="headerlink" title="Event Loop"></a>Event Loop</h3><p>Note that the program defines a <font color="red">display callback</font> function named <code>mydisplay</code></p>
<ul>
<li>Every GLUT program <font color="red"><b>must</b></font> have a display callback</li>
<li>The display callback is executed whenever OpenGL decides the display must be refreshed<ul>
<li>For example, when the window is opened</li>
</ul>
</li>
<li>The <strong>main function ends</strong> with the program entering an event loop</li>
</ul>
<h2 id="Program-Structure"><a href="#Program-Structure" class="headerlink" title="Program Structure"></a>Program Structure</h2><ul>
<li>Most OpenGL programs have a similar structure that consists of the following functions<ul>
<li><code>main()</code>: <ul>
<li>defines the callback functions </li>
<li>opens one or more windows with the required properties</li>
<li>enters event loop (last executable statement)</li>
</ul>
</li>
<li><code>init()</code>: sets the state variables<ul>
<li>Viewing</li>
<li>Attributes</li>
</ul>
</li>
<li>callbacks<ul>
<li>Display callback function</li>
<li>Input and window functions</li>
</ul>
</li>
</ul>
</li>
</ul>
<blockquote>
<p>Then we’re going to see an explicit form of <code>Example</code></p>
</blockquote>
<h3 id="main"><a href="#main" class="headerlink" title="main()"></a><code>main()</code></h3><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;GL/glut.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span>** argv)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="built_in">glutInit</span>(&amp;argc, argv); </span><br><span class="line">	<span class="built_in">glutInitDisplayMode</span>(GLUT_SINGLE | GLUT_RGB); </span><br><span class="line">	<span class="built_in">glutInitWindowSize</span>(<span class="number">500</span>, <span class="number">500</span>); </span><br><span class="line">	<span class="built_in">glutInitWindowPosition</span>(<span class="number">0</span>, <span class="number">0</span>); </span><br><span class="line">	<span class="built_in">glutCreateWindow</span>(<span class="string">&quot;simple2&quot;</span>); </span><br><span class="line">	<span class="built_in">glutDisplayFunc</span>(mydisplay); </span><br><span class="line">	<span class="built_in">init</span>(); </span><br><span class="line">	<span class="built_in">glutMainLoop</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li><code>glutInit</code> —— allows application to get command line arguments and initializes system</li>
<li><code>gluInitDisplayMode</code> —— requests properties for the window (the rendering context)<ul>
<li>RGB color</li>
<li>Single buffering</li>
<li>Properties logically ORed together</li>
</ul>
</li>
<li><code>glutWindowSize</code> —— in pixels</li>
<li><code>glutWindowPosition</code> —— from top-left corner of display</li>
<li><code>glutCreateWindow</code> —— create window with title “simple”</li>
<li><code>glutDisplayFunc</code> —— display callback</li>
<li><code>glutMainLoop</code> —— enter infinite event loop</li>
</ul>
<h3 id="init"><a href="#init" class="headerlink" title="init()"></a><code>init()</code></h3><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">init</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="built_in">glClearColor</span>(<span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">1.0</span>); </span><br><span class="line">	<span class="comment">// black clear color with opaque window</span></span><br><span class="line">	<span class="built_in">glColor3f</span>(<span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>); <span class="comment">// white fill color</span></span><br><span class="line">	<span class="built_in">glMatrixMode</span>(GL_PROJECTION); </span><br><span class="line">	<span class="built_in">glLoadIdentity</span>(); </span><br><span class="line">	<span class="built_in">glOrtho</span>(<span class="number">-1.0</span>, <span class="number">1.0</span>, <span class="number">-1.0</span>, <span class="number">1.0</span>, <span class="number">-1.0</span>, <span class="number">1.0</span>); <span class="comment">// viewing volume</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>Coordinate Systems (have a rough knowing)<ul>
<li>object coordinates (3D)</li>
<li>world coordinates (camera)</li>
<li>window coordinates</li>
</ul>
</li>
<li>About OpenGL Camera</li>
</ul>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr8.png" alt="opengl camera" style="zoom:50%"></div>

<ul>
<li>Orthographic Viewing and Transformation<ul>
<li>In the default orthographic view, points are projected forward along the $z$ axis onto the plane $z = 0$</li>
<li>In OpenGL, projection is carried out by a projection matrix (transformation)</li>
<li>There is only one set of transformation functions so we must set the matrix mode first<ul>
<li><code>glMatrixMode(GL_PROJECTION)</code></li>
</ul>
</li>
<li>Transformation functions are incremental so we start with an identity matrix and alter it with a projection matrix that gives the view volume<ul>
<li><code>glLoadIdentity();</code></li>
<li><code>glOrtho(-1.0, 1.0, -1.0, 1.0, -1.0, 1.0);</code></li>
</ul>
</li>
<li><code>glOrtho(left, right, bottom, top, near, far)</code> is used to determine the projection area.</li>
<li>If the application is in 2D, we can use the function <code>gluOrtho2D(left, right, bottom, top)</code></li>
</ul>
</li>
</ul>
<blockquote>
<p>Here is an example of how to draw a projection on 2D windows. </p>
<p>Because a projection from 3D to 2D is in <strong>OpenGL-Primitives</strong> (I show below), so we only need to paint it out.</p>
</blockquote>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">mydisplay</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="built_in">glClear</span>(GL_COLOR_BUFFER_BIT); </span><br><span class="line">	<span class="built_in">glBegin</span>(GL_POLYGON); </span><br><span class="line">	<span class="comment">// define as polygon</span></span><br><span class="line">	<span class="built_in">glVertex2f</span>(<span class="number">-0.5</span>, <span class="number">-0.5</span>); </span><br><span class="line">	<span class="built_in">glVertex2f</span>(<span class="number">-0.5</span>, <span class="number">0.5</span>); </span><br><span class="line">	<span class="built_in">glVertex2f</span>(<span class="number">0.5</span>, <span class="number">0.5</span>); </span><br><span class="line">	<span class="built_in">glVertex2f</span>(<span class="number">0.5</span>, <span class="number">-0.5</span>); </span><br><span class="line">	<span class="comment">// set 4 vertex to form 4-edges polygon</span></span><br><span class="line">	<span class="built_in">glEnd</span>();</span><br><span class="line">	<span class="built_in">glFlush</span>(); </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr11.png" alt="opengl primitives" style="zoom:70%"></div>



<h3 id="Other-methods-of-OpenGL"><a href="#Other-methods-of-OpenGL" class="headerlink" title="Other methods of OpenGL"></a>Other methods of OpenGL</h3><ol>
<li><code>glShadeModel()</code> to set the color rendering to be <code>GL_SMOOTH</code> (渐变) or <code>GL_FLAT</code> (单色).</li>
<li><code>glViewport(x, y, w, h)</code> to set the viewport of windows.</li>
</ol>
<h2 id="3D-OpenGL"><a href="#3D-OpenGL" class="headerlink" title="3D OpenGL"></a>3D OpenGL</h2><h3 id="Three-Dimensional-Applications"><a href="#Three-Dimensional-Applications" class="headerlink" title="Three-Dimensional Applications"></a>Three-Dimensional Applications</h3><ul>
<li>In OpenGL, 2D applications are a special case of 3D graphics</li>
<li>Going to 3D<ul>
<li>Not much changes</li>
<li>Use <code>glVertex3*()</code></li>
<li>Have to worry about the order in which polygons are drawn or use <strong>hidden-surface removal</strong> (occlusion problem)</li>
<li>Polygons should be simple, convex, flat</li>
</ul>
</li>
</ul>
<h3 id="Gasket-Program"><a href="#Gasket-Program" class="headerlink" title="Gasket Program"></a>Gasket Program</h3><div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr9.png" alt="triangle division" style="zoom:50%"></div>

<ul>
<li>Consider the filled area (black) and the perimeter (the length of all the lines around the filled triangles)</li>
<li>As we continue subdividing<ul>
<li>the area goes to zero (&lt; 2D)</li>
<li>but the perimeter goes to infinity (&gt; 1D)</li>
</ul>
</li>
<li>This is not an ordinary geometric object<ul>
<li>It is neither one- nor two-dimensional</li>
</ul>
</li>
<li>It is a fractal (fractional dimension) object<ul>
<li>Approximately 1.585 D</li>
</ul>
</li>
</ul>
<blockquote>
<font color="red">How to do in program?</font>

<font color="green">Using algorithm of Recursion!</font>


</blockquote>
<ul>
<li>Design <code>display()</code> and <code>myinit()</code></li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">display</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">glClear</span>(GL_COLOR_BUFFER_BIT);</span><br><span class="line">    <span class="built_in">glBegin</span>(GL_TRIANGLES);</span><br><span class="line">    <span class="built_in">divide_triangle</span>(v[<span class="number">0</span>], v[<span class="number">1</span>], v[<span class="number">2</span>], n);</span><br><span class="line">    <span class="built_in">glEnd</span>();</span><br><span class="line">    <span class="built_in">glFlush</span>();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">myinit</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">glMatrixMode</span>(GL_PROJECTION);</span><br><span class="line">    <span class="built_in">glLoadIdentity</span>();</span><br><span class="line">    <span class="built_in">gluOrtho2D</span>(<span class="number">-2.0</span>, <span class="number">2.0</span>, <span class="number">-2.0</span>, <span class="number">2.0</span>);</span><br><span class="line">    <span class="built_in">glMatrixMode</span>(GL_MODELVIEW);</span><br><span class="line">    <span class="built_in">glClearColor</span> (<span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>);</span><br><span class="line">    <span class="built_in">glColor3f</span>(<span class="number">0.0</span>,<span class="number">0.0</span>,<span class="number">0.0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>Then set parameter and callback function in <code>main()</code></li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span> **argv)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    n = <span class="number">4</span>;</span><br><span class="line">    <span class="built_in">glutInit</span>(&amp;argc, argv);</span><br><span class="line">    <span class="built_in">glutInitDisplayMode</span>(GLUT_SINGLE | GLUT_RGB);</span><br><span class="line">    <span class="built_in">glutInitWindowSize</span>(<span class="number">500</span>, <span class="number">500</span>);</span><br><span class="line">    <span class="built_in">glutCreateWindow</span>(<span class="string">&quot;Sierpinski Gasket&quot;</span>);</span><br><span class="line">    <span class="built_in">glutDisplayFunc</span>(display);</span><br><span class="line">    <span class="built_in">myinit</span>();</span><br><span class="line">    <span class="built_in">glutMainLoop</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="Move-to-3D-triangle"><a href="#Move-to-3D-triangle" class="headerlink" title="Move to 3D triangle"></a>Move to 3D triangle</h3><ul>
<li>Add an extra vertex to form tetrahedra</li>
<li>Then we can do like 2D triangle subdivision</li>
</ul>
<font color="red">But we have to deal with <b>Hidden-Surface Removal</b> !!</font>

<ul>
<li><ul>
<li>OpenGL uses a hidden-surface removal method called the z-buffer algorithm that saves depth information as objects are rendered so that only the front objects appear in the image.</li>
</ul>
</li>
</ul>
<blockquote class="blockquote-center">
<p><strong>Using the z-buffer Algorithm</strong></p>

</blockquote>
<p>Requested in <code>main()</code></p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="built_in">glutInitDisplayMode</span>(GLUT_SINGLE | GLUT_RGB | GLUT_DEPTH)</span><br></pre></td></tr></table></figure>
<p>Enabled in <code>init()</code></p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="built_in">glEnable</span>(GL_DEPTH_TEST)</span><br></pre></td></tr></table></figure>
<p>Cleared in the display callback</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="built_in">glClear</span>(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT)</span><br></pre></td></tr></table></figure>
<blockquote class="blockquote-center">
<p><strong>Surface vs. Volume Subdivision</strong></p>

</blockquote>
<ul>
<li>In our example, we subdivided the <strong>surface</strong> of each face</li>
<li>We could also subdivide the volume using the same midpoints</li>
<li>The midpoints define four smaller tetrahedrons, one for each vertex</li>
<li>Keeping only these tetrahedrons removes a volume in the middle</li>
<li>Good programming exercise</li>
</ul>
<hr>
<h1 id="III-Input-amp-Interaction"><a href="#III-Input-amp-Interaction" class="headerlink" title="III. Input &amp; Interaction"></a>III. Input &amp; Interaction</h1><h2 id="Concept"><a href="#Concept" class="headerlink" title="Concept"></a>Concept</h2><ul>
<li>Graphical Input<ul>
<li>Devices can be described either by<ul>
<li>Physical properties<ul>
<li>Mouse, Keyboard, Trackball, etc.</li>
</ul>
</li>
<li>Logical properties: What is returned to program via API<ul>
<li>A position</li>
<li>An object identifier</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>Trigger and Measure</p>
<ul>
<li>Input devices contain a <font color="red">trigger</font> which can be used to send a signal to the operating system<ul>
<li>Button on mouse</li>
<li>Pressing or releasing a key</li>
</ul>
</li>
<li>When triggered, input devices return information (their <font color="red">measure</font>) to the system<ul>
<li>Mouse returns position information</li>
<li>Keyboard returns ASCII code</li>
</ul>
</li>
</ul>
</li>
<li><p>Event Mode</p>
<ul>
<li>Each trigger generates an event whose measure is put in an event queue which can be examined by the user program</li>
</ul>
</li>
</ul>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr10.png" alt="procedure" style="zoom:70%"></div>

<ul>
<li><p>Event Type</p>
<ul>
<li>Window: resize, expose, minimize</li>
<li>Mouse: click one or more buttons</li>
<li>Motion: move mouse</li>
<li>Keyboard: press or release a key</li>
<li>Idle: non-event (无输入时的活动)<ul>
<li>Define what should be done if no other event is in queue</li>
</ul>
</li>
</ul>
</li>
<li><p><font color="green">Recall:</font> callbacks</p>
<ul>
<li>Define a callback function for <strong>each type of event</strong> the graphics system recognizes</li>
<li>E.g. <code>glutMouseFunc(mymouse)</code> where <code>mymouse</code> is a mouse callback function.</li>
</ul>
</li>
<li><font color="red">GLUT  recognizes a subset of the events recognized by any particular operation system</font> : <ul>
<li><code>glutDisplayFunc</code></li>
<li><code>glutMouseFunc</code></li>
<li><code>glutReshapeFunc</code></li>
<li><code>glutKeyboardFunc</code></li>
<li><code>glutIdleFunc</code></li>
<li><code>glutMotionFunc</code>, <code>glutPassiveMotionFunc</code> </li>
</ul>
</li>
</ul>
<h2 id="GLUT-Event-Loop"><a href="#GLUT-Event-Loop" class="headerlink" title="GLUT Event Loop"></a>GLUT Event Loop</h2><ul>
<li><font color="green">Recall:</font> the last statement in <code>main()</code> for a program using GLUT must be <code>glutMainLoop();</code></li>
<li>In each pass through the event loop, GLUT <ul>
<li>looks at the events in the <strong>queue</strong></li>
<li>execute each event if the corresponding callback function is defined.</li>
</ul>
</li>
</ul>
<font color="purple">Important before talking about callbacks:</font> 

<ul>
<li>The form of all GLUT callbacks is fixed</li>
<li>So we must use <strong>globals</strong> (全局变量) to pass information to callbacks</li>
</ul>
<h3 id="Display-Callback"><a href="#Display-Callback" class="headerlink" title="Display Callback"></a>Display Callback</h3><ul>
<li>When windows are refreshed, apply display callbacks<ul>
<li><code>glutDisplayFunc(mydisplay)</code> in <code>main()</code></li>
<li><code>glutPostRedisplay()</code> to <font color="red">avoid multiple display</font> in one single pass through the event loop<ul>
<li>set a <strong>“flag”</strong> at the end of the event loop.</li>
<li>GLUT checks it and display callback function is executed.</li>
</ul>
</li>
</ul>
</li>
<li>Then what’s inside <code>mydisplay</code>?<ul>
<li><code>glClear()</code> to clear the window</li>
<li>Use <font color="red"><b>Double Buffer</b></font> to avoid <font color="blue">partial drawn</font> <ul>
<li><strong>Front Buffer</strong>: one that is <strong>displayed</strong> but not written to</li>
<li><strong>Back Buffer</strong>: one that is <strong>written</strong> to but not displayed</li>
</ul>
</li>
<li><code>glutInitDisplayMode(GLUT_RGB | GLUT_DOUBLE)</code> declare in <code>main()</code> to request a <font color="red">double buffer</font></li>
<li>At the end of display callback buffers are swapped.</li>
</ul>
</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">mydisplay</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"> <span class="built_in">glClear</span>(GL_COLOR_BUFFER_BIT|…)</span><br><span class="line"> ...</span><br><span class="line"> <span class="comment">/* draw graphics here */</span></span><br><span class="line"> ...</span><br><span class="line"> <span class="built_in">glutSwapBuffers</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="Idle-Callback"><a href="#Idle-Callback" class="headerlink" title="Idle Callback"></a>Idle Callback</h3><ul>
<li>The idle callback is executed whenever there are <font color="red">no events</font> in the event queue<ul>
<li><code>glutIdleFunc(myidle)</code> in <code>main()</code></li>
<li><font color="blue">Useful for animation</font> 

</li>
</ul>
</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">myidle</span><span class="params">()</span> </span>&#123;</span><br><span class="line"> <span class="comment">/* change something */</span></span><br><span class="line"> t += dt</span><br><span class="line"> <span class="built_in">glutPostRedisplay</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="Mouse-and-Keyboard-Callbacks"><a href="#Mouse-and-Keyboard-Callbacks" class="headerlink" title="Mouse and Keyboard Callbacks"></a>Mouse and Keyboard Callbacks</h3><ul>
<li><code>glutMouseFunc(mymouse)</code> in <code>main()</code></li>
<li><code>void mymouse(GLint button, GLint state,  GLint x, GLint y)</code> to define mouse callbacks<ul>
<li>Buttons: <code>GLUT_LEFT_BUTTON</code>, <code>GLUT_MIDDLE_BUTTON</code> or <code>GLUT_RIGHT_BUTTON</code></li>
<li>States: <code>GLUT_UP</code> or <code>GLUT_DOWN</code></li>
<li>Cursor Position: top-left corner is (0,0) <font color="gray">[Others depend on winsize]</font></li>
</ul>
</li>
</ul>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr12.png" alt="position" style="zoom:50%"></div>

<blockquote class="blockquote-center">
<p>$<br>y_{\text{OpenGL}}= h-1-y_{text{win}}<br>$</p>

</blockquote>
<font color="blue">E.g. To draw a square when mouse click</font>

<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">mymouse</span><span class="params">(<span class="type">int</span> btn, <span class="type">int</span> state, <span class="type">int</span> x, <span class="type">int</span> y)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"> <span class="keyword">if</span> (btn==GLUT_RIGHT_BUTTON &amp;&amp; state==GLUT_DOWN) <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line"> <span class="keyword">if</span> (btn==GLUT_LEFT_BUTTON &amp;&amp; state==GLUT_DOWN) <span class="built_in">drawSquare</span>(x, y);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">drawSquare</span><span class="params">(<span class="type">int</span> x, <span class="type">int</span> y)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"> y = w – <span class="number">1</span> - y; <span class="comment">/* invert y position */</span></span><br><span class="line"> <span class="comment">/* a random color */</span></span><br><span class="line"> <span class="built_in">glColor3ub</span>((<span class="type">char</span>)<span class="built_in">rand</span>()%<span class="number">256</span>,(<span class="type">char</span>)<span class="built_in">rand</span>()%<span class="number">256</span>,(<span class="type">char</span>)<span class="built_in">rand</span>()%<span class="number">256</span> );</span><br><span class="line"> <span class="built_in">glBegin</span>(GL_POLYGON);</span><br><span class="line"> <span class="built_in">glVertex2f</span>(x+size, y+size);</span><br><span class="line"> <span class="built_in">glVertex2f</span>(x-size, y+size);</span><br><span class="line"> <span class="built_in">glVertex2f</span>(x-size, y-size);</span><br><span class="line"> <span class="built_in">glVertex2f</span>(x+size, y-size);</span><br><span class="line"> <span class="built_in">glEnd</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<hr>
<ul>
<li>We can draw squares (or anything else) continuously as long as a mouse button is depressed by using the motion callback<ul>
<li><code>glutMotionFunc(drawSquare)</code></li>
</ul>
</li>
<li><p>We can draw squares without depressing a button using the <font color="red">passive motion</font> callback (用于鼠标没按下但在移动时的操作)</p>
<ul>
<li><code>glutPassiveMotionFunc(drawSquare)</code></li>
</ul>
</li>
<li><p><strong>Keyboard is almost the same</strong></p>
<ul>
<li><code>glutKeyboardFunc(mykey)</code></li>
<li><code>void mykey(unsigned char key,  int x, int y)</code></li>
</ul>
</li>
</ul>
<p>E.g.</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">mykey</span><span class="params">(<span class="type">unsigned</span> <span class="type">char</span> key, <span class="type">int</span> x, <span class="type">int</span> y)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"> <span class="keyword">if</span> (key == <span class="string">&#x27;Q&#x27;</span> | key == <span class="string">&#x27;q&#x27;</span>) </span><br><span class="line"> <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p><strong>Others:</strong></p>
<p>GLUT defines the <strong>special keys</strong> in <code>glut.h</code></p>
<ul>
<li>Function key 1: <code>GLUT_KEY_F1</code></li>
<li>Up arrow key: <code>GLUT_KEY_UP</code></li>
</ul>
<p>Also check <strong>modifiers</strong></p>
<ul>
<li><code>GLUT_ACTIVE_SHIFT</code>, <code>GLUT_ACTIVE_CTRL</code>, <code>GLUT_ACTIVE_ALT</code> is depressed using <code>glutGetModifiers()</code> </li>
</ul>
</blockquote>
<h3 id="Reshape-Callback"><a href="#Reshape-Callback" class="headerlink" title="Reshape Callback"></a>Reshape Callback</h3><ul>
<li><code>glutReshapeFunc(myreshape)</code> in <code>main()</code></li>
<li><code>void myreshape(int w, int h)</code></li>
</ul>
<p>E.g.</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">myReshape</span><span class="params">(<span class="type">int</span> w, <span class="type">int</span> h)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"> <span class="built_in">glViewport</span>(<span class="number">0</span>, <span class="number">0</span>, w, h);</span><br><span class="line"> <span class="built_in">glMatrixMode</span>(GL_PROJECTION); <span class="comment">/* switch matrix mode */</span></span><br><span class="line"> <span class="built_in">glLoadIdentity</span>();</span><br><span class="line"> </span><br><span class="line"> <span class="keyword">if</span> (w &lt;= h)</span><br><span class="line"> <span class="built_in">gluOrtho2D</span>( <span class="number">-2.0</span>, <span class="number">2.0</span>, <span class="number">-2.0</span> * (GLfloat) h / w,</span><br><span class="line"> <span class="number">2.0</span> * (GLfloat) h / w );</span><br><span class="line"> <span class="keyword">else</span> </span><br><span class="line"> <span class="built_in">gluOrtho2D</span>( <span class="number">-2.0</span> * (GLfloat) w / h, </span><br><span class="line"> <span class="number">2.0</span> * (GLfloat) w / h, <span class="number">-2.0</span>, <span class="number">2.0</span> );</span><br><span class="line"> <span class="built_in">glMatrixMode</span>(GL_MODELVIEW); <span class="comment">/* return to modelview mode */</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="Menu"><a href="#Menu" class="headerlink" title="Menu"></a>Menu</h3><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// main()</span></span><br><span class="line">GLint menu_id = <span class="built_in">glutCreateMenu</span>(mymenu);</span><br><span class="line"><span class="built_in">glutAddMenuEntry</span>(<span class="string">&quot;Clear&quot;</span>, <span class="number">1</span>);</span><br><span class="line"><span class="built_in">glutAddMenuEntry</span>(<span class="string">&quot;Quit&quot;</span>, <span class="number">2</span>);</span><br><span class="line"><span class="built_in">glutAttachMenu</span>(GLUT_RIGHT_BUTTON);</span><br></pre></td></tr></table></figure>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">mymenu</span><span class="params">(<span class="type">int</span> id)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"> <span class="keyword">if</span>(id == <span class="number">1</span>) <span class="built_in">glClear</span>(GL_COLOR_BUFFER_BIT);</span><br><span class="line"> <span class="keyword">if</span>(id == <span class="number">2</span>) <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="Other-Functions"><a href="#Other-Functions" class="headerlink" title="Other Functions"></a>Other Functions</h3><ul>
<li>Dynamic Windows<ul>
<li>Create and destroy during execution</li>
</ul>
</li>
<li>Subwindows</li>
<li>Multiple Windows</li>
<li>Changing callbacks during execution</li>
<li>Timers (look up glutTimerFunc)<ul>
<li>Useful for controlling speed of animation</li>
</ul>
</li>
<li>Portable fonts<ul>
<li>glutBitmapCharacter</li>
<li>glutStrokeCharacter</li>
</ul>
</li>
</ul>
<hr>
<h1 id="IV-Geometric-Objects-amp-Transformations"><a href="#IV-Geometric-Objects-amp-Transformations" class="headerlink" title="IV. Geometric Objects &amp; Transformations"></a>IV. Geometric Objects &amp; Transformations</h1><ul>
<li>Basic elements<ul>
<li>Scalars</li>
<li>Vectors</li>
<li>Points</li>
</ul>
</li>
<li>Basic primitives<ul>
<li>Line segments</li>
<li>Polygons</li>
</ul>
</li>
</ul>
<h2 id="Representation"><a href="#Representation" class="headerlink" title="Representation"></a>Representation</h2><ul>
<li>Introduce<ul>
<li><strong>coordinate systems</strong> for representing vector spaces</li>
<li>frames for representing <strong>affine spaces</strong>(仿射空间)</li>
</ul>
</li>
<li>Discuss change of frames and bases</li>
<li>Introduce homogeneous coordinates</li>
</ul>
<h3 id="Coordinate-Systems"><a href="#Coordinate-Systems" class="headerlink" title="Coordinate Systems"></a>Coordinate Systems</h3><font color="green">Recall: Linear Algebra</font>

<ul>
<li>basis: $v_1,v_2,…,v_n$</li>
<li>a vector written as $v=\alpha_1 v_1+\alpha_2 v_2 + \cdots + \alpha_n v_n$</li>
<li>the <font color="red">coordinate</font> of $v$ in this basis is $\{ \alpha_1,\alpha_2, \cdots , \alpha_n \}$</li>
</ul>
<h3 id="Frame"><a href="#Frame" class="headerlink" title="Frame"></a>Frame</h3><p><strong>Def.</strong> A <font color="red">frame</font> is a system with a single point(origin $P_0$) and a basis vector <font color="blue">in an affine space</font>.</p>
<blockquote class="blockquote-center">
<p>$<br>P=P_0 + \beta_1 v_1 + \beta_2 v_2 + \cdots + \beta_n v_n<br>$</p>

</blockquote>
<h3 id="Homogeneous-Coordinates"><a href="#Homogeneous-Coordinates" class="headerlink" title="Homogeneous Coordinates"></a>Homogeneous Coordinates</h3><p>E.g. for a 3 * 3 space, the 3 * 3 matrices cannot used for translation(平移), because vectors have no position.</p>
<ul>
<li>We extend the $3\times 3$ point to 4-dimension: $(x,y,z) \rightarrow (x,y,z,1)$</li>
<li>and a $4\times 4$ matrix can represent translation, rotation and scaling and shear</li>
<li>using matrix(a template) below, we can maintain $w=0$ for vectors and $w=1$ for points for <font color="red">orthographic viewing</font> .</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\left( \begin{array}{c}<br>a &amp; b &amp; c &amp; tx \\<br>d &amp; e &amp; f &amp; ty \\<br>g &amp; h &amp; i &amp; tz \\<br>0 &amp; 0 &amp; 0 &amp; 1<br>\end{array}\right)<br>$</p>

</blockquote>
<font color="blue">E.g. For a 3D point $(x,y,z)$ , its homogeneous coordinate is $P_h = (x,y,z,1)$ . To translate it, we define a matrix:</font>

<blockquote class="blockquote-center">
<p>$<br>\left( \begin{array}{c}<br>1 &amp; 0 &amp; 0 &amp; tx \\<br>0 &amp; 1 &amp; 0 &amp; ty \\<br>0 &amp; 0 &amp; 1 &amp; tz \\<br>0 &amp; 0 &amp; 0 &amp; 1<br>\end{array}\right)<br>\left( \begin{array}{c}<br>x \\ y \\ z \\ 1<br>\end{array}\right) =<br>\left( \begin{array}{c}<br>x+ tx \\ y+ ty \\ z+ tz \\  1<br>\end{array}\right)<br>$</p>

</blockquote>
<ul>
<li>More generally, homogeneous coordinates are represented as $p=[ wx,wy,wz,w ]^T$</li>
</ul>
<h2 id="Transformation"><a href="#Transformation" class="headerlink" title="Transformation"></a>Transformation</h2><ul>
<li>Affine Transformation: Line preserving</li>
<li><p>Translation: move points</p>
<ul>
<li>$P’=P+d$ where $d=[d_x, d_y, d_z, 0]^T$ </li>
</ul>
</li>
<li><p><font color="green">Recall for Linear Algebra:</font> Some linear transformation: </p>
<ul>
<li>Rotation (2D)</li>
<li>Scaling</li>
<li>Reflection</li>
</ul>
</li>
</ul>
<blockquote>
<p>try to remember their transformation matrices.</p>
</blockquote>
<p><strong>Inverses</strong></p>
<ul>
<li>Translation: $\textbf{T}^{-1}=\textbf{T}(-d_x, -d_y, -d_z)$</li>
<li>Rotation: $\textbf{R}^{-1}(\theta)=\textbf{R}(- \theta)$<ul>
<li>Noted that only $cos(\theta)$ on orthogonal entry</li>
</ul>
</li>
<li>Scaling: $\textbf{S}^{-1}(s_x, s_y, s_z)=\textbf{S}(1/s_x, 1/s_y, 1/s_z)$ </li>
</ul>
<p><strong>Examples</strong></p>
<p>Rotation About a Fixed Point Other than the Origin:</p>
<ol>
<li>Move fixed point to origin</li>
<li>Rotate</li>
<li>Move fixed point back</li>
</ol>
<blockquote class="blockquote-center">
<p>$<br>\textbf{M}=\textbf{T}(p_f)\textbf{R}(\theta)\textbf{T}(-p_f)<br>$</p>

</blockquote>
<p>(bu)</p>
<h2 id="OpenGL-Transformations"><a href="#OpenGL-Transformations" class="headerlink" title="OpenGL Transformations"></a>OpenGL Transformations</h2><div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr13.png" alt="procedure" style="zoom:50%"></div>

<ul>
<li><p><font color="green">Recall:</font> <code>glMatrixMode(GLenum mode)</code> to change the mode of matrix calculation</p>
<ul>
<li>when doing transformation, use <code>GL_MODELVIEW</code> state</li>
</ul>
</li>
<li><p>For all CTM(Current Transformation Matrix) Operations, our CPP Code must load identity matrix first:</p>
</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="built_in">glMatrixMode</span>(GL_MODELVIEW);</span><br><span class="line"><span class="built_in">glLoadIdentity</span>(); <span class="comment">// 重置</span></span><br><span class="line"><span class="built_in">glTranslatef</span>(<span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">-5.0</span>); <span class="comment">// 平移物体</span></span><br></pre></td></tr></table></figure>
<ul>
<li>Beware of using <strong>post-multiplications</strong> (the later operations should be multipled to result matrix $\textbf{C}$ <font color="red">earlier</font>)<ul>
<li>E.g. Rotation About a Fixed Point: $\textbf{C}=\textbf{T}^{-1}\textbf{R}\textbf{T}$</li>
</ul>
</li>
<li>Other Transformation Matrix specifying<ul>
<li>rotation: <code>glRotatef(theta, vx, vy, yz)</code></li>
<li>translation: <code>glTranslatef(dx, dy, dz)</code></li>
<li>scale: <code>glScalef(sx, sy, sz)</code> </li>
</ul>
</li>
</ul>
<hr>
<h1 id="V-Camera-amp-Viewing"><a href="#V-Camera-amp-Viewing" class="headerlink" title="V. Camera &amp; Viewing"></a>V. Camera &amp; Viewing</h1><h2 id="Computer-Viewing"><a href="#Computer-Viewing" class="headerlink" title="Computer Viewing"></a>Computer Viewing</h2><ul>
<li><font color="red">2</font> attributes to define the viewing:<ul>
<li>Positioning the camera<ul>
<li><font color="green">Setting the <b>model-view</b> matrix</font> </li>
</ul>
</li>
<li>Selecting a lens<ul>
<li><font color="green">Setting the <b>projection</b> matrix</font></li>
<li>Perspective or orthographic / view volume / clipping volume …</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="Specify-Different-Space"><a href="#Specify-Different-Space" class="headerlink" title="Specify Different Space"></a>Specify Different Space</h2><div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr13.png" style="zoom:60%"></div>

<ul>
<li>Local / Modeling / Object Space<ul>
<li>Each object model has its own local coordinate frame</li>
</ul>
</li>
<li>World Space (类似全局空间)<ul>
<li><font color="blue">Lights and Camera pose</font> are defined in this space</li>
</ul>
</li>
</ul>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr17.png" style="zoom:60%"></div>

<ul>
<li><strong>Camera Space / View Space / Eye Space</strong><ul>
<li>Camera is located at the origin</li>
<li>Looking in negative $z$ direction</li>
<li>$+y$-axis is the “up-vector”</li>
</ul>
</li>
</ul>
<blockquote>
<p>Initially the <strong>world</strong> and <strong>camera</strong> frames are the same.</p>
<p>To specify camera pose, we need to specify the camera coordinate frame with respect to the world coordinate frame.</p>
</blockquote>
<h2 id="View-Transformation"><a href="#View-Transformation" class="headerlink" title="View Transformation"></a>View Transformation</h2><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="built_in">glLookAt</span>( eyex, eyey, eyez,</span><br><span class="line">		  atx , aty , atz ,</span><br><span class="line">		  upx , upy , upz )</span><br></pre></td></tr></table></figure>
<ul>
<li>通过 eye 和 at 求出前向量</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\text{forward}=\frac{\text{at} - \text{eye}}{|\text{at} - \text{eye}|}<br>$</p>

</blockquote>
<ul>
<li>通过 forward 和 up 求出右向量</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\text{side}=\frac{\text{forward} \times \text{up}}{|\text{forward} \times \text{up}|}<br>$</p>

</blockquote>
<ul>
<li>然后就能得到修正后的上向量</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\text{up’}= \text{forward} \times \text{side}<br>$</p>

</blockquote>
<ul>
<li>求出三个向量后就能确定 camera 的位置和 pose 了</li>
</ul>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr18.png" alt="view-trans" style="zoom:60%"></div>

<ul>
<li>Suppose the camera has been moved to the location $[e_x, e_y, e_z]^T$, and its $x_c$, $y_c$, $z_c$ axes are the unit vectors $\textbf{u}$, $\textbf{v}$, $\textbf{n}$, respectively, then</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\textbf{M}_{\text{view}}=<br>\left[ \begin{array}{c}<br>u_x &amp; u_y &amp; u_z &amp; 0 \\<br>v_x &amp; v_y &amp; v_z &amp; 0 \\<br>n_x &amp; n_y &amp; n_z &amp; 0 \\<br>0 &amp; 0 &amp; 0 &amp; 1<br>\end{array}\right]<br>\cdot<br>\left[ \begin{array}{c}<br>1 &amp; 0 &amp; 0 &amp; -e_x \\<br>0 &amp; 1 &amp; 0 &amp; -e_y \\<br>0 &amp; 0 &amp; 1 &amp; -e_z \\<br>0 &amp; 0 &amp; 0 &amp; 1<br>\end{array}\right]<br>$</p>

</blockquote>
<p>▪ Note that $[e_x, e_y, e_z]^T$ and $\textbf{u}$, $\textbf{v}$, $\textbf{n}$ are all specified with respect to the world frame</p>
<h2 id="Projection-——-Defining-the-View-Volume"><a href="#Projection-——-Defining-the-View-Volume" class="headerlink" title="Projection —— Defining the View Volume"></a>Projection —— Defining the View Volume</h2><ul>
<li>For orthographic projection, use <code>glOrtho()</code></li>
<li>For perspective projection, use <code>glFrustum()</code></li>
</ul>
<h3 id="OpenGL-Orthographic-Projection"><a href="#OpenGL-Orthographic-Projection" class="headerlink" title="OpenGL Orthographic Projection"></a>OpenGL Orthographic Projection</h3><ul>
<li>The glOrtho() function then generates a matrix that linearly maps the view volume to the canonical view volume, where<ul>
<li>(left, bottom, –near) is mapped to (–1, –1, –1)</li>
<li>(right, top, – far) is mapped to (1, 1, 1)</li>
</ul>
</li>
</ul>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr14.png" alt="ortho-projection" style="zoom:60%"></div>

<blockquote>
<p>正投影，能较真实地反映物体大小，物体显示的大小不会因视角变化改变。常用于CAD设计、地图绘制、2D游戏等不需要表现深度感的场景。</p>
</blockquote>
<h3 id="OpenGL-Perspective-Projection"><a href="#OpenGL-Perspective-Projection" class="headerlink" title="OpenGL Perspective Projection"></a>OpenGL Perspective Projection</h3><ul>
<li><code>glFrustum( left, right, bottom, top, near, far )</code><ul>
<li>The <code>glFrustum()</code> function allows (off-center) non-symmetric view volume</li>
</ul>
</li>
<li>Often, we want a <strong>symmetric view volume</strong>. We can use<ul>
<li><code>gluPerspective( fovy, aspect, near, far );</code></li>
</ul>
</li>
</ul>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr15.png" alt="persp-projection" style="zoom:60%"></div>

<blockquote>
<p>透视投影，有深度感，近大远小。常用于3D游戏、虚拟现实、建筑可视化等需要真实感的场景。</p>
</blockquote>
<h4 id="Principle-of-Perspective-Projection"><a href="#Principle-of-Perspective-Projection" class="headerlink" title="Principle of Perspective Projection"></a>Principle of Perspective Projection</h4><div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr19.png" alt="persp-projection-d" style="zoom:60%"></div>

<ul>
<li>Center of projection at the origin</li>
<li>Projection plane is $z = d$, $d &lt; 0$</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>x_p=\frac{x}{z/d}\ \ \ \ y_p=\frac{y}{z/d}\ \ \ \ z_p=d<br>$</p>

</blockquote>
<ul>
<li>Consider $p=Mq$ where</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>p=<br>\left[ \begin{array}{c}<br>x \\ y \\ z \\ z/d<br>\end{array}\right] \ \ \ \ M=<br>\left[ \begin{array}{c}<br>1 &amp; 0 &amp; 0 &amp; 0 \\<br>0 &amp; 1 &amp; 0 &amp; 0 \\<br>0 &amp; 0 &amp; 1 &amp; 0 \\<br>0 &amp; 0 &amp; 1/d &amp; 0<br>\end{array}\right] \ \ \ \ q=<br>\left[ \begin{array}{c}<br>x \\ y \\ z \\ 1<br>\end{array}\right]<br>$</p>

</blockquote>
<ul>
<li>If we scale $p$ , then we get the projection point on plane $z=d$ .</li>
</ul>
<h1 id="VI-Rasterization"><a href="#VI-Rasterization" class="headerlink" title="VI. Rasterization"></a>VI. Rasterization</h1><h2 id="Recall-for-OpenGL-Rendering-Pipeline"><a href="#Recall-for-OpenGL-Rendering-Pipeline" class="headerlink" title="Recall for OpenGL Rendering Pipeline"></a>Recall for OpenGL Rendering Pipeline</h2><div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr16.png" alt="Rendering Pipeline" style="zoom:60%"></div>

<h3 id="Primitive-Assembly-etc"><a href="#Primitive-Assembly-etc" class="headerlink" title="Primitive Assembly, etc."></a>Primitive Assembly, etc.</h3><ul>
<li>Primitive assembly<ul>
<li>Vertex data is collected into complete primitives</li>
<li>Necessary for clipping and back-face culling</li>
</ul>
</li>
<li>Clipping</li>
<li>Perspective division (Object Oriented)<ul>
<li>To normalized device coordinate (NDC) space</li>
</ul>
</li>
<li>Viewport transformation (Viewer Oriented)<ul>
<li>To window space</li>
<li>Include depth range scaling</li>
</ul>
</li>
<li>Back-face culling</li>
</ul>
<h3 id="Rasterization-amp-Fragment-Processing"><a href="#Rasterization-amp-Fragment-Processing" class="headerlink" title="Rasterization &amp; Fragment Processing"></a>Rasterization &amp; Fragment Processing</h3><ul>
<li>Attribute values at fragments are computed by interpolating attribute values assigned to vertices<ul>
<li>Interpolation is performed in window space (2D)</li>
</ul>
</li>
</ul>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr20.png" alt="interpolation" style="zoom:55%"></div>

<ul>
<li>Each generated fragment is processed to determine the color of the corresponding pixel in the frame buffer</li>
<li>Fragment color can be modified by <strong>texture mapping</strong> (纹理映射)<ul>
<li>Texture access (using interpolated texture coordinates)<ul>
<li>Access texture map using texture coordinates</li>
</ul>
</li>
<li>Texture application<ul>
<li>Texture color can be combined with the fragment color of the primitive</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>Per-Fragment Operations</strong></p>
<ul>
<li><font color="blue">Fragment is discarded if it is blocked (occluded) by the corresponding pixel already in the frame buffer</font><ul>
<li>Z-buffer hidden-surface removal</li>
</ul>
</li>
<li><font color="blue">Fragment may be blended with the corresponding pixel already in the frame buffer</font> <ul>
<li>Blending</li>
</ul>
</li>
</ul>
<blockquote>
<p>Let’s talk about something important !!!</p>
</blockquote>
<h2 id="Clipping"><a href="#Clipping" class="headerlink" title="Clipping"></a>Clipping</h2><blockquote>
<p>To clip out primitives that are outside the view volume</p>
</blockquote>
<h3 id="Clipping-2D-Line-Segments"><a href="#Clipping-2D-Line-Segments" class="headerlink" title="Clipping 2D Line Segments"></a>Clipping 2D Line Segments</h3><h4 id="Cohen-Sutherland-Algorithm"><a href="#Cohen-Sutherland-Algorithm" class="headerlink" title="Cohen-Sutherland Algorithm"></a>Cohen-Sutherland Algorithm</h4><ul>
<li>Using <a name="edge-table">edge table</a></li>
</ul>
<table>
<tr>
<td><img src="/2024/06/27/Real-Time-Rendering/rtr21.png" style="zoom:50%"></td>
<td><p><li>Case 1: Both endpoints inside all four lines
<ul><li>Draw (accept) line segment as is</li></ul></li>
<li>Case 2: Both endpoints outside same line
<ul><li>Discard (reject) the line segment</li></ul></li></p></td>
</tr>
<tr>
<td><img src="/2024/06/27/Real-Time-Rendering/rtr22.png" style="zoom:50%"></td>
<td><p><li>Case 3: One endpoint inside all lines and one outside
<ul><li>Must do at least one intersection</li></ul></li>
<li>Case 4: Both outside
<ul><li>May have part inside</li>
<li>Must do at least one intersection</li></ul></li></p></td>
</tr>
</table>

<p><strong>Using Outcode</strong></p>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr23.png" alt="outcode" style="zoom:60%"></div>

<p>E.g. Suppose a line $AB$ with endpoints $A$ and $B$ .</p>
<ul>
<li>If $\text{outcode}(A)=\text{outcode}(B)=0$ , accept the segment</li>
<li>If $\text{outcode}(A)=0$ , $\text{outcode}(B)\not= 0$ , <ul>
<li>Compute intersection</li>
<li>Location of $1$ in outcode($B$) determines which edge to intersect with</li>
<li>If outcode($B$) has two $1$’s, then need to do two intersections</li>
</ul>
</li>
<li>If $\text{outcode}(A)$ &amp; $\text{outcode}(B) \not= 0$ , reject the segment</li>
<li><p>If $\text{outcode}(A)$ &amp; $\text{outcode}(B) = 0$ , but neither of them are $0$ , </p>
<ul>
<li>Shorten line segment by intersecting with one of sides of window</li>
<li>Compute outcode of intersection (new endpoint of shortened line segment)</li>
<li>Re-execute algorithm</li>
</ul>
</li>
<li><p><strong>When it goes to 3D</strong>, we can use 6-bit outcode to represent 6 faces of the window.</p>
</li>
</ul>
<h3 id="Polygon-Clipping"><a href="#Polygon-Clipping" class="headerlink" title="Polygon Clipping"></a>Polygon Clipping</h3><blockquote>
<p>Problems of polygon clipping: may generate multiple polygons.</p>
<p>Solution: For concave polygons, use tessellation function(镶嵌函数) in <code>GLU</code> to change it to multiple convex polygons.</p>
</blockquote>
<ul>
<li>simple way: set axis-aligned bounding box(AABB) for simple calculation.</li>
</ul>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr24.png" alt="outcode" style="zoom:50%"></div>



<h2 id="Rasterization"><a href="#Rasterization" class="headerlink" title="Rasterization"></a>Rasterization</h2><h3 id="Scan-Conversion-of-Line-Segments"><a href="#Scan-Conversion-of-Line-Segments" class="headerlink" title="Scan Conversion of Line Segments"></a>Scan Conversion of Line Segments</h3><p><a name="BA"><b>Bresenham’s Algorithm</b></a></p>
<ul>
<li><font color="red">Key thought</font>: A binary decision problem on how the next pixel lies based on the previous pixel.</li>
</ul>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr25.png" alt="BA" style="zoom:50%"></div>

<ul>
<li>On the next point: $y=m(x_k + 1) + b$</li>
<li>$d_\text{lower} = y-y_k$</li>
<li>$d_\text{upper}=(y_k+1)-y$</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\begin{align}<br>p_k&amp;=\Delta x(d_\text{lower} - d_\text{upper}) \\<br>&amp;=2x_k \Delta y - 2y_k \Delta x + c<br>\end{align}<br>$</p>

</blockquote>
<p>where $c=2\Delta y + \Delta x (2b - 1)$ is an <font color="red">integer constant</font> .</p>
<ul>
<li>If $p_k &gt; 0$ , plot upper pixel</li>
<li><p>If $p_k &lt; 0$ , plot lower pixel</p>
</li>
<li><p>We can incrementally compute $p_{k+1}$ from $p_k$</p>
<ul>
<li>If $p_k &gt; 0$ ,  $p_{k + 1} = p_k + 2\Delta y – 2\Delta x$</li>
<li>If $p_k &lt; 0$, $p_{k + 1} = p_k + 2\Delta y$</li>
<li>where $p_0=2\Delta y - \Delta x$</li>
</ul>
</li>
</ul>
<h3 id="Scan-Conversion-of-Polygons"><a href="#Scan-Conversion-of-Polygons" class="headerlink" title="Scan Conversion of Polygons"></a>Scan Conversion of Polygons</h3><p><strong>Scan-Line Fill — Interpolation</strong></p>
<ul>
<li>$C_1$ $C_2$ $C_3$ specified by glColor or by vertex shading (lighting computation)</li>
<li>$C_4$ determined by interpolating between $C_1$ and $C_3$</li>
<li>$C_5$ determined by interpolating between $C_2$ and $C_3$</li>
<li>Interpolate between $C_4$ and $C_5$ along span</li>
</ul>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr26.png" alt="scPolygon" style="zoom:50%"></div>

<blockquote>
<p>So what we need to do in this algorithm is calculating : </p>
<ol>
<li>points intersact with scan-line (Recall <a href="#BA">Bresenham’s Algorithm</a>)</li>
<li>which polygons lie on this pixel (多边形扫描转换，<a href="#edge-table">边表</a>，活动边表)</li>
</ol>
</blockquote>
<h3 id="Hidden-Surface-Removal"><a href="#Hidden-Surface-Removal" class="headerlink" title="Hidden-Surface Removal"></a>Hidden-Surface Removal</h3><ul>
<li>Painter’s Algorithm<ul>
<li>Fill the objects at the back first, then cover with the front objects</li>
</ul>
</li>
<li>Depth Sorting<ul>
<li>Need $O(n^2)$ at worst</li>
</ul>
</li>
</ul>
<p><strong>Back-Face Culling</strong></p>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr27.png" alt="BFC" style="zoom:90%"></div>

<ul>
<li>Polygons is <font color="red">back-facing</font> if $\textbf{N}_p \cdot \textbf{N} &lt;0$</li>
<li><font color="blue">In OpenGL, we can simply enable culling</font><ul>
<li>By default, polygon vertices must be provided in <font color="blue">counter clockwise</font> order</li>
<li>But may not work correctly for <font color="blue">non-convex</font> polygon</li>
</ul>
</li>
</ul>
<p><strong>Z-Buffer</strong></p>
<ul>
<li>Key thought: Exchange time with space</li>
<li>Use a <font color="red">z-buffer</font> (depth buffer) to store the depth of the closest object at each pixel found so far</li>
</ul>
<h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr16.png" alt="Rendering Pipeline" style="zoom:60%"></div>

<ul>
<li>Viewing this pipeline again:</li>
<li>Using back-face culling to remove hidden-surface</li>
<li>Using scan conversion to do rasterization</li>
<li>Using z-buffer to test the per-fragment</li>
<li>At the end, output frame buffer.</li>
</ul>
<hr>
<h1 id="VII-Illumination"><a href="#VII-Illumination" class="headerlink" title="VII. Illumination"></a>VII. Illumination</h1><p><strong>Local Reflection vs Global Illumination</strong></p>
<ul>
<li>Local reflection<ul>
<li>Considers relationship between a light source, a single surface point, and a view point</li>
<li>No interaction with other objects</li>
</ul>
</li>
<li>Global illumination<ul>
<li>Considers all light sources and surfaces</li>
<li>Inter-reflections and shadows</li>
</ul>
</li>
</ul>
<h2 id="Phong-Illumination-Equation"><a href="#Phong-Illumination-Equation" class="headerlink" title="Phong Illumination Equation"></a>Phong Illumination Equation</h2><blockquote class="blockquote-center">
<p>$<br>I_{\text{Phong}}=k_a i_a + \sum_{m \in \text{lights}} \left(k_d (\textbf{L}_m \cdot \textbf{N}) i_{m,d} + k_s (\textbf{R}_m \cdot \textbf{V})^{\alpha} i_{m,s}  \right)<br>$</p>

</blockquote>
<p>where :</p>
<ul>
<li>$k_a$ 表示环境光反射系数，常数</li>
<li>$k_d$ 表示漫反射系数，常数</li>
<li>$k_s$ 表示镜面高光反射系数，常数</li>
<li>$\alpha$ 表示物体材质光滑程度，由材质决定（材质越光滑系数越大），常量</li>
<li>$\textbf{L}_m$ 表示相对于 $L$ 的反射光线方向</li>
<li>$\textbf{N}$ 表示该点的法线 [Normal Vector]</li>
<li>$\textbf{R}_m$ 表示反射光的方向</li>
<li>$\textbf{V}$ 表示摄像机的方向</li>
<li>$i_{m,d}$ 表示光源$m$的漫反射反射光照，RGB</li>
<li>$i_{m,s}$ 表示光源$m$的高光反射光照，RGB</li>
<li>$i_a$ 表示环境光的光照，RGB</li>
<li>$I_p$ 表示 $p$ 的总光照，RGB</li>
<li>$m$ 表示其中一个光源</li>
</ul>
<blockquote>
<p>Sum 中的两项分别对应下图的两步（Diffuse【漫反射】是 $L \cdot N$ ，Specular 【镜面】是 $R \cdot V$），ambient 对应 $k_a \times i_a$ ，表示局部的环境色渲染。</p>
</blockquote>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr28.png" alt="PIE" style="zoom:70%"></div>


<ul>
<li>Diffuse Reflection: <strong>Lambert’s Cosine Law</strong><ul>
<li>diffuse reflection $\propto \cos{\theta} = \textbf{N} \cdot \textbf{L}$</li>
</ul>
</li>
</ul>
<h2 id="Illumination-in-OpenGL"><a href="#Illumination-in-OpenGL" class="headerlink" title="Illumination in OpenGL"></a>Illumination in OpenGL</h2><ul>
<li>Lighting Computation at <strong>Vertex Processing</strong> stage.</li>
<li>Specifying Vertex Normal Vectors<ul>
<li>Set by <code>glNormal*()</code><ul>
<li><code>glNormal3f(x, y, z)</code></li>
<li><code>glNormal3fv(p)</code></li>
</ul>
</li>
<li><code>glEnable(GL_NORMALIZE)</code> allows for auto-normalization at a performance penalty</li>
</ul>
</li>
<li>Enabling Lighting Computation<ul>
<li>Shading calculations are enabled by<ul>
<li><code>glEnable(GL_LIGHTING)</code></li>
<li>Once lighting is enabled, <code>glColor()</code> is <font color="red">ignored</font></li>
</ul>
</li>
<li>Must enable each light source individually<ul>
<li><code>glEnable(GL_LIGHTi)</code> $i = 0, 1, 2, \cdots $</li>
</ul>
</li>
<li>Can choose light model parameters<ul>
<li><code>glLightModeli(parameter, GL_TRUE)</code><ul>
<li><code>GL_LIGHT_MODEL_LOCAL_VIEWER</code> do not use simplifying distant viewer assumption in calculation</li>
<li><code>GL_LIGHT_MODEL_TWO_SIDED</code> shades both sides of polygons independently</li>
</ul>
</li>
</ul>
</li>
<li><font color="red">An example code of using light</font>:</li>
</ul>
</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">GLfloat diffuse0[] = &#123;<span class="number">1.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">1.0</span>&#125;;</span><br><span class="line">GLfloat ambient0[] = &#123;<span class="number">1.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">1.0</span>&#125;;</span><br><span class="line">GLfloat specular0[] = &#123;<span class="number">1.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">1.0</span>&#125;;</span><br><span class="line">GLfloat light0_pos[] = &#123;<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3</span>,<span class="number">0</span>, <span class="number">1.0</span>&#125;;</span><br><span class="line"></span><br><span class="line"><span class="built_in">glEnable</span>(GL_LIGHTING);</span><br><span class="line"><span class="built_in">glEnable</span>(GL_LIGHT0);</span><br><span class="line"><span class="built_in">glLightfv</span>(GL_LIGHT0, GL_POSITION, light0_pos);</span><br><span class="line"><span class="built_in">glLightfv</span>(GL_LIGHT0, GL_AMBIENT, ambient0);		<span class="comment">// def ambient</span></span><br><span class="line"><span class="built_in">glLightfv</span>(GL_LIGHT0, GL_DIFFUSE, diffuse0);		<span class="comment">// def diffuse</span></span><br><span class="line"><span class="built_in">glLightfv</span>(GL_LIGHT0, GL_SPECULAR, specular0);	<span class="comment">// def spec</span></span><br></pre></td></tr></table></figure>
<ul>
<li>Or using <strong>Global Ambient Light</strong> : <code>glLightModelfv(GL_LIGHT_MODEL_AMBIENT, global_ambient)</code></li>
</ul>
<blockquote>
<p>设置材质和设置光源的参数很像，用 <code>glMaterialfv()</code> 函数，第一个参数改成 <code>GL_FRONT, GL_BACK, GL_FRONT_AND_BACK</code> 表示内外渲染</p>
</blockquote>
<h2 id="Shading"><a href="#Shading" class="headerlink" title="Shading"></a>Shading</h2><h3 id="Gouraud-Shading-vs-Phong-Shading"><a href="#Gouraud-Shading-vs-Phong-Shading" class="headerlink" title="Gouraud Shading vs. Phong Shading"></a>Gouraud Shading vs. Phong Shading</h3><ul>
<li>Flat shading is “bad”</li>
<li>Gouraud Shading<ol>
<li>For each vertex, compute the <font color="red">average normal vector</font> of the polygons that share the vertex</li>
<li>Apply <font color="red">PIE</font> at the vertex using its <font color="blue">average normal vector</font></li>
<li>Smoothly interpolate the computed colors at the vertices of the polygon to the interior of the polygon</li>
</ol>
</li>
<li>Using <font color="red">Gouraud Shading</font> in OpenGL: <code>glShadeModel(GL_SMOOTH)</code> (No Phong Shading use directly)</li>
</ul>
<ul>
<li>Phong Shading<ol>
<li>In Phong Shading, we do not compute the colors of the vertices for interpolation. Instead, for each fragment in the polygon, we interpolate the normal vectors from the vertices</li>
<li>Then, at each fragment, we apply PIE on the interpolated normal vector to compute a color for the fragment</li>
</ol>
</li>
</ul>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr30.png" alt="Gouraud-and-Phong" style="zoom:70%"></div>

<ul>
<li>Differences<ul>
<li>Highlights are produced more faithfully with Phong shading</li>
<li>Gouraud shading produces only “linear interpolation” of colors</li>
<li>Gouraud shading may even miss the highlight</li>
</ul>
</li>
<li>OpenGL does not support Phong Shading<ul>
<li>But can be done by reprogramming the rendering pipeline <font color="red">using shaders</font></li>
</ul>
</li>
</ul>
<h1 id="VIII-Modern-OpenGL-Intro"><a href="#VIII-Modern-OpenGL-Intro" class="headerlink" title="VIII. Modern OpenGL (Intro)"></a>VIII. Modern OpenGL (Intro)</h1><div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr29.png" alt="modern-opengl" style="zoom:60%"></div>

<h2 id="Example-OpenGL-Programs-The-Modern-Way"><a href="#Example-OpenGL-Programs-The-Modern-Way" class="headerlink" title="Example OpenGL Programs: The Modern Way"></a>Example OpenGL Programs: The Modern Way</h2><h3 id="New-Lib"><a href="#New-Lib" class="headerlink" title="New Lib"></a>New Lib</h3><ul>
<li><code>GLEW</code><ul>
<li><font coolr="blue">The OpenGL Extension Wrangler Library</font> </li>
<li>a cross-platform open-source C/C++ extension loading library</li>
<li>provides efficient run-time mechanisms for determining which OpenGL extensions are supported on the target platform</li>
<li><font color="red">Automatically initializes</font> the entry points of new OpenGL functions</li>
</ul>
</li>
<li><code>GLM</code><ul>
<li><font color="blue">OpenGL Mathematics</font> 


</li>
</ul>
</li>
</ul>
<h3 id="Examples-1"><a href="#Examples-1" class="headerlink" title="Examples"></a>Examples</h3><blockquote>
<p>注意：由于课程上给出的示例代码过长，这里只总结一些重要部分，不展示示例代码。OpenGL 的相关教程网上不会缺，可以自行获取。</p>
</blockquote>
<h1 id="IX-Shading-Language"><a href="#IX-Shading-Language" class="headerlink" title="IX. Shading Language"></a>IX. Shading Language</h1><blockquote>
<p>This section is all about coding.</p>
<p>Some basis(Data Type, Data Structure, etc.) is ignored.</p>
</blockquote>
<p><strong>Storage Quantifiers</strong></p>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr31.png" style="zoom:60%"></div>

<p><strong>Function Parameter Qualifiers</strong></p>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr32.png" style="zoom:60%"></div>

<ul>
<li>GLSL has no concepts of pointer or reference</li>
<li>Functions are called by <font color="red">value-return</font></li>
</ul>
<p><strong>Vertex and Fragment Built-in Variables</strong></p>
<table>
<tr>
<td><img src="/2024/06/27/Real-Time-Rendering/rtr33.png"></td>
<td><img src="/2024/06/27/Real-Time-Rendering/rtr34.png"></td>
</tr>
</table>



<ul>
<li><code>gl_FragCoord</code> contains window relative coordinates $(x, y, z, 1/w)$<ul>
<li>$z$ is the depth value (after depth range scaling)</li>
<li>$w$ is $–z_e$ where $z_e$ is the $z$-coordinate of the fragment in the eye space</li>
</ul>
</li>
<li>If <code>gl_FragDepth</code> is not written to, <code>gl_FragCoord.z</code> is used as fragment’s depth</li>
</ul>
<ul>
<li>A fragment’s 2D position is the window-relative coordinates of the fragment’s center<ul>
<li>By default, for the <font color="red">bottom-left-most</font> pixel in the window<ul>
<li><code>gl_FragCoord.x == 0.5</code></li>
<li><code>gl_FragCoord.y == 0.5</code></li>
</ul>
</li>
</ul>
</li>
</ul>
<blockquote>
<p>Modern OpenGL uses <code>.vert</code> and <code>.frag</code> to describe the vertex and fragment rendering.</p>
</blockquote>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// A simple pseudo-code</span></span><br><span class="line">GLuint ShaderProjObj;</span><br><span class="line"><span class="type">const</span> <span class="type">char</span> vert[] = <span class="string">&quot;exmaple.vert&quot;</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">char</span> frag[] = <span class="string">&quot;example.frag&quot;</span>;</span><br><span class="line"><span class="type">const</span> GLfloat lightAmbient[] = &#123; <span class="number">0.0f</span>, <span class="number">0.0f</span>, <span class="number">0.0f</span>, <span class="number">1.0f</span> &#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">static</span> <span class="type">void</span> <span class="title">MyInit</span><span class="params">(<span class="type">void</span>)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// Create Gouraud Shading shader program object.</span></span><br><span class="line">  ShaderProjObj = <span class="built_in">makeShaderProgramFromFiles</span>(vert, frag, <span class="literal">NULL</span>);</span><br><span class="line">  <span class="comment">// Install Gauraud Shading shader program to the rendering pipeline first.</span></span><br><span class="line">  <span class="built_in">glUseProgram</span>(ShaderProjObj);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">static</span> <span class="type">void</span> <span class="title">MyDrawFunc</span><span class="params">(<span class="type">void</span>)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// Query locations of uniform variables.(exmaple)</span></span><br><span class="line">  GLint la = <span class="built_in">glGetUniformLocation</span>(ShaderProjObj, <span class="string">&quot;LightAmbient&quot;</span>);</span><br><span class="line">  <span class="comment">// Set Uniform variable</span></span><br><span class="line">  <span class="built_in">glUniform4fv</span>(la, <span class="number">1</span>, lightAmbient);</span><br><span class="line">  </span><br><span class="line">  objModel3D-&gt;<span class="built_in">render</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<hr>
<h1 id="X-Texture-Mapping-amp-Applications"><a href="#X-Texture-Mapping-amp-Applications" class="headerlink" title="X. Texture Mapping &amp; Applications"></a>X. Texture Mapping &amp; Applications</h1><h2 id="Surface-Parameterization"><a href="#Surface-Parameterization" class="headerlink" title="Surface Parameterization"></a>Surface Parameterization</h2><ul>
<li>Defines a mapping between the 3D surfaces and the 2D texture map<ul>
<li>Defines the mapping $(x_w, y_w, z_w) \leftrightarrow (s,t)$<ul>
<li>$(x_w, y_w, z_w)$ is the 3D coordinates of surface point</li>
<li>$(s, t )$ is the 2D texture coordinates (limited to $[0,1]^2$)</li>
</ul>
</li>
<li>Defines which <strong>“texel”</strong> maps to each surface point</li>
</ul>
</li>
<li>Difficulty<ul>
<li>Non-trivial surface topology causes severe distortion of textures (有些不正常的表面拓扑后会产生纹理混乱)</li>
</ul>
</li>
</ul>
<h1 id="XI-FBO-amp-Shadow-Mapping"><a href="#XI-FBO-amp-Shadow-Mapping" class="headerlink" title="XI. FBO &amp; Shadow Mapping"></a>XI. FBO &amp; Shadow Mapping</h1><h2 id="Framebuffer-Objects-FBO"><a href="#Framebuffer-Objects-FBO" class="headerlink" title="Framebuffer Objects(FBO)"></a>Framebuffer Objects(FBO)</h2><h3 id="Multi-Pass-Rendering"><a href="#Multi-Pass-Rendering" class="headerlink" title="Multi-Pass Rendering"></a>Multi-Pass Rendering</h3><p><strong>Def.</strong> Render 3D scene multiple times (passes), and “combine” the multiple rendered images to synthesize final frame</p>
<ul>
<li>Allows creation of non-displayable framebuffers</li>
<li>OpenGL can redirect rendering output to FBO</li>
<li>Each FBO contains a collection of rendering destinations</li>
</ul>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr37.png" style="zoom:50%"></div>



<ul>
<li>Two types of framebuffer-attachable images<ul>
<li>Texture images<ul>
<li>Render to texture</li>
</ul>
</li>
<li>Renderbuffer images<ul>
<li>Offscreen rendering</li>
</ul>
</li>
</ul>
</li>
<li>Many color attachment points allow multiple render targets (MRT)<ul>
<li>Can query the maximum number of color attachment points with <code>GL_MAX_COLOR_ATTACHMENTS</code> (usually 8)</li>
</ul>
</li>
</ul>
<h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// cpp file</span></span><br><span class="line"><span class="comment">// set up FBO</span></span><br><span class="line">GLuint fboHandle; <span class="comment">// The handle to the FBO</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Generate and bind the framebuffer</span></span><br><span class="line"><span class="built_in">glGenFramebuffers</span>(<span class="number">1</span>, &amp;fboHandle);</span><br><span class="line"><span class="built_in">glBindFramebuffer</span>(GL_FRAMEBUFFER, fboHandle);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Create first texture object</span></span><br><span class="line">GLuint renderTexA;</span><br><span class="line"><span class="built_in">glGenTextures</span>(<span class="number">1</span>, &amp;renderTexA);</span><br><span class="line"><span class="built_in">glActiveTexture</span>(GL_TEXTURE0); <span class="comment">// Use texture unit 0</span></span><br><span class="line"><span class="built_in">glBindTexture</span>(GL_TEXTURE_2D, renderTexA);</span><br><span class="line"><span class="built_in">glTexImage2D</span>(GL_TEXTURE_2D, <span class="number">0</span>, GL_RGBA8, fboWidth, fboHeight, <span class="number">0</span>,</span><br><span class="line">  GL_RGBA, GL_UNSIGNED_BYTE, <span class="literal">NULL</span>);</span><br><span class="line"><span class="comment">// ...</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Attach first texture to FBO</span></span><br><span class="line"><span class="built_in">glFramebufferTexture2D</span>(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT2,</span><br><span class="line">  GL_TEXTURE_2D, renderTexA, <span class="number">0</span>);</span><br><span class="line">  </span><br><span class="line"><span class="comment">// ... second texture object as above</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Create the depth buffer</span></span><br><span class="line">GLuint depthBuf;</span><br><span class="line"><span class="built_in">glGenRenderbuffers</span>(<span class="number">1</span>, &amp;depthBuf);</span><br><span class="line"><span class="built_in">glBindRenderbuffer</span>(GL_RENDERBUFFER, depthBuf);</span><br><span class="line"><span class="built_in">glRenderbufferStorage</span>(GL_RENDERBUFFER, GL_DEPTH_COMPONENT, </span><br><span class="line">  fboWidth, fboHeight);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Bind the depth buffer to the FBO</span></span><br><span class="line"><span class="built_in">glFramebufferRenderbuffer</span>(GL_FRAMEBUFFER, GL_DEPTH_ATTACHMENT,</span><br><span class="line">  GL_RENDERBUFFER, depthBuf);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Set the target for the fragment shader outputs</span></span><br><span class="line">GLenum drawBufs[] = &#123; GL_COLOR_ATTACHMENT2, GL_COLOR_ATTACHMENT3 &#125;;</span><br><span class="line"><span class="built_in">glDrawBuffers</span>(<span class="number">2</span>, drawBufs);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Unbind the framebuffer, and revert to default</span></span><br><span class="line"><span class="built_in">glBindFramebuffer</span>(GL_FRAMEBUFFER, <span class="number">0</span>);</span><br></pre></td></tr></table></figure>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// often in other functions</span></span><br><span class="line"><span class="comment">// DRAW TO TEXTURES</span></span><br><span class="line"><span class="comment">// Bind to texture&#x27;s FBO</span></span><br><span class="line"><span class="built_in">glBindFramebuffer</span>(GL_FRAMEBUFFER, fboHandle);</span><br><span class="line"></span><br><span class="line"><span class="built_in">glViewport</span>(<span class="number">0</span>, <span class="number">0</span>, fboWidth, fboHeight); <span class="comment">// Viewport for the texture</span></span><br><span class="line"><span class="built_in">glClear</span>(GL_DEPTH_BUFFER_BIT);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Use glClearBufferfv() to individually clear color buffers</span></span><br><span class="line"><span class="type">const</span> GLfloat lightGreen[<span class="number">4</span>] = &#123; <span class="number">0.5f</span>, <span class="number">1.0f</span>, <span class="number">0.5f</span>, <span class="number">1.0f</span> &#125;;</span><br><span class="line"><span class="type">const</span> GLfloat lightRed[<span class="number">4</span>] = &#123; <span class="number">1.0f</span>, <span class="number">0.5f</span>, <span class="number">0.5f</span>, <span class="number">1.0f</span> &#125;;</span><br><span class="line"><span class="built_in">glClearBufferfv</span>(GL_COLOR, <span class="number">0</span>, lightGreen);</span><br><span class="line"><span class="built_in">glClearBufferfv</span>(GL_COLOR, <span class="number">1</span>, lightRed);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Setup the projection matrix and view matrix</span></span><br><span class="line"><span class="comment">// for the scene to be rendered to the texture here.</span></span><br><span class="line"><span class="comment">// ...</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">renderTextureScene</span>();</span><br></pre></td></tr></table></figure>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// DRAW FINAL FRAME</span></span><br><span class="line"><span class="comment">// Unbind texture&#x27;s FBO (back to default FB)</span></span><br><span class="line"><span class="built_in">glBindFramebuffer</span>(GL_FRAMEBUFFER, <span class="number">0</span>);</span><br><span class="line"><span class="built_in">glViewport</span>(<span class="number">0</span>, <span class="number">0</span>, winWidth, winHeight); <span class="comment">// Viewport for main window</span></span><br><span class="line"><span class="built_in">glClear</span>(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Setup the projection matrix and view matrix.</span></span><br><span class="line"><span class="comment">// ...</span></span><br><span class="line"><span class="built_in">renderScene</span>();</span><br></pre></td></tr></table></figure>
<h2 id="Shadow-Mapping"><a href="#Shadow-Mapping" class="headerlink" title="Shadow Mapping"></a>Shadow Mapping</h2><table>
<tr align="center">
<td><img src="/2024/06/27/Real-Time-Rendering/rtr38.png"></td>
<td><img src="/2024/06/27/Real-Time-Rendering/rtr39.png"></td>
</tr>
</table>



<h3 id="Algorithm-Overview"><a href="#Algorithm-Overview" class="headerlink" title="Algorithm Overview"></a>Algorithm Overview</h3><ol>
<li>Render the scene using the light source as viewpoint</li>
<li>Save the depth buffer <font color="blue">(a.k.a. shadow map)</font></li>
<li>Clear the framebuffer</li>
<li>Render the scene from camera’s viewpoint<ul>
<li>For each fragment, transform it to the “light space” and compare its “light space” $z$ value with the corresponding $z$ value in the shadow map<ul>
<li>If “light space” z value is larger, the fragment is in shadow and it is lit with only ambient light</li>
<li>Otherwise, the fragment is <font color="red">not</font> in shadow and is <font color="red">fully lit</font></li>
</ul>
</li>
</ul>
</li>
</ol>
<h3 id="Shadow-Map-Coordinates"><a href="#Shadow-Map-Coordinates" class="headerlink" title="Shadow Map Coordinates"></a>Shadow Map Coordinates</h3><ul>
<li>Any 3D point in the view frustum(视图) of the light source must be transformed to the shadow map coordinates $[s, t, p]$ where $s$, $t$, $p$ are in the range $[0,1]$</li>
<li>Given a 3D point $p_M$ in modeling coordinates, its shadow map coordinates $p_L$ is</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>p_L=B \cdot P_L \cdot V_L \cdot M \cdot p_M<br>$</p>

</blockquote>
<ul>
<li>$M$ is the modeling matrix</li>
<li>$V_L$ is the light’s view transformation matrix</li>
<li>$P_L$ is the light’s projection matrix</li>
<li>and $B=\left[ \begin{array} \\<br>0.5&amp;0&amp;0&amp;0.5 \\<br>0&amp;0.5&amp;0&amp;0.5 \\<br>0&amp;0&amp;0.5&amp;0.5 \\<br>0&amp;0&amp;0&amp;1 \\<br>\end{array}\right]$</li>
</ul>
<h3 id="Issues"><a href="#Issues" class="headerlink" title="Issues"></a>Issues</h3><ul>
<li>shadow acnes(失真)<ul>
<li>Sol 1: Subtract a tolerance value from <code>ShadowCoord.z</code> in the fragment shader before the depth comparison</li>
<li>Sol 2: “Offset” the scene backwards when generating the shadow map from the light source<ul>
<li>Use OpenGL function <code>glPolygonOffset()</code></li>
</ul>
</li>
</ul>
</li>
<li>Obvious jaggies(锯齿)<ul>
<li>Percentage Closer Filtering (PCF)</li>
</ul>
</li>
</ul>
<figure class="highlight glsl"><table><tr><td class="code"><pre><span class="line"><span class="comment">// before using PCF</span></span><br><span class="line"><span class="type">void</span> shadeWithShadow()</span><br><span class="line">&#123;</span><br><span class="line">  <span class="type">vec3</span> ambient = ...; <span class="comment">// ambient</span></span><br><span class="line">  <span class="type">vec3</span> diffSpec = ...; <span class="comment">// diffuse and specular</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">// Do the shadow-map lookup</span></span><br><span class="line">  <span class="type">float</span> shadow = <span class="built_in">textureProj</span>(ShadowMap, ShadowCoord);</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// If the fragment is in shadow, use ambient light only.</span></span><br><span class="line">  FragColor = <span class="type">vec4</span>(diffSpec * shadow + ambient, <span class="number">1.0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight glsl"><table><tr><td class="code"><pre><span class="line"><span class="comment">// after using PCF</span></span><br><span class="line"><span class="type">void</span> shadeWithShadow()</span><br><span class="line">&#123;</span><br><span class="line">  <span class="type">vec3</span> ambient = ...; <span class="comment">// ambient</span></span><br><span class="line">  <span class="type">vec3</span> diffSpec = ...; <span class="comment">// diffuse and specular</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">// The sum of the comparisons with nearby texels</span></span><br><span class="line">  <span class="type">float</span> sum = <span class="number">0.0</span>;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// Sum contributions from texels around ShadowCoord</span></span><br><span class="line">  sum += <span class="built_in">textureProjOffset</span>(ShadowMap, ShadowCoord, <span class="type">ivec2</span>(<span class="number">-1</span>,<span class="number">-1</span>));</span><br><span class="line">  sum += <span class="built_in">textureProjOffset</span>(ShadowMap, ShadowCoord, <span class="type">ivec2</span>(<span class="number">-1</span>,<span class="number">1</span>));</span><br><span class="line">  sum += <span class="built_in">textureProjOffset</span>(ShadowMap, ShadowCoord, <span class="type">ivec2</span>(<span class="number">1</span>,<span class="number">1</span>));</span><br><span class="line">  sum += <span class="built_in">textureProjOffset</span>(ShadowMap, ShadowCoord, <span class="type">ivec2</span>(<span class="number">1</span>,<span class="number">-1</span>));</span><br><span class="line">  <span class="type">float</span> shadow = sum * <span class="number">0.25</span>;</span><br><span class="line">  </span><br><span class="line">  FragColor = <span class="type">vec4</span>(diffSpec * shadow + ambient, <span class="number">1.0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="XII-Image-Processing"><a href="#XII-Image-Processing" class="headerlink" title="XII. Image Processing"></a>XII. Image Processing</h1><h1 id="XIII-Ray-Tracing"><a href="#XIII-Ray-Tracing" class="headerlink" title="XIII. Ray Tracing"></a>XIII. Ray Tracing</h1><h2 id="Basic-Ray-Casting"><a href="#Basic-Ray-Casting" class="headerlink" title="Basic Ray Casting"></a>Basic Ray <font color="red">Casting</font></h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">For every pixel</span><br><span class="line">  Construct a ray from the eye</span><br><span class="line">  For every object in the scene</span><br><span class="line">    Find intersection with the ray </span><br><span class="line">    Keep if closest</span><br><span class="line">  Shade depending on light and normal vector(using Phong reflection)</span><br></pre></td></tr></table></figure>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr35.png" style="zoom:50%"></div>



<p><strong>Rasterization vs. Ray Casting</strong></p>
<ul>
<li>Rasterization<ul>
<li>Given a primitive in 3D space, determine which pixels are covered by the primitive</li>
</ul>
</li>
<li>Ray Casting<ul>
<li>At each pixel, determine which primitive covers it</li>
</ul>
</li>
</ul>
<h2 id="Ray-Tracing"><a href="#Ray-Tracing" class="headerlink" title="Ray Tracing"></a>Ray <font color="red">Tracing</font></h2><ul>
<li>From the closest intersection point, secondary rays are shot out<ul>
<li>Reflection ray</li>
<li>Refraction ray</li>
<li>Shadow rays</li>
</ul>
</li>
</ul>
<h3 id="Whitted-style-Recursive-Ray-Tracing"><a href="#Whitted-style-Recursive-Ray-Tracing" class="headerlink" title="Whitted-style(Recursive) Ray Tracing"></a>Whitted-style(Recursive) Ray Tracing</h3><blockquote class="blockquote-center">
<p>$<br>\begin{align}<br>&amp;\textbf{I}= \textbf{I}_{\text{local}}+k_{\text{rg}} \textbf{I}_{\text{reflected}}+k_{\text{tg}} \textbf{I}_{\text{transmitted}} \\<br>\text{where }&amp;\textbf{I}_{\text{local}}= \textbf{I}_{a}k_a+ \color{red}k_{\text{shadow}}\color{black}\textbf{I}_{\text{source}}\left[ k_d(\textbf{N} \cdot \textbf{L}) + k_r (\textbf{R} \cdot \textbf{V})^n + k_t (\textbf{T} \cdot \textbf{V})^m \right]<br>\end{align}<br>$</p>

</blockquote>
<div align="center"><img src="/2024/06/27/Real-Time-Rendering/rtr36.png" style="zoom:50%"></div>

<ul>
<li>So if the material is opaque, the $k_t (\textbf{T} \cdot \textbf{V})^m$ can be omitted.</li>
<li>Also consider <font color="red">Shadow Rays</font>.</li>
</ul>
<p><strong>Scene Description</strong></p>
<ul>
<li>Camera view &amp; image resolution<ul>
<li>Camera position and orientation in world coordinate frame<ul>
<li>Similar to <code>gluLookAt()</code></li>
</ul>
</li>
<li>Field of view<ul>
<li>Similar to <code>gluPerspective()</code>, but <font color="red">no need</font> near &amp; far plane</li>
</ul>
</li>
<li>Image resolution<ul>
<li>Number of pixels in each dimension</li>
</ul>
</li>
</ul>
</li>
<li>Each point light source<ul>
<li>Position</li>
<li>Brightness and color ($\text{I}_{source}$)</li>
<li>A global ambient ($\text{I}_{a}$)</li>
<li>Spotlight is also possible</li>
</ul>
</li>
<li>Each object surface material<ul>
<li>$k$ (each is a RGB vector)</li>
<li>$n$, $m$</li>
<li>Refractive index $\mu$ if $k_{tg} \not= 0$ or $k_{t} \not= 0$</li>
</ul>
</li>
<li>Objects<ul>
<li>Implicit representations (e.g. plane, sphere, quadrics)</li>
<li>Polygon</li>
<li>Parametric (e.g. bicubic Bezier patches)</li>
<li>Volumetric</li>
</ul>
</li>
</ul>
<blockquote>
<p>Q: When to stop recursion?</p>
</blockquote>
<ul>
<li>When the surface is totally diffuse (and opaque)</li>
<li>When reflected/refracted ray hits nothing</li>
<li>When maximum recursion depth is reached</li>
<li>When the contribution of the reflected/refracted ray to the color at the top level is too small<ul>
<li>$(k_{rg1} | k_{tg1}) \times … \times (k_{rg(n−1)} | k_{tg(n−1)}) &lt; \text{threshold}$ </li>
</ul>
</li>
</ul>
<h1 id="Appendices-Reference"><a href="#Appendices-Reference" class="headerlink" title="Appendices (Reference)"></a>Appendices (Reference)</h1><p>If you want to search the reference pages of OpenGL Programming on <code>C++</code> , or use real-time 3D rendering in other field using OpenGL API, please refer to the <a href="https://registry.khronos.org/OpenGL-Refpages/gl4/">OpenGL® 4.5 Reference Pages</a> .</p>
<p>If you are just interesting in shader rendering (like only do fragment shaders), you can go to <a href="https://www.shadertoy.com/">shadertoy</a> to take a look at others’ work or create your own.</p>
<p>One of the contributor of “shadertoy”, Inigo Quilez, has published a tutorial of the skills of shadertoy, and you can learn it here → <a href="https://iquilezles.org/articles/">https://iquilezles.org/articles/</a></p>
]]></content>
      <categories>
        <category>2024 Summer</category>
      </categories>
      <tags>
        <tag>CSE Learning</tag>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title>NUS 夏令营日记</title>
    <url>/2024/06/30/Summer-Workshop-Diary/</url>
    <content><![CDATA[<h1 id="2024-6-29-Sat"><a href="#2024-6-29-Sat" class="headerlink" title="2024-6-29 (Sat.)"></a>2024-6-29 (Sat.)</h1><p>　　经过 4 小时左右的飞行，我于新加坡当地时间（其实就是北京时间）16:50 左右抵达新加坡的樟宜机场(Changi Airport)。然后第一个难题就来了。</p>
<p>　　因为提前在淘宝买了流量网卡，所以我取完行李后还需要先去领取窗口取我的网卡，然后才能在 SG 上网。所以我在这里足足拖了 10-15 分钟。不过好在大部分跟我同一班机的同学都遇到了类似的情况，我们最终在差不多的时间里找到了领队，将我们带回了 NUS。</p>
<p>　　比较庆幸的是，这样的开局算是比较一帆风顺，至此唯一的遗憾就是我到达的时间是下午，所以在樟宜机场的商场拍摄到的大喷泉显得嘈杂且无趣。我的另一位同学似乎拍到了夜景，那张照片我没要到，只能暂且拿一张“日中的喷泉”来献丑了。</p>
<div align="center"><img src="/2024/06/30/Summer-Workshop-Diary/ft.jpg" alt="SG机场喷泉" style="width:700px">Fountain in Changi Airport</div>

<p>　　令我感到无奈的是，开局的一帆风顺并不能掩盖接下来在我身上的种种窘态。目前来看，最令我感到不适应的，反而是我在国内最习以为常甚至感到一丝嫌弃的方面：人口。可能是在大学小区内，也可能是周末的原因，当我收拾好行李打算找个餐厅吃晚饭的时候，就只能看着周围空荡荡的街头，盘算着什么时候来个人问问路。这边的人口（至少在这段时间）实在是少得超出我的想象</p>
<blockquote>
<font color="red">为什么不看地图呢？</font>
<br>
<font color="green">其实 NUS 校区内是有校巴可以通向大部分校内区域的，甚至还能去到地铁站。</font>

</blockquote>
<p>　　但是这又涉及到第二个问题：网络。来到这边后，我才发现 NUS 校内的 WiFi 是很不稳定的。具体表现为坐公交车的时候基本上只有停靠站点的时候才能连上 WiFi（后来我们发现似乎每个公交车站确实装了一台路由器）。</p>
<p>　　于是在这种找不到人问路，又只能干等 WiFi 信号的情况下，我终于想办法来到了 University Town（也称 U-Town）。毕竟我也没想到找了好几个教学区的食堂发现都没开放，我真的哭死。</p>
<div align="center"><img src="/2024/06/30/Summer-Workshop-Diary/night01.jpg" alt="U-Town 夜景" style="width:700px">Night Scene of U-Town</div>

<p>　　大约在晚上 8 点，我终于在 U-Town 吃上了 SG 落地后的第一顿晚饭。我进了 U-Town 的一家韩菜餐馆，点了个不记得叫什么的东西（我一开始以为是炒饭），一共 4.4 SGD，折合人民币大约 23.6 块。然后等端上来了才发现，这就是个加了半熟鸡蛋的方便面。</p>
<p>　　Emmm……( ó × ò)</p>
<p>　　接下来的一段时间我需要以此为基础重塑我的消费观。我在国内生活在一线城市，自认为消费水平也不算低了，不过 SG 的物价依旧令人震惊。</p>
<p>　　上面讲的都是些槽点，但是我对此并不讨厌。所有讲到的槽点几乎都来源于我对于新环境的不适应。包括 NUS 缺少宿舍饮水机和洗衣机，出行不便等等，这些基本都是基于我原来的大学环境作出的直接比较。一方面我的大学我肯定已经熟悉了，另一方面我的大学面积比较小，确实也不存在什么出行问题。</p>
<p>　　我希望我能尽快适应，毕竟我还得在这里待一个月。不过像网购，点外卖这种事情，虽然能解决我的用餐问题，但我也不在这里长期居住，我自己感觉不太需要为此特地去搞个 paynow 之类的账号来满足这些需求。再怎么说我来这里的主要任务还是交流学习，如果以后想来这里的话，那线上支付什么的迟早会解决的。</p>
<p>　　今天先聊到这，以下奉上一些出到 NUS 的小攻略（仅仅基于我第一天的体验，后面可能会推翻）。</p>
<blockquote>
<ol>
<li><p>必须下载 NUS NextBus app，在 NUS 交流基本可以解决大部分出行问题。</p>
</li>
<li><p>网购可选择 Shopee；点外卖可选择 Grab，foodpanda 或 Deliveroo。但网上大部分攻略支持优先选 Grab（功能集成，还能打车）。</p>
</li>
<li><p>不太需要担心英语交流问题。这边大部分的餐饮人员只要会说中文的，基本能一眼看出你是中国学生。</p>
</li>
<li><p>这边的饭堂不太好找，而且不容易在线上获取开放信息。所以刚到 SG 时不妨大胆一点直接去 U-Town 获取稳定食物来源。</p>
</li>
<li><p>SG 的餐饮费用毋庸置疑比国内贵得多，不过也有一些区别。一般性价比较高的大概是在 4.4 - 7 SGD 这个价位上，至少对于我一个成年人来说，这个价位完全能吃饱 + 吃好。</p>
</li>
</ol>
</blockquote>
<hr>
<h1 id="2024-6-30-Sun"><a href="#2024-6-30-Sun" class="headerlink" title="2024-6-30 (Sun.)"></a>2024-6-30 (Sun.)</h1><p>　　不得不说 NUS 的宿舍单人间住的极其舒适，虽然床小了点，只能刚好睡下一个人，但是单人间舒服啊，狠狠地满足了我的私人空间需求。</p>
<p>　　中午我的两位朋友也到了。因为这两天都是给我们办入住的，所以我早一天到的相当于多了一天的适应期（适应期指的是晚上玩新加坡服直接当了一回 4 ping 战士 ´｡✪ω✪｡｀）。</p>
<p>　　本来打算是在宿舍 PGPR 附近找个餐厅吃的（这个展开简直和昨天一模一样），结果又双叒叕没找到，所以又只能去 U-Town 。不过这回去了个挺不错的餐厅 FineFood ，可以说很符合当代大学生的饭堂风格。</p>
<div align="center"><img src="/2024/06/30/Summer-Workshop-Diary/FineFood.jpg" alt="FineFood" style="width:700px">FineFood Canteen</div>

<p>　　这里面有自选餐也有套餐，还有饮料，而且总的来说价格也能接受。反正我点了自选餐，一份菜、一份番茄炒蛋（算作肉）、一份黑椒炒牛肉一共 6.2 SGD 。份量是很够的，就算我没吃早饭，午饭也吃得挺饱。</p>
<p>　　晚上在我们宿舍区的一个小卖部买了点东西草草了事（居然也花了 4.4 SGD）。今天应该就是最后的比较自由的一天了。明天有助理带队参观学校和欢迎晚宴，可以期待一下。</p>
<hr>
<h1 id="2024-7-1-Mon"><a href="#2024-7-1-Mon" class="headerlink" title="2024-7-1 (Mon.)"></a>2024-7-1 (Mon.)</h1><p>　　今天主要有两个活动：Campus Tour 和 Welcome Dinner 。早上随意参观，有学生助理介绍引导。然后到晚上就是去 USC(University Sport Center) 参加欢迎晚宴。</p>
<div align="center"><img src="/2024/06/30/Summer-Workshop-Diary/com-3.jpg" alt="com3" style="width:700px">SoC COM 3</div>

<p>　　由于想更好地休息，我没有花太多时间在参观校园上。我大概了解了我接下来一个月的上课教室、图书馆的大致位置、饭堂和餐厅等，其实前两天已经看得差不多了。</p>
<p>　　至于欢迎晚宴也没什么特别的地方，虽然是自助，不过体量不算大，以至于当我晚上开始写日记时已经感到有些饿了。我能预感到在未来的 4-5 天内，饮食仍然会成为我的一个困扰之处。不过参考几位同学（大佬）的餐饮习惯，应该会好很多。</p>
<div align="center"><img src="/2024/06/30/Summer-Workshop-Diary/welcome-dinner.jpg" alt="welcome dinner" style="width:700px">Place of Welcome Dinner</div>

<p>　　值得一提的是，在晚宴结束后，我和几位同学一起去了肯特岗（地铁站，公交车可达）。地铁站的附近有一个超市叫 Fair Price ，里面的商品可以解决大部分初到新加坡的生活不便问题。（这个超市在 2 楼，想找到可能要花些功夫）</p>
<p>　　在超市里可以找到一些小吃、饮品、面包，还有生活用品如水桶、枕头、纸巾、洗漱用品等。这里甚至还有新鲜的水果，但是普遍很贵———新加坡的水果似乎都很贵，可能跟依赖进口有关。不过我们有幸发现了国内卖 5、6 块钱（RMB）的一种椰子水，在新加坡居然只需要 1 SGD，意味着这里的椰子水几乎和国内的价钱一样！！我们当时就决定大规模购买，不得不说这对于新加坡的夏天非常适用。</p>
<div align="center"><img src="/2024/06/30/Summer-Workshop-Diary/fruit.jpg" alt="fruit" style="width:700px">Fruit in Fair Price</div>

<p>　　以上就是今天的一些感受。从明天开始就是正式上课和写项目了，日记应该也不会天天写，可能隔一段时间写一次学习心得吧（学习笔记另外写）。回见！</p>
<h1 id="2024-7-2-Tue"><a href="#2024-7-2-Tue" class="headerlink" title="2024-7-2 (Tue.)"></a>2024-7-2 (Tue.)</h1><p>　　今天早上开课了，基本上我就要开始习惯课程安排的时间。像一些 deep learning 之类的课程是早上和下午都有课的，一般早上 9 点半到 12 点半，下午两点到五点上课，强度比较高，项目比较难也比较累。像我的课程是实时 3D 渲染的话只有下午有课，从下午一点上到下午四点，剩下的时间自由安排。相对来说我的课程是非常轻松的，而且课程难度本身不高（前提是很多老师上课不讲的代码内容要自己学会）。这样宽裕的时间安排也给了刚来新加坡的我不少到处走的机会。比如今晚就去了新加坡的夜间动物园———— Night Safari。</p>
<p>　　我是和几位朋友一起去的 Night Safari，有一些是老朋友了，还有一些刚认识不久，不过我们之间氛围还算挺好。夜间动物园带来的体验与其他动物园有很大不同。我们先是坐游行电瓶车绕了动物园一圈，看到了不少夜间生活的动物如猫头鹰、豹猫、一些大象等，后来觉得意犹未尽又从步行道走了一段路。一边夜间散步一边还能和朋友们闲聊，这对我这个 i 人来说也是一种奇妙的体验（和外向的人交流真的完全没有心理负担！）。</p>
<div align="center"><img src="/2024/06/30/Summer-Workshop-Diary/nightzoo.jpg" alt="zoo" style="width:700px">Night Safari</div>

<p>　　总的来说我已经开始适应这边的生活了。虽然这两天可能因为水土不服（新加坡饮食类型多样，我吃的也基本是中国菜，完全不应该拉肚子）让我会有些难受，不过调养一段时间就会好很多。我听一些老家在重庆，浙江的同学都说新加坡这边的环境和条件比国内好，可能是我住一线城市的原因吧，我还是比较喜欢我的家乡，不过新加坡环境好确实是客观的，至少这边平均绿植覆盖面广，街道干净。该说不说小国家有小国家的优势，像这种问题治理起来确实方便（我怎么开始突发感慨了？）。</p>
<h1 id="2024-7-5-（Fri-）"><a href="#2024-7-5-（Fri-）" class="headerlink" title="2024-7-5 （Fri.）"></a>2024-7-5 （Fri.）</h1><p>　　今天是第一周上课的最后一天，关于课程的时间安排已经完全适应。我和我的队友基本上在早上九点到十点醒，吃点东西补充下然后去教室预习或复习上课内容，下午四点上完课去 Kent Ridge MRT(肯特岗) 吃晚饭，有时买点夜宵带回宿舍。晚上如果没有小组作业基本就是各自在宿舍干活或放松。</p>
<p>　　今天我们去了肯特的一家餐厅，吃到了我来新加坡这么多天以来最好吃的一顿饭（但是爆了 9.9 SGD 的金币）。真的非常推荐去试试！他们那家的炸鸡，鸡肉真的特别多，而且不柴，9.9 SGD 一顿管饱而且好吃，血赚！</p>
<p>　　By the way，刚进肯特岗地铁站左手边的食阁，两边有两家面包店。两家面包店做的华夫饼也是超级好吃！现做现卖，有蘸酱的一个 2.3 SGD，还算是比较合适的价格了（已经逐渐适应新加坡的物价）。</p>
<p>　　个人感觉除了这两点以外，肯特岗的食阁就没什么推荐的了，基本比不上国内的餐饮，不过这两家真的是，绝了。</p>
<div align="center"><img src="/2024/06/30/Summer-Workshop-Diary/fried-chi.jpg" alt="fried-chicken" style="width:700px">Food in Kent Ridge MRT</div>



<h1 id="2024-7-7-Sun"><a href="#2024-7-7-Sun" class="headerlink" title="2024-7-7 (Sun.)"></a>2024-7-7 (Sun.)</h1><p>　　今天我要收回前面的一个暴论———— U-Town 跟肯特岗比也不是这么缺少美食。今天中午去了趟 U-Town ，本来是想简单在 FineFood 吃一下的，结果在一些奇特指引下，我找到了一个新地方。</p>
<div align="center"><img src="/2024/06/30/Summer-Workshop-Diary/u-town-dine.jpg" alt="u-town-dine" style="width:700px">More in U-Town</div>

<p>　　这地方好吃的东西也挺多的，至少我吃上了质量较高的白切鸡。这个餐厅其实就是在 FineFood 的那栋楼继续往里走的地方，不算难找，而且里面卖的东西还算比较多样。除了我吃的中国菜，还有水果、饮品、和一些其他国家的菜式。个人感觉比 FineFood 大多数套餐实惠。</p>
<p>　　由于今天几乎一天都在下雨，原本我除了中午雨停那会吃了个午饭，就计划一直待在宿舍里了。结果十分意外地，大约在下午 6 点左右，我发现雨停了好一会儿了，于是当即产生了一个出游的想法，并且立即付诸行动。</p>
<div align="center"><img src="/2024/06/30/Summer-Workshop-Diary/raffle.jpg" alt="raffle" style="width:700px">Raffle Place</div>

<p>　　我的想法来得仓促，没来得及叫上其他人，所以独自一人就坐地铁去了 Raffle Place 地铁站，并从那边穿过一栋栋建筑，最终来到了海湾边。</p>
<p>　　这里，就是新加坡的地标级景点————鱼尾狮公园 (Merlion Park)。在鱼尾狮公园的海湾岸边，可以直接看见对岸的金沙空中花园酒店 (Marina Bay Sands Hotel)，也只有在这边才能看到这个三栋建筑的全貌。</p>
<div align="center"><img src="/2024/06/30/Summer-Workshop-Diary/tri-hotel.jpg" alt="MBS Hotel" style="width:700px">MBS Hotel</div>

<p>　　当然了，还有新加坡最著名的景点之一————鱼尾狮雕像。</p>
<div align="center"><img src="/2024/06/30/Summer-Workshop-Diary/merlion.jpg" alt="merlion" style="width:700px">the Merlion</div>

<p>　　不得不说，哪怕是星期天，这里的人依然很多，可见这里确实是不负盛名。因为新加坡临近国庆，所以每周六晚上都会在这个海湾放烟花，我昨天没来可惜了，但今天来这边依然有一些惊喜的收获。</p>
<div align="center"><img src="/2024/06/30/Summer-Workshop-Diary/Jazz.jpg" alt="jazz" style="width:700px">Jazz Band Performance</div>

<p>　　最大的惊喜莫过于当我走过鱼尾狮公园，经过一座步行桥，又绕过了滨海艺术中心（一个榴莲形状的剧场）后，我意外发现了一个爵士乐队在 Esplanade Mall 演奏。现场可以说是坐满了人，连很多经过的游客都停下来，围在了场地外面，站着听他们的演奏。可以说在这样的一个场景下，爵士乐拥有无与伦比的吸引力。无论是华人，欧洲游客，还是印度人，黑人，几乎都能被这样的演奏吸引过来。更有意思的是，我注意到一位站着的华人大叔，掏出了他的一个小本本，用签字笔给每个 solo 的乐手画写生。虽说画的不太像，而且是站着随手画的，但是神态确实到位了，也算是别有一番风格。</p>
<p>　　最后这支乐队还专门演奏了一首中国乐曲，《万水千山总是情》，现场反响非常好。</p>
<div align="center"><img src="/2024/06/30/Summer-Workshop-Diary/tri-hotel-night.jpg" alt="MBS Hotel" style="width:700px">MBS Hotel(night)</div>

<p>　　等我意识到我在那里听了将近半个小时时，天已经几乎黑透了。于是我开始往回走，走时路过了鱼尾狮雕像，又拍了几张鱼尾狮和空中花园酒店和傍晚的时候做对比。在往地铁站走的途中，我特地拐到对岸去看了看莱弗士教堂。据说莱弗士 (Raffle) 是英国人，来到新加坡殖民后，有效促进了这一带的经济发展，所以后人为了纪念他，为他在这里建了一座教堂。而现在，教堂外的草地上，有不少人铺开了毯子，趁着晚风清凉在草地上休息、野炊，甚至有人拿着小音箱忘我地唱歌，颇有一种国内广场的烟火气息。在这里，我算是真正体会到了新加坡的百姓生活的一角。</p>
<p>　　当我回到宿舍，时间也才九点半，明天还要继续上课，今天就先写到这吧。</p>
<h1 id="2024-7-13-Sat"><a href="#2024-7-13-Sat" class="headerlink" title="2024-7-13 (Sat.)"></a>2024-7-13 (Sat.)</h1><p>　　上周不是自己跑去了鱼尾狮公园嘛，还是星期天没碰上烟花。这星期一听说</p>
]]></content>
      <categories>
        <category>Summer Camp</category>
      </categories>
      <tags>
        <tag>Exchange</tag>
        <tag>Dairy</tag>
      </tags>
  </entry>
  <entry>
    <title>MA212 概率论与数理统计</title>
    <url>/2024/08/19/Probability-Theory-and-Mathematical-Statistics/</url>
    <content><![CDATA[<h1 id="第一章-概率"><a href="#第一章-概率" class="headerlink" title="第一章 概率"></a>第一章 概率</h1><h2 id="记数方法"><a href="#记数方法" class="headerlink" title="记数方法"></a>记数方法</h2><ul>
<li>古典概型<ul>
<li>$\Omega$ 只含有限个样本点</li>
<li>每个样本点出现是等可能的</li>
</ul>
</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>P(A)=\frac{A \text{的有利场合数}}{\text{样本点总数}}=\frac{k}{n}<br>$</p>

</blockquote>
<ul>
<li>几何概型<ul>
<li>对比古典概型有无限个样本点</li>
</ul>
</li>
</ul>
<h2 id="全概率定律"><a href="#全概率定律" class="headerlink" title="全概率定律"></a>全概率定律</h2><p><strong>Def.</strong> 设 $\Omega$ 为样本空间，若事件 $B_1,B_2,\cdots ,B_n$ 满足：</p>
<ol>
<li>$B_1,B_2,\cdots ,B_n$ 两两不相容</li>
<li>$B_1 \cup B_2 \cup \cdots \cup B_n = \Omega$</li>
</ol>
<p>则称 $B_1,B_2,\cdots ,B_n$ 为样本空间的一个<font color="red">划分</font>。</p>
<p>由此推出全概率公式：</p>
<blockquote class="blockquote-center">
<p>$<br>P(A)=\sum_{i=1}^{n} P(A|B_i) \cdot P(B_i)<br>$</p>

</blockquote>
<p>由全概率公式和条件概率的乘法公式推导出 <font color="red">Bayes 公式</font>：</p>
<blockquote class="blockquote-center">
<p>$<br>P(B_i|A)=\frac{P(A|B_i)P(B_i)}{\sum_{j=1}^{n} P(A|B_j)P(B_j)}<br>$</p>

</blockquote>
<p>Bayes 公式的实际意义：</p>
<p>假定 $B_1,B_2,\cdots ,B_n$ 为导致实验结果的“原因”，称 $P(B_i) (i=1,2,\cdots ,n)$ 为<font color="red">先验概率</font>。</p>
<p>若试验产生事件 A ，则要探讨事件发生的“原因”：称 $P(B_i|A)$ 为<font color="red">后验概率</font>，称 $P(A|B_i)$ 为<font color="red">原因概率</font></p>
<h1 id="第二章-随机变量"><a href="#第二章-随机变量" class="headerlink" title="第二章 随机变量"></a>第二章 随机变量</h1><h2 id="离散随机变量"><a href="#离散随机变量" class="headerlink" title="离散随机变量"></a>离散随机变量</h2><p>定义：</p>
<blockquote class="blockquote-center">
<p>$<br>P\{ X=x_k \}= p(x_k),\ \ (k=1,2,3,\cdots)<br>$</p>

</blockquote>
<p>为离散型 r.v. X 的概率质量函数 (PMF)</p>
<blockquote class="blockquote-center">
<p>$<br>F(x)=P\{ X \le x \}, -\infty \lt x \lt \infty<br>$</p>

</blockquote>
<p>为离散型 r.v. X 的累计分布函数 (CDF)</p>
<p><strong>泊松定理</strong></p>
<p>设 $\lambda \gt 0$，$n$ 为正整数，$\lim_{n \to \infty} np_n=\lambda$，则有</p>
<blockquote class="blockquote-center">
<p>$<br>\lim_{n\to \infty} C^k_n p^k_n(1-p_n)^{n-k}=\frac{\lambda^{k}e^{-\lambda}}{k!}<br>$</p>

</blockquote>
<h2 id="连续随机变量"><a href="#连续随机变量" class="headerlink" title="连续随机变量"></a>连续随机变量</h2><p>定义：</p>
<blockquote class="blockquote-center">
<p>$<br>F(x)=\int_{-\infty}^{x} f(t)\text{d}t,\ -\infty \lt x \lt \infty<br>$</p>

</blockquote>
<p>其中 $f(t)$ 为连续型 r.v. X 的概率密度函数 (PDF)</p>
<p><strong>标准正态分布</strong></p>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{l}<br>&amp;\Phi(x)=\int_{-\infty}^{x} \psi(x)\text{d}x \\<br>&amp;\psi(x)=\frac{1}{\sqrt{2\pi}\sigma} e^{-\frac{(x-\mu)^2}{2\sigma^2}} \\<br>&amp;s.t.\ \mu=0,\ \sigma^2=1<br>\end{array}<br>$</p>

</blockquote>
<h2 id="随机变量的函数"><a href="#随机变量的函数" class="headerlink" title="随机变量的函数"></a>随机变量的函数</h2><p>例：设随机变量 $X$，$Y$，满足 $Y=aX+b$，如何通过 $X$ 的概率密度分布求出 $Y$ 的 PDF？</p>
<p>解：令 $x=g(y)=\frac{y-b}{a}$，可得 $F_Y(y)=P\{ Y\le y \}=P\{ X\le\frac{y-b}{a} \}=F_X(\frac{y-b}{a})$。</p>
<p>化简得：$f_Y(y)=F_{X}’(g(y))=(g(y))’f_X(g(y))$</p>
<p>如正态分布 $X\sim N(\mu,\sigma^2)$ 的线性函数 $aX+b \sim N(a\mu +b,(a\sigma)^2)$ 也是正态分布</p>
<h1 id="第三章-联合分布"><a href="#第三章-联合分布" class="headerlink" title="第三章 联合分布"></a>第三章 联合分布</h1><h2 id="联合随机变量"><a href="#联合随机变量" class="headerlink" title="联合随机变量"></a>联合随机变量</h2><p>定义：</p>
<blockquote class="blockquote-center">
<p>$<br>F(X,Y)\triangleq P\{ X\le x,Y\le y \}\ \ s.t.\ \{x,y\}\in \mathbb{R}<br>$</p>

</blockquote>
<p>为 $X$ 与 $Y$ 的联合累积分布函数。</p>
<blockquote class="blockquote-center">
<p>$<br>F_X(x)= P\{ X\le x,Y\le \infty \}\ \ s.t.\ x\in \mathbb{R}<br>$</p>

</blockquote>
<p>称为 $X$ 的边际分布，$Y$ 同理。</p>
<p><strong>概率密度函数</strong></p>
<blockquote class="blockquote-center">
<p>$<br>F(x,y)=\int_{-\infty}^{x} \int_{-\infty}^{y} f(u,v)\text{d}u\text{d}v,\ s.t.\ \{ x,y\}\in\mathbb{R}<br>$</p>

</blockquote>
<p>则 $f(x,y)$ 为 $X$，$Y$ 的概率密度函数(joint PDF)</p>
<p><strong>边际密度</strong></p>
<blockquote class="blockquote-center">
<p>$<br>f_X(u)=\int_{-\infty}^{\infty} f(u,y)\text{d}y<br>$</p>

</blockquote>
<p>称为 $X$ 的边际密度，$Y$ 同理。</p>
<h2 id="独立随机变量"><a href="#独立随机变量" class="headerlink" title="独立随机变量"></a>独立随机变量</h2><blockquote class="blockquote-center">
<p>$<br>f(x,y)=f_X(x)\cdot f_Y(y)<br>$</p>

</blockquote>
<p>当上式成立时，$X$，$Y$ 相互独立，即相关系数 $\rho=0$。</p>
<h2 id="条件分布"><a href="#条件分布" class="headerlink" title="条件分布"></a>条件分布</h2><p>（只看连续，离散情况容易推导）</p>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{l}<br>P(X\le x|y\le Y\le y+\epsilon) &amp;=\frac{P\{X\le x,y\le Y\le y+\epsilon\}}{P\{ y\le Y\le y+\epsilon\ \}} \\<br>&amp;=\frac{\int_{-\infty}^{x}\int_{y}^{y+\epsilon} f(u,v)\text{d}u\text{d}v}{\int_{y}^{y+\epsilon} f_Y(v)\text{d}v} \\<br>&amp;=\frac{\epsilon\int_{-\infty}^{x}f(u,y_\epsilon)\text{d}u}{\epsilon f_Y(\tilde{y}_{\epsilon})} \\<br>&amp;= \int_{-\infty}^{x}\frac{f(u,y)}{f_Y(y)} \text{d}u\ \ (\epsilon\to 0)<br>\end{array}<br>$</p>

</blockquote>
<p>定义 $\frac{f(u,y)}{f_Y(y)} \triangleq f_{X|Y}(x|y)$ 为 $Y=y$ 下 $X$ 的<font color="red">条件密度</font></p>
<h2 id="联合分布随机变量的函数"><a href="#联合分布随机变量的函数" class="headerlink" title="联合分布随机变量的函数"></a>联合分布随机变量的函数</h2><p>1 . $Z=X+Y$</p>
<p>利用卷积公式 (可写作 $f_X * f_Y$)：</p>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{l}<br>&amp;f_Z(z)=\int_{-\infty}^{\infty}f_X(z-y)f_Y(y)\text{d}y \\<br>\text{or } &amp;f_Z(z)=\int_{-\infty}^{\infty}f_X(x)f_Y(z-x)\text{d}x<br>\end{array}<br>$</p>

</blockquote>
<font color="red">前提：</font> 

<p>$X$，$Y$ 相互独立（如不独立，可利用联合分布、条件分布求得，或变换成独立变量再求解）。</p>
<p>2 . $Z=\frac{X}{Y}$</p>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{l}<br>&amp;\text{由于 }F_Z(z)=P\{ X/Y\le z \}=\underset{\frac{x}{y}\le z}{\int\int} f(x,y)\text{d}x \text{d}y \text{ 积分区域可能不是矩形} \\<br>&amp;\text{为简化积分计算，使用 }\textbf{J}=\frac{\partial{(x,y)}}{\partial{(u, v)}}= \Large{\left| \begin{array}{c} \frac{\partial{x}}{\partial{u}} &amp; \frac{\partial{x}}{\partial{v}} \\ \frac{\partial{y}}{\partial{u}} &amp; \frac{\partial{y}}{\partial{v}} \end{array} \right|} \\<br>&amp;\text{得 }F_Z(z)=\underset{\Omega}{\int\int} f[x(u,v),y(u,v)] |\textbf{J}|\text{d}u \text{d}v<br>\end{array}<br>$</p>

</blockquote>
<h2 id="顺序统计量"><a href="#顺序统计量" class="headerlink" title="顺序统计量"></a>顺序统计量</h2><p>设 $X_i\sim f(x)$ 是独立同分布的连续型 r.v.，则对于顺序统计量 $X_{(1)}(\min),\cdots ,X_{(n)}(\max)$ ，如何求 $X_{(k)}$ 的密度？</p>
<p>解：对于充分小的空间 $[x,x+\text{d}x]$，有</p>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{l}<br>&amp;P\{ x\lt X_{(k)} \lt x+\text{d}x \}=\left(\begin{array}{c}n \\ k-1 \end{array} \right) F(x)^{k-1} \left(\begin{array}{c}n-k+1 \\ 1 \end{array} \right) [F(x+\text{d}x)-F(x)] \left(\begin{array}{c}n-k \\ n-k  \end{array} \right) [1-F(x+\text{d}x)^{n-k}] \\<br>\therefore\ \ &amp;f_k(x)=\frac{\text{d}P\{ x\lt X_{(k)} \lt x+\text{d}x \}}{\text{d}x}=\frac{n!}{(k-1)!(n-k)!}F(x)^{k-1} f(x)[1-F(x)]^{n-k}<br>\end{array}<br>$</p>

</blockquote>
<p>称此为 Veta 分布，记为 $X\sim Beta(k, n-k+1)$</p>
<p>Beta 密度用于刻画 [0, 1] 上的随机变量：</p>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{l}<br>&amp;f(u)=\frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)}u^{a-1}(1-u)^{b-1} \\<br>s.t.\ &amp;\Gamma(x)=(x-1)! ,\ 0\le u\le 1<br>\end{array}<br>$</p>

</blockquote>
<h1 id="第四章-随机变量的数字特征"><a href="#第四章-随机变量的数字特征" class="headerlink" title="第四章 随机变量的数字特征"></a>第四章 随机变量的数字特征</h1><h2 id="协方差"><a href="#协方差" class="headerlink" title="协方差"></a>协方差</h2><p>定义：</p>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{l}<br>&amp;Cov(X,Y)\triangleq E[(X-E(X))\cdot (Y-E(Y))]<br>\end{array}<br>$</p>

</blockquote>
<p>称为 X，Y 的协方差，其相关系数表示为：</p>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{l}<br>&amp;\rho_{XY}\triangleq Cov(X^{*},Y^{*})=\frac{Cov(X,Y)}{\sqrt{D(X)}\sqrt{E(Y)}}<br>\end{array}<br>$</p>

</blockquote>
<p>利用这个属性进行 X，Y 线性拟合的计算：</p>
<p>记均方误差为 $e=E[(Y-\hat{Y})^2]=E[(Y-(aX+b))^2]$</p>
<p>令 $\left\{ \begin{array}{l} &amp;\frac{\partial{e}}{\partial{b}}=2b+2aE(X)-2E(Y)=0 \\ &amp;\frac{\partial{e}}{\partial{a}}=2aE(X^2)-2E(XY)+2bE(X)=0 \end{array} \right.$</p>
<p>解得 $\left\{ \begin{array}{l} &amp;b_0=\frac{Cov(X,Y)}{D(X)} \\ &amp;a_0=E(Y)-E(X)\cdot b_0 \end{array} \right.$</p>
<p>进一步得 $\underset{a,b}{\min e}=D(Y)(1-\frac{Cov^2(X,Y)}{D(X)D(Y)})=D(Y)(1-\rho^2_{XY})$</p>
<font color="red">注意：</font>$\rho_{XY}=0$ 并不意味着 X，Y 相互独立！（但正态分布能证明 不相关 = 独立）



定义：

对 r.v. X，Y，

$E(X^k)\ \ \ (k=1,2,\cdots)$ 为 <font color="red">k 阶原点矩</font>

<p>$E[(X-E(X))^k]\ \ \ (k=1,2,\cdots)$ 为 <font color="red">k 阶中心矩</font></p>
<p>$E[(X-E(X))^k(Y-E(Y))^l]\ \ \ (k,l=1,2,\cdots)$ 为 <font color="red">k+l 阶混合中心矩</font></p>
<blockquote>
<p>因此，r.v. 的期望是一阶原点矩，方差是2阶中心矩，协方差是2阶混合中心矩。</p>
</blockquote>
<h2 id="条件期望"><a href="#条件期望" class="headerlink" title="条件期望"></a>条件期望</h2><p>定义：</p>
<blockquote class="blockquote-center">
<p>$<br>\left\{\begin{array}{rl}<br>&amp;E(h(Y)|X=x)=\sum_{y}h(y)p_{Y|X}(y|x) &amp;\text{（离散）} \\<br>&amp;E(h(Y)|X=x)=\int_{y}h(y)f_{Y|X}(y|x)\text{d}y &amp;\text{（连续）}<br>\end{array}\right.<br>$</p>

</blockquote>
<blockquote>
<p>特殊情况下，$h(y)=y$</p>
</blockquote>
<p><font color="green">回顾泊松分布：</font> $X\sim P(\lambda t)$</p>
<p>$P(X=k)=\frac{(\lambda t)^k}{k!}e^{-\lambda t}\ \ \ k\in\mathbb{N}$  称为泊松强度。</p>
<p>例：考虑 [0, 1] 区间上均值为 $\lambda$ 的泊松流，令 N 是 [0, 1] 上点的个数。对于 $p\lt 1$，令 X 是 [0, p] 上点的个数。计算给定 N = n 的情况下，X 的条件分布和条件期望。</p>
<p>解：联合分布</p>
<p>$P\{X=x,N=n \}=\frac{(p\lambda)^xe^{-p\lambda}}{x!}\cdot \frac{((1-p)\lambda)^{(n-x)}e^{-(1-p)\lambda}}{(n-x)!}$</p>
<p>而 $N\sim P(\lambda)$</p>
<p>因此 $P\{X=x|N=n \}=\frac{n!}{x!(n-x)!}p^x(1-p)^{(n-x)}\sim b(n,p)$</p>
<p>从而 $X$ 的条件期望为 $np$。</p>
<h1 id="第五章-数理统计（入门）"><a href="#第五章-数理统计（入门）" class="headerlink" title="第五章 数理统计（入门）"></a>第五章 数理统计（入门）</h1><h2 id="大数定律"><a href="#大数定律" class="headerlink" title="大数定律"></a>大数定律</h2><p>（伯努利版）设 $P(A)=p$，则对任意 $\epsilon\gt 0$，有 $\color{red} \underset{n\to \infty}{\lim}=P\{|\frac{n_A}{n}-p|\ge \epsilon \}=0$</p>
<p>（切比雪夫版）$\{X_n\}$ 为独立随机变量列，且期望方差相同，则对任意 $\epsilon\gt 0$，有 $\color{red} \underset{n\to \infty}{\lim}=P\{|\frac{1}{n}\sum_{i=1}^{n}X_i-\mu|\ge \epsilon \}=0$</p>
<p>（这意味着样本量足够大时，期望可被样本的算术均值替代）</p>
<h2 id="中心极限定理"><a href="#中心极限定理" class="headerlink" title="中心极限定理"></a>中心极限定理</h2><p>若 $X_n$ 的分布 $F_n(x)$ 对任意 $x$ 满足</p>
<blockquote class="blockquote-center">
<p>$<br>\color{red}<br>\begin{array}{l}<br>&amp;\underset{n\to \infty}{\lim} F_n(x)=\underset{n\to \infty}{\lim}P\{ \frac{\sum_{i=1}^{n}(X_i-\mu_i)}{\sqrt{\sum_{i=1}^{n}\sigma_i^2}}\le x \}=\psi(x)<br>\end{array}<br>$</p>

</blockquote>
<p>则称 $\{X_n \}$ 服从中心极限定理（$\psi(x)$ 为标准正态）</p>
<p>特别当 $X_n$ 独立同分布，则有 $\underset{n\to \infty}{\lim}P\{ \frac{\sum_{i=1}^{n}X_i-n\mu_i}{\sqrt{n}\sigma_i}\le x \}=\psi(x)$</p>
<blockquote>
<p>德莫夫-拉普拉斯中心极限定理：对 $\eta_n\sim b(n,p)$</p>
<p>$\frac{\eta_n-np}{\sqrt{np(1-p)}}\sim N(0,1)$</p>
<p>参考高尔顿钉板</p>
</blockquote>
<h1 id="第六章-数理统计（基础）"><a href="#第六章-数理统计（基础）" class="headerlink" title="第六章 数理统计（基础）"></a>第六章 数理统计（基础）</h1><h2 id="抽样分布"><a href="#抽样分布" class="headerlink" title="抽样分布"></a>抽样分布</h2><p>1 . $\chi^2$ - 分布</p>
<p>设 $X_1-X_n$ 是来自总体 $X\sim N(0,1)$ 的样本，令</p>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{l}<br>\chi^2=X_1^2+X_2^2+\cdots +X_n^2<br>\end{array}<br>$</p>

</blockquote>
<p>称 $\chi^2$ 服从自由度为 $n$ 的 $\chi^2$ - 分布（也称卡方分布），记为 $\chi^2(n)$。</p>
<blockquote>
<p><font color="blue">自由度：</font>自由度是二次型 $\chi^2=X_1^2+X_2^2+\cdots +X_n^2$ 的秩，即可独立变化的变量个数。</p>
</blockquote>
<p>数字特征：</p>
<ul>
<li>$E(\chi^2)=n$</li>
<li>$D(\chi^2)=2n$</li>
</ul>
<p>2 . t - 分布</p>
<p>设 $X\sim N(0,1)$，$Y\sim \chi^2(n)$，且 $X$，$Y$ 独立，令</p>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{l}<br>t=X/\sqrt{Y/n}<br>\end{array}<br>$</p>

</blockquote>
<p>称 $t$ 为服从自由度为 n 的 t - 分布，记为 $t(n)$。</p>
<p>性质：</p>
<ul>
<li>数字特征<ul>
<li>$E(t)=0$</li>
<li>$D(t)=\frac{n}{n+2}$</li>
</ul>
</li>
<li>当 n 充分大时，T 近似服从 N(0, 1)，即趋近标准正态分布<ul>
<li>可证明 $\underset{n\to\infty}{\lim}f(x)=(2\pi)^{-\frac{1}{2}}e^{-\frac{x^2}{2}}$</li>
</ul>
</li>
</ul>
<p>3 . F - 分布</p>
<p>设 $U\sim \chi^2(n_1)$，$V\sim \chi^2(n_2)$，且 $U$，$V$ 独立，令</p>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{l}<br>F=\Large\frac{U/n_1}{V/n_2}<br>\end{array}<br>$</p>

</blockquote>
<p>称 F 为服从自由度为 $(n_1,n_2)$ 的 F - 分布，记为 $F(n_1,n_2)$。</p>
<p>二级结论：</p>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{l}<br>&amp;T\sim t(n) \Rightarrow T^2\sim F(1,n) \\<br>\text{证：} &amp;T=\frac{X}{\sqrt{Y/n}} \Rightarrow T^2=\frac{X^2/1}{Y/n}, \\<br>\text{ 且 }&amp;X^2,Y\text{ 仍相互独立}<br>\end{array}<br>$</p>

</blockquote>
<h2 id="抽样分布定理"><a href="#抽样分布定理" class="headerlink" title="抽样分布定理"></a>抽样分布定理</h2><p>1 . 设 $X_1\sim X_n$ 是来自总体 $X\sim N(\mu,\sigma^2)$ 的样本，则</p>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{l}<br>\bar{X}\sim N(\mu,\frac{\sigma^2}{n})<br>\end{array}<br>$</p>

</blockquote>
<p>因为 $\bar{X}=(X_1+\cdots +X_n)/n$ ，而线性组合仍服从正态分布。</p>
<p>因此，$E(\bar{X})=\mu$，$D(\bar{X})=\frac{\sigma^2}{n}$</p>
<p>2 . 设 $X_1\sim X_n$ 是来自总体 $X\sim N(\mu,\sigma^2)$ 的样本，$\bar{X}$ 、$S^2$ 分别是样本均值和样本方差，则有</p>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{lr}<br>&amp;\frac{(n-1)S^2}{\sigma^2}\sim \chi^2(n-1) &amp;(1) \\<br>&amp;\bar{X},S^2\text{ 相互独立} &amp;(2)<br>\end{array}<br>$</p>

</blockquote>
<p>3 . waiting…</p>
<p>4 . </p>
<p>5 . </p>
<h1 id="第七章-参数估计"><a href="#第七章-参数估计" class="headerlink" title="第七章 参数估计"></a>第七章 参数估计</h1><h2 id="点估计"><a href="#点估计" class="headerlink" title="点估计"></a>点估计</h2><p>定义：设总体分布函数 $F(x,\theta)$ ， $X_1\sim X_n$ 为样本，构造一个统计量 $\theta=\theta(X_1,\cdots ,X_n)$ 来估计参数 $\theta$ ，则称为参数 $\theta$ 的<strong>估计量</strong>。</p>
<p>将观测值 $x_1,\cdots ,x_n$ 带入 $\theta(X_1,\cdots ,X_n)$ ，得到的 $\theta(x_1,\cdots ,x_n)$ 称为参数 $\theta$ 的<strong>估计值</strong>。</p>
<p>常用点估计法：</p>
<ul>
<li>矩估计：设总体 $X\sim F(x;\theta)$ ，$\theta_1\sim \theta_m$ 未知，设对 n 个样本，总体矩都存在（即 $\alpha_k \triangleq E(X^k),(k=1,2,\cdots,m)$ ），由辛钦大数定律得</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{l}<br>&amp;A_k=\frac{1}{n}\sum_{i=1}^{n}X^k_i \overset{P}{\longrightarrow}E(X^k)=\alpha_k\ \ (n\to\infty,k=1,2,\cdots,m) \\<br>\text{可认为 }&amp;A_k\approx E(X^k)=\int{x^k}\text{d}F \triangleq \alpha_k(\theta_1,\cdots, \theta_m) &amp; \\<br>\therefore &amp; \left\{\begin{array}{l}<br>&amp;\alpha_1(\theta_1,\cdots, \theta_m)=E(X) \approx A_1 \\<br>&amp;\alpha_2(\theta_1,\cdots, \theta_m)=E(X^2) \approx A_2 \\<br>&amp;\vdots \\<br>&amp;\alpha_m(\theta_1,\cdots, \theta_m)=E(X^m) \approx A_m<br>\end{array}\right.<br>\end{array}<br>$</p>

</blockquote>
<p>解上述方程组得：</p>
<blockquote class="blockquote-center">
<p>$<br>\left\{<br>\begin{array}{l}<br>&amp;\hat{\theta}_1=\hat{\theta}_1(A_1,A_2,\cdots,A_m) \\<br>&amp;\vdots \\<br>&amp;\hat{\theta}_m=\hat{\theta}_m(A_1,A_2,\cdots,A_m) \\<br>\end{array}<br>\right.<br>$</p>

</blockquote>
<ul>
<li>最大似然估计：构造似然函数 $L(\theta)$ ，通过求极大值点得到参数值</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>L(\theta)=<br>\left\{<br>\begin{array}{lr}<br>&amp;p(x_1,x_2,\cdots,x_n;\theta)=\prod_{i=1}^{n}p(x_i;\theta) &amp;(\text{离散}) \\<br>&amp;f(x_1,x_2,\cdots,x_n;\theta)=\prod_{i=1}^{n}f(x_i;\theta) &amp;(\text{连续}) \\<br>\end{array}<br>\right.<br>$</p>

</blockquote>
<p>取对数便于求偏导（对每个参数 $\theta_i$ 求偏导）：$\large\frac{\partial{\ln{L}}}{\partial{\theta_i}}=0$</p>
<p><strong>参数评价标准</strong></p>
<ul>
<li>无偏性：$E(\hat\theta)=\theta$</li>
<li>有效性：$E(\hat\theta_1)=E(\hat\theta_2)=\theta$ 且 $D(\hat\theta_1)\le D(\hat\theta_2)$，则称 $\hat\theta_1$ 较 $\hat\theta_2$ 有效。</li>
<li>相合性（一致性）：设 $\hat\theta_n=\hat\theta(X_1,X_2,\cdots,X_n)$ 是 $\theta$ 的点估计，若 $\forall \theta\in\Theta$ 满足对 $\forall\epsilon\gt 0$ 有 $\color{red}\underset{n\to\infty}{\lim}P\{|\hat\theta_n -\theta|\ge \epsilon \}=0$ ，则称 $\hat\theta_n$ 是 $\theta$ 的<font color="red">相合估计</font>，记作 $\hat\theta_n\overset{P}{\longrightarrow}\theta(n\to\infty)$ 。</li>
</ul>
<h2 id="区间估计"><a href="#区间估计" class="headerlink" title="区间估计"></a>区间估计</h2><blockquote>
<p>区别：点估计构造一个参数统计量，而区间估计构造两个并将 $(\theta_1,\theta_2)$ 以一定的置信度作为 $\theta$ 的估算区间。</p>
</blockquote>
<p>定义：设总体 $X\sim F(x;\theta)$ ，若存在 2 个统计量</p>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{lr}<br>&amp;\underline{\theta}=\underline{\theta}(X_1,\cdots,X_n),\ \ \ \overline{\theta}=\overline{\theta}(X_1,\cdots,X_n) &amp;(\underline{\theta}\lt\overline{\theta})<br>\end{array}<br>$</p>

</blockquote>
<p>使得 $\forall\theta\in\Theta$ 有 $P\{\underline{\theta}\le\theta\le\overline{\theta}\}\ge 1-\alpha$ ，则称随机区间 $(\underline{\theta},\overline{\theta})$ 为 $\theta$ 的<font color="red">置信水平</font>为 $1-\alpha$ 的<font color="red">置信区间</font>，$\underline{\theta}$ 和 $\overline{\theta}$ 分别称为置信下限和置信上限。</p>
<ul>
<li>区间估计一般方法<ul>
<li>枢轴法（对应 t-分布的应用）</li>
<li>波动理论（对应卡方分布的应用）</li>
</ul>
</li>
</ul>
<p><strong>二级结论总结</strong></p>
<ol>
<li>$\sigma^2$ 已知，对 $\mu$ 估计：$\color{red}(\bar{X}-u_{1-\frac{\alpha}{2}}\frac{\sigma}{\sqrt{n}},\bar{X}+u_{1-\frac{\alpha}{2}}\frac{\sigma}{\sqrt{n}})$</li>
<li>$\sigma^2$ 未知，对 $\mu$ 估计：$\color{red}(\bar{X}-\frac{S}{\sqrt{n}}t_{1-\frac{\alpha}{2}}(n-1),\bar{X}+\frac{S}{\sqrt{n}}t_{1-\frac{\alpha}{2}}(n-1))$</li>
<li>$\mu$ 未知，对 $\sigma^2$ 估计：$\large\color{red}(\frac{(n-1)S^2}{\chi^2_{1-\frac{\alpha}{2}}(n-1)}, \frac{(n-1)S^2}{\chi^2_{\frac{\alpha}{2}}(n-1)})$</li>
</ol>
<p><em>后两条的推导式：</em></p>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{c}<br>&amp;P\left\{ \frac{|\bar{X}-\mu|}{S/\sqrt{n}}\lt t_{1-\frac{\alpha}{2}}(n-1) \right\}=1-\alpha \\<br>&amp;P\left\{\chi^2_{\frac{\alpha}{2}}(n-1)\lt \frac{(n-1)S^2}{\sigma^2}\lt\chi^2_{1-\frac{\alpha}{2}}(n-1) \right\}=1-\alpha<br>\end{array}<br>$</p>

</blockquote>
<h1 id="第八章-假设检验"><a href="#第八章-假设检验" class="headerlink" title="第八章 假设检验"></a>第八章 假设检验</h1><h2 id="一、建立对立的假设："><a href="#一、建立对立的假设：" class="headerlink" title="一、建立对立的假设："></a>一、建立对立的假设：</h2><p>原假设（零假设）$H_0$ 和备择假设（对立假设）$H_1$</p>
<ol>
<li>保护原假设：原假设错误的“代价”必须小于备择假设（如原假设新药物有副作用）</li>
<li>原假设趋于维持现状</li>
<li>原假设取简单假设</li>
</ol>
<h2 id="二、给出检验统计量，确定拒绝域形式"><a href="#二、给出检验统计量，确定拒绝域形式" class="headerlink" title="二、给出检验统计量，确定拒绝域形式"></a>二、给出检验统计量，确定拒绝域形式</h2><p>拒绝域是拒绝原假设的样本值范围，其补集为接受域。</p>
<p>设置合理的 $C$ 值（待定常数），使得 $\bar{X}$ 大于/小于该常数时，拒绝原假设。</p>
<p><strong>I 类错误与 II 类错误</strong></p>
<p>I 类错误指拒绝原假设但是原假设为真的情况，用 $\alpha$ 表示犯错概率，一般控制在 $(0.01,0.1)$ 范围内。(也称<font color="red">显著水平</font>)</p>
<p>II 类错误指接受原假设但原假设为假的情况，用 $\beta$ 表示。</p>
<h2 id="三、根据显著水平和统计量的分布确定临界值"><a href="#三、根据显著水平和统计量的分布确定临界值" class="headerlink" title="三、根据显著水平和统计量的分布确定临界值"></a>三、根据显著水平和统计量的分布确定临界值</h2><p>根据 NP 原则，先保证犯 I 类错误的概率不超过 $\alpha$，再令犯 II 类错误的概率尽可能小。</p>
<p>例：取 $\alpha=0.05$ ，当 $H_0:\mu=0$ 成立时，$\frac{\bar{X}}{0.6/\sqrt{9}}\sim N(0,1)$。（统计量分布）则可进行如下计算：</p>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{l}<br>P\{\bar{X}\ge C|\mu=0 \}&amp;=P\left\{\frac{\bar{X}}{\sigma/\sqrt{n}}\ge\frac{C}{\sigma/\sqrt{n}}|\mu=0 \right\} \\<br>&amp;=1-\psi\left(\frac{C}{\sigma/\sqrt{n}}\right)\le\alpha=0.05\ \ (0.05=\psi(-\textbf{z}_{0.05})) \\<br>&amp;\Rightarrow \frac{C}{0.6/\sqrt{9}}\ge \textbf{z}_{0.05}=1.645 \Rightarrow C\ge0.329<br>\end{array}<br>$</p>

</blockquote>
<p>因此取 $C=0.329$ 以减小 II 类错误！</p>
<h2 id="四、根据样本数据判断是否要拒绝假设"><a href="#四、根据样本数据判断是否要拒绝假设" class="headerlink" title="四、根据样本数据判断是否要拒绝假设"></a>四、根据样本数据判断是否要拒绝假设</h2><blockquote>
<p>例：如 $\bar{x}=0.522\gt 0.329$，则拒绝原假设。</p>
</blockquote>
<h2 id="正态总体参数的假设检验样例"><a href="#正态总体参数的假设检验样例" class="headerlink" title="正态总体参数的假设检验样例"></a>正态总体参数的假设检验样例</h2><p>In development…</p>
]]></content>
      <categories>
        <category>2023 Fall</category>
      </categories>
      <tags>
        <tag>CSE Learning</tag>
        <tag>Maths</tag>
      </tags>
  </entry>
  <entry>
    <title>MA113 线性代数</title>
    <url>/2024/08/25/Linear-Algebra/</url>
    <content><![CDATA[<h1 id="About"><a href="#About" class="headerlink" title="About"></a>About</h1><p>由于篇仅用于某些计算机相关课程的复习，所以某些“不太重要”的知识点要么默认已知，要么不会提及（如转置的概念和二级结论，行列式的概念等）。</p>
<p>由于教材不同或版本原因，对于一些符号可能有差异（如表示单位方阵有 $I/E$，以下统一使用本人学习的教材所用符号）</p>
<h1 id="第一章-矩阵（入门）"><a href="#第一章-矩阵（入门）" class="headerlink" title="第一章 矩阵（入门）"></a>第一章 矩阵（入门）</h1><h2 id="矩阵的逆"><a href="#矩阵的逆" class="headerlink" title="矩阵的逆"></a>矩阵的逆</h2><p>定义：$AC=CA=I\Longleftrightarrow$ $C$ 是 $A$ 的逆，记作 $A^{-1}$。</p>
<blockquote>
<p>不是所有方阵都有逆，不可逆<font color="red">方阵</font>称为<font color="red">奇异矩阵</font>。</p>
</blockquote>
<h2 id="矩阵的-LDU-分解"><a href="#矩阵的-LDU-分解" class="headerlink" title="矩阵的 LDU 分解"></a>矩阵的 LDU 分解</h2><p>定义：$\color{red}PA=LDU$，其中 $L$ 是下三角矩阵，$D$ 是对角矩阵，$U$ 是主对角元为 1 的上三角矩阵。($P$ 仅用作行交换)</p>
<h1 id="第二章-向量空间"><a href="#第二章-向量空间" class="headerlink" title="第二章 向量空间"></a>第二章 向量空间</h1><h2 id="基的相关定理"><a href="#基的相关定理" class="headerlink" title="基的相关定理"></a>基的相关定理</h2><p><strong>一、坐标：</strong> 令 $A=\{v_1,v_2,\cdots,v_n\}$ 是 $\mathbb{V}^n$ 的一组基，$\forall w\in\mathbb{V}^n$ ，有唯一数组 $\{a_1,a_2,\cdots,a_n\}$ 使 $w=a_1v_1+a_2v_2+\cdots +a_nv_n$ ，则该数组是 $\mathbb{A}$（向量空间的一组基）中 $w$ 的坐标，记为 $[w]_A$ 。</p>
<p><strong>二、满秩：</strong> 对于一个 $m*n$ 矩阵 $A$，若 $rank(A)=m$，则称 $A$ 行满秩，若 $rank(A)=n$，则称 $A$ 列满秩。</p>
<ul>
<li>若 $A_{m\times n}$ 行满秩（可推出 $m\le n$），且前 $m$ 列线性独立，令 $A=\left[A_0|X\right]$ ，则右逆 $C=\left[\begin{array}{c}A_0^{-1} \\ 0\end{array}\right]$ ；</li>
<li>若 $A_{m\times n}$ 列满秩（可推出 $m\ge n$），且前 $n$ 行线性独立，令 $A=\left[\begin{array}{c}A_0 \\ Y\end{array}\right]$ ，则左逆 $B=\left[A_0^{-1}|\ 0\right]$ 。</li>
</ul>
<p><strong>三、线性变换：</strong></p>
<ul>
<li>求解变换矩阵的方法：<ul>
<li>1）自然基变换求解</li>
<li>2）非自然基变换求解：利用矩阵逆运算</li>
</ul>
</li>
</ul>
<h1 id="第三章-正交性"><a href="#第三章-正交性" class="headerlink" title="第三章 正交性"></a>第三章 正交性</h1><p><strong>正交补</strong></p>
<p>对于子空间 $V \subseteq \mathbb{R}^n$，所有与 $V$ 正交的向量集合组成的空间称为正交补，写作 $W=V^{\bot}$。</p>
<p><strong>投影</strong></p>
<p>向量 $b$ 在向量 $a$ 上的投影表示为：$proj_a:b\mapsto p=\hat xa$</p>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{l}<br>&amp;0=a^T(b-\hat{x}a)\Rightarrow \hat{x}=\frac{a^Tb}{a^T a} \\<br>\therefore &amp;proj_a(b)=\frac{aa^T}{a^Ta}\cdot b<br>\end{array}<br>$</p>

</blockquote>
<p>所以，投影矩阵为 $P=\frac{aa^T}{|a|^2}$</p>
<h2 id="最小二乘"><a href="#最小二乘" class="headerlink" title="最小二乘"></a>最小二乘</h2><p>若系统 $Ax=b$ 无解，则其最小二乘解（残差最小）为 $\hat{x}=(A^TA)^{-1}A^T b$，其投影 $p=A\hat{x}=A(A^TA)^{-1}A^T b$。</p>
<h2 id="正交基（重点）"><a href="#正交基（重点）" class="headerlink" title="正交基（重点）"></a>正交基（重点）</h2><p>正交矩阵 $Q$ 满足 $Q^TQ=I$，即 $Q$ 的每一列（向量）组成了 $\mathbb{R}^n$ 的标准正交基。</p>
<h2 id="Gram-Schmidt-正交化"><a href="#Gram-Schmidt-正交化" class="headerlink" title="Gram-Schmidt 正交化"></a>Gram-Schmidt 正交化</h2><ul>
<li>基本思想：从每一个新向量中扣除其在已知方向上的投影分量</li>
<li>步骤：<ol>
<li>求投影（正交化）</li>
<li>求标准基（单位化）</li>
</ol>
</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{l}<br>&amp;A_j=a_j-(q_1^T a_j)q_1-(q_2^T a_j)q_2—\cdots -(q_{j-1}^T a_j)q_{j-1} \\<br>&amp;q_j=\frac{A_j}{|A_j|}<br>\end{array}<br>$</p>

</blockquote>
<h2 id="QR-分解（重点）"><a href="#QR-分解（重点）" class="headerlink" title="QR 分解（重点）"></a>QR 分解（重点）</h2><p>$A=QR$</p>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{l}<br>A= \left[\begin{array}{c} a&amp;b&amp;c \end{array}\right]=\left[\begin{array}{c} q_1 &amp; q_2 &amp; q_3 \end{array}\right]\left[\begin{array}{c} q_1^Ta &amp; q_1^Tb &amp; q_1^Tc \\ &amp; q_2^Tb &amp; q_2^Tc \\ &amp;&amp; q_3^Tc \end{array}\right]=QR<br>\end{array}<br>$</p>

</blockquote>
<blockquote>
<p>$Q$ 可通过 Gram-Schmidt 过程求得，$R$ 通过 $R=Q^TA$ 求得。</p>
</blockquote>
<h1 id="第四章-行列式"><a href="#第四章-行列式" class="headerlink" title="第四章 行列式"></a>第四章 行列式</h1><p>略。</p>
<h1 id="第五章-特征值与特征向量"><a href="#第五章-特征值与特征向量" class="headerlink" title="第五章 特征值与特征向量"></a>第五章 特征值与特征向量</h1><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>定义：设 $A$ 为 $n$ 阶矩阵。若存在一个非零向量 $x$ 和标量 $\lambda$ 满足 $Ax=\lambda x$ ，则称 $\lambda$ 为 $A$ 的一个特征值，$x$ 为 $\lambda$ 对应的特征向量。</p>
<p>定义：设 $A=[a_{ij}]_{n\times n}$ 为 $n$ 阶方阵：</p>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{l}<br>f(\lambda)=|A-\lambda I|=\left|\begin{array}{c} a_{11}-\lambda &amp; a_{12} &amp; \cdots &amp; a_{1n} \\ a_{21} &amp; a_{22}-\lambda &amp; \cdots &amp; a_{2n} \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ a_{n1} &amp; a_{n2} &amp; \cdots &amp; a_{nn}-\lambda \end{array}\right|<br>\end{array}<br>$</p>

</blockquote>
<p>为 $A$ 的特征多项式。</p>
<ul>
<li>求特征值和特征向量的方法：<ul>
<li>计算 A 的特征多项式</li>
<li>求出全部根（特征值）</li>
<li>带入特征方程求出特征向量</li>
</ul>
</li>
<li>特征值的性质：以矩阵 $A$ 的所有特征值为例<ul>
<li>特征值之积：$\prod_{i}\lambda_i=|A|$</li>
<li>特征值之和：$\sum_{i}\lambda_i=trace(A)$，称为 $A$ 的迹</li>
</ul>
</li>
</ul>
<h2 id="矩阵对角化"><a href="#矩阵对角化" class="headerlink" title="矩阵对角化"></a>矩阵对角化</h2><p>定义：$\exists S,\ S^{-1}AS=\Lambda\Rightarrow$ 矩阵 $A$ 可对角化（$\Lambda$ 是对角矩阵，对角元为 $A$ 的特征值）</p>
<p>概念：</p>
<ul>
<li>代数重数：特征值 $\lambda_i$ 的最大重复数</li>
<li>几何重数：$\lambda_i$ 对应的特征子空间（即 $A-\lambda_i I$ 的零空间）的维数</li>
</ul>
<p>定理：</p>
<ul>
<li>当且仅当对于 $A$ 的每个特征值 $\lambda_i$，几何重数等于（一般是小于等于）代数重数时，矩阵 $A$ 可对角化</li>
<li>定义中 $S$ 的第 $j$ 列是 $A$ 的第 $j$ 个特征值所对应的特征向量</li>
<li>设 $A$，$B$ 为同阶可对角化矩阵，当且仅当 $AB=BA$ 时，它们有相同的特征向量。</li>
</ul>
<h2 id="复矩阵"><a href="#复矩阵" class="headerlink" title="复矩阵"></a>复矩阵</h2><p>概念：</p>
<ul>
<li>共轭：$z=a+ib \to \bar{z}=a-ib$</li>
<li>极坐标：$\begin{array}{l} &amp;a+ib=r(\cos{\theta}+i\sin{\theta})=re^{i\theta} \\ &amp;a-ib=r(\cos{\theta}-i\sin{\theta})=re^{-i\theta} \end{array}$</li>
</ul>
<p>极坐标简化运算：$(a+bi)\times (c+di)=re^{i\theta}\times Re^{i\alpha} \to$ 模长为 $rR$，角度为 $\theta +\alpha$</p>
<p><strong>厄米特矩阵 (Hermitian Matrix)</strong></p>
<p>定义1：对于一复数矩阵 $A$，其转置为 $\bar{A}^T$，称为 $A$ 的厄米特矩阵，记为 $A^H$ 。</p>
<p>定义2：若矩阵 $A$ 满足 $A^H=A$，则称 $A$ 是厄米特矩阵。</p>
<h2 id="三种对角化分解"><a href="#三种对角化分解" class="headerlink" title="三种对角化分解"></a>三种对角化分解</h2><ul>
<li><font color="red">可对角化矩阵</font>可以用<font color="blue">可逆矩阵</font>进行对角化：$A=S\Lambda S^{-1}$</li>
<li><font color="red">实对称矩阵</font>可以用<font color="blue">正交矩阵</font>进行对角化：$A=Q\Lambda Q^T$</li>
<li><font color="red">厄米特矩阵</font>可以用<font color="blue">酉矩阵</font>进行对角化：$A=U\Lambda U^H$<ul>
<li>酉矩阵是满足 $U^H=U^{-1}$ 的矩阵</li>
</ul>
</li>
</ul>
<h2 id="相似矩阵"><a href="#相似矩阵" class="headerlink" title="相似矩阵"></a>相似矩阵</h2><p>定义：若矩阵 $A$，$B$ 满足 $B=MAM^{-1}$（其中，$M$ 是可逆矩阵），则称 $A$ 与 $B$ 相似，记为 $A\sim B$。</p>
<p>定理：</p>
<ol>
<li>$A$ 和 $B$ 有相同的特征值。</li>
<li>当且仅当 $M^{-1}v$ 是 $B$ 的一个特征向量时，$v$ 是 $A$ 的特征向量。</li>
<li>$A$ 和 $B$ 有相同的行列式、秩和迹。</li>
</ol>
<p><strong>相似变换</strong></p>
<p>定理：同一个线性变换在两组基下的表示矩阵 $A$ 和 $B$ 是相似的</p>
<p>证明：令 $V=\mathbb{R}^2$ ，$T$ 为 $V$ 的一个线性变换；又设另一组基 $\{w_1,w_2\}$，证明如下</p>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{l}<br>&amp;T(v_1)=a_{11}v_1+a_{12}v_2\ \ \ \ T(v_2)=a_{21}v_1+a_{22}v_2 \\<br>\therefore &amp;\left[\begin{array}{c}Tv_1&amp;Tv_2\end{array}\right]=\left[\begin{array}{c}v_1&amp;v_2\end{array}\right]\left[\begin{array}{c}a_{11}&amp;a_{21} \\ a_{12}&amp;a_{22}\end{array}\right]=\left[\begin{array}{c}v_1&amp;v_2\end{array}\right]A \\<br>\because &amp;\left\{\begin{array}{l}&amp;w_1=m_{11}v_1+m_{12}v_2 \\ &amp;w_2=m_{21}v_1+m_{22}v_2 \end{array}\right. \\<br>\therefore &amp;\left[\begin{array}{c}w_1&amp;w_2\end{array}\right]=\left[\begin{array}{c}v_1&amp;v_2\end{array}\right]M \\<br>&amp;\left[\begin{array}{c}Tw_1&amp;Tw_2\end{array}\right]=\left[\begin{array}{c}Tv_1&amp;Tv_2\end{array}\right]M \\<br>\text{also }\because &amp;\left[\begin{array}{c}Tw_1&amp;Tw_2\end{array}\right]=\left[\begin{array}{c}w_1&amp;w_2\end{array}\right]B \\<br>\therefore &amp;MB=AM \Rightarrow B=M^{-1}AM\text{(相似)}<br>\end{array}<br>$</p>

</blockquote>
<h2 id="舒尔定理"><a href="#舒尔定理" class="headerlink" title="舒尔定理"></a>舒尔定理</h2><p>对一个 $n$ 阶方阵 $A$，总有一个酉矩阵 $U$，令 $U^{-1}AU=T$，$T$ 为与 $A$ 相似的三角矩阵，且对角线上的值是 $A$ 的特征值</p>
<p>推论：当 $A$ 为厄米特矩阵时，$T^H=(U^{-1}AU)^H=U^{-1}A^H U=T$。$T$ 是对角矩阵（证明了谱定律：$A=A^H \Rightarrow A$ 是可对角化的）</p>
<h1 id="第六章-正定矩阵"><a href="#第六章-正定矩阵" class="headerlink" title="第六章 正定矩阵"></a>第六章 正定矩阵</h1><h2 id="二次型"><a href="#二次型" class="headerlink" title="二次型"></a>二次型</h2><blockquote class="blockquote-center">
<p>$<br>f(x,y)=ax^2+2bxy+cy^2<br>$</p>

</blockquote>
<ul>
<li>当且仅当 $ac\gt b^2$ 且 $a\gt 0(a\lt 0)$ 时，$f(x,y)$ 为正定（负定），存在唯一最小（最大）值【定点】</li>
<li>若 $ac=b^2$，则根据 $a$ 的值称为半正定/半负定，存在不唯一最小（最大）值</li>
<li>当 $ac\lt b^2$，称二次型 $f$ 不定，此时二次型所过定点非最大也非最小，称为<font color="red">鞍点</font></li>
</ul>
<p>二次型的另一种表示：($A$ 是实对称矩阵)</p>
<blockquote class="blockquote-center">
<p>$<br>ax^2+2bxy+cy^2=\left[\begin{array}{c}x&amp;y\end{array}\right]\left[\begin{array}{c}a&amp;b \\ b&amp;c\end{array}\right]\left[\begin{array}{c}x \\ y\end{array}\right]=x^TAx<br>$</p>

</blockquote>
<blockquote>
<p>正定二次型所对应矩阵 $A$ 为正定矩阵 </p>
</blockquote>
<h2 id="主轴定理（重点）"><a href="#主轴定理（重点）" class="headerlink" title="主轴定理（重点）"></a>主轴定理（重点）</h2><p>定义：</p>
<p>设 $A_{n\times n}$ 为实对称矩阵则有一个变换 $x=Qy$（ 为正交矩阵），将二次型 $x^T Ax$ 转变为 $y^T\Lambda y$（不含交叉乘积项），通过这种变换，可以得到一个标准二次型 $y^T\Lambda y=\lambda_1y_1^2+\lambda_2y_2^2+\cdots +\lambda_n y_n^2$。</p>
<p>例：设 $A=\left[\begin{array}{c}5&amp;-2 \\ -2&amp;5\end{array}\right]$ ，即 $x^T Ax=5x_1^2-4x_1x_2+5x_2^2$ 。可求得 $A$ 的特征值是 $3$ 和 $7$，对应的特征向量为 $u_1=\left[\begin{array}{c}1/\sqrt{2} \\ 1/\sqrt{2}\end{array}\right]$ 和 $u_2=\left[\begin{array}{c}-1/\sqrt{2} \\ 1/\sqrt{2}\end{array}\right]$。</p>
<p>令 $Q=\left[\begin{array}{c}u_1&amp;u_2\end{array}\right]=\left[\begin{array}{c}1/\sqrt{2}&amp;-1/\sqrt{2} \\ 1/\sqrt{2}&amp;1/\sqrt{2}\end{array}\right]$，由 $x=Qy$ 得：$y^T\Lambda y=3y_1^2+7y_2^2$。</p>
<blockquote>
<p>用法：将实对称矩阵 $A$ 正交对角化：$A=Q\Lambda Q^T$。再通过 $y=Q^T x$ 得到 $y$。</p>
</blockquote>
<h2 id="合同变换法"><a href="#合同变换法" class="headerlink" title="合同变换法"></a>合同变换法</h2><p>思路：任意 n 阶实对称矩阵 A，都存在可逆矩阵 C，使得 $C^TAC=diag(d_1,d_2,\cdots,d_n)$。通过对矩阵 $A$ 的初等行/列变换，可以得到合同变换矩阵 $C$ 和变换后的矩阵 $D=C^TAC$</p>
<blockquote class="blockquote-center">
<p>$<br>\left[\begin{array}{c}C^T&amp;0 \\ 0&amp;I\end{array}\right]\left[\begin{array}{c}A \\ I\end{array}\right]C=\left[\begin{array}{c}C^TAC \\ C\end{array}\right]=\left[\begin{array}{c}D \\ C\end{array}\right]<br>$</p>

</blockquote>
<p>由此可见，用正交变换法得到的标准型并不唯一（参考主轴定理）。标准型不唯一，但是标准型的正负号个数不变。</p>
<h2 id="奇异值分解（重点）"><a href="#奇异值分解（重点）" class="headerlink" title="奇异值分解（重点）"></a>奇异值分解（重点）</h2><p>思路：当矩阵非方阵时，不可进行特征值分解（正交对角化）。此时可以进行奇异值分解。</p>
<p>定义：可对任意矩阵进行奇异值分解（SVD）：</p>
<blockquote class="blockquote-center">
<p>$<br>A=U\Sigma V^T<br>$</p>

</blockquote>
<p>其中，$\Sigma$ 为 $m\times n$ 对角阵（非方阵），其对角线处非零元素记为 $\sigma_1,\sigma_2.\cdots,\sigma_r$ ，这些元素称为 $A$ 的奇异值，也是 $AA^T$ 的特征值的平方根。</p>
<ul>
<li>正交矩阵 $U$：$m$ 行 $n$ 列，每个向量是 $AA^T$ 的特征向量；</li>
<li>正交矩阵 $V$：$n$ 行 $n$ 列，每个向量是 $A^TA$ 的特征向量。</li>
</ul>
]]></content>
      <categories>
        <category>2022 Fall</category>
      </categories>
      <tags>
        <tag>Maths</tag>
      </tags>
  </entry>
  <entry>
    <title>MA234 大数据导论与实践（三）</title>
    <url>/2024/08/29/Big-Data-3/</url>
    <content><![CDATA[<h1 id="Big-Data-III"><a href="#Big-Data-III" class="headerlink" title="Big Data (III)"></a>Big Data (III)</h1><h2 id="VI-Ensemble-Methods-集成方法"><a href="#VI-Ensemble-Methods-集成方法" class="headerlink" title="VI. Ensemble Methods (集成方法)"></a>VI. Ensemble Methods (集成方法)</h2><ul>
<li>Two commonly used ensemble methods<ul>
<li><strong>Bagging</strong><ul>
<li>Random sampling : generating independent models, and averaging for regressions (making majority vote for classifications) [随机采样进行建模]</li>
<li><font color="red">Reducing variances(方差)</font></li>
<li>E.g. <em>Random Forest</em></li>
</ul>
</li>
<li><strong>Boosting</strong><ul>
<li>Sequential training : training the subsequent models based on the errors of previous models <font color="grey">[复盘“错误”]</font></li>
<li><font color="red">Reducing bias(误差)</font></li>
<li>E.g. AdaBoost and GBDT</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Bagging"><a href="#Bagging" class="headerlink" title="Bagging"></a>Bagging</h3><p><strong>Algorithm</strong></p>
<ul>
<li>Input : training set $D = \{(x_1, y_1), …,(x_N, y_N)\}$</li>
<li>Output : additive model $\hat{f}_\text{bag} (x)$</li>
</ul>
<ol>
<li>For $m = 1$ to $M$ :<ol>
<li>Sample from $D$ with replacement to obtain $D_m$</li>
<li><font color="red">Train a model</font> $\hat f_m(x)$ from the dataset $D_m$ : for <font color="#4a4aff">classification</font>, $\hat f_m(x)$ returns a $K$-class 0-1 vector $e_k$ ; for <font color="#4a4aff">regression</font>, it is just a value</li>
</ol>
</li>
<li>Compute <strong>bagging estimate</strong> $\hat{f}_\text{bag} (x)=\frac{1}{M} \sum_{m=1}^{M} \hat f_m(x) $<ol>
<li>for <font color="#4a4aff">classification</font>, make majority vote $\hat{G}_\text{bag}(x)=\arg\max_k \hat f_k(x)$</li>
<li>for <font color="#4a4aff">regression</font>,  just return <font color="red">the average value</font></li>
</ol>
</li>
</ol>
<p><strong>Variance Reduction</strong></p>
<ul>
<li>In bagging, we use the same model to train different sample set in each iteration ; assume the models $\{\hat f_m(x)\}_{m=1}^{M}$ have the <font color="red">same variance</font> $\sigma^2 (x)$, while the <font color="red">correlation</font> of each pair is $\rho(x)$ </li>
<li>Then the variance of the final model is :</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{l}<br>\text{Var}(\hat{f}_{bag}(x)) &amp;= \frac{1}{M^2}\left(\sum_{m=1}^{M}\text{Var}(\hat{f}_m(x)) + \sum_{t\neq m}\text{Cov}(\hat{f}_t(x)\hat{f}_m(x))\right) \\ &amp;= \rho(x)\sigma^2(x) + \frac{1-\rho(x)}{M}\sigma^2(x)<br>\end{array}<br>$</p>

</blockquote>
<ul>
<li>As $M\to\infty$ , $\text{Var}(\hat f_{bag}(x))\to \rho(x)\sigma^2(x)$ . This usually <font color="red">reduces the variance</font>.</li>
<li>If $\rho(x)=0$ , the variance approach zero.</li>
<li>The <font color="red">random sampling</font> in bagging is to reduce the correlation $ρ(x)$, i.e., make the sub-predictors as independent as possible</li>
</ul>
<h4>Random Forest</h4>

<ul>
<li>More randomness on <strong>Decision Tree</strong> : avoid local optimal<ul>
<li>Sampling on the <font color="blue">training data</font> with replacement</li>
<li>Select <font color="blue">features</font> at random</li>
</ul>
</li>
<li>Example : RF consisting of $3$ independent trees, each with an error rate of $40\%$. Then the probability that more than one tree misclassify the samples is $0.4^3 + 3 <em> 0.4^2 </em> (1 − 0.4) = 0.352$</li>
<li><strong>Algorithm</strong><ul>
<li>Input : training set $D =\{(x_1,y_1),(x_2,y_2),…,(x_N,y_N)\}$</li>
<li>Output : additive model $\hat{f}_{\text{rf}}(x)$</li>
</ul>
<ol>
<li>For $m = 1$ to $M$ :<ol>
<li>Sample from $D$ with replacement to obtain $D_m$</li>
<li>Grow a random-forest tree $T_m$ to the dataset $D_m$ : by recursively repeating the following steps for each terminal node of the tree, until the minimum node size $n_{min}$ is reached<ul>
<li>Select $q$ features at <font color="red">random</font> from the $p$ features</li>
<li>Pick the best feature/split-point among the $q$</li>
<li>Split the node into two daughter nodes</li>
</ul>
</li>
</ol>
</li>
<li>Output the ensemble of trees $\{T_m\}_{m=1}^M$ : for <font color="blue">regression</font>, $\hat{f}_rf(x) = \frac{1}{M} \sum_{m=1}^M T_m(x)$; for <font color="blue">classification</font>, make majority vote</li>
</ol>
</li>
<li><font color="red">Small value</font> of $q$ increases the <font color="red">independency</font> of trees;  empirically, $q = \log_2 p + 1$</li>
</ul>
<h4>Model Evaluation</h4>

<ul>
<li><strong>Out-of-bag (OOB)</strong> errors : The observation is called out-of-bag sample to some trees if it is <font color="red">not sampled</font> for those trees. Denote the training set in the m-th sampling by $D_m$. <em>OOB error</em> is computed as :<ol>
<li>For each observation $(x_i, y_i)$, find the trees which treat it as OOB sample : <br>$\{\hat T_m(\textbf{x}) : (\textbf{x}_i, y_i) \notin D_m \}$</li>
<li>Use those trees to classify this observation and make majority vote as the label of this observation :<br>$\hat{f}_\text{oob}(\textbf{x}_i)=\arg\underset{y\in\mathcal Y}\max \sum_{m=1}^{M} I(\hat{f}_{m}(\textbf{x}_{i})=y)I(\textbf{x}_{i} \notin D_{m})$</li>
<li>Compute the number of misclassified samples, and take the ratio of this number to the total number of samples as OOB error : <br>$Err_{oob}=\frac{1}{N} \sum_{m=1}^{M} I(\hat{f}_{oob}(\textbf{x}_i) \not = y_i)$</li>
</ol>
</li>
</ul>
<blockquote>
<p>Q: OOB 数据是否指所有生成的树都没有选择到的数据？</p>
<p>Q: 第二步为什么不是 $I(\hat f_m(\textbf{x}_i)=y \wedge \textbf{x}_i\notin D_m)$ ?</p>
</blockquote>
<ul>
<li><strong>Pros</strong><ul>
<li>Bagging or random forest (RF) work for models with high variance but low bias (<font color="red">deal with overfitting</font>)</li>
<li>Better for <font color="red">nonlinear</font> estimators</li>
<li>RF works for very <font color="red">high-dimensional data</font>, and no need to do feature selection as RF gives the feature importance</li>
<li>Easy to do <font color="red">parallel computing</font></li>
</ul>
</li>
<li><strong>Cons</strong><ul>
<li>Overfitting when the samples are large-sized with <font color="blue">great noise</font>, or when the dimension of data is low</li>
<li>Slow computing performance comparing to single tree</li>
<li><font color="red">Hard to interpret</font>

</li>
</ul>
</li>
</ul>
<hr>
<h3 id="Boosting-amp-AdaBoost"><a href="#Boosting-amp-AdaBoost" class="headerlink" title="Boosting &amp; AdaBoost"></a>Boosting &amp; AdaBoost</h3><blockquote>
<p>Principle : Combines the outputs of many <font color="blue">“weak” classifiers</font> to produce a powerful “committee”</p>
<p><font color="blue">Weak classifiers</font> : error rate $&lt; 0.5$ (random guessing)</p>
</blockquote>
<table>
    <tr><td><img align="left" src="/2024/08/29/Big-Data-3/bd36.png" style="zoom:100%"></td>
        <td><font color="red">Sequentially</font> apply the weak classifiers to the repeatedly modified data, emphasizing the misclassified samples<br><br>
        Combine weak classifiers through a weighted majority vote or averaging to produce the final prediction</td></tr>
</table>



<font size="4">Boosting fits an additive model</font>

<ul>
<li>Additive Model : $f(x)=\sum_{m=1}^{M}\beta_m b(x;\gamma_m)$  where $\gamma$ is the parameter of basic function, $\beta$ is the coefficient.</li>
<li>Possible choices for <font color="blue">basis function</font> $b(x;\gamma_m)$<ul>
<li>Neural Network : $\sigma(\gamma_0+\gamma_1^T x)$ , where $\sigma(t)=1/(1+e^{-t})$</li>
<li>Wavelets</li>
<li>Cubic Spline Basis</li>
<li>Trees</li>
<li>Eigenfunctions in reproducing kernel Hilbert space (RKHS)</li>
</ul>
</li>
<li><strong>Parameter fitting</strong> : $\underset{\{ \beta_m,\gamma_m\}} \min \sum_{i=1}^{N} L(y_i,\sum_{m=1}^{M}\beta_m b(x_i;\gamma_m))$</li>
<li>Loss function : <font color="red">squared error $L(y, f (x)) = (y − f (x))^2$</font> or likelihood-based loss</li>
</ul>
<p><b><font size="4">Forward <font color="red">Stagewise</font> Additive Model&lt;/font&gt;</font></b></p>
<blockquote>
<p>Difference between “Forward Stepwise” and “Forward Stagewise”</p>
<ul>
<li>Stepwise regression initialize model with all predictors(forward) or no predictors(backward), and then iteratively <font color="red">adds or removes</font> variables based on a defined criterion(e.g. AIC and BIC)</li>
<li><strong>Stagewise</strong> regression initialize model with all predictors, and then in each iteration, it <font color="red">adjusts the coefficients</font> of the predictors by a small amount in the direction that improves the model’s performance.</li>
</ul>
<p><strong>Stagewise</strong> regression is designed to be more robust to multicollinearity and can produce more stable and interpretable models compared to stepwise regression.<br>Useful when there are many potential predictors, and the goal is to identify the most important ones while maintaining model stability.</p>
</blockquote>
<p><strong>Algorithm</strong></p>
<ul>
<li>Input : training set $D =\{(x_1,y_1),(x_2,y_2),…,(x_N,y_N)\}$</li>
<li>Output : additive model $f_M(x)$</li>
</ul>
<ol>
<li>Initialize $f_0(x)=0$</li>
<li>For $m=1$ to $M$ :<br> 2.1. Compute $(\beta_m,\gamma_m)=\underset{\beta ,\gamma}{\arg\min} \sum_{i=1}^{N} L(y_i,f_{m-1}(x_i)+\beta b(x_i;\gamma))$<br> 2.2. Update $f_m(x)=f_{m-1}(x)+\beta_m b(x_i;\gamma_m)$</li>
</ol>
<p>Squared error loss in step 2.1:</p>
<blockquote class="blockquote-center">
<p>$<br>L(y_i,f_{m-1}(x_i)+\beta b(x_i;\gamma))=\underbrace{(y_i-f_{m-1}(x_i))}_{\text{residual}}-\beta b(x_i;\gamma)^2<br>$</p>

</blockquote>
<blockquote>
<p>What if we use Exponential loss in step 2.1 ?</p>
</blockquote>
<ul>
<li>Exponential loss : $L(y,f(x))=\exp(-yf(x))$</li>
<li><font color="blue">Classifier</font> as basis function : $b(x; \gamma) = G(x) \in \{−1, 1\}$</li>
<li>Let $w_i^{(m)}=\exp(-y_i f_{m-1}(x_i))$ , then step 2.1 turn to be :</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\begin{align}{l}<br>(\beta_m, G_m) &amp;= \arg \min_{\beta, G} \sum_{i=1}^{n} w_i^{(m)} \exp(-\beta y_i G(x_i))\\<br>&amp;=\arg \min_{\beta, G} \left[ \sum_{y_i \neq G(x_i)} w_i^{(m)} (e^{\beta} - e^{-\beta}) + e^{-\beta} \sum_{i=1}^{n} w_i^{(m)} \right]<br>\end {align}<br>$</p>

</blockquote>
<ul>
<li>We get $\beta_m$ and $G_m$ separately :</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\begin{align}{l}<br>G_m &amp;= \arg \min_G \sum_{i=1}^{n} w_i^{(m)} I(y_i \neq G(x_i)) \\<br>\beta_m &amp;= \arg \min_{\beta} \left[ \epsilon_m (e^{\beta} - e^{-\beta}) + e^{-\beta} \right] = \frac{1}{2} \log \frac{1-\epsilon_m}{\epsilon_m} \\<br>\epsilon_m &amp;= \left(\left(\sum_{i=1}^{n} w_i^{(m)} I(y_i \neq G(x_i))\right) \left/\right. \sum_{i=1}^{n} w_i^{(m)}\right)<br>\end{align}<br>$</p>

</blockquote>
<p>where $\epsilon_m$ is weighted error rate.</p>
<h4>AdaBoost Algorithm</h4>

<table><tr>
<td><img align="center" src="/2024/08/29/Big-Data-3/bd37.png" style="zoom:50%"></td>
<td><img align="center" src="/2024/08/29/Big-Data-3/bd38.png" style="zoom:90%"></td>
</tr></table>

<h5>Loss Functions</h5>

<ul>
<li>For classification, exponential loss and binomial negative log-likelihood (deviance) loss $\log(1 + \exp(−2yf))$ share the same population minimizer ; thus it is equivalent to MLE rule</li>
<li>For classification, squared error loss is not good (not monotonically decreasing) ; the exponential loss is good and binomial deviance is better (less penalty for large $−yf$)</li>
</ul>
<hr>
<h3 id="Gradient-Boosting-Decision-Tree-GBDT"><a href="#Gradient-Boosting-Decision-Tree-GBDT" class="headerlink" title="Gradient Boosting Decision Tree (GBDT)"></a>Gradient Boosting Decision Tree (GBDT)</h3><center><h4>Boosting Tree</h4></center>

<ul>
<li>Using classification trees or regression trees as <font color="blue">base learners</font></li>
<li>$f_M(x) = \sum_{m=1}^{M} T(x; \Theta_m)$ where $T(x; \Theta) = \sum_{j=1}^{J} \gamma_j I(x \in R_j)$ <font color="grey">[树的表示方法：代表将输入空间划分为$J$个互不相交的区域$R_1,\cdots,R_J$，并在每个区域上确定输出的常量$\gamma_j$。所以$J$代表树的复杂度即叶节点个数 ]</font></li>
<li>Parameter set $\Theta = \{R_j, \gamma_j\}_{j=1}^{J}$ </li>
<li>Parameter finding : minimizing the empirical risk </li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{rl}<br>&amp;\hat{\Theta} = \arg \min_{\Theta} \sum_{j=1}^{J} \sum_{x_i \in R_j} L(y_i, \gamma_j) \qquad &amp;\text{Combinatorial optimization}<br>\end{array}<br>$</p>

</blockquote>
<ul>
<li>Approximate suboptimal solutions : <ol>
<li>Finding $\gamma_j$ given $R_j$ : $\gamma_j = \bar{y}_j = \frac{1}{|R_j|} \sum_{y_i \in R_j} y_i$   for $L^2$ loss ; and  $\gamma_j =$ modal class in $R_j$   for misclassification loss </li>
<li>Finding $R_j$ given $\gamma_j$ : Difficult, need to estimate $\gamma_j$ as well ;<br>greedy, top-down recursive partitioning algorithm</li>
</ol>
</li>
</ul>
<center><h4>Boosting Tree as Forward Stagewise Algorithm</h4></center>

<ul>
<li>$\hat{\Theta}_m = \arg \min_{\Theta_m} \sum_{i=1}^{N} L(y_i, f_{m-1}(x_i) + T(x_i; \Theta_m))$<ol>
<li>$\hat{\gamma}_{jm} = \arg \min_{\gamma_{jm}} \sum_{x_i \in R_{jm}} L(y_i, f_{m-1}(x_i) + \gamma_{jm})$</li>
<li>Finding $R_{jm}$ is more difficult than for a single tree in general.</li>
</ol>
</li>
<li>Squared-error loss : fit a tree to the residual<br> $L(y_i, f_{m-1}(x_i) + T(x_i; \Theta_m)) = (y_i - f_{m-1}(x_i) - T(x_i; \Theta_m))^2$</li>
<li>Two-class classification and exponential loss : AdaBoost for trees, <ul>
<li>$\hat{\Theta}_m = \arg \min_{\Theta_m} \sum_{i=1}^{N} w_i^{(m)} \exp[-y_i T(x_i; \Theta_m)]$</li>
</ul>
</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\hat{\gamma}_{jm} = \log \Large\frac{\sum_{x_i \in R_{jm}} w_i^{(m)} l(y_i = 1)}{\sum_{x_i \in R_{jm}} w_i^{(m)} l(y_i = -1)}<br>$</p>

</blockquote>
<ul>
<li>Absolute error or the Huber loss : robust but slow</li>
</ul>
<center><h4>Gradient Descent for General Loss</h4></center>

<ul>
<li>Supervised learning is equivalent to the optimization problem</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\min_{f}L(f)=\min_{f}\sum_{i=1}^{N}L(y_i,f(x_i))<br>$</p>

</blockquote>
<ul>
<li>Numberical optimization : $\hat{\textbf{f}}=\arg\min_{\textbf{f}}L(\textbf{f})$  where  $\textbf{f}=\{f(x_1),f(x_2),\cdots,f(x_N)\}$ </li>
<li>Appriximate $\hat{\textbf{f}}$ by $\textbf{f}_M=\sum_{m=0}^{M} \textbf{h}_m$ , where $\textbf{f}_0=\textbf{h}_0$ is <font color="red">the initial guess</font>.</li>
<li>Gradient Descent method : $\textbf{f}_m=\textbf{f}_{m-1}-\rho_m \textbf{g}_m$  , where $g_{im}=\left[\frac{\partial L(y_i,f(x_i))}{\partial f(x_i)} \right]_{f(x_i)=f_{m-1}(x_i)}$  , and $\textbf{h}_m=-\rho_m\textbf{g}_m$ .</li>
<li>Here $\color{red}\rho_m$ is the learning rate, and $\color{red}\textbf{g}_m$ is the <font color="red">gradient of the target function</font> $\color{red}L(f)$ at the point $f(x_i)$ . So $\rho_m$ decides the <font color="blue">step length</font> of the gradient.</li>
</ul>
<blockquote>
<p>Usage of Gradient Descent on <strong>Decision Tree</strong></p>
<ul>
<li>Find a Tree $T(x;\Theta_m)$ by minimization problem :</li>
</ul>
</blockquote>
<blockquote class="blockquote-center">
<p>$<br>\tilde{\Theta}_m=\arg\min_{\Theta_m}\sum_{i=1}^{N}(-g_{im}-T(x_i;\Theta_m))^2<br>$</p>

</blockquote>
<blockquote>
<p>In general, $\tilde{R}_{jm}\not=R_{jm}$ </p>
</blockquote>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">Setting</th>
<th style="text-align:center">Loss Function</th>
<th style="text-align:center">$-\partial L(y_i,f(x_i))/\partial f(x_i)$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Regression</td>
<td style="text-align:center">$\frac{1}{2}\left[y_i-f(x_i) \right]^2$</td>
<td style="text-align:center">$y_i-f(x_i)$</td>
</tr>
<tr>
<td style="text-align:center">Regression</td>
<td style="text-align:center">$\lvert y_i-f(x_i)\rvert$</td>
<td style="text-align:center">$\text{sign}\left[y_i-f(x_i) \right]$</td>
</tr>
<tr>
<td style="text-align:center">Regression</td>
<td style="text-align:center">Huber</td>
<td style="text-align:center">$y_i-f(x_i)$  for $\lvert y_i-f(x_i)\rvert \le \delta_m$<br>$\delta_m\text{sign}\left[y_i-f(x_i) \right]$  for $\lvert y_i-f(x_i)\rvert \gt \delta_m$ <br>where $\delta_m=\alpha^{\text{th}}$-quantile $\{\lvert y_i-f(x_i)\rvert \}$</td>
</tr>
<tr>
<td style="text-align:center">Classification</td>
<td style="text-align:center">Deviance</td>
<td style="text-align:center">$k^{th}$ component: $I(y_i=\mathcal G_k)-p_k(x_i)$</td>
</tr>
</tbody>
</table>
</div>
<center><h4>GBDT Algorithm</h4></center>

<ul>
<li>Input : training set $D = \{(x_1, y_1), \ldots, (x_N, y_N)\}$, loss function $L(y, f(x))$</li>
<li>Output : boosting tree $\hat{f}(x)$</li>
</ul>
<ol>
<li>Initialize $f_0(x) = \arg\min_\gamma \sum_{i=1}^{N} L(y_i, \gamma)$</li>
<li>For $m = 1$ to $M$ : <ol>
<li>For $i = 1, 2, \ldots, N$ compute $r_{im} = \bigg[\frac{\partial L(y_i,f(x_i))}{\partial f(x_i)}\bigg]_{f=f_{m-1}}$</li>
<li>Fit a regression tree to the target residual $r_{im}$, giving terminal regions $R_{jm}$ (表示第 j 个样本在第 m 个基模型上的残差) , $j = 1, \ldots, J_m$ </li>
<li>For $j = 1, \ldots, J_m$, compute $\gamma_{jm} = \arg\min_\gamma \sum_{x_i \in R_{jm}} L(y_i, f_{m-1}(x_i) + \gamma)$</li>
<li>Update $f_m(x) = f_{m-1}(x) + \sum_{j=1}^{J_m} \gamma_{jm}I(x_i \in R_{jm})$</li>
</ol>
</li>
<li>$\hat{f}(x) = f_M(x)$</li>
</ol>
<p><strong>Regularization</strong></p>
<ul>
<li><p><font color="red">Shrinkage</font> : the step 2.4 is modified as $f_m(x) = f_{m-1}(x) + \nu \sum_{j=1}^{J_m} \gamma_{jm}I(x_i \in R_{jm})$</p>
</li>
<li><p><font color="red">Subsampling</font> : at each iteration, sample a fraction $\eta$ of the training set and grow the next tree using the subsample</p>
</li>
<li><p>Shrinkage + subsampling : best performance</p>
</li>
</ul>
<p><strong>Feature importance and Partial Dependence Plots</strong></p>
<ul>
<li>Feature importance<ul>
<li>When fitting a single tree $T$, at each node $t$, one feature $X_{v(t)}$ and one separate value $X_{v(t)} = c_{v(t)}$ are chosen to improve a certain quantity of criterion (e.g. GINI, entropy, squared error, etc.)</li>
<li>Sum all these improvements $i_t$ brought by each feature $X_k$ over all internal nodes: $I_k(T) = \sum_{t=1}^{J-1} i_t I(v(t) = k)$</li>
<li>Average the improvements of all trees $\Rightarrow$ importance of that feature: $I_k=\frac{1}{M} \sum_{m=1}^{M} I_k(T_m)$</li>
</ul>
</li>
<li>Partial Dependence Plots<ul>
<li>Partial dependence of $f(X)$ on $X_S$ : $f_S(X_S) = E_{X_C}f(X_S, X_C)$</li>
<li>Estimate by empirical mean : $\hat{f}_S(X_S) = \frac{1}{N} \sum_{i=1}^{N} f(X_S, X_{iC})$</li>
</ul>
</li>
</ul>
<hr>
<h2 id="VII-Clustering"><a href="#VII-Clustering" class="headerlink" title="VII. Clustering"></a>VII. Clustering</h2><ul>
<li>Different from classification : it is <font color="red">unsupervised learning</font> ; no outputs or labels</li>
<li>Central goal : Optimize the similarity (or dissimilarity) between the individual objects being clustered :<ul>
<li>Obtain <font color="blue">great similarity</font> of samples <font color="blue">within</font> cluster</li>
<li>Obtain <font color="#c4c400">small similarity</font> of samples <font color="#c4c400">between</font> clusters</li>
</ul>
</li>
<li>Cost functions : not related to the outputs, but related to the similarity</li>
<li>Two kinds of input data :<ul>
<li>$n × n$ similarity (dissimilarity) matrix $D$ : only depends on the distances between pairs of samples ; may lose some information on data</li>
<li>Original data with features $X \in R^{n×d}$</li>
</ul>
</li>
</ul>
<h3 id="K-Mean-Clustering"><a href="#K-Mean-Clustering" class="headerlink" title="K-Mean Clustering"></a>K-Mean Clustering</h3><center><font size="5">Idea</font></center>

<ul>
<li>Data set $\{x_i\}_{i=1}^n$, $x_i \in \mathbb{R}^d$</li>
<li>Representatives : Mass center of $k$th-cluster $C_k$ is $c_k$, $k = 1, \ldots, K$</li>
<li>Sample $x_i$ belongs to cluster $k$ if $d(x_i, c_k) &lt; d(x_i, c_m)$ for $m \neq k$, where $d(x_i, x_j)$ is dissimilarity function</li>
<li>Make the mass centers well-located so that the average distance between each sample to its cluster center is as small as possible</li>
</ul>
<center><img src="/2024/08/29/Big-Data-3/bd39.png" style="zoom:90%"></center>



<center><font size="5">Optimization Problem</font></center>

<ul>
<li>Let $C : \{1, \ldots, n\} \rightarrow \{1, \ldots, k\}$ be the assignment from the data indices to the cluster indices. $C(i) = k$ means $x_i \in C_k$</li>
<li>Total point scatter : <ul>
<li>$T = \frac{1}{2} \sum_{i=1}^{n} \sum_{j=1}^{n} d(x_i, x_j) =\frac{1}{2} \sum_{k=1}^{K} \sum_{C(i)=k}\left( \sum_{C(j)=k} d_{ij} + \sum_{C(j)\neq k} d_{ij}\right) = W(C) + B(C)$</li>
</ul>
</li>
<li>Loss function ($d$ is the distance) :<ul>
<li>within-cluster point scatter $W(C) = \frac{1}{2} \sum_{k=1}^{K} \sum_{C(i)=k} \sum_{C(j)=k} d_{ij}$ ; </li>
<li>between-cluster point scatter $B(C) = \frac{1}{2} \sum_{k=1}^{K} \sum_{C(i)=k} \sum_{C(j)\neq k} d_{ij}$</li>
</ul>
</li>
<li>Minimize $W(C)$ is equivalent to maximize $B(C)$</li>
</ul>
<h4 id="Hierarchical-Clustering"><a href="#Hierarchical-Clustering" class="headerlink" title="Hierarchical Clustering"></a>Hierarchical Clustering</h4><ul>
<li>Clustering in different hierarchies, generating tree structure </li>
<li>Two approaches : <ul>
<li><font color="blue">Agglomerate clustering : bottom-up</font></li>
<li><font color="blue">Divisive clustering : top-down</font> </li>
</ul>
</li>
<li>Limitation : once merged or divided, the operation cannot be modified</li>
</ul>
<h5>Agglomerate Clustering</h5>

<ul>
<li><p>Given n samples and proximity matrix, do the following steps : </p>
<ol>
<li>Let every observation represent a singleton cluster </li>
<li>Merge the two closest clusters into one single cluster </li>
<li>Calculate the new proximity matrix (dissimilarity between two clusters) </li>
<li>Repeat step 2 and 3, until all samples are merged into one cluster </li>
</ol>
</li>
<li><p>Three methods for computing intergroup dissimilarity : </p>
<ul>
<li>Single linkage (SL) </li>
<li>Complete linkage (CL) </li>
<li>Average linkage (AL)</li>
</ul>
</li>
</ul>
<h5>Generalized Agglomerative Scheme</h5>

<p>()</p>
<h3 id="DBSCAN"><a href="#DBSCAN" class="headerlink" title="DBSCAN"></a>DBSCAN</h3><center><font size="5">Concept</font></center>

<ul>
<li>Three type of points :<ul>
<li><strong>Core point</strong> : # of samples in its $\epsilon$-neighborhood $&gt; \text{MinPts}$</li>
<li><strong>Boundary point</strong> : it lies in the $\epsilon$-neighborhood of some core point, # of samples in its $\epsilon$-neighborhood $&lt; \text{MinPts}$ </li>
<li><strong>Noise point</strong> : neither core point nor boundary point, it lies in the sparse region</li>
</ul>
</li>
</ul>
<center><img src="/2024/08/29/Big-Data-3/bd40.png" style="zoom:70%"></center>





<h3 id="Model-Assessment"><a href="#Model-Assessment" class="headerlink" title="Model Assessment"></a>Model Assessment</h3><center><font size="5">Purity</font></center>

<p><strong>Def.</strong> Total purity defined as </p>
<blockquote class="blockquote-center">
<p>$<br>\text{Purity}\triangleq \sum_i \frac{n_i}{n}p_i=\sum_i\frac{n_i}{n}(\max_j p_{ij})<br>$</p>

</blockquote>
<p>E.g. $\text{purity}=\frac{6}{17}\cdot \frac{4}{6}+\frac{6}{17}\cdot\frac{5}{6}+\frac{5}{17}\cdot\frac{3}{5}=0.71$ </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">|-------|-------|--------|</span><br><span class="line">| A B B | A A A |  A  A  |</span><br><span class="line">|       |       |        |</span><br><span class="line">| B B C | A A B | C C C  |</span><br><span class="line">|-------|-------|--------|</span><br></pre></td></tr></table></figure>
<center><font size="5">Confusion Matrix</font></center>

<div>
<img src="/2024/08/29/Big-Data-3/bd41.png" style="zoom:70%">
</div>
]]></content>
      <categories>
        <category>2024 Spring</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>CSE Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>CS305 计算机网络</title>
    <url>/2024/09/09/Computer-Networks/</url>
    <content><![CDATA[<h1 id="Chapter-1-Introduction"><a href="#Chapter-1-Introduction" class="headerlink" title="Chapter 1: Introduction"></a>Chapter 1: Introduction</h1><HR style="FILTER: alpha(opacity=0, finishopacity=100,style=1)" width="100%" color="black" size="2">

<center><font face="STXinwei" size="5">Layout</font></center>

<p><strong>1.1</strong> what is the Internet?</p>
<p><strong>1.2</strong> network edge</p>
<ul>
<li>end systems, access networks, links</li>
</ul>
<p><strong>1.3</strong> network core</p>
<ul>
<li>packet switching, circuit switching, network, structure</li>
</ul>
<p><strong>1.4</strong> delay, loss, throughput in networks</p>
<p><strong>1.5</strong> protocol layers, service models</p>
<p><strong>1.6</strong> networks under attack: security</p>
<HR style="FILTER: alpha(opacity=0,finishopacity=100,style=1)" width="100%" color="black" size="2">



<blockquote>
<p>Learning top-down, we have 5 layer about computer network</p>
</blockquote>
<ul>
<li>Application: supporting network applications<ul>
<li>IMAP, SMTP, HTTP</li>
</ul>
</li>
<li>Transport: process-process data transfer<ul>
<li>TCP, UDP</li>
</ul>
</li>
<li>Network: routing of datagrams from source to destination<ul>
<li>IP, routing protocols</li>
</ul>
</li>
<li>Link: data transfer between neighboring  network elements<ul>
<li>Ethernet, 802.11 (WiFi), P2P</li>
</ul>
</li>
<li>Physical: bits “on the wire”</li>
</ul>
<h2 id="1-1-Structure-of-Internet"><a href="#1-1-Structure-of-Internet" class="headerlink" title="1.1. Structure of Internet"></a>1.1. Structure of Internet</h2><table>
<tr>
<td><img src="/2024/09/09/Computer-Networks/cn1.png" style="zoom:60%"></td>
<td><img src="/2024/09/09/Computer-Networks/cn2.png" style="zoom:60%"></td>
</tr>
</table>



<h2 id="1-2-Network-edge"><a href="#1-2-Network-edge" class="headerlink" title="1.2. Network edge"></a>1.2. Network edge</h2><ul>
<li>end systems (hosts):<ul>
<li>run application programs</li>
<li>e.g. Web, email</li>
<li>at “edge of network”</li>
</ul>
</li>
<li>client/server model<ul>
<li>client host requests, receives service from always-on server</li>
<li>e.g., Web browser/server; email client/server</li>
</ul>
</li>
<li>peer-peer model:<ul>
<li>minimal (or no) use of dedicated servers</li>
<li>e.g. Skype,  BitTorrent</li>
</ul>
</li>
</ul>
<p><strong>Hosts: sends packets of data</strong></p>
<p>Host sending function:</p>
<ul>
<li>takes application message</li>
<li>breaks into smaller chunks, known as packets, of length $L$ bits</li>
<li>transmits packet into access network at transmission rate $R$<ul>
<li>aka link capacity, bandwidth (即链路容量或带宽)</li>
</ul>
</li>
</ul>
<p><img src="/2024/09/09/Computer-Networks/cn3.png" style="zoom:80%"></p>
<blockquote class="blockquote-center">
<p>$<br>\text{packet transmission delay}=\frac{L\text{(bits)}}{R\text{(bits/sec)}}<br>$</p>

</blockquote>
<h2 id="Plus-Access-Networks-接入网"><a href="#Plus-Access-Networks-接入网" class="headerlink" title="Plus: Access Networks(接入网)"></a>Plus: Access Networks(接入网)</h2><p><strong>Def.</strong> The network that physically connects an <font color="red">end system</font> to the <font color="red">first router (edge router)</font> on a path from the end system to any other distant end system.</p>
<p>Different kinds of access networks:</p>
<ul>
<li>Cable network</li>
<li>Digital subscriber line (DSL)</li>
<li>Home network</li>
<li>Wireless access network</li>
<li>Enterprise access network</li>
</ul>
<p><strong>Cable network</strong></p>
<p><img src="/2024/09/09/Computer-Networks/cn4.png" style="zoom:60%"></p>
<ul>
<li>Cable Internet access makes use of the cable television company’s existing <font color="blue">cable television infrastructure</font>.</li>
<li>Shared broadcast medium<ul>
<li>Shared downstream and upstream</li>
<li>Distributed multiple access control: avoid collision (分频段控制)</li>
</ul>
</li>
<li>Applying Frequency division multiplexing (频分复用)</li>
<li>Hybrid fiber coax (HFC): fiber + coaxial cable (光纤+同轴电缆)<ul>
<li>asymmetric: up to 30 Mbps downstream transmission rate(下行传输效率), 2 Mbps upstream transmission rate</li>
</ul>
</li>
<li>network of cable, fiber attaches homes to ISP router<ul>
<li>homes share access network to cable headend(多家庭网络接入同一电缆头部)</li>
</ul>
</li>
</ul>
<p><strong>DSL(digital subscriber line)</strong></p>
<ul>
<li>Digital subscriber line (DSL) makes use of the its wired local phone(有线本地电话) access of local telephone company (telco).</li>
<li>Use existing telephone line to central office DSLAM<ul>
<li>data over DSL phone line goes to Internet</li>
<li>voice over DSL phone line goes to telephone net</li>
</ul>
</li>
<li>&lt; 2.5 Mbps upstream transmission rate (typically &lt; 1 Mbps)</li>
<li>&lt; 24 Mbps downstream transmission rate (typically &lt; 10 Mbps)</li>
</ul>
<p><strong>Wireless Access Network</strong></p>
<ul>
<li>Shared wireless access network connects end systems to router<ul>
<li>via base station aka “access point”</li>
</ul>
</li>
<li>Wireless LANs(WLAN):<ul>
<li>within building (100 ft)</li>
<li>802.11b/g/n/ac (WiFi): 11, 54, 800, 1733 Mbps transmission rate</li>
</ul>
</li>
<li>Wide-area wireless access<ul>
<li>provide by telco (cellular) operator</li>
<li>10 Mbps, 100Mbps, 10Gbps </li>
<li>3G, 4G, 5G</li>
</ul>
</li>
</ul>
<blockquote>
<p>补充：信号传输物理介质</p>
<ul>
<li>单位：bit</li>
<li>有向介质<ul>
<li>固体介质如铜，光纤和同轴缆线</li>
</ul>
</li>
<li>无向介质<ul>
<li>无线电</li>
</ul>
</li>
</ul>
</blockquote>
<h2 id="1-3-Network-Core-网络核心"><a href="#1-3-Network-Core-网络核心" class="headerlink" title="1.3. Network Core(网络核心)"></a>1.3. Network Core(网络核心)</h2><p><strong>Def.</strong>  The mesh(链路网格) of packet switches and links that interconnects the Internet’s end systems.</p>
<h3 id="Packet-switching-vs-Circuit-switching"><a href="#Packet-switching-vs-Circuit-switching" class="headerlink" title="Packet switching vs. Circuit switching"></a>Packet switching vs. Circuit switching</h3><p><strong>Packet Switching</strong></p>
<p>Basic thought: Hosts break long messages into packets and each packet is forwarded independently.</p>
<p><img src="/2024/09/09/Computer-Networks/cn5.png" style="zoom:60%"></p>
<ul>
<li><font color="red">store-and-forward</font></li>
<li>each packet is transmitted at <font color="red">full link capacity</font></li>
<li><font color="red">not reserved</font> → queueing delay and packet loss<ul>
<li>queuing delay: packets will queue, wait to be transmitted on link</li>
<li>packet loss(丢包): packets can be dropped (lost) if memory (buffer) fills up</li>
</ul>
</li>
</ul>
<blockquote>
<p>Make it clear: what’s routing ? what’s forwarding ?</p>
<p><font color="red">Routing</font> is global actions: determine source-destination paths taken by packets, and need routing algorithm</p>
<p><font color="red">Forwarding</font> is local actions (inside 1 router): move arriving packets from router’s input link to appropriate router output link</p>
</blockquote>
<p><strong>Circuit Switching: FDM vs. TDM</strong></p>
<p>Basic thought: Determine path before the message being transmitted (called).</p>
<ul>
<li>Advantage: Guaranteed constant rate</li>
<li>Reserved (dedicated resources): buffer, link</li>
<li>Limitation: Circuit idle（空闲）if not used by call (no sharing)</li>
</ul>
<ul>
<li>About <strong>FDM</strong>(频分复用) and <strong>TDM</strong>(时分复用)<ul>
<li>FDM divides frequencies into (narrow) frequency bands → bandwidth<ul>
<li>transmit at max rate of that narrow band</li>
</ul>
</li>
<li>TDM divides time into slots<ul>
<li>at maximum rate of (wider) frequency band, but only during its time slot(s)</li>
<li>have T virtual links in each frame (graph below)</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="/2024/09/09/Computer-Networks/cn6.png" style="zoom:60%"></p>
<p>An example to calculate delay in <strong>Circuit Switching</strong>: </p>
<p><img src="/2024/09/09/Computer-Networks/cn7.png" style="zoom:60%"></p>
<p align="center">----- COMPARISON -----</p>

<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">Packet Switching</th>
<th style="text-align:center">Circuit Switching</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">not reserved</td>
<td style="text-align:center">reserved (dedicated resources):<br>buffer, link, transmission rate</td>
</tr>
<tr>
<td style="text-align:center">packet forwarded independently(每步独立)</td>
<td style="text-align:center">establish an end-to-end link</td>
</tr>
<tr>
<td style="text-align:center">at full link capacity</td>
<td style="text-align:center">a fraction of each link’s capacity</td>
</tr>
<tr>
<td style="text-align:center">queuing delay</td>
<td style="text-align:center">guaranteed constant rate</td>
</tr>
<tr>
<td style="text-align:center">packet loss</td>
<td style="text-align:center">circuit segment idle</td>
</tr>
</tbody>
</table>
</div>
<blockquote>
<p>Therefore, Packet Switching is more used in network(more users but have low prob to online at the same time), Circuit Switching is more used in telephone call(assuring rate and connection).</p>
</blockquote>
<h3 id="Network-Structure"><a href="#Network-Structure" class="headerlink" title="Network Structure"></a>Network Structure</h3><p><img src="/2024/09/09/Computer-Networks/cn8.png" style="zoom:60%"></p>
<ul>
<li>Different ISPs from different business</li>
<li><font color="red">Internet exchange point(IXP)</font> as a connection between ISPs, or direct linking by <font color="red">peering links</font></li>
<li>Regional network may arise to connect access nets to ISPs</li>
<li><font color="red">Content provider networks</font>(e.g. Google, Microsoft) may run their own network, to bring services, content close to end users.</li>
</ul>
<h2 id="1-4-Performance-Metric"><a href="#1-4-Performance-Metric" class="headerlink" title="1.4. Performance Metric"></a>1.4. Performance Metric</h2><ul>
<li>Delay<ul>
<li>Nodal delay &amp; end-to-end delay</li>
</ul>
</li>
<li>Packet Loss</li>
<li>Throughput<ul>
<li>the amount of data per second that can be transferred between end systems</li>
</ul>
</li>
</ul>
<font color="green">Recall: Packet Switching would make packets queuing at each router(delay), if a router is full, the new packet would be dropped(loss).</font>



<h3 id="Delay-Nodal-vs-End-to-end"><a href="#Delay-Nodal-vs-End-to-end" class="headerlink" title="Delay: Nodal vs. End-to-end"></a>Delay: Nodal vs. End-to-end</h3><p><strong>Nodal Delay</strong></p>
<blockquote class="blockquote-center">
<p>$<br>d_{\text{nodal}}=d_{\text{proc}}+d_{\text{queue}}+d_{\text{trans}}+d_{\text{prop}}<br>$</p>

</blockquote>
<ul>
<li>$d_{\text{proc}}$ : nodal processing<ul>
<li>check bit errors</li>
<li>determine output link</li>
<li>typically &lt; 1 msec</li>
</ul>
</li>
<li>$d_{\text{queue}}$ : <ul>
<li>time waiting at output link for transmission </li>
<li>depends on congestion(拥堵) level of router</li>
</ul>
</li>
<li>$d_{\text{trans}}$ : 传输时延<ul>
<li>$L$: packet length (bits) </li>
<li>$R$: transmission rate (bps)</li>
<li>$d_{\text{trans}} = L/R$</li>
</ul>
</li>
<li>$d_{\text{prop}}$ : 传播时延<ul>
<li>$d$: length of physical link</li>
<li>$s$: propagation speed in medium (~$2x10^8$ m/sec)</li>
<li>$d_{\text{prop}} = d/s$</li>
</ul>
</li>
</ul>
<blockquote>
<p>Easy way to understand $d_{\text{trans}}$ and $d_{\text{prop}}$</p>
<p>Assume that a ten-car caravan(packets) is moving through tollbooth (end/routers). Think of a car as a bit data.<br>Suppose that the Tollbooth takes 12 sec to service one car (transmission time) and cars runs at a speed of 100 km/hr (propagation speed).</p>
<font color="red">Q: How long does it take the <b>last car</b> to arrive at the 2nd tollbooth?</font>

<p>Now the time to “push” entire caravan through tollbooth onto highway = 12 * 10 = 120 sec, known as <font color="blue">Transmission Delay</font>;</p>
<p>The time for last car to propagate from 1st to 2nd tollbooth: 100km / (100km/hr) = 1 hr, known as <font color="blue">Propagation Delay</font>.</p>
<font color="green">A: 62 mins</font>



</blockquote>
<ul>
<li>Special: Queuing Delay — Vary from packet to packet<ul>
<li>When characterizing queuing delay, statistical measures:<ul>
<li>average queuing delay</li>
<li>variance of queuing delay</li>
<li>the probability that the queuing delay exceeds some specified value</li>
</ul>
</li>
<li>Use Traffic intensity $=\lambda L / R$ to measure avg queuing delay.<ul>
<li>$\lambda$ : average packet arrival rate (packets per sec)</li>
<li>$\lambda L / R \to 0$: avg. queueing delay small</li>
<li>$\lambda L / R \to 1$: avg. queueing delay $\to \infty$ (queuing theory)</li>
<li>$\lambda L / R \gt 1$: more “work” arriving than can be serviced, average delay infinite!</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>End-to-end Delay</strong></p>
<blockquote class="blockquote-center">
<p>$<br>d_{\text{end-end}}=N(d_{\text{proc}}+d_{\text{trans}}+d_{\text{prop}})<br>$</p>

</blockquote>
<p align="center">What do "real" Internet delay & loss look like?</p>

<blockquote>
<p>Refer to <a href="#lab01">Lab 1</a></p>
</blockquote>
<h3 id="Throughput-吞吐量"><a href="#Throughput-吞吐量" class="headerlink" title="Throughput(吞吐量)"></a>Throughput(吞吐量)</h3><p><strong>Def.</strong> rate (bits/time unit) at which bits transferred between sender/receiver.</p>
<blockquote>
<p>Throughput is decided by the pipe with minimum fluid-carry-rate.</p>
</blockquote>
<ul>
<li>More complex condition: 10 connections (fairly) share backbone bottleneck link R bits/sec<ul>
<li>Per-connection end-end throughput: $\min{\{R_c, R_s, R/10\}}$</li>
<li>In practice: $R_c$ or $R_s$ is often bottleneck</li>
</ul>
</li>
</ul>
<p><img src="/2024/09/09/Computer-Networks/cn9.png" style="zoom:40%"></p>
<h2 id="1-5-Protocol-layers-amp-Service-models"><a href="#1-5-Protocol-layers-amp-Service-models" class="headerlink" title="1.5. Protocol layers &amp; Service models"></a>1.5. Protocol layers &amp; Service models</h2><blockquote>
<font color="red">Q: Why layering?</font>

<p>To deal with complex systems: </p>
<ul>
<li>Explicit structure allows identification, relationship of complex system’s pieces</li>
<li>modularization eases maintenance, updating of system</li>
</ul>
<font color="red">Q: Any drawbacks?</font>

<ul>
<li>One layer may duplicate lower layer functionality</li>
<li>Functionality at one layer may need information that is present only in another layer</li>
</ul>
</blockquote>
<ul>
<li>An easy model to describe how networks layering:</li>
</ul>
<p><img src="/2024/09/09/Computer-Networks/cn10.png" style="zoom:60%"></p>
<ul>
<li>Layers: Each layer provide services to the layer above<ul>
<li>via its own internal-layer actions</li>
<li>relying on services provided by layer below</li>
</ul>
</li>
</ul>
<p><strong>Encapsulation</strong></p>
<ul>
<li>Used to keep content of data safe and assure the layer below to acquire enough info to transmit.</li>
</ul>
<p><img src="/2024/09/09/Computer-Networks/cn11.png" style="zoom:40%"></p>
<h2 id="1-6-Security"><a href="#1-6-Security" class="headerlink" title="1.6. Security"></a>1.6. Security</h2><p><strong>Attack Type</strong></p>
<ol>
<li>Malware(恶意软件) into hosts via Internet<ul>
<li>virus</li>
<li>worm</li>
</ul>
</li>
<li>Attack server: Denial of Service(DoS), make resources(server, bandwidth) unavailable to legitimate(合法的) traffic by overwhelming resource with bogus(伪造的) traffic.<ul>
<li>aka. 更改 domain 地址</li>
</ul>
</li>
<li>Sniff packets(拆包，拦截):<ul>
<li>broadcast media</li>
<li>read all packets passing by</li>
</ul>
</li>
<li>Use fake addresses:<ul>
<li>send packet with false source address</li>
</ul>
</li>
</ol>
<p><strong>Defense Lines</strong></p>
<ul>
<li>authentication</li>
<li>confidentiality(密保): via encryption</li>
<li>integrity checks(多重检测)</li>
<li>access restrictions</li>
<li>firewalls: <ul>
<li>off-by-default: filter packets</li>
<li>detecting / reacting to DoS attacks</li>
</ul>
</li>
</ul>
<h1 id="Chapter-2-Application-Layer"><a href="#Chapter-2-Application-Layer" class="headerlink" title="Chapter 2: Application Layer"></a>Chapter 2: Application Layer</h1><HR style="FILTER: alpha(opacity=0, finishopacity=100,style=1)" width="100%" color="black" size="2">

<center><font face="STXinwei" size="5">Layout</font></center>

<p><strong>2.1</strong> principles of network applications</p>
<p><strong>2.2</strong> Web and HTTP</p>
<p><strong>2.3</strong> Electronic mail</p>
<ul>
<li>SMTP, POP3, IMAP</li>
</ul>
<p><strong>2.4</strong> DNS</p>
<p><strong>2.5</strong> P2P applications</p>
<p><strong>2.6</strong> video streaming and content distribution networks</p>
<p><strong>2.7</strong> socket programming with UDP and TCP</p>
<HR style="FILTER: alpha(opacity=0, finishopacity=100,style=1)" width="100%" color="black" size="2">

<blockquote>
<p>Learning Goals: </p>
<p>有关网络应用协议的概念与实现：包括用户-服务端架构，peer-to-peer 架构和传输层服务模型</p>
<p>学习一些广泛使用的应用层协议：如HTTP，POP3，DNS等</p>
<p>学习如何搭建简单网络应用：assignment 1 相关，用 python 建立用户-服务端之间的相互通信</p>
</blockquote>
<h2 id="2-1-Principles-of-network-applications"><a href="#2-1-Principles-of-network-applications" class="headerlink" title="2.1. Principles of network applications"></a>2.1. Principles of network applications</h2><ul>
<li>Consider building a network application :<ul>
<li><font color="red">Q1: Which architecture?</font> client-server or peer-to-peer?</li>
<li><font color="red">Q2: Which transport layer protocol to choose?</font> TCP? UDP?</li>
<li><font color="red">Q3: Which protocol to follow?</font> HTTP for Web? SMTP for email? Customized?</li>
</ul>
</li>
</ul>
<h3 id="Architecture-of-network"><a href="#Architecture-of-network" class="headerlink" title="Architecture of network"></a>Architecture of network</h3><p><strong>Client-Server Architecture</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">Server</th>
<th style="text-align:center">Client</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">always-on host</td>
<td style="text-align:center">communicate with server(can shutdown)</td>
</tr>
<tr>
<td style="text-align:center">permanent(fixed, well-known) IP address</td>
<td style="text-align:center">may have dynamic IP addresses</td>
</tr>
<tr>
<td style="text-align:center">data centers for scaling</td>
<td style="text-align:center">no direct communication with each other</td>
</tr>
</tbody>
</table>
</div>
<p><strong>P2P Architecture</strong></p>
<ul>
<li><em>no</em> always-in server, directly communicate</li>
<li>peers <em>request</em> service from other peers, <em>provide</em> service in return to otehr peers<ul>
<li><font color="red">self scalability:</font> new peers bring new service capacity and new service demands</li>
</ul>
</li>
</ul>
<blockquote>
<p>Hybrid arch: client-server + P2P</p>
</blockquote>
<h3 id="Transport-layer-protocol"><a href="#Transport-layer-protocol" class="headerlink" title="Transport layer protocol"></a>Transport layer protocol</h3><blockquote>
<p>Q: How do apps (at end systems) exchange messages? (E.g. how does a browser exchange message with a server?)</p>
<p>A: Split to 2 questions:</p>
<ul>
<li><font color="red">Who send/recv msg to/from network?</font> <font color="green">Process(进程)</font></li>
<li><font color="red">Where does process send/recv msg to/from?</font> <font color="green">Sockets(套接字)</font>

</li>
</ul>
</blockquote>
<p>Comparison:</p>
<ol>
<li><ul>
<li>Processes within same host communicate using  <font color="red">inter-process communication</font> (defined by OS)</li>
<li>Processes in different hosts communicate by exchanging messages across the <font color="red">computer network</font></li>
</ul>
</li>
<li><ul>
<li><strong>client process:</strong> process that initiates communication (发送方轮询)</li>
<li><strong>server process:</strong> process that waits to be contacted (接收方阻塞)</li>
</ul>
</li>
<li>(2) is compatible in :<ul>
<li>Client-server architecture</li>
<li>P2P architectures having client processes &amp; server processes</li>
</ul>
</li>
</ol>
<h4 id="Interface-between-Process-and-Computer-Networks-Sockets"><a href="#Interface-between-Process-and-Computer-Networks-Sockets" class="headerlink" title="Interface between Process and Computer Networks: Sockets"></a>Interface between Process and Computer Networks: Sockets</h4><p><img src="/2024/09/09/Computer-Networks/cn12.png"></p>
<ul>
<li><p>Process sends/receives messages to/from the network through socket</p>
<ul>
<li><font color="blue">sending process</font> shoves(推送) message <strong>“out door”</strong></li>
<li><font color="blue">sending process</font> relies on transport infrastructure (on other side of door) to deliver message to socket at <font color="blue">receiving process</font>
</li>
</ul>
</li>
<li><p>To receive messages, sockets must be identified by</p>
<ul>
<li>The address of the host: <font color="red">IP address</font></li>
<li>An identifier that specifies the receiving process/socket: <font color="red">port numbers</font> (标识进程)</li>
<li>Some default port number:<ul>
<li>HTTP server: 80</li>
<li>HTTPS server: 433</li>
<li>mail server: 25</li>
</ul>
</li>
</ul>
</li>
</ul>
<blockquote>
<font color="red">Q: How to choose transport service?</font>

<font color="green">A: choose one of the available transport-layer protocols (e.g., UDP, TCP)</font>

</blockquote>
<ul>
<li>Measurements for transport service choosing:<ul>
<li>Throughput</li>
<li>Timing</li>
<li>Security</li>
</ul>
</li>
</ul>
<p><img src="/2024/09/09/Computer-Networks/cn13.png"></p>
<ul>
<li>以上是部分应用的需求，下面我们可以看到这些应用选择了哪项传输服务。</li>
</ul>
<h4 id="Brief-looking-on-transport-protocols"><a href="#Brief-looking-on-transport-protocols" class="headerlink" title="Brief looking on transport protocols"></a>Brief looking on transport protocols</h4><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">TCP Service</th>
<th style="text-align:center">UDP Service</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><font color="red">connection-oriented:</font> setup required between client and server processes (TCP connection/full-duplex)</td>
<td style="text-align:center"><font color="red">connectionless</font></td>
</tr>
<tr>
<td style="text-align:center"><font color="red">reliable transport</font> between sending and receiving process</td>
<td style="text-align:center"><font color="red">unreliable data transfer</font> between sending and receiving process</td>
</tr>
<tr>
<td style="text-align:center"><font color="red">congestion(拥堵) control</font>: throttle(阻断) sender when network overloaded</td>
<td style="text-align:center">-</td>
</tr>
<tr>
<td style="text-align:center"><font color="red">no provide</font>: timing, minimum throughput guarantee, security</td>
<td style="text-align:center"><font color="red">no provide</font>: reliability, congestion control, timing, throughput guarantee, security, or connection setup</td>
</tr>
</tbody>
</table>
</div>
<blockquote>
<p>注意！TCP 和 UDP 都不直接保证安全性。TCP 保证连接稳定，UDP 保证传输效率。</p>
<p>UDP 适用于时间敏感的通信中。当遇到丢包比延迟要好的情况时，就使用 UDP 传输。</p>
</blockquote>
<p><img src="/2024/09/09/Computer-Networks/cn14.png"></p>
<h3 id="Application-level-protocols-Brief"><a href="#Application-level-protocols-Brief" class="headerlink" title="Application-level protocols (Brief)"></a>Application-level protocols (Brief)</h3><ul>
<li>App-layer protocol defines<ul>
<li><font color="red">types of messages exchanged</font><ul>
<li>e.g., request, response </li>
</ul>
</li>
<li><font color="red">message syntax (语法)</font><ul>
<li>what fields in messages &amp; how fields are delineated</li>
</ul>
</li>
<li><font color="red">message semantics (语义)</font> <ul>
<li>meaning of information in fields</li>
</ul>
</li>
<li><font color="red">rules</font> for when and how processes send &amp; respond to messages</li>
</ul>
</li>
</ul>
<blockquote>
<p>应用层协议只是应用的一部分：</p>
<p>以 Web 为例：Web 是一个服务端-客户端应用，允许用户从 Web 服务器获取文档，其组成有</p>
<ul>
<li>一个文档标准格式（HTML）</li>
<li>Web 浏览器（Browsers）</li>
<li>Web 服务器</li>
<li>应用层协议</li>
</ul>
</blockquote>
<h2 id="2-2-Web-and-HTTP"><a href="#2-2-Web-and-HTTP" class="headerlink" title="2.2. Web and HTTP"></a>2.2. Web and HTTP</h2><ul>
<li><font color="red">Web page</font> consists of <font color="red">base HTML-file</font> which includes <font color="red">several referenced objects</font></li>
<li>each object is addressable by a <font color="red">URL</font></li>
</ul>
<p><img src="/2024/09/09/Computer-Networks/cn15.png"></p>
<ul>
<li>Web<ul>
<li>client-server architecture</li>
<li>use HTTP as its application layer protocol</li>
</ul>
</li>
<li>HTTP (hypertext transfer protocol) defines <ul>
<li>HTTP request: how <font colo="red">Web clients request</font> Web pages from Web servers</li>
<li>HTTP response: how <font color="red">servers transfer</font> Web pages to clients</li>
</ul>
</li>
</ul>
<table>
    <tr>
        <td><p>Client-server architecture:</p><p><font color="red">client</font>: browser that requests, receives, (using HTTP protocol) and “displays” Web objects</p><p><font color="red">server</font>: Web server sends (using HTTP protocol) objects in response to  requests</p></td>
        <td><img src="/2024/09/09/Computer-Networks/cn16.png"></td>
    </tr>
</table>

<h3 id="HTTP"><a href="#HTTP" class="headerlink" title="HTTP"></a>HTTP</h3><p><strong>Outline</strong></p>
<ul>
<li>HTTP Overview<ul>
<li>HTTP runs over TCP</li>
<li>HTTP is stateless</li>
<li>Persistent and non-persistent connection</li>
</ul>
</li>
<li>Request and response messages</li>
<li>Cookies</li>
<li>Web caching</li>
</ul>
<h4 id="HTTP-overview-TCP"><a href="#HTTP-overview-TCP" class="headerlink" title="HTTP overview: TCP"></a>HTTP overview: TCP</h4><ul>
<li>client initiates TCP connection (creates socket) to server,  port 80</li>
<li>server accepts TCP connection from client</li>
<li>HTTP messages (application-layer protocol messages) exchanged between browser (HTTP client) and Web server (HTTP server)</li>
<li>TCP connection closed</li>
</ul>
<p><img src="/2024/09/09/Computer-Networks/cn17.png"></p>
<p><b><font color="red">HTTP is “stateless” !</font></b></p>
<ul>
<li>Server maintains no information about past client requests.</li>
<li>If a client asks for the same object twice, the server resends the object.</li>
</ul>
<p><b><font color="red">Persistent &amp; non-persistent connection</font></b></p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">persistent HTTP</th>
<th style="text-align:center">non-persistent HTTP</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">multiple objects can be sent over single TCP connection between client and server</td>
<td style="text-align:center">at most one object sent over TCP connection, then connection closed</td>
</tr>
<tr>
<td style="text-align:center">server leaves connection open after sending response;<br>server closes a connection when it isn’t used <font color="red">for a certain time</font></td>
<td style="text-align:center">OS overhead (TCP buffer, variables) for each TCP connection</td>
</tr>
<tr>
<td style="text-align:center">client sends requests <font color="red">as soon as</font> it encounters a referenced object</td>
<td style="text-align:center">browsers often open <font color="red">parallel TCP connections</font> to fetch referenced objects</td>
</tr>
</tbody>
</table>
</div>
<center>-----        Calculation        -----</center>

<blockquote>
<p><strong>Conception.</strong> RTT(round-trip-time) is time for a small packet to travel from client to server and back (一个来回)</p>
</blockquote>
<ul>
<li>For persistent HTTP, time from init TCP conn to, e.g., $n$ times files received is : <blockquote class="blockquote-center">
<p>$<br>\text{Time}=1\text{RTT}+n\times\text{RTT}<br>$</p>

</blockquote></li>
<li>For non-persistent HTTP, is :<blockquote class="blockquote-center">
<p>$<br>\text{Time} = 2\times \text{RTT}<br>$</p>

</blockquote>
</li>
</ul>
<h4 id="Messages"><a href="#Messages" class="headerlink" title="Messages"></a>Messages</h4><ol>
<li>HTTP request messages</li>
</ol>
<table><tr>
    <td><img src="/2024/09/09/Computer-Networks/cn18.png"></td>
    <td><img src="/2024/09/09/Computer-Networks/cn19.png"></td>
</tr><tr>
    <td>Particular case</td>
    <td>General cases</td>
</tr></table>

<ol>
<li>HTTP response messages</li>
</ol>
<table><tr>
    <td><img src="/2024/09/09/Computer-Networks/cn20.png"></td>
    <td><img src="/2024/09/09/Computer-Networks/cn21.png"></td>
</tr><tr>
    <td>Particular case</td>
    <td>General cases</td>
</tr></table>

<p><strong>Status Code</strong></p>
<ul>
<li><code>200 OK</code></li>
<li><code>301 Moved Permanently</code></li>
<li><code>400 Bad Request</code></li>
<li><code>404 Not Found</code></li>
<li><code>505 HTTP Version Not Supported</code></li>
</ul>
<h4 id="Cookies"><a href="#Cookies" class="headerlink" title="Cookies"></a>Cookies</h4><blockquote>
<p>因为 HTTP 是无状态的，但是 Web 应用有保存用户状态的需求，所以需要一个机制识别用户</p>
</blockquote>
<p><img src="/2024/09/09/Computer-Networks/cn22.png"></p>
<blockquote>
<p>Cookies 的工作原理</p>
</blockquote>
<p><img src="/2024/09/09/Computer-Networks/cn23.png"></p>
<ul>
<li>Cookies are associated with <font color="red">web browser</font><ul>
<li>E.g. Suppose “Bob” register for Amazon server, then he get a cookie for himself (user-level), but “Susan” have no cookie for Amazon. If she also register(even in same host), the web browser will store a cookie for her.</li>
</ul>
</li>
<li>Cookies and privacy:<ul>
<li>cookies permit sites to learn a lot about you</li>
<li>you may supply name and e-mail to sites</li>
</ul>
</li>
</ul>
<h4 id="Web-caches-proxy-代理-server"><a href="#Web-caches-proxy-代理-server" class="headerlink" title="Web caches: proxy(代理) server"></a>Web caches: proxy(代理) server</h4><blockquote>
<p>目的：用户无需访问原始服务器来获取资源</p>
</blockquote>
<p><img src="/2024/09/09/Computer-Networks/cn24.png"></p>
<ul>
<li>Cache (Proxy server) acts as both client and server<ul>
<li>server for original requesting client</li>
<li>client to origin server</li>
</ul>
</li>
<li>typically cache is <font color="red">installed by ISP</font> (university, company, residential ISP)</li>
<li>Why Web caching?<ul>
<li><font color="green">reduce <u>response time</u> for client request (bottleneck bandwidth)</font></li>
<li><font color="green"><u>reduce traffic</u> on an institution’s access link</font></li>
<li><font color="green">Internet dense with caches: enables “poor” content providers to <u>effectively deliver content</u> (so does P2P file sharing)</font>



</li>
</ul>
</li>
</ul>
<center>-----        Calculation        -----</center>

<ul>
<li>Assume that<ul>
<li>avg object size: $1M$ bits</li>
<li>avg request rate from browsers to origin servers: $15$ requests/sec</li>
<li>avg data rate to all browsers: $15 Mbps$</li>
<li>RTT from router A to any origin server: 2 sec (Internet delay)</li>
<li>access link rate: $15.4 Mbps$</li>
</ul>
</li>
<li>Consequences:<ul>
<li>LAN utilization: $15Mbps/100Mbps=0.15$</li>
<li>access link utilization: $15/15.4=0.974$</li>
<li>total delay = Internet delay + access delay + LAN delay = $2sec+\text{minutes} + \text{milliseconds}$</li>
</ul>
</li>
</ul>
<table><tr>
    <td><img src="/2024/09/09/Computer-Networks/cn25.png"></td>
    <td><img src="/2024/09/09/Computer-Networks/cn26.png"></td>
</tr><tr>
    <td><center>Large access link</center></td>
    <td><center>Cache server</center></td>
</tr></table>

<ul>
<li>Assume that<ul>
<li>access link rate: 150 Mbps (p1)</li>
</ul>
</li>
<li>Therefore:<ul>
<li>access link utilization: $15/150=0.1$</li>
<li>total delay = $2sec + \text{milliseconds} + \text{milliseconds}$</li>
</ul>
</li>
</ul>
<ul>
<li>Now we have cache server ! (p2)<ul>
<li>suppose cachee hit rate is 0.4 (40% at cache, 60% at origin)</li>
</ul>
</li>
<li>Therefore:<ul>
<li>(avg) data rate to browsers over access link $=0.6\times 15 Mbps=9Mbps$</li>
<li>(avg) access link utilization $=9/15.4=0.58$</li>
<li>avg delay $=0.6\times \text{(delay from origin servers)}+0.4\times \text{(delay when satisfied at  cache)}=0.6\times 2.01 +0.4\times (~msecs) = ~1.2secs$</li>
<li>Conclusion: faster than with 150 Mbps link and cheaper!</li>
</ul>
</li>
</ul>
<center>-----        Calculation End        -----</center>

<blockquote>
<p>Q: 用户向代理服务器请求内容，如果初始服务器的内容更改，而代理服务器的内容未更新，如何解决？</p>
<p>A: Conditional <code>GET</code> → <code>GET</code> method + <code>If-Modified-Since</code></p>
</blockquote>
<ul>
<li>Proxy cache: specify date of cached copy in HTTP request: <code>If-modified-since: &lt;date&gt;</code></li>
<li>Server: response contains no object if cached copy is up-to-date: <code>HTTP/1.0 304 Not Modified</code> or <code>HTTP /1.0 200 OK</code> if modified</li>
</ul>
<p><img src="/2024/09/09/Computer-Networks/cn27.png"></p>
<h2 id="2-3-Electronic-Mail"><a href="#2-3-Electronic-Mail" class="headerlink" title="2.3. Electronic Mail"></a>2.3. Electronic Mail</h2><ul>
<li>Overview<ul>
<li>Main components</li>
<li>Alice sends an email to Bob</li>
</ul>
</li>
<li>SMTP</li>
<li>Mail Message Format</li>
<li>Mail Access Protocol<ul>
<li>POP3</li>
<li>IMAP</li>
<li>HTTP: Web-based Email</li>
</ul>
</li>
</ul>
<h3 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h3><p><img src="/2024/09/09/Computer-Networks/cn28.png"></p>
<p>3 major components:</p>
<ul>
<li>User agents<ul>
<li>Allow users to read, reply to, forward, save and compose messages</li>
<li>e.g. Outlook, iPhone mail client</li>
</ul>
</li>
<li>Mail servers<ul>
<li>Always-on hosts</li>
<li><font color="red">User mailbox</font> contains outgoing, incoming messages</li>
<li><font color="red">Message queue</font> of outgoing (to be sent) mail messages</li>
<li><font color="red">Simple Mail Transfer Protocol (SMTP)</font> between mail servers to send email messages (见上图)</li>
<li>Both client and server sides of SMTP run on mail server.<ul>
<li>client process: sending mail server</li>
<li>server  process: receiving mail server</li>
</ul>
</li>
</ul>
</li>
<li><font color="red">simple mail transfer protocol</font> (SMTP): use TCP</li>
</ul>
<p><strong>Learning by scenario: Alice sends message to Bob</strong></p>
<p><img src="/2024/09/09/Computer-Networks/cn29.png"></p>
<ol>
<li>Alice uses user agent to compose message “to” <code>bob@hamburger.edu</code></li>
<li>Alice’s user agent sends message to her mail server; message placed in message queue</li>
<li>client side of SMTP opens TCP connection with Bob’s mail server</li>
<li>SMTP client sends Alice’s message over the TCP connection</li>
<li>Bob’s mail server places the message in Bob’s mailbox</li>
<li>Bob invokes his user agent to read message</li>
</ol>
<h3 id="Simple-Mail-Transfer-Protocol-SMTP"><a href="#Simple-Mail-Transfer-Protocol-SMTP" class="headerlink" title="Simple Mail Transfer Protocol(SMTP)"></a>Simple Mail Transfer Protocol(SMTP)</h3><table><tr>
    <td><ul><li>Uses TCP to reliably transfer email message from client to server, port 25</li><li>Direct transfer: sending server to receiving server (no intermediate server)</li><li>Three phases of transfer</li><ul><li>handshaking (greeting): indicate email address</li><li>transfer of messages: persistent connection</li><li>closure</li></ul><li>Two types of messages (like HTTP)</li><ul><li>commands: text</li><li>response: status code and phrase</li></ul></ul></td>
    <td><img src="/2024/09/09/Computer-Networks/cn30.png"></td>
</tr></table>



<font color="red">Properties of SMTP :</font>


<ul>
<li>SMTP uses persistent connections</li>
<li>SMTP requires message (header &amp; body) to be in  ASCII</li>
<li>SMTP server uses <font color="red">CRLF</font>(回车换行符) to determine end of message</li>
</ul>
<p>Comparison with HTTP :</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">HTTP</th>
<th style="text-align:center">SMTP</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">pull</td>
<td style="text-align:center">push //TODO</td>
</tr>
<tr>
<td style="text-align:center">ASCII in header</td>
<td style="text-align:center">ASCII in header and body</td>
</tr>
<tr>
<td style="text-align:center">each object encapsulated in its own response message</td>
<td style="text-align:center">multiple objects sent in one message</td>
</tr>
</tbody>
</table>
</div>
<p><img src="/2024/09/09/Computer-Networks/cn31.png"></p>
<blockquote>
<font color="red">Q: Why not having mail servers directly on user’s local PC?</font>

<font color="green">A: Mail server manages mailboxes and runs the client and server sides of SMTP. (Bob's PC have to remain always on in order to receive new mail)</font>

</blockquote>
<p><img src="/2024/09/09/Computer-Networks/cn32.png"></p>
<blockquote>
<font color="red">Q: Why not letting Alice send to Bob’s mail server directly?</font>

<p><font color="green">A: Bob’s mail server may fail; need to repeatedly send the message until success.</font> // TODO</p>
</blockquote>
<h3 id="Mail-Message-Format"><a href="#Mail-Message-Format" class="headerlink" title="Mail Message Format"></a>Mail Message Format</h3><blockquote>
<p>How do you write an e-mail …</p>
<p>Header lines, e.g., <code>To:</code>, <code>From:</code>, <code>Subject:</code>, etc.<br>Body, the messages</p>
</blockquote>
<h3 id="Mail-Access-Protocol"><a href="#Mail-Access-Protocol" class="headerlink" title="Mail Access Protocol"></a>Mail Access Protocol</h3><blockquote>
<p>Well, <code>SMTP</code> is used to delivery mail to receiver’s server (a push operation), but how does Bob obtain the mail ?</p>
</blockquote>
<p><img src="/2024/09/09/Computer-Networks/cn33.png"></p>
<ul>
<li><strong>POP3</strong>: Post Office Protocol 3: authorization, download <ul>
<li><font color="blue">TCP, port 110(未加密) or 995(加密)</font></li>
</ul>
</li>
<li><strong>IMAP</strong>: Internet Mail Access Protocol: more features, including maintain folders, keep user state</li>
<li><strong>HTTP</strong>: gmail, Hotmail, Yahoo! Mail, etc. [Web-based Email]</li>
</ul>
<ul>
<li>More about <code>POP3</code> ——</li>
<li>Authorization phase<ul>
<li>client commands: <ul>
<li><code>user</code>: declare username</li>
<li><code>pass</code>: password</li>
</ul>
</li>
<li>server responses<ul>
<li><code>+OK</code></li>
<li><code>-ERR</code></li>
</ul>
</li>
</ul>
</li>
<li>Transaction phase<ul>
<li>client:<ul>
<li><code>list</code>: list message numbers</li>
<li><code>retr</code>: retrieve message by number</li>
<li><code>dele</code>: delete</li>
<li><code>quit</code></li>
</ul>
</li>
</ul>
</li>
<li><p>Update phase (After <code>Quit</code>, the mail server deletes the messages marked as deletion)</p>
</li>
<li><p>比较 POP3 和 IMAP</p>
</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">POP3</th>
<th style="text-align:center">IMAP</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">邮件下载到本地设备，通常在下载后会从服务器上删除</td>
<td style="text-align:center">邮件保留在服务器上，用户可以在多个设备上访问同一封邮件</td>
</tr>
<tr>
<td style="text-align:center">不支持在多个设备之间同步邮件</td>
<td style="text-align:center">能够保持所有设备之间的邮件（状态）一致性</td>
</tr>
<tr>
<td style="text-align:center">通常不支持文件夹管理</td>
<td style="text-align:center">支持文件夹管理</td>
</tr>
<tr>
<td style="text-align:center">下载后可以在没有互联网的情况下查看邮件</td>
<td style="text-align:center">设计用于在线访问，包括搜索、标记等操作</td>
</tr>
</tbody>
</table>
</div>
<h2 id="2-4-Domain-Name-System-DNS-重点"><a href="#2-4-Domain-Name-System-DNS-重点" class="headerlink" title="2.4. Domain Name System(DNS) [重点!]"></a>2.4. Domain Name System(DNS) [重点!]</h2><ul>
<li>DNS Services</li>
<li>DNS Structure<ul>
<li>Hierarchical structure</li>
<li>Iterated and recursive query</li>
</ul>
</li>
<li>DNS protocol<ul>
<li>DNS Records</li>
<li>Query and reply messages</li>
</ul>
</li>
<li>Inserting records into DNS</li>
</ul>
<h3 id="DNS-Services"><a href="#DNS-Services" class="headerlink" title="DNS Services"></a>DNS Services</h3><p><strong>Def.</strong> hostname to IP address translation</p>
<ul>
<li>Host aliasing<ul>
<li><code>www.ibm.com</code> (alias) is really <code>servereast.backup2.ibm.com</code> (canonical 本名)</li>
</ul>
</li>
<li>load distribution<ul>
<li>replicated Web servers: many IP addresses correspond to one name (多个 IP 共享一个名字)</li>
<li>rotation distributes the traffic (作用是减轻负担)</li>
</ul>
</li>
</ul>
<blockquote>
<p>How does APPs invoke DNS Service?</p>
</blockquote>
<ol>
<li>An application invokes the client side of DNS<ul>
<li>specifying the hostname that needs to be translated</li>
</ul>
</li>
<li>DNS in the user’s host takes over, sending a query message into the network. <ul>
<li>DNS query and reply messages </li>
<li><font color="blue">UDP datagrams to port 53.</font> (faster)</li>
</ul>
</li>
<li>After a delay, ranging from milliseconds to seconds, DNS in the user’s host receives a DNS reply message that provides the desired mapping.</li>
<li>The <font color="red">mapping (hostname - IP)</font> is then passed to the invoking application.</li>
</ol>
<h3 id="DNS-Structure"><a href="#DNS-Structure" class="headerlink" title="DNS Structure"></a>DNS Structure</h3><blockquote>
<p>为何分层级？</p>
<p>考虑到容错率（单点报错），速度或地区访问差异等。</p>
</blockquote>
<p><img src="/2024/09/09/Computer-Networks/cn34.png"></p>
<p><strong>Properties.</strong> DNS is a distributed, hierarchical database.</p>
<ul>
<li><font color="red">Root DNS Servers:</font>  find IP address of the <code>.com</code> <font color="red">TLD DNS server</font> (网址越靠后的部分越在顶层)<ul>
<li>Provide the IP addresses of the TLD servers</li>
</ul>
</li>
<li><font color="red">Top-Level Domain (TLD) DNS:</font> client queries <code>.com</code> DNS server to get <code>google.com</code> <font color="red">authoritative DNS server</font><ul>
<li>Top-level domains: com, org, net, edu, aero, jobs, museums; </li>
<li>Top-level country domains: uk, fr, cn, jp;</li>
</ul>
</li>
<li>Authoritative <font color="red">DNS servers:</font> client queries  <code>google.com</code>  DNS server to get  IP address for  <code>www.google.com / scholar.google.com</code><ul>
<li>organization’s own DNS server(s), providing authoritative hostname to IP mappings for organization’s named hosts </li>
<li>can be maintained by <font color="blue">organization</font> or <font color="blue">service provider</font></li>
</ul>
</li>
</ul>
<blockquote>
<p>Local DNS Server</p>
<ul>
<li>Does not strictly belong to hierarchy</li>
<li>Each ISP (residential ISP, company, university) has one<ul>
<li>also called “default name server”</li>
</ul>
</li>
</ul>
<p>When a host connects to an ISP, the ISP provides the <font color="red">IP addresses</font> of one or more of local DNS servers</p>
<p>When host makes DNS query, query is sent to <font color="red">local DNS server</font></p>
<ul>
<li>acts as <font color="blue">proxy</font>, forwards query into hierarchy</li>
<li>has <font color="blue">local cache</font> of recent name-to-address translation pairs (but may be out of date!)</li>
</ul>
</blockquote>
<table>
    <tr>
    <td><img src="/2024/09/09/Computer-Networks/cn35.png"></td>
    <td><img src="/2024/09/09/Computer-Networks/cn36.png"></td>
    </tr><tr>
    <td><center>Iterated query</center></td>
    <td><center>Recursive query</center></td>
    </tr>
</table>

<blockquote>
<p>补充：关于如何解决本地 DNS 缓存过期的问题，目前主流的方法是通过设置合理的 TTL (Time to live) 值。时间到了就会重新查询上游 DNS 服务器。</p>
</blockquote>
<h3 id="DNS-Protocol"><a href="#DNS-Protocol" class="headerlink" title="DNS Protocol"></a>DNS Protocol</h3><p><strong>Properties.</strong> DNS is a distributed database storing <font color="red">resource records</font> (RR).</p>
<blockquote class="blockquote-center">
<p>$<br>\text{RR format}=\text{(name, value, type, TTL)}<br>$</p>

</blockquote>
<ul>
<li><font color="red">type = A</font><ul>
<li><code>name</code> is hostname</li>
<li><code>value</code> is IP address</li>
</ul>
</li>
<li><font color="red">type = NS</font><ul>
<li><code>name</code> is domain (e.g., <code>foo.com</code>)</li>
<li><code>value</code> is hostname of authoritative server for this domain (e.g., <code>dns.foo.com</code>)</li>
</ul>
</li>
<li>type = CNAME<ul>
<li><code>name</code> is alias name for some “canonical” (the real) name</li>
<li><code>www.ibm.com</code> is really <code>servereast.backup2.ibm.com</code></li>
<li><code>value</code> is canonical name</li>
</ul>
</li>
<li><p>type = MX</p>
<ul>
<li><code>value</code> is canonical name(真名) of the mailserver with <code>name</code> (alias name)</li>
</ul>
</li>
<li><p>If a DNS server is <font color="red">authoritative</font> for a particular hostname</p>
<ul>
<li>the DNS server will contain a <u>Type A record</u> for the hostname</li>
<li>(Even if the DNS server is not authoritative, it may contain a Type A record in its cache.) </li>
</ul>
</li>
<li>If a server is <font color="red">not authoritative</font> for a hostname<ul>
<li>the server will contain a <u>Type NS record</u> for the domain that includes the hostname</li>
<li>it will also contain a <u>Type A record</u> that provides the IP address of the DNS server in the <code>value</code> field of the NS record.</li>
</ul>
</li>
<li>Example: an <code>.edu</code> TLD server is not authoritative for <code>gaia.cs.umass.edu</code><ul>
<li><code>(umass.edu, dns.umass.edu, NS)  // NS record</code></li>
<li><code>(dns.umass.edu, 128.119.40.111, A)  // A record</code></li>
</ul>
</li>
</ul>
<blockquote>
<p>DNS 协议支持查询（Query）和回复（Reply）两种操作，且消息的格式相同。</p>
</blockquote>
<p><img src="/2024/09/09/Computer-Networks/cn37.png"></p>
<p><img src="/2024/09/09/Computer-Networks/cn38.png"></p>
<ul>
<li><p>Example: a reply to an MX query</p>
</li>
<li><p><u>Answer section</u>: Type MX</p>
<ul>
<li>an RR providing the canonical hostname (at <code>value</code>) of a mail server. </li>
</ul>
</li>
<li><u>Additional section</u>: Type A<ul>
<li>the IP address (at <code>value</code>) for the canonical hostname (at <code>name</code>) of the mail server.</li>
</ul>
</li>
</ul>
<h3 id="Inserting-records-into-DNS"><a href="#Inserting-records-into-DNS" class="headerlink" title="Inserting records into DNS"></a>Inserting records into DNS</h3><p><strong>Example</strong></p>
<ul>
<li>New startup “Network Utopia”</li>
<li>Register name <code>networkuptopia.com</code> at <font color="red">DNS register</font> (e.g., Network Solutions)<ul>
<li>provide <font color="red">names, IP addresses</font> of authoritative DNS server (primary and secondary)</li>
<li>registrar inserts two RRs into <code>.com</code> TLD server :<ul>
<li><code>(networkutopia.com, dns1.networkutopia.com, NS)</code></li>
<li><code>(dns1.networkutopia.com, 212.212.212.1, A)</code></li>
</ul>
</li>
</ul>
</li>
<li>Then users can access by recursive query in the ways shown 👇</li>
</ul>
<p><img src="/2024/09/09/Computer-Networks/cn39.png"></p>
<blockquote>
<p>Attack DNS (略)</p>
</blockquote>
<h2 id="2-5-P2P-applications"><a href="#2-5-P2P-applications" class="headerlink" title="2.5. P2P applications"></a>2.5. P2P applications</h2><ul>
<li>Properties<ul>
<li>no always-on server</li>
<li>arbitrary end systems directly communicate</li>
<li>peers are intermittently connected and change IP addresses (IP 可变)</li>
</ul>
</li>
<li>Example<ul>
<li>file distribution (BitTorrent)</li>
<li>Streaming (KanKan)</li>
<li>VoIP (Skype)</li>
</ul>
</li>
</ul>
<h3 id="P2P-vs-Client-Server"><a href="#P2P-vs-Client-Server" class="headerlink" title="P2P vs. Client-Server"></a>P2P vs. Client-Server</h3><p>Question: How much time to distribute file (size F) from one server to N peers?</p>
<ul>
<li>Suppose $u_s$ is server upload capacity, $d_i$ is download capacity of peer $i$</li>
<li>Time to distribute file to all peers $D_{C-S}$ is :</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>D_{C-S}\ge \max{NF/u_s, F/d_{\text{min}}}<br>$</p>

</blockquote>
<ul>
<li>So the $D$ increases linearly in $N$</li>
</ul>
<p><img src="/2024/09/09/Computer-Networks/cn40.png"></p>
<ul>
<li>As each host provide $u_i$ for uploading capacity</li>
<li>Server must upload at least one copy ($F/u_s$)</li>
<li>time $D_{P2P}$ is :</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>D_{P2P}\ge \max{F/d_{min}, F/u_s, NF/(u_s+\sum{u_i})}<br>$</p>

</blockquote>
<h3 id="P2P-file-distribution-BitTorrent"><a href="#P2P-file-distribution-BitTorrent" class="headerlink" title="P2P file distribution: BitTorrent"></a>P2P file distribution: BitTorrent</h3><blockquote>
<p>How P2P works 👇</p>
</blockquote>
<p><img src="/2024/09/09/Computer-Networks/cn41.png"></p>
<ul>
<li>Some points:<ul>
<li><font color="red">TCP connection</font> with other peers</li>
<li>Once get entire file, one will leave or remain in BitTorrent</li>
</ul>
</li>
</ul>
<center>Machanism about BitTorrent</center>

<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><font color="red">requesting</font> chunks</th>
<th style="text-align:center"><font color="red">sending</font> chunks: tit-for-tat</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">at any time, different peers have different subsets of file chunks</td>
<td style="text-align:center">maintain a priority list of top-N peers</td>
</tr>
<tr>
<td style="text-align:center">periodically, asks each “neighbor” for list of chunks</td>
<td style="text-align:center">periodically, select one additional peer(“optimistically unchoke”) to start sending chunks, and chokes others</td>
</tr>
<tr>
<td style="text-align:center">request missing chunks, rarest first</td>
<td style="text-align:center">sends chunks to those who sending me chunks at highest rate</td>
</tr>
</tbody>
</table>
</div>
<blockquote>
<p>通俗解释：请求发包优先找请求得最少的，发包优先发请求最多的。(符合常理)</p>
</blockquote>
<p><strong>tit-for-tat</strong></p>
<ul>
<li>(1) Alice “optimistically unchokes” Bob</li>
<li>(2) Alice becomes one of Bob’s top-four providers; Bob reciprocates</li>
<li>(3) Bob becomes one of Alice’s top-four providers</li>
</ul>
<h2 id="2-6-video-streaming-and-content-distribution-networks"><a href="#2-6-video-streaming-and-content-distribution-networks" class="headerlink" title="2.6. video streaming and content distribution networks"></a>2.6. video streaming and content distribution networks</h2><ul>
<li>Challenge<ul>
<li>scale —— how to reach ~1B users?</li>
<li>heterogeneity (异质性) —— different users have different capabilities</li>
<li>video traffic (视频流量) —— major consumer of Internet bandwidth</li>
</ul>
</li>
<li>Solution<ul>
<li>distributed, application-level infrastructure</li>
</ul>
</li>
</ul>
<blockquote>
<p>Video has demand of multiple images per sec (e.g. 60 FPS needs 60 img/sec)</p>
<p>Use redundancy within and between images to decrease # bits used to encode image (前后帧图像分块，同色的块不再传输)</p>
<p>A more efficient way below 👇</p>
</blockquote>
<h3 id="Streaming-multimedia-DASH"><a href="#Streaming-multimedia-DASH" class="headerlink" title="Streaming multimedia: DASH"></a>Streaming multimedia: DASH</h3><ul>
<li>DASH: Dynamic, Adaptive Streaming over HTTP</li>
<li>Server:<ul>
<li>divides video file into <font color="red">multiple chunks</font></li>
<li>each chunk stored, encoded at different rates </li>
<li>manifest file: provides URLs for different chunks encoded at different rates </li>
</ul>
</li>
<li>Client:<ul>
<li>periodically measures server-to-client bandwidth</li>
<li>consulting manifest, requests one chunk at a time <ul>
<li>chooses maximum coding rate sustainable given current bandwidth</li>
<li>can choose different coding rates at different points in time (depending on available bandwidth at time)</li>
</ul>
</li>
</ul>
</li>
</ul>
<blockquote>
<p>在这里 client 是自由的。何时请求数据块，用哪种编码速率，向哪个地址请求数据块，都由 client 自己决定。</p>
</blockquote>
<h3 id="Content-Distribution-Network-CDN"><a href="#Content-Distribution-Network-CDN" class="headerlink" title="Content Distribution Network(CDN)"></a>Content Distribution Network(CDN)</h3><blockquote>
<p>Why not using “mega-server” ?</p>
<p>单点错误（容错率低），巨大负载，对远距离用户不友好等</p>
</blockquote>
<p><img src="/2024/09/09/Computer-Networks/cn42.png"></p>
<p><strong>Solution.</strong> CDN store/serve multiple copies of videos at multiple geographically distributed sites</p>
<ul>
<li>In practice, push CDN servers deep into many access networks; (inside ISPs)</li>
<li>Or smaller number (10’s) of larger clusters in Internet Exchange Point (IXP); (outside ISPs)</li>
</ul>
<p><strong>E.g.</strong> See how Bob request video by CDN : </p>
<p><img src="/2024/09/09/Computer-Networks/cn43.png"></p>
<blockquote>
<p>用户查找“最近” CDN 服务器的两种策略：地理距离最短或实时计算最短延迟</p>
</blockquote>
<h2 id="2-7-Socket-programming-with-UDP-and-TCP"><a href="#2-7-Socket-programming-with-UDP-and-TCP" class="headerlink" title="2.7. Socket programming with UDP and TCP"></a>2.7. Socket programming with UDP and TCP</h2><p><strong>Goal:</strong> learn how to build client/server applications that communicate using sockets.</p>
<p><strong>Socket:</strong> door between application process and end-end-transport protocol</p>
<h3 id="Socket-programming-with-UDP"><a href="#Socket-programming-with-UDP" class="headerlink" title="Socket programming with UDP"></a>Socket programming with UDP</h3><ul>
<li>No “connections”</li>
<li>Transmitted data may be lost or received out-of-order</li>
</ul>
<p><img src="/2024/09/09/Computer-Networks/cn44.png"></p>
<ul>
<li>Implementation 【server】</li>
</ul>
<figure class="highlight python"><figcaption><span>server.py</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> socket <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line">serverPort = <span class="number">12000</span></span><br><span class="line">serverSocket = socket(AF_INET, SOCK_DGRAM)  <span class="comment"># create socket</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;UDP socket is identified by destination IP address and port number&#x27;&#x27;&#x27;</span></span><br><span class="line">serverSocket.bind((<span class="string">&#x27;&#x27;</span>, serverPort))</span><br><span class="line"><span class="built_in">print</span> (“The server <span class="keyword">is</span> ready to receive”)</span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;clientAddress = IP + port&#x27;&#x27;&#x27;</span></span><br><span class="line">    message, clientAddress = serverSocket.recvfrom(<span class="number">2048</span>)</span><br><span class="line">    modifiedMessage = message.decode().upper()  <span class="comment"># what server do</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;response to client&#x27;&#x27;&#x27;</span></span><br><span class="line">    serverSocket.sendto(modifiedMessage.encode(), clientAddress)</span><br></pre></td></tr></table></figure>
<ul>
<li>Implemetation 【client】</li>
</ul>
<figure class="highlight python"><figcaption><span>client.py</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;Client do not need to specify port-num&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">from</span> socket <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line">serverName = <span class="string">&#x27;hostname&#x27;</span>  <span class="comment"># either IP address or hostname</span></span><br><span class="line">serverPort = <span class="number">12000</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;AF_INET -&gt; IPv4, SOCK_DGRAM -&gt; UDP&#x27;&#x27;&#x27;</span></span><br><span class="line">clientSocket = socket(AF_INET, SOCK_DGRAM)</span><br><span class="line">message = raw_input(<span class="string">&#x27;Input lowercase sentence:&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;Direct send, no connection&#x27;&#x27;&#x27;</span></span><br><span class="line">clientSocket.sendto(message.encode(), (serverName, serverPort))</span><br><span class="line">modifiedMessage, serverAddress = clientSocket.recvfrom(<span class="number">2048</span>)</span><br><span class="line"><span class="built_in">print</span>(modifiedMessage.decode())</span><br><span class="line">clientSocket.close()  <span class="comment"># client leave</span></span><br></pre></td></tr></table></figure>
<h3 id="Socket-programming-with-TCP"><a href="#Socket-programming-with-TCP" class="headerlink" title="Socket programming with TCP"></a>Socket programming with TCP</h3><ul>
<li>Client must contact server<ul>
<li>server process must first be running</li>
<li>server must have created socket (door) that welcomes client’s contact (<font color="blue">welcome socket</font>)</li>
</ul>
</li>
<li>Client contacts server by: <ul>
<li>Creating TCP socket, specifying IP address, port number of server process</li>
<li>Client TCP establishes connection to server TCP</li>
<li>when contacted by client, <font color="red">server TCP creates new socket</font> for server process to communicate with that particular client (允许服务端与多个客户连接)</li>
</ul>
</li>
</ul>
<blockquote>
<p>Identifications difference between UDP and TCP socket (对应到同一个套接字所需参数): </p>
<p>UDP = dst.IP + dst.port</p>
<p>TCP = dst.IP + dst.port + src.IP + src.port</p>
</blockquote>
<p><img src="/2024/09/09/Computer-Networks/cn45.png"></p>
<ul>
<li>Implementation 【server】</li>
</ul>
<figure class="highlight python"><figcaption><span>server.py</span></figcaption><table><tr><td class="code"><pre><span class="line">serverPort = <span class="number">12000</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;SOCK_STREAM -&gt; TCP&#x27;&#x27;&#x27;</span></span><br><span class="line">serverSocket = socket(AF_INET,SOCK_STREAM)</span><br><span class="line">serverSocket.bind((<span class="string">&#x27;&#x27;</span>,serverPort))</span><br><span class="line">serverSocket.listen(<span class="number">1</span>)  <span class="comment"># Times to listening, must before client</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;The server is ready to receive&#x27;</span>)</span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    connectionSocket, addr = serverSocket.accept()</span><br><span class="line">     </span><br><span class="line">    sentence = connectionSocket.recv(<span class="number">1024</span>).decode()</span><br><span class="line">    capitalizedSentence = sentence.upper()  <span class="comment"># what server do</span></span><br><span class="line">    connectionSocket.send(capitalizedSentence.encode())</span><br><span class="line">    connectionSocket.close()</span><br></pre></td></tr></table></figure>
<ul>
<li>Implementation 【client】</li>
</ul>
<figure class="highlight python"><figcaption><span>client.py</span></figcaption><table><tr><td class="code"><pre><span class="line">serverName = <span class="string">&#x27;servername&#x27;</span></span><br><span class="line">serverPort = <span class="number">12000</span></span><br><span class="line">clientSocket = socket(AF_INET, SOCK_STREAM)</span><br><span class="line">clientSocket.connect((serverName,serverPort))  <span class="comment"># set up connection(SYN)</span></span><br><span class="line">sentence = raw_input(<span class="string">&#x27;Input lowercase sentence:&#x27;</span>)</span><br><span class="line">clientSocket.send(sentence.encode())  <span class="comment"># &quot;3rd hand-shaking&quot;</span></span><br><span class="line">modifiedSentence = clientSocket.recv(<span class="number">1024</span>)</span><br><span class="line"><span class="built_in">print</span> (‘From Server:’, modifiedSentence.decode())</span><br><span class="line">clientSocket.close()  <span class="comment"># client leave first</span></span><br></pre></td></tr></table></figure>
<h1 id="Chapter-3-Transport-Layer"><a href="#Chapter-3-Transport-Layer" class="headerlink" title="Chapter 3: Transport Layer"></a>Chapter 3: Transport Layer</h1><HR style="FILTER: alpha(opacity=0, finishopacity=100,style=1)" width="100%" color="black" size="2">

<center><font face="STXinwei" size="5">Layout</font></center>

<p><strong>3.1</strong> transport-layer services</p>
<p><strong>3.2</strong> multiplexing and demultiplexing</p>
<p><strong>3.3</strong> connectionless transport: UDP</p>
<p><strong>3.4</strong> principles of reliable data transfer</p>
<p><strong>3.5</strong> connection-oriented transport: TCP</p>
<ul>
<li>segment structure</li>
<li>reliable data transfer</li>
<li>flow control</li>
<li>connection management</li>
</ul>
<p><strong>3.6</strong> principles of congestion control</p>
<p><strong>3.7</strong> TCP congestion control</p>
<HR style="FILTER: alpha(opacity=0, finishopacity=100,style=1)" width="100%" color="black" size="2">

<h2 id="3-1-Transport-Layer-Services"><a href="#3-1-Transport-Layer-Services" class="headerlink" title="3.1. Transport Layer Services"></a>3.1. Transport Layer Services</h2><ul>
<li><strong>Transport vs. App</strong><ul>
<li>logical communication between <font color="blue">app processes</font> running on different <font color="red">hosts</font></li>
<li>Transport protocols run in <font color="red">end systems</font><ul>
<li>send side: breaks app messages into segments, passes to network layer</li>
<li>rcv side: reassembles segments into messages, passes to app layer (<font color="green">Recall encapsulations</font>)</li>
</ul>
</li>
</ul>
</li>
<li><strong>Transport vs. Network</strong></li>
</ul>
<p><img src="/2024/09/09/Computer-Networks/cn46.png"></p>
<ul>
<li>hosts = houses</li>
<li>processes = kids</li>
<li>app messages = letters in envelopes</li>
<li><font color="red">transport protocol = Ann and Bill</font></li>
<li><font color="red">network-layer protocol = postal service</font>

</li>
</ul>
<blockquote>
<p>大部分传输层的服务包含在网络层中（如确保延迟时间和带宽的服务，因此 UDP 和 TCP 都不包含此服务），但仍有一些是网络层不提供的（如安全保障，rdt等）。</p>
</blockquote>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">TCP</th>
<th style="text-align:center">UDP</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">reliable, in-order delivery</td>
<td style="text-align:center">unreliable, unordered delivery</td>
</tr>
<tr>
<td style="text-align:center">connection setup</td>
<td style="text-align:center">no-frills(简洁的) extension</td>
</tr>
<tr>
<td style="text-align:center">congestion control and flow control</td>
<td style="text-align:center">process-to-process data delivery and error checking</td>
</tr>
</tbody>
</table>
</div>
<h2 id="3-2-Multiplexing-Demultiplexing"><a href="#3-2-Multiplexing-Demultiplexing" class="headerlink" title="3.2. Multiplexing / Demultiplexing"></a>3.2. Multiplexing / Demultiplexing</h2><p><strong>Def.</strong> extending the host-to-host delivery service to a process-to-process delivery service for applications running on the hosts.</p>
<p><img src="/2024/09/09/Computer-Networks/cn47.png"></p>
<blockquote>
<p>在 Ann and Bill 的例子里，这就像每个小朋友（进程）都有对应的名字和 ID，通过对此进行标识，可以让通信双方的 Socket 知道如何进行下一步传输。</p>
</blockquote>
<ul>
<li>Sending host： Host uses <font color="red">IP addresses &amp; port numbers</font> to direct segment to appropriate socket</li>
<li>Receiving host：Host receives IP datagrams from network layer<ul>
<li>each datagram has source IP address, destination IP address</li>
<li>each datagram carries one transport-layer segment</li>
</ul>
</li>
</ul>
<h3 id="UDP-Connectionless-demux"><a href="#UDP-Connectionless-demux" class="headerlink" title="UDP: Connectionless demux"></a>UDP: Connectionless demux</h3><p><img src="/2024/09/09/Computer-Networks/cn48.png"></p>
<ul>
<li>IP datagrams with same <code>dst.port</code> #, but <font color="red">different source IP addresses</font> and/or source port numbers will be directed to <font color="red">same</font> socket at destination.</li>
</ul>
<h3 id="TCP-Connection-oriented-demux"><a href="#TCP-Connection-oriented-demux" class="headerlink" title="TCP: Connection-oriented demux"></a>TCP: Connection-oriented demux</h3><p><img src="/2024/09/09/Computer-Networks/cn49.png"></p>
<blockquote>
<p>图中的 Socket 不再对应于进程，而是对应线程</p>
</blockquote>
<ul>
<li>Web servers have different sockets for each connecting client<ul>
<li>Both the initial connection-establishment segments and the segments carrying HTTP requests will have destination <strong>port 80</strong>.</li>
<li>non-persistent HTTP will have different socket for each request</li>
</ul>
</li>
</ul>
<h2 id="3-3-Connectionless-transport-UDP"><a href="#3-3-Connectionless-transport-UDP" class="headerlink" title="3.3. Connectionless transport: UDP"></a>3.3. Connectionless transport: UDP</h2><ul>
<li>UDP is used in:<ul>
<li>streaming multimedia apps (loss tolerant, rate sensitive)</li>
<li>DNS</li>
</ul>
</li>
<li>reliable transfer over UDP: (都是在其他层解决的，所以说 UDP 是不可靠的传输)<ul>
<li>add reliability at application layer</li>
<li>application-specific error recovery!</li>
</ul>
</li>
</ul>
<h3 id="UDP-Checksum"><a href="#UDP-Checksum" class="headerlink" title="UDP Checksum"></a>UDP Checksum</h3><p><strong>Goal:</strong> detect “errors” (e.g., flipped bits) in transmitted segment (from source to destination)</p>
<ul>
<li>Q: Why UDP using checksum?</li>
<li>A: <ul>
<li>no guarantee that all the links provide error checking</li>
<li>bit errors could be introduced when segments are in memory</li>
<li>Lower cost comparing to checking in app-level.</li>
</ul>
</li>
</ul>
<p><img src="/2024/09/09/Computer-Networks/cn50.png"></p>
<ul>
<li>Sender:<ul>
<li>treat segment contents, including header fields,  as sequence of 16-bit integers</li>
<li>checksum: 1s complement of the sum of segment contents</li>
<li>sender puts checksum value into UDP checksum field</li>
</ul>
</li>
<li>Receiver:<ul>
<li>check the sum of the segment<ul>
<li>All bits are equal to 1 - no error detected. But maybe errors nonetheless? More later…</li>
<li>Otherwise: error detected</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>Example</strong></p>
<p><img src="/2024/09/09/Computer-Networks/cn51.png" style="zoom:60%"></p>
<p><img src="/2024/09/09/Computer-Networks/cn52.png" style="zoom:60%"></p>
<blockquote>
<p>一个更简单的证明例子：</p>
<p>设三个加数为 <code>0101</code>, <code>1101</code>, <code>1011</code></p>
<p>$0101+1101=10010 \rightarrow +1011=11101$ ，补位得 <code>1110</code>，取反得 <code>0001</code></p>
<p>接收方计算：$0101+1101=10010 \rightarrow +1011=11101 \rightarrow + 0001=11110$，补位得 <code>1111</code></p>
<p>全 1 符合条件，暂时检测不出错误。</p>
</blockquote>
<h2 id="3-4-Principles-of-Reliable-Data-Transfer-rdt"><a href="#3-4-Principles-of-Reliable-Data-Transfer-rdt" class="headerlink" title="3.4. Principles of Reliable Data Transfer (rdt)"></a>3.4. Principles of Reliable Data Transfer (rdt)</h2><h3 id="Overview-1"><a href="#Overview-1" class="headerlink" title="Overview"></a>Overview</h3><p><img src="/2024/09/09/Computer-Networks/cn53.png"></p>
<blockquote>
<p>We mainly use FSM to describe rdt clearly. Template as pic above.</p>
</blockquote>
<ul>
<li>Perfectly reliable channel: <code>rdt1.0</code></li>
<li>Channel with bit error: <ul>
<li>bit error in packet: <code>rdt 2.0</code></li>
<li>bit error in ACK: <code>2.1</code></li>
<li>NAK-free: <code>2.2</code></li>
</ul>
</li>
<li>Lossy channel: <code>rdt 3.0</code></li>
</ul>
<h3 id="rdt-1-0"><a href="#rdt-1-0" class="headerlink" title="rdt 1.0"></a>rdt 1.0</h3><ul>
<li>Underlying channel “perfectly reliable”<ul>
<li>no bit error</li>
<li>no loss of packet</li>
</ul>
</li>
<li>Therefore, no control for feedback</li>
</ul>
<p><img src="/2024/09/09/Computer-Networks/cn54.png" style="zoom:50%"></p>
<h3 id="rdt-2-0"><a href="#rdt-2-0" class="headerlink" title="rdt 2.0"></a>rdt 2.0</h3><ul>
<li>Underlying channel may <font color="blue">flip bits</font> (0 → 1) in packet</li>
<li><font color="red">Q: how to recover from errors?</font><ul>
<li>acknowledgements (ACKs): receiver explicitly tells sender that pkt received OK</li>
<li>negative acknowledgements (NAKs): receiver explicitly tells sender that pkt had errors</li>
<li>sender retransmits pkt on receipt of NAK</li>
</ul>
</li>
</ul>
<ul>
<li>New Machanism in <code>rdt 2.0</code><ul>
<li>Error detection: checksum</li>
<li>Receiver feedback: control msgs (ACK,NAK) <code>rcvr-&gt;sender</code></li>
<li>Retransmission</li>
</ul>
</li>
</ul>
<p><img src="/2024/09/09/Computer-Networks/cn55.png" style="zoom:50%"></p>
<ul>
<li><code>rdt 2.0</code> has a <font color="red">fatal flaw</font> !</li>
<li><font color="red">What if ACK / NAK packet is corrupted?</font></li>
<li>Handling corrupted ACKs or NAKs:<ul>
<li>Op1. Keep asking until get answer ( foolish ! )</li>
<li>Op2. add enough checksum to recover</li>
<li>Op3. when garbled ACK or NAK, retransmit (👈seems better, but still some probs)</li>
</ul>
</li>
</ul>
<h3 id="rdt-2-1"><a href="#rdt-2-1" class="headerlink" title="rdt 2.1"></a>rdt 2.1</h3><p><img src="/2024/09/09/Computer-Networks/cn56.png" style="zoom:50%"></p>
<p><img src="/2024/09/09/Computer-Networks/cn57.png" style="zoom:50%"></p>
<ul>
<li>Recv maintain seq # as Sender do (正常情况下持有相同状态值)</li>
<li>Sender check if received ACK/NAK corrupted</li>
<li>Recv check if received packet is duplicate</li>
</ul>
<blockquote>
<p>例：sender 在状态 0，receiver 在状态 0</p>
<p>此时 sender 发送一个 seq0 的包，recv 正常收到，解包并发送 ACK，然后转向状态 1。</p>
<p>但是 sender 没收到 ACK，重发 seq0。recv 则会再发 ACK（根据 FSM），如此到 sender 收到 ACK，然后转向状态 1。然后 sender 发送 seq1 的包。如此循环。</p>
</blockquote>
<h3 id="rdt-2-2"><a href="#rdt-2-2" class="headerlink" title="rdt 2.2"></a>rdt 2.2</h3><p><img src="/2024/09/09/Computer-Networks/cn58.png" style="zoom:50%"></p>
<ul>
<li>Optimization<ul>
<li>using ACKs only (sends ACK for last pkt received OK)</li>
<li>must send ACK with seq #</li>
</ul>
</li>
</ul>
<h3 id="rdt-3-0"><a href="#rdt-3-0" class="headerlink" title="rdt 3.0"></a>rdt 3.0</h3><ul>
<li><font color="red">New Assumption:</font> underlying channel can also lose packets (data, ACKs)</li>
<li>Approach: sender waits “reasonable” amount of time for ACK </li>
<li>retransmits if no ACK received in this time</li>
<li>if pkt (or ACK) just delayed (not lost):<ul>
<li>retransmission will be duplicate, but seq. #’s already handles this</li>
<li>receiver must specify seq # of pkt being ACKed</li>
</ul>
</li>
<li>requires countdown timer<ul>
<li>start timer, timer interrupt, stop timer</li>
</ul>
</li>
</ul>
<ul>
<li>Sender in <code>rdt 3.0</code></li>
</ul>
<p><img src="/2024/09/09/Computer-Networks/cn59.png" style="zoom:50%"></p>
<blockquote>
<p>Some calculations: </p>
<p>How to calc the utilization of sender ($U_{\text{sender}}$) ? Suppose that $RTT = 30 msec$, $R = 1 Gbps$, $L = 8000 bits$</p>
<p>$U_{\text{sender}}=\frac{L/R}{RTT + L/R}=\frac{.008}{30.008}=0.00027$</p>
<p>Utilization 可以理解成某个终端的有效工作时间占比</p>
</blockquote>
<h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><p><strong>Key techniques</strong></p>
<ul>
<li>Checksum (2.0)</li>
<li>ACK packet (2.0)</li>
<li>Retransmission (2.0)</li>
<li>Sequence number (2.1)</li>
<li>Timeout (3.0)</li>
</ul>
<h3 id="Pipelined-Protocols"><a href="#Pipelined-Protocols" class="headerlink" title="Pipelined Protocols"></a>Pipelined Protocols</h3><ul>
<li>Go-Back-N<ul>
<li>Timer for the oldest unACKed packet</li>
<li>Cumulative ACK</li>
<li>Retransmit all packets in the window </li>
</ul>
</li>
<li>Selective repeat<ul>
<li>Timer for each packet in window</li>
<li>Individual ACK for each correctly received packets</li>
<li>Retransmit only those packets that might be lost or corrupted</li>
</ul>
</li>
</ul>
<h4 id="Go-Back-N"><a href="#Go-Back-N" class="headerlink" title="Go-Back-N"></a>Go-Back-N</h4><p><img src="/2024/09/09/Computer-Networks/cn60.png" style="zoom:70%"></p>
<ul>
<li>$k$-bits seq # in pkt header: range $[0, 2^k -1]$</li>
<li>At most $N$ pkts in flight(in the “window”) are allowed</li>
</ul>
<ul>
<li><font color="blue">Sender:</font> When <code>rdt_send()</code> is called from above, <ul>
<li>window is not full: a packet is sent, variables are updated. </li>
<li>window is full: simply returns the data back to the upper laye</li>
<li>A timer for the <font color="red">oldest</font> transmitted but not yet ACKed packet<ul>
<li>timeout occurs: resends all packets in the window;</li>
<li><code>ACK(n)</code>: slide window; restart timer </li>
</ul>
</li>
</ul>
</li>
<li><font color="blue">Receiver:</font> Receipt of an ACK.<ul>
<li><font color="red">Cumulative acknowledgment (ACK)</font></li>
<li><code>ACK(n)</code>: all packets with a sequence # <font color="red">up to and including</font> $n$ have been correctly received at the receiver<ul>
<li>Expect $n$ and receive $n$: <code>ACK(n)</code></li>
<li>Expect $n$ and receive others: previous <code>ACK</code>; discard packet</li>
</ul>
</li>
</ul>
</li>
</ul>
<blockquote>
<p>Obvious that GBN didn’t have a receiver buffering (discard out-of-order pkt), and generate many dup-ACKs as well !</p>
</blockquote>
<h4 id="Selective-Repeat"><a href="#Selective-Repeat" class="headerlink" title="Selective Repeat"></a>Selective Repeat</h4><ul>
<li>Receiver individually acknowledge <font color="red">all</font> correcly received pkts<ul>
<li>buffers pkts for eventual in-order delivery to upper layer</li>
<li>Receiver need to keep track of the <font color="red">out-of-packets</font></li>
</ul>
</li>
<li>Sender only resends pkts for which ACK not received<ul>
<li>sender maintain timer for <font color="red">each</font> unACKed pkt</li>
</ul>
</li>
</ul>
<p><img src="/2024/09/09/Computer-Networks/cn61.png" style="zoom:60%"></p>
<p><img src="/2024/09/09/Computer-Networks/cn62.png" style="zoom:60%"></p>
<blockquote>
<p>Well, it may be hard to understand. So I offer an easy example, with window size is only 4, to show that how would the receiver (more significant) respond to unexpected packet receiving.</p>
</blockquote>
<p><img src="/2024/09/09/Computer-Networks/cn63.png" style="zoom:50%"></p>
<ul>
<li>When <code>ack2</code> arrives, sender’s window move with <code>pkt6</code> being the sendbase.</li>
<li><font color="red">But here's a problem !</font></li>
<li>Consider seq # = [0, 3] , and window size N = 3<ul>
<li>Left case is Okay, but consider the wrost case(Right)</li>
</ul>
</li>
</ul>
<table><tr>
    <td><img src="/2024/09/09/Computer-Networks/cn64.png" style="zoom:50%"></td>
    <td><img src="/2024/09/09/Computer-Networks/cn65.png" style="zoom:50%"></td>
</tr></table>

<ul>
<li>The receiver will recognize the <font color="blue">retransmit</font> <code>pkt0</code> as the latter one, and think that the 2 <code>pkt0</code> are both ACKed.</li>
<li>Then receiver send <code>ACK(0)</code> back to sender.<ul>
<li>If sender receive <code>ACK(0)</code>, then everything goes on, but receiver lose the former 3 pkts forever !</li>
<li>If send doesn’t receive, then sender window sticks to (0, 1, 2), receiver window sticks to (3, 0, 1), which is a deadlock, until sender get <code>ACK(0)</code>.</li>
</ul>
</li>
<li><font color="red">How to deal ?</font> <font color="green">Constraint: Window size N must be less than or equal to half of seq # range.</font>

</li>
</ul>
<blockquote>
<p>More detail refer to <a href="#lab08">Lab 8</a></p>
</blockquote>
<h2 id="3-5-Connection-Oriented-Transport-TCP"><a href="#3-5-Connection-Oriented-Transport-TCP" class="headerlink" title="3.5. Connection-Oriented Transport: TCP"></a>3.5. Connection-Oriented Transport: TCP</h2><h3 id="Overview-2"><a href="#Overview-2" class="headerlink" title="Overview"></a>Overview</h3><ul>
<li><strong>point-to-point</strong><ul>
<li>one sender, one receiver</li>
<li>No buffers or variables are allocated to network elements between hosts</li>
</ul>
</li>
<li><strong>reliable, in-order byte stream</strong><ul>
<li>no “message boundaries”</li>
<li>Seq # and ACK # are in unit of byte, rather than pkt</li>
</ul>
</li>
<li><strong>pipelined</strong><ul>
<li>TCP congestion and flow control set window size</li>
</ul>
</li>
<li><strong>full duplex data</strong><ul>
<li>bi-directional data flow in same connection</li>
<li>Maximum Segment Size (MSS)</li>
</ul>
</li>
<li><strong>connection-oriented</strong><ul>
<li>handshakings init sender and receiver state before data transfer</li>
</ul>
</li>
<li><strong>flow controlled</strong><ul>
<li>sender will never overwhelm receiver (ensure safety)</li>
</ul>
</li>
</ul>
<p><img src="/2024/09/09/Computer-Networks/cn66.png" style="zoom:60%"></p>
<ul>
<li>TCP grab chunk of data from the sender buffer<ul>
<li>MSS: maximum segment size, typically 1460 bytes</li>
<li>MTU: maximum transmission unit (link-layer frame), typically 1500 bytes<ul>
<li>Application data + TCP/IP header ( typically 40 bytes )</li>
</ul>
</li>
</ul>
</li>
<li>TCP receive a segment at the other end, place it in receiver buffer</li>
<li>Application reads the stream from the receiver buffer</li>
</ul>
<h3 id="TCP-RDT"><a href="#TCP-RDT" class="headerlink" title="TCP RDT"></a>TCP RDT</h3><h4 id="Segment-Structure"><a href="#Segment-Structure" class="headerlink" title="Segment Structure"></a>Segment Structure</h4><p><img src="/2024/09/09/Computer-Networks/cn67.png" style="zoom:60%"></p>
<ul>
<li>TCP view data as <font color="blue">an untrusted, but ordered, stream of bytes</font>.</li>
<li>Seq numbers are over the stream of transmitted bytes and not over the series of transmitted segment.<ul>
<li>seq #: byte stream “number” of first byte in the segment’s data</li>
<li>ACK #: seq # of next byte expected from the other side<ul>
<li>e.g. receiver has received bytes 0 - 535 and 900 - 1000; then, acknowledgement number is 536.</li>
</ul>
</li>
</ul>
</li>
<li>E.g. Telnet case: User types a <code>char</code> at host A, and host A sends it to host B</li>
</ul>
<p><img src="/2024/09/09/Computer-Networks/cn68.png" style="zoom:60%"></p>
<h4 id="RTT-estimation"><a href="#RTT-estimation" class="headerlink" title="RTT estimation"></a>RTT estimation</h4><font color="green">Recall: Round-trip Time (RTT), the time from sender sending the pkt  to sender receiving corresponding ACK.</font>

<ul>
<li><font color="red">Q: How to set TCP timeout value?</font></li>
<li>longer than RTT 👉 But RTT <strong>varies</strong></li>
<li>too short 👉 premature timeout, unnecessary retransmission</li>
<li>too long 👉 slow reaction to segment loss</li>
</ul>
<ul>
<li><font color="red">Q: How to estimate RTT?</font></li>
<li>Sample RTT: measure time from segment transmission until ACK receipt (<strong>ignore retransmissions</strong>)</li>
<li>But it maybe vary. 👉 average several <em>recent</em> measurements, not just <font color="red">current SampleRTT</font>.</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\text{EstimatedRTT}=(1-\alpha)\times \text{EstimatedRTT}+\alpha \times \text{SampleRTT}<br>$</p>

</blockquote>
<p><img src="/2024/09/09/Computer-Networks/cn68.png" style="zoom:60%"></p>
<blockquote>
<p>Typically value $\alpha=0.125$</p>
</blockquote>
<ul>
<li>Also we need an interval for the toleration of the variability of RTT (typically $\beta=0.25$)</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{c}<br>\text{DevRTT}=(1-\beta)\times\text{DevRTT}+\alpha \times | \text{SampleRTT} - \text{EstimatedRTT} | \\<br>\text{TimeoutInterval}=\text{EstimatedRTT} + 4 \times \text{DevRTT}<br>\end{array}<br>$</p>

</blockquote>
<h4 id="Reliable-Data-Transfer"><a href="#Reliable-Data-Transfer" class="headerlink" title="Reliable Data Transfer"></a>Reliable Data Transfer</h4><blockquote>
<p>TCP thinks that IP below itself as unreliable, so it provide reliable data transfer</p>
</blockquote>
<ul>
<li>Sender Events<ul>
<li>data received from app:<ul>
<li>create segment with <font color="red">seq num</font> (which is byte-stream number of first data byte in  segment)</li>
<li>start timer if not already running</li>
</ul>
</li>
<li>timeout: <ul>
<li>retransmit the timeout segment</li>
<li>restart timer</li>
</ul>
</li>
<li>ack received: <ul>
<li>if ack num from previously unacked segments, update that segments (unACKed 👉 ACKed)</li>
<li>if there are still unACKed segments, <font color="blue">start timer</font></li>
</ul>
</li>
</ul>
</li>
<li>Receiver Events</li>
</ul>
<p><img src="/2024/09/09/Computer-Networks/cn70.png" style="zoom:60%"></p>
<p><strong>Double Timeout</strong></p>
<ul>
<li>Each time TCP retransmits, it sets the <font color="red">next timeout interval to twice</font> the previous value</li>
</ul>
<p><strong>Fast retransmission</strong></p>
<p>…</p>
<h4 id="Flow-Control"><a href="#Flow-Control" class="headerlink" title="Flow Control"></a>Flow Control</h4><p><strong>Def.</strong>  Receiver controls sender, so sender won’t <font color="red">overflowz</font> receiver’s buffer by transmitting too much, too fast.</p>
<p><img src="/2024/09/09/Computer-Networks/cn71.png" style="zoom:60%"></p>
<ul>
<li>And sender will try to limit the unACKed data to receiver’s <code>rwnd</code> value</li>
</ul>
<h4 id="Control-Managment"><a href="#Control-Managment" class="headerlink" title="Control Managment"></a>Control Managment</h4><ul>
<li>Before data transfer, “Alice” and “Bob” (using TCP) will have a <font color="red">three-way handshakes</font> to guarantee connection.</li>
<li>Three flags to convey the info about connection: <code>RST</code>, <code>SYN</code>, <code>FIN</code></li>
</ul>
<p><img src="/2024/09/09/Computer-Networks/cn72.png" style="zoom:60%"></p>
<ul>
<li>Once three handshakes finish, the server and client can start data transfer.</li>
<li>In the future sements, <code>SYNbit</code> = 0.</li>
<li>After all segments ACKed, the sender closes the connection 👇</li>
</ul>
<p><img src="/2024/09/09/Computer-Networks/cn73.png" style="zoom:60%"></p>
<h2 id="3-6-Principles-of-Congestion-Control"><a href="#3-6-Principles-of-Congestion-Control" class="headerlink" title="3.6. Principles of Congestion Control"></a>3.6. Principles of Congestion Control</h2><p><strong>Def.</strong> <font color="red">Congestion</font> is too many sources sending too much data too fast for <font color="red">network</font> to handle.</p>
<h3 id="Causes-Costs-of-congestion"><a href="#Causes-Costs-of-congestion" class="headerlink" title="Causes / Costs of congestion"></a>Causes / Costs of congestion</h3><p>(1) 2 senders ＜(＾－＾)＞ 2 receivers; <font color="red">one router</font> with infinite buffer but output link capacity is $R$ ; <font color="red">No retransmission</font></p>
<p>(2) Consider retransmission</p>
<p>(3) More than one router</p>
<p><strong>Summary</strong></p>
<ul>
<li>Cause<ul>
<li>Shared link; limited link capacity</li>
<li>Sending at a high rate</li>
</ul>
</li>
<li>Cost of Congestion<ul>
<li>Delay</li>
<li>Packet lost  and retransmission</li>
<li>Unneeded retransmission: waste</li>
<li>“upstream” transmission capacity was wasted</li>
</ul>
</li>
<li>Approaches to Congestion Control<ul>
<li>End-to-end<ul>
<li>TCP segment loss or round-trip segment delay </li>
<li>TCP decreases its window size accordingly</li>
</ul>
</li>
<li>Network-assisted congestion control:<ul>
<li>routers provide feedback to the sender and/or receiver</li>
<li>a single bit indicating congestion at a link; the maximum host sending rate the router can support</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="3-7-TCP-Congestion-Control"><a href="#3-7-TCP-Congestion-Control" class="headerlink" title="3.7. TCP Congestion Control"></a>3.7. TCP Congestion Control</h2><ul>
<li><font color="red">Q1:</font> How does a TCP sender limit the rate at which it sends traffic into its connection? <ul>
<li>Congestion window</li>
<li>LastByteSend - LastByteAcked $\le$ min {cwnd, rwnd}</li>
</ul>
</li>
<li><font color="red">Q2:</font> How does a TCP sender perceive that there is congestion on the path between itself and the destination? <ul>
<li>timeout</li>
<li>three duplicate ACKs</li>
</ul>
</li>
<li><font color="red">Q3:</font> What algorithm should the sender use to change its send rate as a function of perceived end-to-end congestion?</li>
</ul>
<h3 id="Congestion-Control-Details"><a href="#Congestion-Control-Details" class="headerlink" title="Congestion Control: Details"></a>Congestion Control: Details</h3><ul>
<li>Three components:<ul>
<li>Slow start：exponentially increase</li>
<li>Congestion avoidance: linearly increase</li>
<li>Fast recovery(as shown below) :</li>
</ul>
</li>
</ul>
<p><img src="/2024/09/09/Computer-Networks/cn74.png" style="zoom:60%"></p>
<ul>
<li>TCP congestion control: additive increase multiplicative decrease<ul>
<li><font color="red">additive increase:</font> increase cwnd by 1 MSS every RTT until loss detected</li>
<li><font color="red">multiplicative decrease:</font> cut cwnd in half after loss </li>
</ul>
</li>
<li>TCP throughput<ul>
<li>ignore slow start, assume always data to send</li>
<li>$W$: window size (measured in bytes) where loss occurs</li>
</ul>
</li>
</ul>
<p><img src="/2024/09/09/Computer-Networks/cn75.png" style="zoom:80%"></p>
<h3 id="TCP-Fairness"><a href="#TCP-Fairness" class="headerlink" title="TCP Fairness"></a>TCP Fairness</h3><p><strong>Fairness goal:</strong> if $K$ TCP sessions share same  bottleneck link of bandwidth $R$, each should have  average rate of $R/K$</p>
<h1 id="Chapter-4-Network-Layer"><a href="#Chapter-4-Network-Layer" class="headerlink" title="Chapter 4: Network Layer"></a>Chapter 4: Network Layer</h1><HR style="FILTER: alpha(opacity=0, finishopacity=100,style=1)" width="100%" color="black" size="2">

<center><font face="STXinwei" size="5">Layout</font></center>

<p><strong>4.1</strong> Overview of Network layer</p>
<ul>
<li>data plane</li>
<li>control plane</li>
</ul>
<p><strong>4.2</strong> What’s inside a router</p>
<p><strong>4.3</strong> IP: Internet Protocol</p>
<ul>
<li>datagram format</li>
<li>fragmentation</li>
<li>IPv4 addressing</li>
<li>network address translation</li>
<li>IPv6</li>
</ul>
<p><strong>4.4</strong> Generalized Forward and SDN</p>
<ul>
<li>match</li>
<li>action</li>
<li>OpenFlow  examples of match-plus-action in action</li>
</ul>
<HR style="FILTER: alpha(opacity=0,finishopacity=100,style=1)" width="100%" color="black" size="2">



<h2 id="4-1-Overview-of-Network-Layer"><a href="#4-1-Overview-of-Network-Layer" class="headerlink" title="4.1. Overview of Network Layer"></a>4.1. Overview of Network Layer</h2><ul>
<li>transport segment from sending to receiving host </li>
<li>on sending side encapsulates segments into datagrams</li>
<li>on receiving side, delivers segments to transport layer</li>
<li>network layer protocols in every host, router</li>
<li>router examines header fields in all IP datagrams passing through it</li>
</ul>
<p><strong>Two key network-core functions</strong></p>
<ul>
<li>Forwarding: move packets from router’s input to appropriate router output <ul>
<li><font color="red">Data Plane</font></li>
</ul>
</li>
<li>Routing: determine route taken by packets from source to destination<ul>
<li>routing algorithm</li>
<li><font color="red">Control Plane</font>



</li>
</ul>
</li>
</ul>
<h2 id="4-2-What’s-inside-a-router"><a href="#4-2-What’s-inside-a-router" class="headerlink" title="4.2. What’s inside a router"></a>4.2. What’s inside a router</h2><p><img src="/2024/09/09/Computer-Networks/cn76.png"></p>
<h3 id="Router-Overview"><a href="#Router-Overview" class="headerlink" title="Router Overview"></a>Router Overview</h3><ul>
<li>Input port</li>
<li>Switch fabrics</li>
<li>Output port</li>
<li>Queuing<ul>
<li>Input port queue</li>
<li>Output port queue</li>
<li>Scheduling</li>
</ul>
</li>
</ul>
<h3 id="Input-port-amp-Output-port-function"><a href="#Input-port-amp-Output-port-function" class="headerlink" title="Input port &amp; Output  port function"></a>Input port &amp; Output  port function</h3><h3 id="Switching-Fabrics"><a href="#Switching-Fabrics" class="headerlink" title="Switching Fabrics"></a>Switching Fabrics</h3><p><img src="/2024/09/09/Computer-Networks/cn77.png" style="zoom:70%"></p>
<h3 id="Queueing-calculation"><a href="#Queueing-calculation" class="headerlink" title="Queueing calculation"></a>Queueing calculation</h3><blockquote>
<p>How much buffering ?</p>
</blockquote>
<ul>
<li>$RTT \times \text{link capacity } C$ </li>
<li>Recent recommendation: with N flows, buffering = $\frac{RTT \times C}{\sqrt{N}}$</li>
</ul>
<h2 id="4-3-IP-Internet-Protocol"><a href="#4-3-IP-Internet-Protocol" class="headerlink" title="4.3. IP: Internet Protocol"></a>4.3. IP: Internet Protocol</h2><h3 id="Outline"><a href="#Outline" class="headerlink" title="Outline"></a>Outline</h3><ul>
<li>datagram format</li>
<li>fragmentation</li>
<li>IPv4 addressing</li>
<li>network address translation</li>
<li>IPv6</li>
</ul>
<blockquote>
<p>See about network layer</p>
</blockquote>
<p><img src="/2024/09/09/Computer-Networks/cn78.png" style="zoom:70%"></p>
<h3 id="Datagram-format"><a href="#Datagram-format" class="headerlink" title="Datagram format"></a>Datagram format</h3><p><img src="/2024/09/09/Computer-Networks/cn79.png" style="zoom:70%"></p>
<h3 id="IP-fragmentation"><a href="#IP-fragmentation" class="headerlink" title="IP fragmentation"></a>IP fragmentation</h3><ul>
<li>network links have <strong>max transmission unit (MTU)</strong> - largest possible link-level frame<ul>
<li>different link types, different MTUs</li>
</ul>
</li>
<li>large IP datagram divided (“fragmented”) within net <font color="grey">[类似传输层的分块]</font><ul>
<li>one datagram becomes several datagrams reassembly</li>
<li>“reassembled” only at <font color="red">final destination</font></li>
<li>IP header bits used to identify, order related fragments</li>
</ul>
</li>
</ul>
<h3 id="IPv4"><a href="#IPv4" class="headerlink" title="IPv4"></a>IPv4</h3><h4 id="Addressing"><a href="#Addressing" class="headerlink" title="Addressing"></a>Addressing</h4><ul>
<li>IP address: 32-bit identifier for interface of hosts and routers</li>
<li>Interface: (network interface card) connection between host/router and physical link<ul>
<li>router’s typically have multiple interfaces</li>
<li>host typically has one or two interfaces (e.g., wired Ethernet, wireless 802.11)</li>
</ul>
</li>
</ul>
<h4 id="Subnet"><a href="#Subnet" class="headerlink" title="Subnet"></a>Subnet</h4><ul>
<li>What is a subnet ?<ul>
<li>device interfaces with same subnet part of IP address</li>
<li>can physically reach each other without intervening router </li>
</ul>
</li>
<li>each <font color="red">isolated network</font> is called a subnet</li>
</ul>
<p><img src="/2024/09/09/Computer-Networks/cn80.png" style="zoom:70%"></p>
<blockquote>
<p>E.g. How many subnet here ?</p>
<p>Answer: 6.</p>
</blockquote>
<h4 id="How-to-assign-obtain-IP-address"><a href="#How-to-assign-obtain-IP-address" class="headerlink" title="How to assign/obtain IP address?"></a>How to assign/obtain IP address?</h4><ul>
<li>Classless InterDomain Routing (CIDR)<ul>
<li>A method to assign blocks of IP address</li>
<li>subnet portion of address of arbitrary length</li>
<li>address format: <code>a.b.c.d/x</code>, where <code>x</code> is # bits in subnet portion of address<ul>
<li>e.g. address is <code>200.23.16.0/23</code>, then the subnet is <code>255.255.254.0</code></li>
</ul>
</li>
</ul>
</li>
<li><font color="red">Q1: How does an ISP get block of addresses ?</font><ul>
<li><font color="green">A1: ICANN: Internet Corporation for Assigned Names and Numbers</font><ul>
<li>allocates addresses</li>
<li>manages DNS</li>
<li>assigns domain names, resolves disputes</li>
</ul>
</li>
</ul>
</li>
<li><font color="red">Q2: How does a subnet get block of addresses ?</font><ul>
<li><font color="green">A2: gets allocated portion of its provider ISP’s address space</font><ul>
<li>e.g. ISP’s block is <code>200.23.16.0/20</code>, then the Organizations IP address can be :</li>
<li><code>200.23.16.0/23</code>, <code>200.23.18.0/23</code>, <code>200.23.20.0/23</code>… <code>200.23.30.0/23</code>(8 Organizations, 3 bits changed)</li>
<li>Another example to explain this :</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="/2024/09/09/Computer-Networks/cn81.png"><br><img src="/2024/09/09/Computer-Networks/cn82.png"></p>
<ul>
<li><font color="red">Q3: How does a subnet get block of addresses ?</font><ul>
<li><font color="green">DHCP: Dynamic Host Configuration Protocol: dynamically get address from as server</font></li>
<li>goal: allow host to <font color="blue">dynamically</font> obtain its IP address from network server when it joins network<ul>
<li>can renew its lease on address in use</li>
<li>allows reuse of addresses (only hold address while connected/“on”)</li>
<li>support for mobile users who want to join network (more shortly)</li>
</ul>
</li>
<li>Let’s see how DHCP works in a case :</li>
</ul>
</li>
</ul>
<p><img src="/2024/09/09/Computer-Networks/cn83.png"></p>
<ul>
<li>DHCP can return more than just allocated IP address on subnet:<ul>
<li>address of first-hop router for client</li>
<li>name and IP address of DNS sever</li>
<li>network mask (indicating network versus host portion of address)</li>
</ul>
</li>
</ul>
<h3 id="NAT-Network-Address-Translation"><a href="#NAT-Network-Address-Translation" class="headerlink" title="NAT (Network Address Translation)"></a>NAT (Network Address Translation)</h3><ul>
<li>NAT: reserve blocks of IP addresses for LANs<ul>
<li>private network using private IP addr</li>
</ul>
</li>
</ul>
<p><img src="/2024/09/09/Computer-Networks/cn84.png"></p>
<ul>
<li><font color="red">Motivation:</font> local network uses just one IP address<ul>
<li>just one IP address for all devices</li>
<li>can change addresses of devices in local network without notifying outside world (内部对外部独立)</li>
<li>can change ISP without changing addresses of devices in local network (外部对内部独立)</li>
<li>devices inside local network not explicitly addressable, visible by outside world (a security plus)</li>
</ul>
</li>
<li><font color="red">Implementation:</font><ul>
<li><strong>Outgoing datagrams:</strong> replace <code>(source IP address, port #)</code> of every outgoing datagram to <code>(NAT IP address, new port #)</code>. Remote clients/servers will respond using <code>(NAT IP address, new port #)</code> as destination addr <font color="blue">(Not genial addr)</font></li>
<li>In NAT translation table, record all translation pairs</li>
<li><strong>Incoming datagrams:</strong> replace <code>(NAT IP address, new port #)</code> in dest fields of every incoming datagram with corresponding <code>(source IP address, port #)</code> stored in NAT table</li>
</ul>
</li>
</ul>
<p><img src="/2024/09/09/Computer-Networks/cn85.png"></p>
<h3 id="IPv6"><a href="#IPv6" class="headerlink" title="IPv6"></a>IPv6</h3><h4 id="Format"><a href="#Format" class="headerlink" title="Format"></a>Format</h4><ul>
<li>IPv6 using:<ul>
<li>128-bit address space</li>
<li>fixed-length 40 byte header</li>
<li>no fragmentation allowed</li>
</ul>
</li>
</ul>
<blockquote>
<p>Why ?</p>
</blockquote>
<p><img src="/2024/09/09/Computer-Networks/cn89.png" style="zoom:70%"></p>
<ul>
<li><strong>priority</strong>:  identify priority among datagrams in flow</li>
<li><strong>flow Label</strong>: identify datagrams in same “flow.”  (concept of“flow” not well defined).</li>
<li><strong>next header</strong>: identify upper layer protocol for data (for example, to TCP or UDP).</li>
<li>Other changes<ul>
<li><strong>checksum</strong>: removed entirely to reduce processing time at each hop</li>
<li><strong>options</strong>: allowed, but outside of header, indicated by “Next Header” field</li>
<li>no fragmentation:<ul>
<li>too large to be forwarded over the outgoing link</li>
<li>the router simply drops the datagram and sends a “Packet Too Big” ICMP error message</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="Tunneling"><a href="#Tunneling" class="headerlink" title="Tunneling"></a>Tunneling</h4><ul>
<li>not all routers can be upgraded simultaneously 👉 mixed IPv4 and IPv6</li>
<li>Solution — Tunneling: IPv6 datagram carried as payload in IPv4 datagram among IPv4 routers</li>
</ul>
<p><img src="/2024/09/09/Computer-Networks/cn90.png" style="zoom:70%"></p>
<ul>
<li>transfer in routers 👇</li>
</ul>
<p><img src="/2024/09/09/Computer-Networks/cn91.png" style="zoom:70%"></p>
<h2 id="4-4-Generalized-Forward-and-SDN"><a href="#4-4-Generalized-Forward-and-SDN" class="headerlink" title="4.4. Generalized Forward and SDN"></a>4.4. Generalized Forward and SDN</h2><ul>
<li>Each router contains a flow table that is computed and distributed by a logically centralized routing controller.</li>
<li>Flow Table defines router’s <font color="red">match &amp; action rules</font></li>
</ul>
<p><img src="/2024/09/09/Computer-Networks/cn92.png" style="zoom:70%"></p>
<h3 id="OpenFlow-data-plane-abstraction"><a href="#OpenFlow-data-plane-abstraction" class="headerlink" title="OpenFlow data plane abstraction"></a>OpenFlow data plane abstraction</h3><table>
<tr>
<td><img src="/2024/09/09/Computer-Networks/cn97.png"></td>
<td><img src="/2024/09/09/Computer-Networks/cn98.png"></td>
</tr>
<tr>
<td><img src="/2024/09/09/Computer-Networks/cn99.png"></td>
<td><img src="/2024/09/09/Computer-Networks/cn100.png"></td>
</tr>
</table>

<ul>
<li>Summary of Openflow</li>
<li><strong>match+action:</strong> unifies different kinds of devices</li>
<li>Router<ul>
<li>match: longest destination IP prefix</li>
<li>action: forward out a link</li>
</ul>
</li>
<li>Switch<ul>
<li>match: destination MAC address</li>
<li>action: forward</li>
</ul>
</li>
<li>Firewall<ul>
<li>match: IP addresses and TCP/UDP port numbers</li>
<li>action: permit or deny </li>
</ul>
</li>
<li>NAT<ul>
<li>match: IP address and port</li>
<li>action: rewrite address and port</li>
</ul>
</li>
</ul>
<h1 id="Chapter-5-Network-Layer-–-The-Control-Plane"><a href="#Chapter-5-Network-Layer-–-The-Control-Plane" class="headerlink" title="Chapter 5: Network Layer – The Control Plane"></a>Chapter 5: Network Layer – The Control Plane</h1><HR style="FILTER: alpha(opacity=0, finishopacity=100,style=1)" width="100%" color="black" size="2">

<center><font face="STXinwei" size="5">Layout</font></center>

<p><strong>5.1</strong>  introduction</p>
<p><strong>5.2</strong> routing protocols</p>
<ul>
<li>link state (global)</li>
<li>distance vector (decentralized)</li>
</ul>
<p><strong>5.3</strong> intra-AS routing in the Internet: OSPF</p>
<p><strong>5.4</strong> routing among the ISPs: BGP</p>
<p><strong>5.5</strong> The SDN control plane</p>
<p><strong>5.6</strong> ICMP: The Internet Control Message Protocol </p>
<p><strong>5.7</strong> Network management and SNMP</p>
<HR style="FILTER: alpha(opacity=0,finishopacity=100,style=1)" width="100%" color="black" size="2">



<h2 id="5-1-Intro"><a href="#5-1-Intro" class="headerlink" title="5.1. Intro"></a>5.1. Intro</h2><blockquote>
<p><font color="green">Recall:</font> two network-layer functions</p>
<p>forwarding: move packets from router’s input to appropriate router output<br>(data plane)</p>
<p>routing: determine route taken by packets from source to destination<br>(control plane)</p>
</blockquote>
<ul>
<li>Two approaches to structuring network control plane:<ul>
<li>per-router control (traditional)</li>
<li>logically centralized control (software defined networking)<ul>
<li>A distinct (typically remote) controller interacts with local control agents (CAs) in routers to compute forwarding tables</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="5-2-routing-protocols"><a href="#5-2-routing-protocols" class="headerlink" title="5.2. routing protocols"></a>5.2. routing protocols</h2><h3 id="link-state-——-getting-global-info"><a href="#link-state-——-getting-global-info" class="headerlink" title="link state —— getting global info"></a>link state —— getting global info</h3><ul>
<li>A linke-state routing algorithm: <strong>Dijkstra</strong> !!!</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Init:</span><br><span class="line">N = &#123;u&#125;</span><br><span class="line">for all nodes v </span><br><span class="line">  if v adjacent to u        </span><br><span class="line">    then D(v) = c(u,v) </span><br><span class="line">  else D(v) = INF</span><br><span class="line"></span><br><span class="line">Loop:</span><br><span class="line">  find w not in N such that D(w) is a minimum</span><br><span class="line">  add w to N</span><br><span class="line">  update D(v) for all v adjacent to w and not in N:</span><br><span class="line">    D(v) &lt;- min(D(v), D(w)+c(w, v))</span><br><span class="line">until all nodes in N</span><br></pre></td></tr></table></figure>
<ul>
<li>An example:</li>
</ul>
<p><img src="/2024/09/09/Computer-Networks/cn86.png"></p>
<h3 id="distance-vector-——-getting-decentralized-info"><a href="#distance-vector-——-getting-decentralized-info" class="headerlink" title="distance vector —— getting decentralized info"></a>distance vector —— getting decentralized info</h3><ul>
<li><font color="blue">Distributed:</font> each node receives some information from one or more of its directly attached neighbors, performs a calculation, and then distributes the results of its calculation back to its neighbors. </li>
<li><font color="blue">Iterative:</font> this process continues on until no more information is exchanged between neighbors. </li>
<li><font color="blue">Asynchronous:</font> it does not require all of the nodes to operate in lockstep with each other.</li>
</ul>
<blockquote>
<p>Introduce <strong>Bellman-Ford Equation</strong></p>
</blockquote>
<ul>
<li>$d_{x}(y):=$ cost of least-cost path from $x$ to $y$</li>
<li>$d_{x}(y)=\min_{v}\{ c(x,v)+d_{v}(y) \}$<ul>
<li>where $v$ represnets all neighbors of $x$</li>
</ul>
</li>
</ul>
<blockquote>
<p>How this work in DV ?</p>
</blockquote>
<ul>
<li>Node $x$:<ul>
<li>knows cost to each neighbor $v$: $c(x,v)$</li>
<li>maintains its recent distance vector $D_x = [D_x(y): y \in N ]$</li>
<li>maintains its neighbors’ recent distance vectors. For each neighbor $v$, $x$ maintains $D_v = [D_v(y): y \in N ]$</li>
</ul>
</li>
<li>Key Idea:<ul>
<li>From time-to-time, each node sends its own <font color="red">recent</font> distance vector (DV) to neighbors</li>
<li>When $x$ receives new DV from neighbor, it updates its own DV using B-F equation</li>
<li>If its DV has changed, sends the updated DV to neighbors </li>
</ul>
</li>
</ul>
<table><tr>
    <td><img src="/2024/09/09/Computer-Networks/cn87.png"></td>
    <td><img src="/2024/09/09/Computer-Networks/cn88.png"></td>
</tr></table>

<blockquote>
<p>Problems: In “good news” (some link cost decrease), the update of forwarding table converge fast (with fewer iterations). But in “bad news” (cost increase), it require more iters to converge the forwarding table!</p>
</blockquote>
<p><strong>Solution: Poisoned reverse</strong></p>
<ul>
<li>(Example above.) If $Z$ routes through $Y$ to get to $X$ :<ul>
<li>$Z$ tells $Y$ its ($Z$’s) distance to $X$ is infinite (so $Y$ won’t route to $X$ via $Z$)</li>
</ul>
</li>
<li>However, when there are <font color="red">more than one loop</font>, this method doesn’t work!</li>
</ul>
<h3 id="Comparison-of-LS-and-DV"><a href="#Comparison-of-LS-and-DV" class="headerlink" title="Comparison of LS and DV"></a>Comparison of LS and DV</h3><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center">Link State</th>
<th style="text-align:center">Distance Vector</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">message complexity</td>
<td style="text-align:center">with $n$ nodes, $E$ links, $O(nE)$ msgs sent</td>
<td style="text-align:center">exchange between neighbors only</td>
</tr>
<tr>
<td style="text-align:center">Speed of convergence</td>
<td style="text-align:center">$O(n^2)$ algorithm</td>
<td style="text-align:center">time varies(count-to-infinite problem)</td>
</tr>
<tr>
<td style="text-align:center">Robustness</td>
<td style="text-align:center">node can advertise incorrect link cost, each node computes only its own table</td>
<td style="text-align:center">DV node can advertise incorrect path cost, each node’s table used by others</td>
</tr>
</tbody>
</table>
</div>
<h2 id="5-3-intra-AS-routing-in-the-Internet-OSPF"><a href="#5-3-intra-AS-routing-in-the-Internet-OSPF" class="headerlink" title="5.3. intra-AS routing in the Internet: OSPF"></a>5.3. intra-AS routing in the Internet: OSPF</h2><blockquote>
<p>Both LS and DV have problems in practice</p>
<p>We want to make routing scalable</p>
</blockquote>
<ul>
<li>Solution: aggregate routers into regions known as “autonomous systems” (AS) (a.k.a. “domains”)<ul>
<li>Gateway router: at “edge” of its own AS, has link(s) to router(s) in other AS</li>
<li>Interior router: no link to other AS</li>
</ul>
</li>
</ul>
<p><img src="/2024/09/09/Computer-Networks/cn101.png" style="zoom:60%"></p>
<ul>
<li>intra-AS routing<ul>
<li>routing among hosts, routers in <font color="red">same AS</font> (“network”)</li>
<li>all routers in AS must run same intra-domain protocol</li>
<li>routers in different AS can run different intra-AS routing protocol</li>
</ul>
</li>
<li>inter-AS routing<ul>
<li>routing among AS’es</li>
<li>gateways perform inter-AS routing (as well as intra-AS routing)</li>
</ul>
</li>
</ul>
<blockquote>
<p>Q: How does it function in practice?</p>
<p>A: forwarding table  configured by both intra and inter-AS routing algorithm</p>
</blockquote>
<h3 id="Intra-AS-Routing"><a href="#Intra-AS-Routing" class="headerlink" title="Intra-AS Routing"></a>Intra-AS Routing</h3><ul>
<li>also known as interior gateway protocols (IGP)</li>
<li>most common intra-AS routing protocols:<ul>
<li>RIP: Routing Information Protocol (distance vector-based)</li>
<li>OSPF: Open Shortest Path First (link state based)</li>
<li>IS-IS protocol essentially same as OSPF</li>
<li>IGRP: Interior Gateway Routing Protocol (Cisco proprietary for decades, until 2016)</li>
</ul>
</li>
</ul>
<blockquote>
<p>Inter-AS Routing will be talked in 5.4</p>
</blockquote>
<h3 id="OSPF-Open-Shortest-Path-First"><a href="#OSPF-Open-Shortest-Path-First" class="headerlink" title="OSPF (Open Shortest Path First)"></a>OSPF (Open Shortest Path First)</h3><ul>
<li>“open”: publicly available<ul>
<li>Message format, routing algorithms, link-state broadcast, etc.</li>
</ul>
</li>
<li>uses link-state algorithm <ul>
<li>link state packet dissemination</li>
<li>topology map at each node</li>
<li>route computation using Dijkstra’s algorithm</li>
</ul>
</li>
<li>router floods OSPF link-state advertisements to all other routers in entire AS<ul>
<li>carried in OSPF messages <font color="red">directly over IP</font> (rather than TCP or UDP)</li>
<li>Reliable message transfer, link-state broadcast</li>
</ul>
</li>
</ul>
<p><strong>OSPF “advanced” features</strong></p>
<ul>
<li><font color="red">security:</font> all OSPF messages authenticated (to prevent malicious intrusion) <ul>
<li>Password; private and public key </li>
</ul>
</li>
<li><font color="red">multiple same-cost paths</font> allowed (only one path in RIP)</li>
<li>integrated uni- and <font color="red">multi-cast</font> support: <ul>
<li>Multicast OSPF (MOSPF) uses same topology data base as OSPF</li>
</ul>
</li>
<li><font color="red">hierarchical</font> OSPF in large domains.<ul>
<li><font color="red">Two-level hierarchy:</font> local area, backbone.<ul>
<li>link-state advertisements only in area </li>
<li>each nodes has detailed area topology; only know direction (shortest path) to nets in other areas.</li>
</ul>
</li>
<li><font color="red">Area border routers:</font> routing packets outside the area.</li>
<li><font color="red">Backbone routers:</font> run OSPF routing limited to backbone.</li>
<li><font color="red">Boundary (gateway) routers:</font> connect to other AS’es.</li>
</ul>
</li>
</ul>
<p><img src="/2024/09/09/Computer-Networks/cn102.png"></p>
<h2 id="5-4-Routing-among-the-ISPs-BGP"><a href="#5-4-Routing-among-the-ISPs-BGP" class="headerlink" title="5.4. Routing among the ISPs: BGP"></a>5.4. Routing among the ISPs: BGP</h2><blockquote>
<p>5.3 is about intra-AS routing (inside 1 AS), while 5.4 will talk about <strong>inter-AS</strong> routing (between 2 or more AS)</p>
</blockquote>
<h3 id="Overview-3"><a href="#Overview-3" class="headerlink" title="Overview"></a>Overview</h3><ul>
<li>BGP: iBGP, eBGP</li>
<li>Route Selection</li>
<li>IP-Anycast</li>
<li>BGP Routing Policy</li>
</ul>
<h3 id="BGP"><a href="#BGP" class="headerlink" title="BGP"></a>BGP</h3><ul>
<li>Each pair of BGP (Border Gateway Protocol) routers (“peers”) exchanges BGP messages over TCP connection:<ul>
<li>advertising paths to destination network prefixes (e.g., X)</li>
</ul>
</li>
</ul>
<p><img src="/2024/09/09/Computer-Networks/cn93.png" style="zoom:50%"></p>
<ul>
<li><strong>eBGP:</strong> When AS3 gateway router 3a advertises path AS3,X to AS2 gateway router 2c:<ul>
<li>AS3 promises to AS2 it will forward datagrams towards X</li>
</ul>
</li>
</ul>
<p><img src="/2024/09/09/Computer-Networks/cn94.png" style="zoom:50%"></p>
<ul>
<li><strong>iBGP:</strong> When 1c accept the advertisement from 2a (2a told 1c that “it has a way to X”), 1c will propagate it to <strong>all routers</strong> in AS1</li>
</ul>
<blockquote>
<p><font color="red">Q:</font> how does router set forwarding table entry to distant prefix ?</p>
<p><font color="green">A:</font> Work BGP, OSPF and forwarding table entries together 👇</p>
</blockquote>
<ul>
<li>E.g. <code>1d</code> wants to go to <code>X</code></li>
<li><code>1a</code>, <code>1b</code>, <code>1d</code> learn about dest <code>X</code> via iBGP from <code>1c</code>: “path to X goes through 2a (NEXT-HOP)”</li>
<li>to get to <code>2a-I1</code>, forward over outgoing local interface 1<ul>
<li>Intra-AS protocol</li>
</ul>
</li>
</ul>
<h3 id="Route-Selection"><a href="#Route-Selection" class="headerlink" title="Route Selection"></a>Route Selection</h3><p>Choose route based on one of the severals policies:</p>
<ol>
<li>local preference value attribute: policy decision</li>
<li>shortest AS-PATH </li>
<li>closest NEXT-HOP router: hot potato routing</li>
<li>additional criteria </li>
</ol>
<blockquote>
<p>Hot potato routing: choose local gateway that has least intra domain cost (the shortest way to “go out”!)</p>
</blockquote>
<h3 id="IP-Anycast-Service-CDN-DNS"><a href="#IP-Anycast-Service-CDN-DNS" class="headerlink" title="IP Anycast Service: CDN/DNS"></a>IP Anycast Service: CDN/DNS</h3><p><img src="/2024/09/09/Computer-Networks/cn95.png" style="zoom:60%"></p>
<h3 id="BGP-Routing-Policy"><a href="#BGP-Routing-Policy" class="headerlink" title="BGP Routing Policy"></a>BGP Routing Policy</h3><ul>
<li>policy: <ul>
<li>inter-AS: admin wants control over how its traffic routed, who routes through its net. </li>
<li>intra-AS: single admin, so no policy decisions needed </li>
</ul>
</li>
<li>performance: <ul>
<li>intra-AS: can focus on performance</li>
<li>inter-AS: policy may dominate over performance</li>
</ul>
</li>
<li>scale:<ul>
<li>hierarchical routing saves table size, reduced update traffic</li>
</ul>
</li>
</ul>
<h2 id="5-5-The-SDN-control-plane"><a href="#5-5-The-SDN-control-plane" class="headerlink" title="5.5. The SDN control plane"></a>5.5. The SDN control plane</h2><blockquote>
<p><font color="green">Recall:</font> SDN logically centralized control plane</p>
<p>A distinct (typically remote) controller interacts with local control agents (CAs) in routers to compute forwarding tables</p>
</blockquote>
<p><img src="/2024/09/09/Computer-Networks/cn96.png" style="zoom:60%"></p>
<ul>
<li><font color="red">Q:</font> Why a logically centralized control plane ?</li>
<li>easier network management: avoid router misconfigurations, greater flexibility of traffic flows</li>
<li>table-based forwarding (recall OpenFlow API) allows “programming” routers<ul>
<li>centralized “programming” easier: compute tables centrally and distribute</li>
<li>distributed “programming” more difficult: compute tables as result of distributed algorithm (protocol) implemented in each and every router </li>
</ul>
</li>
<li>open (non-proprietary) implementation of control plane</li>
</ul>
<blockquote>
<p>Traffic engineering has difficulties:</p>
<ol>
<li>To define path needs to know link weights</li>
<li>hard to support multi-path routing (balance traffic)</li>
<li>one switch hard to handle different source to different dst.</li>
</ol>
</blockquote>
<ul>
<li>What SDN do ?<ol>
<li>generalized “flow based” forwarding  (e.g., OpenFlow)</li>
<li>control, data plane  separation</li>
<li>control plane functions external to data plane switches</li>
<li>programmable control applications</li>
</ol>
</li>
</ul>
<h3 id="Components-of-SDN-controller"><a href="#Components-of-SDN-controller" class="headerlink" title="Components of SDN controller"></a>Components of SDN controller</h3><ul>
<li><strong>Interface layer to network control apps</strong>: abstractions API</li>
<li><strong>Network-wide state management layer</strong>: state of networks links, switches, services: a distributed database</li>
<li><strong>communication layer</strong>: communicate between SDN controller and controlled switches (e.g. OpenFlow)</li>
</ul>
<blockquote>
<p>OpenFlow protocol</p>
</blockquote>
<ul>
<li>controller-to-switch messages<ul>
<li><strong>configure</strong>: controller queries/sets  switch configuration parameters</li>
<li><strong>modify-state</strong>: add, delete, modify  flow entries in the OpenFlow tables</li>
<li><strong>Read-state</strong>: collect statistics and  counter values from the switch’s  flow table and ports</li>
<li><strong>packet-out</strong>: controller can send this  packet out of specific switch port</li>
</ul>
</li>
<li>switch-to-controller messages<ul>
<li>packet-in: transfer packet (and its  control) to controller.  See packet out message from controller</li>
<li>flow-removed: flow table entry  deleted at switch</li>
<li>port status: inform controller of a change on a port.</li>
</ul>
</li>
</ul>
<h2 id="5-6-ICMP-The-Internet-Control-Message-Protocol"><a href="#5-6-ICMP-The-Internet-Control-Message-Protocol" class="headerlink" title="5.6. ICMP: The Internet Control Message Protocol"></a>5.6. ICMP: The Internet Control Message Protocol</h2><ul>
<li>used by hosts &amp; routers to communicate network level information<ul>
<li>error reporting: unreachable host, network, port, protocol</li>
<li>echo request/reply (used by ping)</li>
</ul>
</li>
<li>network-layer “above” IP:<ul>
<li>ICMP msgs carried in IP datagrams</li>
</ul>
</li>
<li>ICMP message: <ul>
<li>Type + code + the header and the first 8 bytes of IP datagram causing error</li>
</ul>
</li>
</ul>
<p><img src="/2024/09/09/Computer-Networks/cn103.png" style="zoom:60%"></p>
<h3 id="Traceroute-and-ICMP"><a href="#Traceroute-and-ICMP" class="headerlink" title="Traceroute and ICMP"></a>Traceroute and ICMP</h3><ul>
<li>source sends series of UDP segments to destination<ul>
<li>first set has <code>TTL = 1</code></li>
<li>second set has <code>TTL = 2</code>, etc.</li>
<li>unlike port number</li>
</ul>
</li>
<li>when datagram in nth set arrives to nth router:<ul>
<li>router discards datagram and sends source ICMP message (type 11, code 0)</li>
<li>ICMP message include name of router &amp; IP address</li>
</ul>
</li>
<li>when ICMP message arrives, source records RTTs</li>
<li><strong>OR</strong> traceroute fail: the destination return ICMP “post unreachable” message (type 3, code 3), and source stops.</li>
</ul>
<p><img src="/2024/09/09/Computer-Networks/cn104.png"></p>
<h2 id="Summary-1"><a href="#Summary-1" class="headerlink" title="Summary"></a>Summary</h2><blockquote>
<p>What we learn in network layer</p>
</blockquote>
<ul>
<li>approaches to network control plane<ul>
<li>per-router control (traditional)</li>
<li>logically centralized control (software defined networking)</li>
</ul>
</li>
<li>traditional routing algorithms<ul>
<li>implementation in Internet: OSPF, BGP</li>
</ul>
</li>
<li>SDN controllers<ul>
<li>implementation in practice: ODL, ONOS</li>
</ul>
</li>
<li>Internet Control Message Protocol</li>
<li>(network management)</li>
</ul>
<h1 id="Chapter-6-Link-Layer"><a href="#Chapter-6-Link-Layer" class="headerlink" title="Chapter 6: Link Layer"></a>Chapter 6: Link Layer</h1><HR style="FILTER: alpha(opacity=0, finishopacity=100,style=1)" width="100%" color="black" size="2">

<center><font face="STXinwei" size="5">Layout</font></center>

<p><strong>6.1</strong>  introduction, services</p>
<p><strong>6.2</strong> error detection, correction </p>
<p><strong>6.3</strong> multiple access protocols</p>
<p><strong>6.4</strong> LANs</p>
<ul>
<li>addressing, ARP</li>
<li>Ethernet</li>
<li>switches</li>
<li>VLANS</li>
</ul>
<p><strong>6.5</strong> link virtualization: MPLS</p>
<p><strong>6.6</strong> data center networking</p>
<p><strong>6.7</strong> a day in the life of a web request</p>
<HR style="FILTER: alpha(opacity=0,finishopacity=100,style=1)" width="100%" color="black" size="2">



<h2 id="6-1-Introduction-amp-Services"><a href="#6-1-Introduction-amp-Services" class="headerlink" title="6.1. Introduction &amp; Services"></a>6.1. Introduction &amp; Services</h2><p><img src="/2024/09/09/Computer-Networks/cn105.png" style="zoom:80%"></p>
<p><strong>Link layer services</strong></p>
<ul>
<li><font color="red">framing, link access</font>: <ul>
<li>encapsulate datagram into frame, adding header, trailer</li>
<li>channel access if shared medium</li>
<li>“MAC” addresses used in frame headers to identify source, destination  <ul>
<li>different from IP address!</li>
</ul>
</li>
</ul>
</li>
<li><font color="red">reliable delivery between adjacent nodes</font>:<ul>
<li>seldom used on low bit-error link (fiber, some twisted pair)</li>
<li>wireless links: high error rates<ul>
<li>Q: why both link-level and end-end reliability?</li>
</ul>
</li>
</ul>
</li>
<li><font color="red">flow control</font>: <ul>
<li>pacing between adjacent sending and receiving nodes</li>
</ul>
</li>
<li><font color="red">error detection</font>: <ul>
<li>errors caused by signal attenuation, noise. </li>
<li>receiver detects presence of errors: <ul>
<li>signals sender for retransmission or drops frame </li>
</ul>
</li>
</ul>
</li>
<li><font color="red">error correction</font>: <ul>
<li>receiver identifies and corrects bit error(s) without resorting to retransmission</li>
</ul>
</li>
<li><font color="red">half-duplex and full-duplex</font>:<ul>
<li>with half duplex, nodes at both ends of link can transmit, but not at same time</li>
</ul>
</li>
</ul>
<p><strong>Adaptors Communicating</strong></p>
<p><img src="/2024/09/09/Computer-Networks/cn106.png"></p>
<ul>
<li>Sending side:<ul>
<li>encapsulates datagrams in frame</li>
<li>adds error checking bits, rdt, flow control, etc.</li>
</ul>
</li>
<li>Receiving side:<ul>
<li>looks for errors, rdt, flow control, etc.</li>
<li>extracts datagram, passes to upper layer at receiving side</li>
</ul>
</li>
</ul>
<h2 id="6-2-Error-detection-amp-correction"><a href="#6-2-Error-detection-amp-correction" class="headerlink" title="6.2. Error detection &amp; correction"></a>6.2. Error detection &amp; correction</h2><p>EDC = Error Detection and Correction bits</p>
<p>D = Data protected by error checking, may include header fields</p>
<p><img src="/2024/09/09/Computer-Networks/cn107.png"></p>
<ul>
<li>Parity check</li>
<li>Check-sum methods (<font color="green">Recall internet checksum</font>)</li>
<li>Cyclic-redundancy check</li>
</ul>
<h3 id="Parity-Check"><a href="#Parity-Check" class="headerlink" title="Parity Check"></a>Parity Check</h3><p><img src="/2024/09/09/Computer-Networks/cn108.png"></p>
<p>Case 1: one-bit error 👉 good performance;</p>
<p>Case 2: multiple-bits error, but in different lines 👉 some correct bits may be detected as incorrect</p>
<p>Case 3: multiple-bits error in one line 👉 may fail to detect</p>
<h3 id="Cyclic-redundancy-check"><a href="#Cyclic-redundancy-check" class="headerlink" title="Cyclic redundancy check"></a>Cyclic redundancy check</h3><p><img src="/2024/09/09/Computer-Networks/cn109.png"></p>
<ul>
<li>view <code>D</code>, and choose (r + 1) bit pattern (generator), <code>G</code></li>
<li>goal: choose r CRC bits, R, such that<ul>
<li>{D, R} exactly divisible by G (modulo 2)</li>
<li>receiver knows G, divides {D, R} by G. If non-zero remainder: error detected!</li>
<li>can detect all consecutive bit errors of r bits or less</li>
</ul>
</li>
<li>E.g. 👇</li>
</ul>
<p><img src="/2024/09/09/Computer-Networks/cn110.png"></p>
<h2 id="6-3-Multiple-Access-Protocol"><a href="#6-3-Multiple-Access-Protocol" class="headerlink" title="6.3. Multiple Access Protocol"></a>6.3. Multiple Access Protocol</h2><p><strong>2 types of “links”</strong></p>
<ul>
<li>point-to-point<ul>
<li>PPP for dial-up access</li>
<li>point-to-point link between Ethernet switch, host</li>
</ul>
</li>
<li><font color="red">broadcast (shared wire or medium)</font>:<ul>
<li>old-fashioned Ethernet</li>
<li>802.11 wireless LAN (WLAN)</li>
</ul>
</li>
</ul>
<h3 id="multiple-access-protocol"><a href="#multiple-access-protocol" class="headerlink" title="multiple access protocol"></a>multiple access protocol</h3><ul>
<li>distributed algorithm that determines how nodes share channel, i.e., determine which and when node can transmit</li>
<li>communication about channel sharing must use channel itself! <ul>
<li>no out-of-band channel for coordination</li>
</ul>
</li>
</ul>
<p><strong>Ideal MAC</strong></p>
<ol>
<li>Given channel of rate $R$ bps, $M$ nodes wanted to transmit can send at rate $R/M$</li>
<li>Fully decentralized<ul>
<li>no special node to coordinate transmissions</li>
<li>no synchronization of clocks, slots</li>
</ul>
</li>
<li>simple</li>
</ol>
<p><strong>Three broad classes</strong></p>
<ul>
<li><font color="red">channel partitioning</font>:<ul>
<li>divide channel into smaller “pieces” (time slots, frequency, code)</li>
<li>allocate piece to node for exclusive use</li>
</ul>
</li>
<li><font color="red">random access</font>:<ul>
<li>channel not divided, allow collisions</li>
<li>“recover” from collisions</li>
</ul>
</li>
<li><font color="red">“taking turns”</font>:<ul>
<li>nodes take turns, but nodes with more to send can take longer turns</li>
</ul>
</li>
</ul>
<h4 id="Channel-partitioning-MAC-protocols"><a href="#Channel-partitioning-MAC-protocols" class="headerlink" title="Channel partitioning MAC protocols"></a>Channel partitioning MAC protocols</h4><ul>
<li>TDMA (Time Division Multiple Access)<ul>
<li>access to channel in “rounds” </li>
<li>each station gets fixed length slot (length = packet transmission time) in each round </li>
<li>unused slots go idle </li>
<li>example: 6-station LAN, 1,3,4 have packets to send, slots 2,5,6 idle</li>
</ul>
</li>
</ul>
<p><img src="/2024/09/09/Computer-Networks/cn111.png"></p>
<ul>
<li>FDMA: frequency division multiple access <ul>
<li>channel spectrum divided into frequency bands</li>
<li>each station assigned fixed frequency band</li>
<li>unused transmission time in frequency bands go idle </li>
<li>example: 6-station LAN, 1, 3, 4 have packet to send, frequency bands 2, 5, 6 idle </li>
</ul>
</li>
</ul>
<p><img src="/2024/09/09/Computer-Networks/cn112.png"></p>
<ul>
<li>Limitations:<ul>
<li>sometimes idle but somtimes full (not efficient enough)</li>
</ul>
</li>
</ul>
<h4 id="Random-access-protocols"><a href="#Random-access-protocols" class="headerlink" title="Random access protocols"></a>Random access protocols</h4><ul>
<li>Random access; if fails, wait for a random time</li>
<li>two or more transmitting nodes 👉  “collision”,</li>
<li>random access MAC protocol specifies: <ul>
<li>how to detect collisions</li>
<li>how to recover from collisions (e.g., via delayed retransmissions)</li>
</ul>
</li>
<li>Advantage: when node has packet to send<ul>
<li>transmit at full channel data rate R.</li>
<li>no a priori coordination among nodes</li>
</ul>
</li>
<li>examples of random access MAC protocols:<ul>
<li>slotted ALOHA</li>
<li>ALOHA</li>
<li>CSMA, CSMA/CD (Ethernet), CSMA/CA (802.11) <font color="grey">[See at Chap 7]</font></li>
</ul>
</li>
</ul>
<h4 id="Slotted-ALOHA-example-of-RAP"><a href="#Slotted-ALOHA-example-of-RAP" class="headerlink" title="Slotted ALOHA: example of RAP"></a>Slotted ALOHA: example of RAP</h4><p><img src="/2024/09/09/Computer-Networks/cn113.png"></p>
<ul>
<li>Operations: when node obtains fresh frame, transmits in next slot<ul>
<li>if no collision: node can send new frame in next slot</li>
<li>if collision: node retransmits frame in each subsequent slot with probability <code>p</code> until success</li>
</ul>
</li>
<li>Pros<ul>
<li>single active node can continuously transmit at full rate of channel</li>
<li>highly decentralized: only slots in nodes need to be in sync</li>
<li>simple</li>
</ul>
</li>
<li>Cons<ul>
<li>collisions, wasting slots</li>
<li>idle slots</li>
<li>clock synchronization</li>
</ul>
</li>
</ul>
<center>---  Calculations ---</center>

<ul>
<li>Suppose: $N$ nodes with many frames to send, each transmits in slot with probability $p$</li>
</ul>
<blockquote>
<p>会算ALOHA的有效传输的效率</p>
<p>CSMA：传输前感知——会遇到collision：传输延迟导致</p>
<p>CSMA+CD (Collision Detection): Lec14 p19</p>
<p>Ethernet CSMA/CD algorithm（了解）</p>
</blockquote>
<h4 id="“Taking-turns”-MAC-protocols"><a href="#“Taking-turns”-MAC-protocols" class="headerlink" title="“Taking turns” MAC protocols"></a>“Taking turns” MAC protocols</h4><p>look for best of both worlds! </p>
<ul>
<li>when one node wants to transmit, it can send at rate $R$. </li>
<li>when $M$ nodes want to transmit, each can send at  average rate $R/M$</li>
</ul>
<blockquote>
<p>概念：master 主机和 slaves 主机</p>
<p>master 轮询（无论 slaves 是否有 frame）</p>
<p>问题：轮询消耗；master 单点错误</p>
<p>另一种方式：token 传输</p>
<p>token 经过节点，有 frame 传 frame，没有直接 pass</p>
<p>问题：token 负载和单点错误</p>
</blockquote>
<h2 id="6-4-LANs"><a href="#6-4-LANs" class="headerlink" title="6.4 LANs"></a>6.4 LANs</h2><blockquote>
<p>概念：lec14 p29</p>
<p>MAC （或 LAN或以太网）地址：适配器（在网络接口）的地址</p>
<p>链路层 switches 没有 MAC 地址</p>
<p>作用：获取“本地”（同一个子网？）的 frame</p>
<p>概念： LAN 地址和 ARP</p>
<p>Lec14 p29：每个 LAN 上的适配器有一个唯一的 LAN 地址</p>
<ul>
<li>MAC 地址类似 ID；IP 地址类似邮政编码</li>
</ul>
</blockquote>
<ul>
<li>一个适配器给另一个适配器发送 frame<ul>
<li>用 dst 的MAC地址封装然后发送到局域网</li>
</ul>
</li>
<li>适配器接收到时检查是否匹配，选择是否解封装或丢弃</li>
<li>MAC 广播地址 <code>FF-FF-FF-FF-FF-FF</code></li>
</ul>
<blockquote>
<p>Q: How to determine interface’s MAC address, given its  IP address?</p>
</blockquote>
<h3 id="ARP"><a href="#ARP" class="headerlink" title="ARP"></a>ARP</h3><p><strong>Def.</strong> Resolve addresses only for  interfaces on the same subnet.</p>
<ul>
<li><strong>ARP table</strong>: each IP node (host,  router) on LAN has table</li>
</ul>
<h4 id="ARP-protocol"><a href="#ARP-protocol" class="headerlink" title="ARP protocol"></a>ARP protocol</h4><ul>
<li>same LAN<ul>
<li>broadcast</li>
</ul>
</li>
<li>diff LAN<ul>
<li>focus on addressing – at IP (datagram) and MAC layer (frame)</li>
<li>assume A knows B’s IP address, knows IP address of first hop router (e.g. R) or knows R’s MAC address?</li>
<li>Lec14 p37-p41</li>
</ul>
</li>
</ul>
<h3 id="Ethernet"><a href="#Ethernet" class="headerlink" title="Ethernet"></a>Ethernet</h3><ul>
<li>first widely used LAN technology </li>
<li>simpler, cheap </li>
<li>kept up with speed race: 10 Mbps – 10 Gbps</li>
</ul>
<blockquote>
<p>概念：bus，star</p>
</blockquote>
<ul>
<li>了解：Ethernet frame structure<ul>
<li><strong>Preamble</strong>: 7 bytes with pattern <code>10101010</code> followed by one byte with  pattern <code>10101011</code></li>
<li>dst / src addresses: 6 byte source, destination MAC addresses</li>
<li><strong>type</strong>: indicates higher layer protocol (mostly IP)</li>
<li><strong>CRC</strong>: cyclic redundancy check at receiver (with error detection)</li>
</ul>
</li>
<li>Connectionless and Unreliable<ul>
<li>no handshaking between sending and  receiving NICs</li>
<li>receiving NIC doesn’t send acks or nacks  to sending NIC</li>
</ul>
</li>
<li>Ethernet’s MAC protocol: <font color="red">unslotted CSMA/CD with  binary backoff</font> </li>
</ul>
<blockquote>
<p>Ethernet 有普遍的 MAC 协议和帧格式，但是物理网络（网线/传输速度）不同</p>
</blockquote>
<h3 id="Switch"><a href="#Switch" class="headerlink" title="Switch"></a>Switch</h3><blockquote>
<p>介绍：Ethernet Switch——链路层设备，用于中转帧（含选择）</p>
<p>switch 实现多并发传输</p>
<p>switch 无需人工配置（自学习），维护一个 switch table：(MAC address of host, interface  to reach host, time stamp)</p>
<p>自学习例子：终端 A 对应接口 x，终端 B 对应接口（未知），A 往 B 发送帧：</p>
<ul>
<li>switch 中未学习到B的接口：往x以外的所有接口输送</li>
<li>发现 B 对应接口 x ：丢弃帧</li>
<li>发现 B 对应接口 y ：forward</li>
</ul>
</blockquote>
<p>了解：企业（机构）网络 Lec14 p57</p>
<blockquote>
<p>对比 bus/hub，switch 的优势：</p>
<ul>
<li>Elimination of collisions (one frame on a time)</li>
<li>Heterogeneous links (diff link with diff speed)</li>
<li>Management (disconnect malfunctions NI)</li>
</ul>
</blockquote>
<h3 id="VLANs"><a href="#VLANs" class="headerlink" title="VLANs"></a>VLANs</h3><blockquote>
<p>Motivation:</p>
<ul>
<li>single broadcast domain (效率，安全)</li>
<li>Inefficient use of switches</li>
</ul>
</blockquote>
<h4 id="Port-based-VLAN"><a href="#Port-based-VLAN" class="headerlink" title="Port-based VLAN"></a>Port-based VLAN</h4><ul>
<li>traffic isolation (defined by switch port or MAC addresses)</li>
<li>dynamic membership</li>
<li>forwarding between VLANS: done  via routing (just as with separate  switches)</li>
</ul>
<blockquote>
<p>Q: what if one VLAN over multiple switches ?</p>
<p>A: one trunk port to connect two switches.</p>
</blockquote>
<h2 id="6-6-data-center-networking-略"><a href="#6-6-data-center-networking-略" class="headerlink" title="6.6 data center networking (略)"></a>6.6 data center networking (略)</h2><h2 id="6-7-a-day-in-the-life-of-a-web-request"><a href="#6-7-a-day-in-the-life-of-a-web-request" class="headerlink" title="6.7 a day in the life of a web request"></a>6.7 a day in the life of a web request</h2><ol>
<li>connecting to the Internet<ul>
<li>send DHCP to DHCP server, which reply DHCP ACK to endpoint</li>
<li>get IP address, info of DNS server and first-hop router IP</li>
</ul>
</li>
<li>ARP: get MAC address of first-hop</li>
<li>DNS: get IP of <code>www.google.com</code> , for example</li>
<li>TCP connection carrying HTTP</li>
<li>HTTP request/reply</li>
</ol>
<h1 id="Chapter-7-Wireless-and-Mobile-Networks"><a href="#Chapter-7-Wireless-and-Mobile-Networks" class="headerlink" title="Chapter 7. Wireless and Mobile Networks"></a>Chapter 7. Wireless and Mobile Networks</h1><HR style="FILTER: alpha(opacity=0, finishopacity=100,style=1)" width="100%" color="black" size="2">

<center><font face="STXinwei" size="5">Layout</font></center>

<p><strong>7.1</strong>  introduction</p>
<p><strong>Wireless</strong></p>
<p><strong>7.2</strong> Wireless links, characteristics</p>
<ul>
<li>CDMA</li>
</ul>
<p><strong>7.3</strong> IEEE 802.11 wireless LANs (“Wi-Fi”)</p>
<p><strong>7.4</strong> Cellular Internet Access</p>
<ul>
<li>architecture</li>
<li>standards (e.g., 3G, LTE)</li>
</ul>
<p><strong>Mobility</strong></p>
<p><strong>7.5</strong> Principles: addressing and routing to mobile users</p>
<p><strong>7.6</strong> Mobile IP</p>
<p><strong>7.7</strong> Handling mobility in cellular networks</p>
<p><strong>7.8</strong> Mobility and higher-layer protocols</p>
<HR style="FILTER: alpha(opacity=0,finishopacity=100,style=1)" width="100%" color="black" size="2">



<h2 id="7-1-Intro"><a href="#7-1-Intro" class="headerlink" title="7.1 Intro"></a>7.1 Intro</h2><h2 id="Elements"><a href="#Elements" class="headerlink" title="Elements"></a>Elements</h2><ul>
<li>wireless hosts</li>
<li>base station</li>
<li>wireless link</li>
</ul>
<h2 id="7-2-Wireless-links"><a href="#7-2-Wireless-links" class="headerlink" title="7.2 Wireless links"></a>7.2 Wireless links</h2><ul>
<li>Characters<ul>
<li>decreased signal strength</li>
<li>interference from other sources</li>
<li>multipath propagation</li>
</ul>
</li>
</ul>
<blockquote>
<p>概念：SNR: signal-to-noise ratio</p>
</blockquote>
<h3 id="CDMA-Code-Division-Multiple-Access"><a href="#CDMA-Code-Division-Multiple-Access" class="headerlink" title="CDMA: Code Division Multiple Access"></a>CDMA: Code Division Multiple Access</h3><ul>
<li>unique “code” assigned to each user; i.e., code set  partitioning <ul>
<li>all users share same frequency, but each user has own  “chipping” sequence (i.e., code) to encode data </li>
<li>allows multiple users to “coexist” and transmit  simultaneously with minimal interference (if codes are  “orthogonal”) </li>
</ul>
</li>
<li>encoded signal = (original data) x (chipping  sequence) </li>
<li>decoding: inner-product of encoded signal and  chipping sequence</li>
</ul>
<h2 id="7-3-IEEE-802-11-Wireless-LAN"><a href="#7-3-IEEE-802-11-Wireless-LAN" class="headerlink" title="7.3 IEEE 802.11 Wireless LAN"></a>7.3 IEEE 802.11 Wireless LAN</h2><ul>
<li>2.4-5 GHz unlicensed  spectrum </li>
<li>up to 11 Mbps </li>
<li>direct sequence spread  spectrum (DSSS) in physical  layer <ul>
<li>all hosts use same  chipping code</li>
</ul>
</li>
</ul>
<blockquote>
<p>802.11 LAN Architecture: Lec15 p36</p>
<p>Collision Avoidance: RTS-CTS  exchange: Lec15 p38 (熟悉流程)</p>
</blockquote>
<h2 id="7-4-Cellular-Internet-access"><a href="#7-4-Cellular-Internet-access" class="headerlink" title="7.4 Cellular Internet  access"></a>7.4 Cellular Internet  access</h2><blockquote>
<p>蜂窝网络</p>
</blockquote>
<p>Cell</p>
<ul>
<li>covers geographical region </li>
<li>base station (BS)  analogous to 802.11 AP </li>
<li>mobile users  attach to network  through BS </li>
<li>air-interface:  physical and link layer protocol between mobile and BS</li>
</ul>
<h2 id="7-5-Principles-addressing-and-routing-to-mobile-users"><a href="#7-5-Principles-addressing-and-routing-to-mobile-users" class="headerlink" title="7.5 Principles: addressing  and routing to mobile  users"></a>7.5 Principles: addressing  and routing to mobile  users</h2><h1 id="Labs"><a href="#Labs" class="headerlink" title="Labs"></a>Labs</h1><h2 id="Week-1"><a href="#Week-1" class="headerlink" title="Week 1"></a><a name="lab01">Week 1</a></h2><blockquote>
<p>Introduce to Lab 01:</p>
<p>应用层（Application）</p>
<ul>
<li><code>ipconfig</code></li>
<li><code>nslookup</code></li>
</ul>
<p>网络层（Network）</p>
<ul>
<li><code>ping</code></li>
<li><code>tracert</code></li>
<li><code>netstat</code></li>
</ul>
<p>链路层（Link）</p>
<ul>
<li><code>arp</code></li>
</ul>
</blockquote>
<ul>
<li>Protocol layering (TCP/IP)<ul>
<li>Application: HTTP, HTTPS, SMTP, POP3, FTP, DNS, DHCP, etc.</li>
<li>Transport: TCP, UDP</li>
<li>Network: IPv4, IPv6, ICMP, IGMP, ARP</li>
<li>Link</li>
<li>Physical</li>
</ul>
</li>
</ul>
<ul>
<li>Domain name(App Layer)<ul>
<li>www.sustech.edu.cn</li>
<li>www.baidu.com</li>
</ul>
</li>
<li>IP address(Network Layer)<ul>
<li>IPv4 (点分十进制)<ul>
<li>32 bits, dotted decimal notation</li>
<li>e.g. 192.168.1.1</li>
</ul>
</li>
<li>IPv6<ul>
<li>128 bits, hecadecimal notation</li>
<li>e.g. 2002::4ab8:7b76</li>
</ul>
</li>
</ul>
</li>
<li>Physical/MAC address(Link Layer)<ul>
<li>48 bits, hexadecimal notation</li>
<li>e.g. 8a-69-0c-51-98-66</li>
</ul>
</li>
</ul>
<ul>
<li>Use <code>ipconfig</code> to check your PC’s network configurations (Wins)<ul>
<li>use <code>ifconfig</code> in MacOS</li>
<li>IP Address = {Network Number, Host Number}</li>
<li>Subnet Mask (子网掩码): n ‘1’ + m ‘0’ (totally 32 bits)<ul>
<li>e.g. 255.255.252.0 (22 ‘1’ and 10 ‘0’)</li>
</ul>
</li>
<li>Network Number = Subnet Mask &amp; IP Address<ul>
<li>e.g. if IP Address is <code>129.168.1.1</code> and Subnet Mask is <code>255.255.252.0</code>, then Network Number is <code>129.168.0.0</code> and Host Number is <code>0.0.1.1</code></li>
</ul>
</li>
</ul>
</li>
<li>Try <code>ipconfig -release</code> (haha~)<ul>
<li>find your network shutdown! (DHCP disabled)</li>
<li>use <code>ipconfig -renew</code> to apply for a new one.</li>
</ul>
</li>
</ul>
<p><strong>DNS Server</strong></p>
<ul>
<li>Try <code>ipconfig -displaydns</code>: looking for info about network(DNS) cache</li>
<li>Use <code>ipconfig -flushdns</code> to clear and refresh the DNS cache</li>
</ul>
<p><strong>ARP (地址解析协议)</strong></p>
<ul>
<li><code>arp -a</code><ul>
<li>Display all ARP information, that is, the corresponding relationship between all activated IP addresses and physical<br>addresses</li>
</ul>
</li>
<li><code>arp -d</code><ul>
<li>Delete all ARP cache contents. </li>
<li>If the IP address is specified in the command, only the ARP cache information of the IP address is deleted.</li>
</ul>
</li>
<li><code>arp -s</code><ul>
<li>Adding the corresponding relationship between IP address and physical address to ARP cache</li>
<li>e.g. <code>arp -s 172.16.0.19 00-10-5C-BE-11-CC</code></li>
</ul>
</li>
</ul>
<ul>
<li><code>nslookup</code> to find the corresponding IP through the host name, or find the corresponding host by specifying the IP.<ul>
<li>e.g. <code>nslookup www.baidu.com</code> or <code>nslookup 140.207.198.6</code></li>
</ul>
</li>
</ul>
<p><strong>Ping</strong></p>
<ul>
<li>Use <code>ping</code> to check network connectivity<ul>
<li><code>ping /?</code> : look up usage</li>
<li><code>ping -t</code> : ping the specific host ‘til stopped</li>
<li><code>ping -i</code> : Time to live(TTL)</li>
<li><code>ping -n &lt;count&gt;</code> : set echo requests number</li>
</ul>
</li>
</ul>
<p><strong>Tracert: trace route</strong></p>
<ul>
<li>Use <code>tracert</code> to track the routing to check the connectivity of the network.</li>
<li>An example of this(address is fake):</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">C:\Users\xxx&gt; tracert www.baidu.com</span><br><span class="line"></span><br><span class="line">Tracing route to www.a.shifen.com [240e:ff:e020:966:0:ff:b042:f296]</span><br><span class="line">over a maximum of 30 hops:</span><br><span class="line"></span><br><span class="line">  1    14 ms    31 ms    14 ms  3010:dc5:207e:1107::6</span><br><span class="line">  2     7 ms     3 ms     3 ms  3010:dc5:207e:1:1::2</span><br><span class="line">  3     2 ms     2 ms     3 ms  3010:dc5:207e:1::1:1</span><br><span class="line">  4     4 ms     6 ms     3 ms  3010:250:3c02::d:1</span><br><span class="line">  5     2 ms     7 ms     2 ms  cernet2.net [3010:dc5:a2:4400::1101]</span><br><span class="line">  6     4 ms     4 ms     3 ms  3010:dc5:2:121::1</span><br><span class="line">  7     7 ms     7 ms     6 ms  3010:dc5:2:18::1</span><br><span class="line">  8     *        8 ms     6 ms  3010:dc5:2:704::2</span><br><span class="line">  9     9 ms     *        *     240e::e:3:2008:402</span><br><span class="line"> 10     6 ms     7 ms     7 ms  240e::c:3:5200:902</span><br><span class="line"> 11     8 ms     6 ms     7 ms  240e:1f:5000:64::3</span><br><span class="line"> 12   171 ms     *      150 ms  240e:1f:5800:35::3</span><br><span class="line"> 13     9 ms    10 ms     8 ms  240e:ff:e020:8ff::73</span><br><span class="line"> 14    44 ms    44 ms    44 ms  240c:4001:3170::ec2:eb2:3</span><br><span class="line"> 15    42 ms    44 ms    43 ms  240c:4001:3170::eb1:eb2:2</span><br><span class="line"> 16    44 ms    43 ms    43 ms  240c:4051:1317:2eb:1eaf:4:eb01:2</span><br><span class="line"> 17    46 ms    45 ms    44 ms  240c:4051:1317:205:1eaf:4:1b05:5</span><br><span class="line"> 18     8 ms     8 ms     8 ms  240e:ff:e020:966:0:ff:b042:f296</span><br><span class="line"></span><br><span class="line">Trace complete.</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>Traceroute program:</strong> provides delay measurement from source to router along end-end Internet path towards destination. For $i$ in $N$ node($N-1$ routers and 1 end):<ul>
<li>sends three packets (as probes) with a time-to-live (TTL) of $i$; will reach router $i$ on path towards destination</li>
<li>router $i$ will return packets to sender</li>
<li>sender times interval between transmission and reply.</li>
</ul>
</li>
</ul>
<h2 id="Week-2"><a href="#Week-2" class="headerlink" title="Week 2"></a>Week 2</h2><h3 id="Wireshark-使用"><a href="#Wireshark-使用" class="headerlink" title="Wireshark 使用"></a>Wireshark 使用</h3><h2 id="Week-8"><a href="#Week-8" class="headerlink" title="Week 8"></a><a name="lab08">Week 8</a></h2><h3 id="SACK"><a href="#SACK" class="headerlink" title="SACK"></a>SACK</h3><font color="green">Review:</font>

<ul>
<li>SACK<ul>
<li>Sliding Window</li>
<li>Retransmission</li>
</ul>
</li>
</ul>
<p><img src="/2024/09/09/Computer-Networks/lab1.png" style="zoom:60%"></p>
<ul>
<li>In practice, while applying SACK, the message often containing “edge” to help clarify the state of pkts<ul>
<li><code>SLE</code>: Left Edge of Block is the first sequence number of this block.</li>
<li><code>SRE</code>: Right Edge of Block is the sequence number immediately following the last sequence number of this block.</li>
<li>Each block represents <font color="red">received bytes</font> of data that are <font color="red">contiguous and isolated</font>; that is, the bytes just below the block, (Left Edge of Block - 1), and just above the block, (Right Edge of Block), have <font color="red">NOT</font> been received.</li>
</ul>
</li>
<li>E.g. If <code>Ack = 1461</code>, <code>SLE = 4381, SRE = 5841</code>, it means packet [4381 - 5840] in bytes has been received, the waiting packets is/are [1461 - 4380] in bytes.</li>
<li>E.g. If there is no <code>SLE</code> or <code>SRE</code>, that means <code>Ack</code> is the lowest bytes unreceived.</li>
</ul>
<p><img src="/2024/09/09/Computer-Networks/lab2.png"></p>
<ul>
<li>Retransmission:</li>
<li>Receiver send immediately <code>Dup Ack</code> when receiving out-of-order pkt. Receiver “wants to tell” sender there is something out-of-order and what it expect (ACK #)</li>
<li>But sender doesn’t know whether the <code>Dup Ack</code> is caused by pkt loss or reordering of pkts. (Shown above)<ul>
<li>Assume it’s reordering pkts, then <code>Dup Ack #</code> is few (1 or 2), then receiver will generate a new <code>ACK</code></li>
<li>If it’s pkt loss, then there’re moer than 3 <code>Dup Ack</code>, and sender should retransmit the <code>ACK #</code> pkt</li>
</ul>
</li>
</ul>
<h3 id="QUIC-Quick-UDP-Internet-Connections"><a href="#QUIC-Quick-UDP-Internet-Connections" class="headerlink" title="QUIC: Quick UDP Internet Connections"></a>QUIC: Quick UDP Internet Connections</h3><p><strong>Def.</strong> A UDP-Based Multiplexed and Secure Transport</p>
<h2 id="Week-11"><a href="#Week-11" class="headerlink" title="Week 11"></a>Week 11</h2><h3 id="Use-of-eNSP"><a href="#Use-of-eNSP" class="headerlink" title="Use of eNSP"></a>Use of eNSP</h3><h1 id="Appendix"><a href="#Appendix" class="headerlink" title="Appendix"></a>Appendix</h1><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">缩写</th>
<th style="text-align:center">释义</th>
<th style="text-align:center">缩写</th>
<th style="text-align:center">释义</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">DSL</td>
<td style="text-align:center">数字用户线</td>
<td style="text-align:center">LAN</td>
<td style="text-align:center">局域网</td>
</tr>
<tr>
<td style="text-align:center">DSLAM</td>
<td style="text-align:center">数字用户线接入复用器</td>
<td style="text-align:center">WLAN</td>
<td style="text-align:center">无线局域网</td>
</tr>
<tr>
<td style="text-align:center">HFC(Hybrid fiber coax)</td>
<td style="text-align:center">混合光纤同轴电缆</td>
<td style="text-align:center">WAN</td>
<td style="text-align:center">广域网(无线接入网)</td>
</tr>
<tr>
<td style="text-align:center">ISP</td>
<td style="text-align:center">网络服务提供商</td>
<td style="text-align:center">ARP</td>
<td style="text-align:center">地址解析协议</td>
</tr>
<tr>
<td style="text-align:center">HTML</td>
<td style="text-align:center">超文本标记语言</td>
<td style="text-align:center">HTTP(S)</td>
<td style="text-align:center">超文本传输（安全）协议</td>
</tr>
<tr>
<td style="text-align:center">DNS</td>
<td style="text-align:center">域名系统</td>
<td style="text-align:center">CDN</td>
<td style="text-align:center">内容分发网络</td>
</tr>
<tr>
<td style="text-align:center">URL</td>
<td style="text-align:center">统一资源定位</td>
<td style="text-align:center">SDN</td>
<td style="text-align:center">软件定义网络</td>
</tr>
<tr>
<td style="text-align:center">NIC</td>
<td style="text-align:center">网络接口卡（网卡）</td>
<td style="text-align:center">DHCP</td>
<td style="text-align:center">动态主机配置协议</td>
</tr>
<tr>
<td style="text-align:center">NAT</td>
<td style="text-align:center">网络地址翻译</td>
<td style="text-align:center">MAC</td>
<td style="text-align:center">(Media Access Control)</td>
</tr>
<tr>
<td style="text-align:center">OSPF</td>
<td style="text-align:center">Open Shortest Path First</td>
<td style="text-align:center">BGP</td>
<td style="text-align:center">Border Gateway Protocol</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
</tbody>
</table>
</div>
</HR></HR></HR></HR></HR></HR></HR></HR></HR></HR></HR></HR></HR></HR>]]></content>
      <categories>
        <category>2024 Fall</category>
      </categories>
      <tags>
        <tag>CSE Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>CS302 计算机操作系统</title>
    <url>/2024/09/13/Operating-Systems/</url>
    <content><![CDATA[<h1 id="Lec01-Intro"><a href="#Lec01-Intro" class="headerlink" title="Lec01. Intro"></a>Lec01. Intro</h1><h2 id="Before-this-course-about"><a href="#Before-this-course-about" class="headerlink" title="Before this course (about)"></a>Before this course (about)</h2><ul>
<li>Have basic concept about Computer Organization</li>
<li>Be familiar to at least one programming language (better be <code>C / C++</code>)</li>
<li>We use <code>Rust</code> as example code in this course<ul>
<li>Learning Rust : <a href="https://doc.rust-lang.org/stable/book/">https://doc.rust-lang.org/stable/book</a></li>
<li>Search for OSTD <code>lib</code> and <code>mod</code> : <a href="https://docs.rs/ostd/latest/ostd/">https://docs.rs/ostd/latest/ostd/</a></li>
</ul>
</li>
</ul>
<h2 id="Definitions-of-OS"><a href="#Definitions-of-OS" class="headerlink" title="Definitions of OS"></a>Definitions of OS</h2><blockquote>
<p>What is a computer ?</p>
<p>How does a modern computer work ?</p>
<p>What is operating systems ?</p>
</blockquote>
<ul>
<li>Structure of a Computer System (4 parts)<ul>
<li>Hardware<ul>
<li>Provides basic computing resources</li>
<li>CPU, memory, I/O devices</li>
</ul>
</li>
<li>Operating system<ul>
<li>Controls and coordinates use of hardware among various applications and users</li>
</ul>
</li>
<li>Application programs<ul>
<li>Define the ways in which the system resources are used to solve the computing problems of the users</li>
<li>Word processors, compilers, web browsers, database systems, video games</li>
</ul>
</li>
<li>Users<ul>
<li>People, machines, other computers</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>Def.</strong> OS is a group of software that makes the computer operate <font color="red">correctly and efficiently</font> in an easy-to-use manner.</p>
<ul>
<li>Execute user programs and make solving user problems easier</li>
<li>Make the computer system convenient to use</li>
<li>Use the computer hardware in an efficient manner (hardware abstraction)</li>
</ul>
<blockquote>
<p>ask again: what is an OS ?</p>
</blockquote>
<ul>
<li>It includes a software program called <font color="red">kernel</font><ul>
<li>manages all the physical devices (e.g., CPU, RAM and hard disk)</li>
<li>exposes some functions such as <font color="red">system calls</font> for others to configure the kernel or build software (e.g., C library)  on top</li>
</ul>
</li>
<li>It includes other “helper” programs<ul>
<li>Such as a <font color="red">shell</font>, which renders a simple command-line user interface with a full set of commands</li>
<li>Such as a <font color="red">GUI</font> (graphic user interface), which renders a user friendly interface with icons representing files and folders</li>
<li>Such as a <font color="red">Browser</font>, which helps the user to visit websites</li>
</ul>
</li>
</ul>
<blockquote>
<p>ask again and again: what is an OS ?</p>
</blockquote>
<ul>
<li>An OS is a <font color="red">resource manager</font><ul>
<li>Managing CPUs, memory, disks, I/O devices (keyboards, USB drive, sensors, …)</li>
<li>Arbitrator of conflicting requests for efficient and fair resource use</li>
</ul>
</li>
<li>An OS is a <font color="red">control program</font><ul>
<li>Controls execution of programs to prevent errors and improper use of the computer</li>
</ul>
</li>
</ul>
<blockquote>
<font face="Segoe Script" size="5">SHORT SUMMARY</font>

<p>There is no exact definition about Operating System. It can have so many functions and computer depends on it so much.<br>It’s like a bridge between users and hardware, between applications and hardware. All of the modern computer cannot live without Operating Systems.</p>
<p>But what an OS actually do ?</p>
</blockquote>
<h2 id="What-does-an-Operating-Systems-do"><a href="#What-does-an-Operating-Systems-do" class="headerlink" title="What does an Operating Systems do ?"></a>What does an Operating Systems do ?</h2><ul>
<li>Virtualization (虚拟化)<ul>
<li>Virtualize CPU: Run multiple programs on a single CPU (as if there are many CPUs)</li>
<li>Virtualize memory: Give each process (or programs if you will) the illusion of running in its own memory address space</li>
</ul>
</li>
<li>Concurrency (并发性)<ul>
<li>Run multi-threaded programs and make sure they execute correctly</li>
</ul>
</li>
<li>Persistence (持久性)<ul>
<li>Write data (from volatile SRAM/DRAM) into persistent storage</li>
<li>Performance, crash-resilience</li>
</ul>
</li>
<li>etc.</li>
</ul>
<p><em>Organzied by the functionalities of OS (<strong>three easy pieces</strong>)</em></p>
<ul>
<li>Virtualization (Process, scheduling, memory address space, swapping)</li>
<li>Concurrency (Threads, locks, semaphores)</li>
<li>Persistence (I/O, storage, file systems)</li>
</ul>
<h2 id="OS-Concepts"><a href="#OS-Concepts" class="headerlink" title="OS Concepts"></a>OS Concepts</h2><h3 id="Process-进程"><a href="#Process-进程" class="headerlink" title="Process (进程)"></a>Process (进程)</h3><p><strong>Def.</strong> A process is a program in execution. (Program is a passive entity and process is an active entity.)</p>
<p><strong>Properties</strong></p>
<ul>
<li>Process needs resources to accomplish its task<ul>
<li>CPU, memory, I/O, files</li>
<li>Process termination requires reclaim of any reusable resources</li>
</ul>
</li>
<li>Process executes instructions sequentially, one at a time, until completion<ul>
<li>Single-threaded process has one program counter specifying location of next instruction to execute</li>
<li>Multi-threaded process has one program counter per thread</li>
</ul>
</li>
<li>Typically, system has many processes, some user, some operating system running concurrently on one or more CPUs<ul>
<li>Concurrency by multiplexing the CPUs among the processes / threads</li>
</ul>
</li>
</ul>
<h3 id="Process-Management"><a href="#Process-Management" class="headerlink" title="Process Management"></a>Process Management</h3><ul>
<li>Creating and deleting both user and system processes</li>
<li>Suspending and resuming processes</li>
<li>Providing mechanisms for process synchronization</li>
<li>Providing mechanisms for process communication</li>
<li>Providing mechanisms for deadlock handling</li>
</ul>
<h3 id="Memory"><a href="#Memory" class="headerlink" title="Memory"></a>Memory</h3><ul>
<li>DRAM (Dynamic Random Access Memory) is the main memory used for all desktop, laptops, servers, and mobile devices</li>
<li>CPU only directly interacts with the main memory during execution<ul>
<li>All data in memory before and after processing</li>
<li>All instructions in memory in order to execute</li>
</ul>
</li>
<li>OS manages the main memory for kernel and processes<ul>
<li>OS dictates which process can access which memory regio</li>
</ul>
</li>
</ul>
<h3 id="Memory-Management"><a href="#Memory-Management" class="headerlink" title="Memory Management"></a>Memory Management</h3><ul>
<li>Memory management determines what is in memory when<ul>
<li>Optimizing CPU utilization and computer response to users</li>
</ul>
</li>
<li>Memory management activities<ul>
<li>Keeping track of which parts of memory are currently being used and by whom</li>
<li>Deciding which processes (or parts thereof) and data to move into and out of memory</li>
<li>Allocating and deallocating memory space as needed</li>
</ul>
</li>
</ul>
<h3 id="File-System-amp-I-O"><a href="#File-System-amp-I-O" class="headerlink" title="File System &amp; I/O"></a>File System &amp; I/O</h3><ul>
<li>File-System management<ul>
<li>Files usually organized into directories</li>
<li>Access control on most systems to determine who can access what</li>
<li>OS activities include<ul>
<li>Creating and deleting files and directories</li>
<li>Primitives to manipulate files and dirs</li>
<li>Mapping files onto secondary storage</li>
<li>Backup files onto stable (non-volatile) storage media</li>
</ul>
</li>
</ul>
</li>
<li>I/O Subsystem<ul>
<li>One purpose of OS is to hide peculiarities of hardware devices from the user</li>
<li>I/O subsystem responsible for<ul>
<li>Memory management of I/O including <ul>
<li>buffering (storing data temporarily while it is being transferred)</li>
<li>caching (storing parts of data in faster storage for performance)</li>
</ul>
</li>
<li>General device-driver interface</li>
<li>Drivers for specific hardware devices</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Protection-and-Security"><a href="#Protection-and-Security" class="headerlink" title="Protection and Security"></a>Protection and Security</h3><ul>
<li>Protection 👉 any mechanism for controlling access of processes or users to resources defined by the OS</li>
<li>Security 👉 defense of the system against internal and external attacks<ul>
<li>Huge range, including denial-of-service (DoS), worms (蠕虫), viruses, identity theft, theft of service</li>
</ul>
</li>
</ul>
<hr>
<h1 id="Lec02-OS-Basics"><a href="#Lec02-OS-Basics" class="headerlink" title="Lec02. OS Basics"></a>Lec02. OS Basics</h1><h2 id="Outline"><a href="#Outline" class="headerlink" title="Outline"></a>Outline</h2><ul>
<li>Dual-mode operations</li>
<li>Kernel structure</li>
<li>Operating system services</li>
</ul>
<h2 id="Dual-Mode-Operations"><a href="#Dual-Mode-Operations" class="headerlink" title="Dual-Mode Operations"></a>Dual-Mode Operations</h2><h3 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h3><ul>
<li>Evolution of OS<ul>
<li>A library to handle low-level I/O<ul>
<li>Issue: Fault and security isolation</li>
</ul>
</li>
<li>Kernel: A bigger “library” to handle low-level I/O<ul>
<li>Kernel needs to be protected from faulty/malicious apps</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="/2024/09/13/Operating-Systems/os201.png"></p>
<ul>
<li>Application code runs in <font color="red">User mode</font></li>
<li>Kernel code runs in <font color="red">Kernel mode</font><ul>
<li>Dual-mode operation allows OS to protect itself and other system components (attack from app can be handle by kernel)</li>
</ul>
</li>
<li><font color="red">Question:</font> What is needed in the hardware to support “dual mode” operation?<ul>
<li>A bit for representing current mode (user/kernel mode bit)</li>
<li>Certain operations / actions only permitted in kernel mode (in user mode they fail or trap)</li>
<li>{ User 👉 Kernel } transition sets kernel mode AND saves the user PC<ul>
<li>Operating system code carefully puts aside user state then performs the necessary operations</li>
</ul>
</li>
<li>{ Kernel 👉 User } transition clears kernel mode AND restores appropriate user PC</li>
</ul>
</li>
</ul>
<p>Mode bits on different architectures 👇</p>
<table><tr>
    <td><img src="/2024/09/13/Operating-Systems/os202.png"></td>
    <td><img src="/2024/09/13/Operating-Systems/os203.png"></td>
</tr></table>



<h3 id="Mode-Transitions"><a href="#Mode-Transitions" class="headerlink" title="Mode Transitions"></a>Mode Transitions</h3><p>Three types :</p>
<ul>
<li>System call <ul>
<li>Process requests a system service, e.g., <code>exit</code></li>
<li>Like a function call, but <fotn color="blue">“outside” the process&lt;/font&gt;</fotn></li>
<li>Does not have the address of the system function to call</li>
<li>Marshall (排序？) the syscall id and args in registers and exec syscall</li>
</ul>
</li>
<li>Interrupt<ul>
<li>External asynchronous event <font color="red">triggers context switch</font></li>
<li>e. g., Timer, I/O device</li>
<li>Independent of user process</li>
</ul>
</li>
<li>Trap or Exception<ul>
<li>Internal synchronous event in process triggers context switch</li>
<li>e.g., Protection violation (segmentation fault), Divide by zero, …</li>
</ul>
</li>
</ul>
<h4 id="System-Calls"><a href="#System-Calls" class="headerlink" title="System Calls"></a>System Calls</h4><p><strong>Def.</strong> Programming interface to the services provided by the OS, typically written in a high-level language (C or C++).</p>
<blockquote>
<p>中文解释：系统调用是一个用高级程序语言定义的，调用操作系统提供的服务的程序接口。</p>
</blockquote>
<p><strong>Implementation</strong></p>
<ul>
<li>Typically, a number associated with each system call<ul>
<li>System-call interface maintains a table indexed according to these numbers</li>
</ul>
</li>
<li>The system call interface invokes intended system call in OS kernel and returns status of the system call and any return values <font color="blue">(a basic example below)</font></li>
<li>The caller needs to know nothing about how the system call is implemented<ul>
<li>Just needs to obey calling convention and understand what OS will do </li>
<li>Most details of OS interface hidden from programmer by library API<ul>
<li>Managed by run-time support library (set of functions built into libraries included with compiler)</li>
</ul>
</li>
</ul>
</li>
</ul>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="meta">#[allow(dead_code)]</span></span><br><span class="line"><span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">handle_syscall</span>(user_context: &amp;<span class="keyword">mut</span> UserContext, user_space: &amp;UserSpace) &#123;</span><br><span class="line">  <span class="keyword">const</span> SYS_EXIT: <span class="type">usize</span> = <span class="number">93</span>;</span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line">  </span><br><span class="line">  <span class="keyword">let</span> <span class="variable">args</span> = [</span><br><span class="line">    user_context.<span class="title function_ invoke__">a0</span>(),</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">  ];</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">let</span> <span class="variable">ret</span>: <span class="type">Result</span>&lt;SyscallReturn&gt; = <span class="keyword">match</span> user_context.<span class="title function_ invoke__">a7</span>() &#123;</span><br><span class="line">    SYS_EXIT =&gt; &#123;</span><br><span class="line">      <span class="comment">// operations</span></span><br><span class="line">      <span class="title function_ invoke__">Ok</span>(SyscallReturn::NoReturn)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// Other syscalls</span></span><br><span class="line">  &#125;</span><br><span class="line">	</span><br><span class="line">  <span class="keyword">match</span> ret &#123;</span><br><span class="line">    <span class="title function_ invoke__">Ok</span>(val) =&gt; <span class="keyword">match</span> val &#123;</span><br><span class="line">      SyscallReturn::<span class="title function_ invoke__">Return</span>(val) =&gt; user_context.<span class="title function_ invoke__">set_a0</span>(val <span class="keyword">as</span> <span class="type">usize</span>),</span><br><span class="line">      SyscallReturn::NoReturn =&gt; &#123;&#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="title function_ invoke__">Err</span>(err) =&gt; user_context.<span class="title function_ invoke__">set_a0</span>(-(err.<span class="title function_ invoke__">error</span>() <span class="keyword">as</span> <span class="type">i32</span> <span class="keyword">as</span> <span class="type">isize</span>) <span class="keyword">as</span> <span class="type">usize</span>),</span><br><span class="line">  &#125;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>Types of Syscalls</li>
</ul>
<p><img src="/2024/09/13/Operating-Systems/os204.png"></p>
<h4 id="Exception-and-Interrupt"><a href="#Exception-and-Interrupt" class="headerlink" title="Exception and Interrupt"></a>Exception and Interrupt</h4><ul>
<li><strong>Exceptions (synchronous)</strong> react to an abnormal condition <ul>
<li>E.g., Map the swapped-out page back to memory</li>
<li>Divide by zero</li>
<li>Illegal memory accesses</li>
</ul>
</li>
<li><strong>Interrupts (asynchronous)</strong> preempt normal execution <ul>
<li>Notification from device (e.g., new packets, disk I/O completed)</li>
<li>Preemptive scheduling (e.g., timer ticks)</li>
<li>Notification from another CPU (i.e., Inter-processor Interrupts)</li>
</ul>
</li>
<li>More about (in the same procedure)<ul>
<li>Stop execution of the current program</li>
<li>Start execution of a handler</li>
<li>Processor accesses the handler through an entry in the <fotn color="red">Interrupt Descriptor Table (IDT)&lt;/font&gt;</fotn></li>
<li>Each interrupt is defined by a number</li>
</ul>
</li>
</ul>
<h2 id="Kernel-Structure"><a href="#Kernel-Structure" class="headerlink" title="Kernel Structure"></a>Kernel Structure</h2><h3 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h3><p><strong>I. Monolithic Kernel</strong></p>
<ul>
<li>A monolithic kernel is an operating system software framework that holds <font color="red">all privileges to access</font> I/O devices, memory, hardware interrupts and the CPU stack. </li>
<li>Monolithic kernels <font color="red">contain many components</font>, such as memory subsystems and I/O subsystems, and are usually very large.<ul>
<li>Including filesystems, device drivers, etc.</li>
</ul>
</li>
<li>Monolithic kernel is the basis for Linux, Unix, MS-DOS.</li>
</ul>
<p><strong>II. Micro Kernel</strong></p>
<ul>
<li>Microkernels outsource the traditional operating system functionality to ordinary user processes for better flexibility, security, and fault tolerance.</li>
</ul>
<p><img src="/2024/09/13/Operating-Systems/os205.png"></p>
<ul>
<li>OS functionalities are pushed to user-level servers (e.g., user-level memory manager) </li>
<li>User-level servers are trusted by the kernel (often run as root)</li>
<li>Protection mechanisms stay in kernel while resource management policies go to the user-level servers</li>
<li>Representative micro-kernel OS<ul>
<li>Mach, 1980s at CMU</li>
<li>seL4, the first formally verified micro-kernel, more on <a href="http://sel4.systems/">http://sel4.systems</a></li>
</ul>
</li>
</ul>
<p><strong>Pros and Cons</strong></p>
<ul>
<li>Pros<ul>
<li>Kernel is more responsive (kernel functions in preemptible user-level processes)</li>
<li>Better stability and security (less code in kernel)</li>
<li>Better support of concurrency and distributed OS (later…..)</li>
</ul>
</li>
<li>Cons<ul>
<li>More IPC needed and thus more context switches (slower)</li>
</ul>
</li>
</ul>
<p><strong>III. Hybrid Kernel</strong></p>
<ul>
<li>A combination of a monolithic kernel and a micro kernel<ul>
<li>Example: Windows OS</li>
</ul>
</li>
</ul>
<p><strong>IV. FrameKernel: Asterinas</strong></p>
<p><img src="/2024/09/13/Operating-Systems/os206.png"></p>
<h3 id="OS-Design-Principles"><a href="#OS-Design-Principles" class="headerlink" title="OS Design Principles"></a>OS Design Principles</h3><ul>
<li>Internal structure of different Operating Systems can vary widely<ul>
<li>Start by defining goals and specifications </li>
<li>Affected by choice of hardware, type of system</li>
</ul>
</li>
<li>User goals and System goals<ul>
<li>User goals 👉 operating system should be convenient to use, easy to learn, reliable, safe, and fast</li>
<li>System goals 👉 operating system should be easy to design, implement, and maintain, as well as flexible, reliable, error-free, and efficient</li>
</ul>
</li>
<li>OS separates policies and mechanisms<ul>
<li>Policy: which software could access which resource at what time<ul>
<li>E.g., if two processes access the same device at the same time, which one goes first</li>
<li>E.g., if a process hopes to read from keyboard</li>
</ul>
</li>
<li>Mechanism: How is the policy enforced<ul>
<li>E.g., request queues for devices, running queues for CPUs</li>
<li>E.g., access control list for files, devices, etc.</li>
</ul>
</li>
<li>The separation of policy from mechanism is a very important principle, it allows <font color="red">maximum flexibility</font> if policy decisions are to be changed later</li>
</ul>
</li>
</ul>
<h2 id="Operating-System-Services"><a href="#Operating-System-Services" class="headerlink" title="Operating System Services"></a>Operating System Services</h2><p><strong>I. User-helpful OS services</strong></p>
<ul>
<li><font color="red">User interface</font> - Almost all operating systems have a user interface (UI)<ul>
<li>Varies between Command-Line (CLI), Graphics User Interface (GUI), Batch</li>
</ul>
</li>
<li><font color="red">Program execution</font> - The system must be able to load a program into memory and to run that program, end execution, either normally or abnormally (indicating error)</li>
<li><font color="red">I/O operations</font> -  A running program may require I/O, which may involve a file or an I/O device </li>
<li><font color="red">File-system manipulation</font> -  The file system is of particular interest. Obviously, programs need to read and write files and directories, create and delete them, search them, list file Information, permission management</li>
<li>Communications – Processes may exchange information, on the same computer or between computers over a network<ul>
<li>Communications may be via shared memory or through message passing (packets moved by the OS)</li>
</ul>
</li>
<li>Error detection – OS needs to be constantly aware of possible errors<ul>
<li>May occur in the CPU and memory hardware, in I/O devices, in user program</li>
<li>For each type of error, OS should take the appropriate action to ensure correct and consistent computing</li>
<li>Debugging facilities can greatly enhance the user’s and programmer’s abilities to efficiently use the system</li>
</ul>
</li>
</ul>
<p><strong>II. User Operating System Interface</strong></p>
<ul>
<li><font color="red">Command Line Interface (CLI)</font> or command interpreter allows direct command entry</li>
<li><font color="red">User-friendly desktop metaphor interface</font><ul>
<li>e.g. mouse, keyboard and monitor. Icons of app.</li>
</ul>
</li>
<li>Many systems now include both CLI and GUI interfaces</li>
</ul>
<p><strong>III. System Programs</strong></p>
<ul>
<li>Provide a convenient environment for program development and execution</li>
<li>Most users’ view of the operation system is defined by system programs<ul>
<li>File management </li>
<li>Status Info</li>
</ul>
</li>
<li>Programming-language support 👉 Compilers, assemblers, debuggers and interpreters sometimes provided</li>
<li>Program loading and execution</li>
<li>Communications 👉 Provide the mechanism for creating virtual connections among processes, users, and computer systems</li>
</ul>
<hr>
<h1 id="Lec03-Process"><a href="#Lec03-Process" class="headerlink" title="Lec03. Process"></a>Lec03. Process</h1><h2 id="Outline-1"><a href="#Outline-1" class="headerlink" title="Outline"></a>Outline</h2><ul>
<li>Process and system calls</li>
<li>Process creation</li>
<li>Kernel view of processes</li>
<li>Kernel view of <code>fork()</code>, <code>exec()</code>, and <code>wait()</code></li>
<li>More about processes</li>
</ul>
<h2 id="Process-and-System-Calls"><a href="#Process-and-System-Calls" class="headerlink" title="Process and System Calls"></a>Process and System Calls</h2><h3 id="What’s-a-process"><a href="#What’s-a-process" class="headerlink" title="What’s a process ?"></a>What’s a process ?</h3><ul>
<li>Process is a program in execution</li>
<li>A program is a file on the disk<ul>
<li>Code and static data</li>
</ul>
</li>
<li>A process is loaded by the OS <ul>
<li>Code and static data are loaded from the program</li>
<li>Heap and stack are created by the OS</li>
</ul>
</li>
<li>A process is an abstraction of machine states<ul>
<li>Memory: address space</li>
<li>Register:<ul>
<li>Program Counter (PC) or Instruction Pointer</li>
<li>Stack pointer</li>
<li>frame pointer</li>
</ul>
</li>
<li>I/O: all files opened by the process</li>
</ul>
</li>
</ul>
<blockquote>
<p>Seems that definitions of process are multiple, there is only one way to get unique process.</p>
</blockquote>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">void</span>)</span> &#123;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;My PID is %d\n&quot;</span>, getpid());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="Process-Life-Cycle"><a href="#Process-Life-Cycle" class="headerlink" title="Process Life Cycle"></a>Process Life Cycle</h3><p><img src="/2024/09/13/Operating-Systems/os301.png" style="zoom:70%"></p>
<h3 id="What’s-System-calls"><a href="#What’s-System-calls" class="headerlink" title="What’s System calls ?"></a>What’s System calls ?</h3><ul>
<li>System call is a function call.<ul>
<li>exposed by the kernel.</li>
<li>abstraction of kernel operations.</li>
</ul>
</li>
<li>System call is <font color="red">a call by number</font></li>
<li>System call sometimes need extra parameter. Three ways to pass param.<ul>
<li>Registers: pass the parameters in registers<ul>
<li>In some cases, may be more parameters than registers</li>
<li><code>x86</code> and <code>risc-v</code> take this approach</li>
</ul>
</li>
<li>Blocks: Parameters stored in a memory block and <font color="red">address of the block passed</font> as a parameter in a register (e.g. pic below)</li>
<li>Stack: Parameters placed, or pushed, onto the stack by the program and popped off the stack by the operating system<ul>
<li>Block and stack methods do not limit the number or length of parameters being passed</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="/2024/09/13/Operating-Systems/os302.png"></p>
<h3 id="System-Call-v-s-Library-API-Call"><a href="#System-Call-v-s-Library-API-Call" class="headerlink" title="System Call v.s. Library API Call"></a>System Call v.s. Library API Call</h3><p>Test:</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">Name</th>
<th style="text-align:center">System call ?</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><code>printf()</code> &amp; <code>scanf()</code></td>
<td style="text-align:center">No</td>
</tr>
<tr>
<td style="text-align:center"><code>malloc()</code> &amp; <code>free()</code></td>
<td style="text-align:center">NO</td>
</tr>
<tr>
<td style="text-align:center"><code>fopen()</code> &amp; <code>fclose()</code></td>
<td style="text-align:center">No</td>
</tr>
<tr>
<td style="text-align:center"><code>mkdir()</code> &amp; <code>rmdir()</code></td>
<td style="text-align:center">Yes</td>
</tr>
<tr>
<td style="text-align:center"><code>chown()</code> &amp; <code>chmod()</code></td>
<td style="text-align:center">Yes</td>
</tr>
</tbody>
</table>
</div>
<ul>
<li>E.g. <code>fopen()</code><ul>
<li><code>fopen()</code> invokes the system call <code>open()</code>.</li>
<li><code>open()</code> is too primitive and is not programmer-friendly!</li>
</ul>
</li>
</ul>
<h2 id="Process-Creation"><a href="#Process-Creation" class="headerlink" title="Process Creation"></a>Process Creation</h2><h3 id="fork"><a href="#fork" class="headerlink" title="fork()"></a><code>fork()</code></h3><ul>
<li>Parent process create children processes. (form <strong>tree</strong> structure)</li>
<li>use <code>pid</code> to identify a process</li>
<li>Address space<ul>
<li>Child duplicate of parent</li>
<li>Child has a program loaded into it</li>
</ul>
</li>
<li>UNIX examples<ul>
<li><code>fork()</code> system call creates new process</li>
<li><code>exec()</code> system call used after a fork to replace the process’ memory space with a new program</li>
</ul>
</li>
</ul>
<p><img src="/2024/09/13/Operating-Systems/os303.png"></p>
<ul>
<li>View on example : 👆<ul>
<li>Both the parent and the child <font color="red">execute the same program</font>.</li>
<li>The child process starts its execution at the location that <code>fork()</code> is returned, <font color="red">not from the beginning of the program</font>.</li>
</ul>
</li>
<li>Another example below :</li>
</ul>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">void</span>)</span> &#123;</span><br><span class="line">  <span class="type">int</span> result;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;before fork...\n&quot;</span>);</span><br><span class="line">  result = fork();  <span class="comment">// System call</span></span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;result = %d&quot;</span>, result);</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">if</span> (result == <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;I&#x27;m the child. My PID is %d\n&quot;</span>, getpid());</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;I&#x27;m the parent. My PID is %d\n&quot;</span>, getpid());</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;Program terminated.\n&quot;</span>);</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ol>
<li>Suppose parent’s pid is 1234. Then the <code>fork()</code> create a child process with pid 1235.</li>
<li><code>fork()</code> returns value for both parent and child process. See how they differ in value.</li>
<li><font color="red">CPU decides</font> which process run first.</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># if child run first:</span><br><span class="line">$ ./fork_example</span><br><span class="line">before fork...</span><br><span class="line">result = 0</span><br><span class="line">I&#x27;m the child. My PID is 1235</span><br><span class="line">Program terminated.</span><br><span class="line">result = 1235</span><br><span class="line">I&#x27;m the parent. My PID is 1234</span><br><span class="line">Program terminated.</span><br><span class="line"></span><br><span class="line"># if parent run first:</span><br><span class="line">$ ./fork_example</span><br><span class="line">before fork...</span><br><span class="line">result = 1235</span><br><span class="line">I&#x27;m the parent. My PID is 1234</span><br><span class="line">Program terminated.</span><br><span class="line">result = 0</span><br><span class="line">I&#x27;m the child. My PID is 1235</span><br><span class="line">Program terminated.</span><br></pre></td></tr></table></figure>
<ul>
<li><code>fork()</code> behaves like “cell division”.<ul>
<li>It creates the child process by cloning from the parent process, including all user-space data</li>
</ul>
</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">Cloned items</th>
<th style="text-align:center">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Program counter<br>[CPU register]</td>
<td style="text-align:center">That’s why they both execute from the same line of code after <code>fork()</code> returns.</td>
</tr>
<tr>
<td style="text-align:center">Program code<br>[File &amp; Memory]</td>
<td style="text-align:center">They are sharing the same piece of code.</td>
</tr>
<tr>
<td style="text-align:center">Memory</td>
<td style="text-align:center">Including local variables, global variables, and dynamically allocated memory.</td>
</tr>
<tr>
<td style="text-align:center">Opened files<br>[Kernel’s internal]</td>
<td style="text-align:center">If the parent has opened a file “fd”, then the child will also have file “fd” opened automatically.</td>
</tr>
</tbody>
</table>
</div>
<ul>
<li><ul>
<li>also something distinct:</li>
</ul>
</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">Distinct items</th>
<th style="text-align:center">Parent</th>
<th style="text-align:center">Child</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Return value of <code>fork()</code></td>
<td style="text-align:center">PID of child</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td style="text-align:center">PID</td>
<td style="text-align:center">unchanged</td>
<td style="text-align:center">new pid(not necessarily parent’s +1)</td>
</tr>
<tr>
<td style="text-align:center">Parent process</td>
<td style="text-align:center">unchanged</td>
<td style="text-align:center">Parent.</td>
</tr>
<tr>
<td style="text-align:center">Running time</td>
<td style="text-align:center">Cumulated</td>
<td style="text-align:center">Just created, should be 0</td>
</tr>
<tr>
<td style="text-align:center">[Advanced]File locks</td>
<td style="text-align:center">unchanged</td>
<td style="text-align:center">None</td>
</tr>
</tbody>
</table>
</div>
<h3 id="exec"><a href="#exec" class="headerlink" title="exec()"></a><code>exec()</code></h3><blockquote>
<p>If a process can only <strong>duplicate itself</strong> and <strong>always runs the same program</strong>, it’s not meaningful. How can we execute other programs ?</p>
<p>Answer: using <code>exec()</code> system call !</p>
</blockquote>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">void</span>)</span> &#123;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;Before execl...\n&quot;</span>);</span><br><span class="line">  execl(<span class="string">&quot;/bin/ls&quot;</span>, <span class="string">&quot;/bin/ls&quot;</span>, <span class="literal">NULL</span>);  <span class="comment">// what does this mean?</span></span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;after execl...\n&quot;</span>);</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Output</span></span><br><span class="line">$ ./exec_example</span><br><span class="line">Before execl...</span><br><span class="line">./exec_example</span><br><span class="line">./exec_example.c</span><br><span class="line">$ _</span><br></pre></td></tr></table></figure>
<ul>
<li>Detail about <code>exec()</code></li>
<li>Run the command <code>/bin/ls</code></li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">Argument Order</th>
<th style="text-align:center">Value in example</th>
<th style="text-align:center">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">“/bin/ls”</td>
<td style="text-align:center">The file that the programmer wants to execute.</td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:center">“/bin/ls”</td>
<td style="text-align:center">When the process switches to “/bin/ls”, this string is the program argument[0].</td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:center">NULL</td>
<td style="text-align:center">This states the end of the program argument list.</td>
</tr>
</tbody>
</table>
</div>
<ul>
<li>E.g. run the command <code>/bin/ls -l</code><ul>
<li>C code: <code>execl(&quot;/bin/ls&quot;, &quot;/bin/ls&quot;, &quot;-l&quot;, NULL);</code></li>
</ul>
</li>
</ul>
<blockquote>
<p><font color="red">Q:</font> Why the origin program ends ? (No “after execl…” printed)</p>
<p><font color="green">A:</font> The program in the address space has been changed.</p>
<p>解释：<code>exec_example</code> 程序调用 <code>execl()</code> 系统调用后，该进程的地址空间存储代码的部分会切换成 <code>execl</code> 中参数指定的程序，而该程序运行结束后不会切换回原来的程序代码，所以进程结束。</p>
</blockquote>
<p>Summary</p>
<ul>
<li>The process is changing the code that is executing and never returns to the original code.<ul>
<li>The last two lines of codes are therefore not executed.</li>
</ul>
</li>
<li>The process that calls an <code>exec</code> system call will replace user space info, e.g.,<ul>
<li>Program Code</li>
<li>Memory: local variables, global variables, and dynamically allocated memory;</li>
<li>Register value: e.g., the program counter;</li>
</ul>
</li>
<li>But, the kernel-space info of that process is preserved, including:<ul>
<li>PID;</li>
<li>Process relationship;</li>
<li>etc.</li>
</ul>
</li>
</ul>
<h3 id="wait"><a href="#wait" class="headerlink" title="wait()"></a><code>wait()</code></h3><blockquote>
<p><font color="green">Recall:</font> previous exmaple with syscall <code>wait()</code> .</p>
</blockquote>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">void</span>)</span> &#123;</span><br><span class="line">  <span class="type">int</span> result;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;before fork...\n&quot;</span>);</span><br><span class="line">  result = fork();</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;result = %d&quot;</span>, result);</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">if</span> (result == <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;I&#x27;m the child.\n&quot;</span>);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;My PID is %d.\n&quot;</span>, getpid());</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;I&#x27;m the parent.\n&quot;</span>, getpid());</span><br><span class="line">    wait(<span class="literal">NULL</span>);  <span class="comment">// difference here</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;My PID is %d.\n&quot;</span>, getpid())</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;Program terminated.\n&quot;</span>);</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li><code>wait()</code> called at parent process 👉 if the CPU schedules <font color="red">parent process to run first</font>, then it will wait until child process finished.(like this 👇)</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ ./fork_example</span><br><span class="line">before fork...</span><br><span class="line">result = 1235</span><br><span class="line">I&#x27;m the parent.</span><br><span class="line">result = 0</span><br><span class="line">I&#x27;m the child.</span><br><span class="line">My PID is 1235.</span><br><span class="line">Program terminated.</span><br><span class="line">My PID is 1234.</span><br><span class="line">Program terminated.</span><br></pre></td></tr></table></figure>
<p><img src="/2024/09/13/Operating-Systems/os304.png"></p>
<ul>
<li><code>wait()</code> vs. <code>waitpid()</code><ul>
<li><code>wait()</code><ul>
<li>Wait for any one of the child processes</li>
<li>Detect child <font color="red">termination only</font></li>
</ul>
</li>
<li><code>waitpid()</code><ul>
<li>Depending on the parameters, waitpid() will wait for a particular child only</li>
<li>Depending on the parameters, waitpid() can detect different status changes of the child (resume/stop by a signal)</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="Kernel-view-of-processes"><a href="#Kernel-view-of-processes" class="headerlink" title="Kernel view of processes"></a>Kernel view of processes</h2><h3 id="PCB"><a href="#PCB" class="headerlink" title="PCB"></a>PCB</h3><p><img src="/2024/09/13/Operating-Systems/os305.png"></p>
<p><img src="/2024/09/13/Operating-Systems/os306.png"></p>
<h3 id="Process-and-Thread"><a href="#Process-and-Thread" class="headerlink" title="Process and Thread"></a>Process and Thread</h3><ul>
<li>One process may have more than one threads (一个进程对多个线程)<ul>
<li>A single-threaded process performs a single thread of execution</li>
<li>A multi-threaded process performs multiple threads of execution <strong>“concurrently”</strong>, thus allowing <strong>short response time</strong> to user’s input even when the main thread is busy</li>
</ul>
</li>
<li>PCB is extended to include information about each thread</li>
</ul>
<p>单线程进程 vs. 多线程进程 👇</p>
<p><img src="/2024/09/13/Operating-Systems/os307.png"></p>
<h3 id="Context-Switch"><a href="#Context-Switch" class="headerlink" title="Context Switch"></a>Context Switch</h3><ul>
<li>Once a process runs on a CPU, it only gives back the control of a CPU<ul>
<li>when it makes a system call</li>
<li>when it raises an exception</li>
<li>when an interrupt occurs</li>
</ul>
</li>
<li>What if none of these would happen for a long time?<ul>
<li>Coorperative scheduling: OS will have to wait<ul>
<li>Early Macintosh OS, old Alto system</li>
</ul>
</li>
<li>Non-coorperative scheduling: timer interrupts<ul>
<li>Modern operating systems</li>
</ul>
</li>
</ul>
</li>
<li>When OS kernel regains the control of CPU<ul>
<li>It first completes the task<ul>
<li>Serve system call, or</li>
<li>Handle interrupt/exception</li>
</ul>
</li>
<li>It then decides which process to run next<ul>
<li>by asking its <strong>CPU scheduler</strong> (in later chapter)</li>
</ul>
</li>
<li>It performs a <strong>context switch</strong> if the soon-to-be-executing process is different from the previous one</li>
</ul>
</li>
</ul>
<p><strong>About context switch</strong></p>
<ul>
<li>During context switch, the system must <strong>save</strong> the state of the old process and <strong>load</strong> the saved state for the new process</li>
<li>Context of a process is represented in the PCB</li>
<li>The time used to do context switch is an overhead of the system; the system does no useful work while switching<ul>
<li>Time of context switch depends on hardware support</li>
<li>Context switch cannot be too frequent</li>
</ul>
</li>
</ul>
<h2 id="Kernel-view-of-fork-exec-and-wait-❗Important"><a href="#Kernel-view-of-fork-exec-and-wait-❗Important" class="headerlink" title="Kernel view of fork(), exec(), and wait() (❗Important)"></a>Kernel view of <code>fork()</code>, <code>exec()</code>, and <code>wait()</code> (❗Important)</h2><h3 id="Overview-1"><a href="#Overview-1" class="headerlink" title="Overview"></a>Overview</h3><p><img src="/2024/09/13/Operating-Systems/os308.png"></p>
<h3 id="fork-Kernel-View"><a href="#fork-Kernel-View" class="headerlink" title="fork(): Kernel View"></a><code>fork()</code>: Kernel View</h3><table>
<tr>
<td><img src="/2024/09/13/Operating-Systems/os309.png"></td>
<td><img src="/2024/09/13/Operating-Systems/os310.png"></td>
</tr>
<tr>
<td><img src="/2024/09/13/Operating-Systems/os311.png"></td>
<td><img src="/2024/09/13/Operating-Systems/os312.png"></td>
</tr>
</table>

<ul>
<li>More inside <code>fork()</code> (in kernel view)</li>
<li>After creating the child process(PCB) and allocating user space(Dup’ or CoW), CPU take control to decide which one run first</li>
<li>Both processes store their return value in PCB, ready to return from <code>fork()</code></li>
</ul>
<p><img src="/2024/09/13/Operating-Systems/os313.png"></p>
<blockquote>
<p>What if two processes, sharing the same opened file, write to that file together?</p>
</blockquote>
<h3 id="exec-Kernel-View"><a href="#exec-Kernel-View" class="headerlink" title="exec(): Kernel View"></a><code>exec()</code>: Kernel View</h3><p><img src="/2024/09/13/Operating-Systems/os314.png"></p>
<h3 id="wait-and-exit-Kernel-View"><a href="#wait-and-exit-Kernel-View" class="headerlink" title="wait() and exit(): Kernel View"></a><code>wait()</code> and <code>exit()</code>: Kernel View</h3><blockquote>
<p>In user’s view :</p>
</blockquote>
<p><a name="os315"><img src="/2024/09/13/Operating-Systems/os315.png"></a></p>
<blockquote>
<p><code>exit()</code> in kernel view :</p>
</blockquote>
<table>
<tr>
<td><img src="/2024/09/13/Operating-Systems/os316.png"></td>
<td><img src="/2024/09/13/Operating-Systems/os317.png"></td>
</tr>
<tr>
<td><img src="/2024/09/13/Operating-Systems/os318.png"></td>
<td><img src="/2024/09/13/Operating-Systems/os319.png"></td>
</tr>
</table>

<ul>
<li>Summary of <code>exit()</code></li>
<li>(1) Clean up most of the allocated kernel-space memory</li>
<li>(2) Clean up the exit process’s user-space memory.</li>
<li>(3) Notify the parent with <code>SIGCHLD</code>.</li>
</ul>
<blockquote>
<p>One problem: How do the two process communicate ? 👉 How does parent receive the signal ?</p>
</blockquote>
<ul>
<li>Brief view on <code>wait()</code></li>
</ul>
<table>
<tr>
<td><img src="/2024/09/13/Operating-Systems/os320.png"></td>
<td><img src="/2024/09/13/Operating-Systems/os321.png"></td>
</tr>
<tr>
<td><img src="/2024/09/13/Operating-Systems/os322.png"></td>
<td><img src="/2024/09/13/Operating-Systems/os323.png"></td>
</tr>
</table>


<p>（笔记不全）</p>
<ul>
<li>Case Analysis</li>
<li><strong>I.</strong> Normal case<ul>
<li>Parent call <code>wait()</code>, and then child exit and sent <code>SIGCHLD</code> </li>
</ul>
</li>
<li><p><strong>II.</strong> Parent’s wait() after Child’s exit()</p>
<ul>
<li>This case is okay but the zombie wanders around until <code>wait()</code> is called</li>
</ul>
</li>
<li><p>Using <code>wait()</code> for Resource Management</p>
</li>
<li>It is not only about process execution / suspension …</li>
<li>It is about system resource management.<ul>
<li>A zombie takes up a PID;</li>
<li>The total number of PIDs are limited;<ul>
<li>Read the limit: <code>cat /proc/sys/kernel/pid_max</code></li>
<li>It is 32,768.</li>
</ul>
</li>
<li>What will happen if we don’t clean up the zombies? (maybe the computer cannot run any program.)</li>
</ul>
</li>
</ul>
<h2 id="More-about-processes"><a href="#More-about-processes" class="headerlink" title="More about processes"></a>More about processes</h2><h3 id="The-First-Process"><a href="#The-First-Process" class="headerlink" title="The First Process"></a>The First Process</h3><ul>
<li>We now focus on the process-related events.<ul>
<li>The kernel, while it is booting up, creates the first process – <code>init</code>.</li>
</ul>
</li>
<li>The <code>init</code> process:<ul>
<li>has <code>PID = 1</code>, and</li>
<li>is running the program code <code>/sbin/init</code>.</li>
</ul>
</li>
<li>Its first task is to create more processes …<ul>
<li>Using <code>fork()</code> and <code>exec()</code>.</li>
</ul>
</li>
</ul>
<p><strong>A Tree of Process</strong></p>
<ul>
<li>You can view the tree with the command:<ul>
<li><code>pstree</code>; or</li>
<li><code>pstree –A</code> for ASCII-character-only display.</li>
</ul>
</li>
<li>Problem: What if a parent process (in the process tree) terminates before its children ?<ul>
<li><font color="green">Answer:</font> Using Re-parent</li>
<li>In Linux<ul>
<li>The <code>init</code> process will become the step-mother of all orphans</li>
<li>It’s called re-parenting</li>
</ul>
</li>
<li>In Windows<ul>
<li>It maintains a forest-like process hierarchy </li>
</ul>
</li>
</ul>
</li>
<li>Re-parent Explanation<ul>
<li>exitting parent change all the children’s <strong>parent pointer</strong> to init process</li>
</ul>
</li>
</ul>
<p><img src="/2024/09/13/Operating-Systems/os324.png" style="zoom:50%"></p>
<ul>
<li>Background Jobs<ul>
<li>The re-parenting operation enables something called background jobs in Linux</li>
<li>It allows a process runs <strong>without a parent terminal/shell</strong></li>
</ul>
</li>
</ul>
<h3 id="Measure-Process-Time"><a href="#Measure-Process-Time" class="headerlink" title="Measure Process Time"></a>Measure Process Time</h3><blockquote>
<p>Two aspect: User Time vs. System Time</p>
</blockquote>
<p><strong>Def.</strong> Real time: whole time to execute the program.</p>
<p><strong>Def.</strong> User time: time to run a user’s code.</p>
<p><strong>Def.</strong> System time: time to run a system’s code.</p>
<ul>
<li>The user time and the sys time together define the performance of an application.<ul>
<li>When writing a program, you must consider both the user time and the sys time.<ul>
<li>E.g., the output of the following two programs are exactly the same. But, their running time is not. (Pro 1 spend much more time to system call)</li>
</ul>
</li>
</ul>
</li>
</ul>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Pro 1</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> MAX 1000000</span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">void</span>)</span> &#123;</span><br><span class="line">  <span class="type">int</span> i;</span><br><span class="line">  <span class="keyword">for</span>(i = <span class="number">0</span>; i &lt; MAX; i++)</span><br><span class="line">    <span class="built_in">printf</span>(“x\n”);</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Pro 2</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> MAX 1000000</span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">void</span>)</span> &#123;</span><br><span class="line">  <span class="type">int</span> i;</span><br><span class="line">  <span class="keyword">for</span>(i = <span class="number">0</span>; i &lt; MAX / <span class="number">5</span> ; i++)</span><br><span class="line">    <span class="built_in">printf</span>(“x\nx\nx\nx\nx\n”);</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="Lec04-CPU-Scheduler"><a href="#Lec04-CPU-Scheduler" class="headerlink" title="Lec04. CPU Scheduler"></a>Lec04. CPU Scheduler</h1><h2 id="Outline-2"><a href="#Outline-2" class="headerlink" title="Outline"></a>Outline</h2><ul>
<li>Scheduler Concept</li>
<li>Different Scheduling Algorithm</li>
<li>Optimization</li>
</ul>
<h2 id="Scheduler-Concept"><a href="#Scheduler-Concept" class="headerlink" title="Scheduler Concept"></a>Scheduler Concept</h2><ul>
<li>Scheduling is important when multiple processes wish to run on a single CPU<ul>
<li>CPU scheduler decides which process to run next</li>
</ul>
</li>
<li>Two types of processes<ul>
<li>CPU bound and I/O bound</li>
</ul>
</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center">CPU bound</th>
<th style="text-align:center">I/O bound</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Def</td>
<td style="text-align:center">Spends most of its running time on the CPU,<br> i.e., <code>user-time -&gt; sys-time</code></td>
<td style="text-align:center">Spends most of its running time on I/O,<br> i.e., <code>sys-time -&gt; user-time</code></td>
</tr>
<tr>
<td style="text-align:center">E.g.</td>
<td style="text-align:center">AI course assignments.</td>
<td style="text-align:center"><code>/bin/ls</code>, networking programs</td>
</tr>
</tbody>
</table>
</div>
<ul>
<li>CPU scheduler selects one of the processes that are ready to execute and allocates the CPU to it</li>
<li>CPU scheduling decisions may take place when a process:<ol>
<li>Switches from running to waiting state</li>
<li>Switches from running to ready state</li>
<li>Switches from waiting to ready</li>
<li>Terminates</li>
</ol>
</li>
</ul>
<p><strong>Scheduling Algorithm Optimization Criteria</strong></p>
<ul>
<li>Given a set of processes, with <ul>
<li><strong>Arrival time:</strong> the time they arrive in the CPU ready queue (from waiting state or from new state) </li>
<li><strong>CPU requirement:</strong> their expected CPU burst time</li>
</ul>
</li>
<li>Minimize average turnaround time<ul>
<li><strong>Turnaround time:</strong> The time between the arrival of the task and the time it is blocked or terminated.</li>
</ul>
</li>
<li>Minimize average waiting time<ul>
<li><strong>Waiting time:</strong> The accumulated time that a task has waited in the ready queue.</li>
</ul>
</li>
<li>Reduce the number of context switches</li>
</ul>
<h2 id="Different-Algorithm"><a href="#Different-Algorithm" class="headerlink" title="Different Algorithm"></a>Different Algorithm</h2><h3 id="Shortest-Job-First-SJF"><a href="#Shortest-Job-First-SJF" class="headerlink" title="Shortest Job First (SJF)"></a>Shortest Job First (SJF)</h3><blockquote>
<p>定义：字面意思</p>
<p>Type</p>
<ul>
<li>Non-preemptive</li>
<li>Preemptive</li>
</ul>
</blockquote>
<ul>
<li>Non-preemptive SJF<ul>
<li>when new process arrive ready queue, the scheduler won’t step in immediately (until the current process blocked or terminated)</li>
<li>when scheduler steps in, it selects next task based on <strong>remaining CPU requirement</strong></li>
</ul>
</li>
<li>Preemptive SJF<ul>
<li>whenever a new process arrive ready queue, the scheduler steps in and selects the next task based on <strong>remaining CPU requirement</strong></li>
</ul>
</li>
</ul>
<h3 id="Round-robin-RR"><a href="#Round-robin-RR" class="headerlink" title="Round-robin (RR)"></a>Round-robin (RR)</h3><ul>
<li>Preemptive<ul>
<li>Every process given a <strong>quantum</strong> (the amount of time allowed to execute)</li>
<li>when a process’s quantum used up, the process is preempted, placed at the end of the queue, with its quantum recharge</li>
<li>then, <strong>the scheduler step in</strong> and choose the next process</li>
</ul>
</li>
<li>New process add to the tail of ready queue<ul>
<li>but won’t trigger a new selection decision</li>
</ul>
</li>
</ul>
<blockquote>
<p>一个调度是否抢占，在 RR 中看的是触发调度时正在运行的进程是否已经执行完毕。</p>
</blockquote>
<h3 id="Priority-scheduling"><a href="#Priority-scheduling" class="headerlink" title="Priority scheduling"></a>Priority scheduling</h3><ul>
<li>A <strong>priority number</strong> (integer) is associated with each process</li>
<li>The CPU is allocated to the process with the highest priority (smallest integer $equiv$ highest priority)<ul>
<li>Nonpreemptive: newly arrived process simply put into the queue</li>
<li>Preemptive: if the priority of the newly arrived process is higher than priority of the currently running process, <strong>preempt the CPU</strong></li>
</ul>
</li>
<li>Static priority and dynamic priority<ul>
<li>static priority: fixed priority throughout its lifetime</li>
<li>dynamic priority: priority changes over time</li>
</ul>
</li>
<li>SJF is a priority scheduling where priority is the next CPU burst time</li>
</ul>
<ul>
<li>Problem: Starvation —— low priority process may never execute</li>
<li>Solution: Aging —— as time progresses increase the priority of the process<ul>
<li>在等待队列待得越久，优先级越高，后续越容易被调度运行</li>
</ul>
</li>
</ul>
<h2 id="Optimization-Completely-Fair-Scheduler"><a href="#Optimization-Completely-Fair-Scheduler" class="headerlink" title="Optimization: Completely Fair Scheduler"></a>Optimization: Completely Fair Scheduler</h2><ul>
<li>Scheduling class<ul>
<li>Standard Linux kernel implements two scheduling classes</li>
<li>(1) Default scheduling class: CFS</li>
<li>(2) Real-time scheduling class</li>
</ul>
</li>
<li>Varying length scheduling quantum<ul>
<li>Traditional UNIX scheduling uses 90ms fixed scheduling quantum</li>
<li>CFS assigns a proposition of CPU processing time to each task</li>
</ul>
</li>
<li>Nice value<ul>
<li>$-20$ to $+19$, default nice is 0</li>
<li>Lower nice value indicates a higher relative priority</li>
<li>Higher value is “being nice” (“够好了，不用这么多时间运行了”)</li>
<li>Task with lower nice value receives higher proportion of CPU time</li>
</ul>
</li>
<li>Virtual run time<ul>
<li>Each task has a per-task variable vruntime</li>
<li>Decay factor<ul>
<li>Lower priority has higher rate of decay </li>
<li>nice = 0 virtual run time is identical to actual physical run time</li>
<li>A task with nice $&gt; 0$ runs for 200 milliseconds, its vruntime will be higher than 200 milliseconds</li>
<li>A task with nice $\lt 0$ runs for 200 milliseconds, its vruntime will be lower than 200 milliseconds</li>
</ul>
</li>
</ul>
</li>
<li>Lower virtual run time, higher priority<ul>
<li>To decide which task to run next, scheduler chooses the task that has the smallest vruntime value</li>
<li>Higher priority can preempt lower priority</li>
</ul>
</li>
</ul>
<p><strong>Example</strong></p>
<ul>
<li>Example: Two tasks have the same nice value</li>
<li>One task is I/O bound and the other is CPU bound</li>
<li><strong>vruntime</strong> of I/O bound will be shorter than <strong>vruntime</strong> of CPU bound</li>
<li>I/O bound task will eventually have higher priority and preempt CPU-bound tasks whenever it is ready to run</li>
</ul>
<h1 id="Lec05-Synchronization"><a href="#Lec05-Synchronization" class="headerlink" title="Lec05. Synchronization"></a>Lec05. Synchronization</h1><h2 id="Outline-3"><a href="#Outline-3" class="headerlink" title="Outline"></a>Outline</h2><ul>
<li>Process Communications: Race Condition and Mutual Exclusion</li>
<li>Solution Implementation: Critical Section</li>
<li>Spin-based Lock</li>
<li>Sleep-based Lock</li>
</ul>
<h2 id="Process-Communications"><a href="#Process-Communications" class="headerlink" title="Process Communications"></a>Process Communications</h2><ul>
<li>Threads of the same process share the same address space<ul>
<li>Global variables are shared by multiple threads</li>
<li>Communication between threads made easy</li>
</ul>
</li>
<li>Process may also need to communicate with each other<ul>
<li>Information sharing: <ul>
<li>e.g., sharing between Android apps</li>
</ul>
</li>
<li>Computation speedup: <ul>
<li>e.g., Message Passing Interface (MPI)</li>
</ul>
</li>
<li>Modularity and isolation: <ul>
<li>e.g., Chrome’s multi-process architecture</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Problems-Synchronization-of-Threads-Processes"><a href="#Problems-Synchronization-of-Threads-Processes" class="headerlink" title="Problems: Synchronization of Threads/Processes"></a>Problems: Synchronization of Threads/Processes</h3><blockquote>
<p><strong>A Joke:</strong> A programmer had a problem. He thought to himself, “I know, I’ll solve it with threads!”. has Now problems. two he</p>
</blockquote>
<h3 id="Race-Condition"><a href="#Race-Condition" class="headerlink" title="Race Condition"></a>Race Condition</h3><table>
<tr>
<td><img src="/2024/09/13/Operating-Systems/os501.png"></td>
<td><img src="/2024/09/13/Operating-Systems/os502.png"></td>
</tr>
</table>

<ul>
<li>The above scenario is called the race condition.<ul>
<li>May happen whenever “shared object” + “multiple processes/threads” + “concurrently”</li>
</ul>
</li>
<li>A race condition means<ul>
<li>The outcome of an execution depends on a particular order in which the shared resource is accessed.</li>
</ul>
</li>
<li>Remember: race condition is always a bad thing and debugging race condition is a nightmare!</li>
</ul>
<h2 id="Solution-Critical-Section"><a href="#Solution-Critical-Section" class="headerlink" title="Solution: Critical Section"></a>Solution: Critical Section</h2><p><img src="/2024/09/13/Operating-Systems/os503.png"></p>
<p><strong>Def.</strong> <font color="red">Mutual Exclusion</font> is when one process access the shared memory, no one else could access it.</p>
<p><strong>Implementation: Critical Section</strong></p>
<table>
<tr>
<td><img src="/2024/09/13/Operating-Systems/os504.png"></td>
<td><img src="/2024/09/13/Operating-Systems/os505.png"></td>
</tr>
</table>

<ul>
<li>A critical section is the code segment that access shared objects.<ul>
<li>Critical section should be as tight as possible.<ul>
<li>Well, you can set the entire code of a program to be a big critical section.</li>
<li>But, the program will have a very high chance to block other processes or to be blocked by other processes.</li>
</ul>
</li>
<li>Note that one critical section can be designed for accessing more than one shared objects.</li>
</ul>
</li>
<li>Critical Section Implementation<ul>
<li>Requirement #1. Mutual Exclusion<ul>
<li>No two processes could be simultaneously go inside their own critical sections.</li>
</ul>
</li>
<li>Requirement #2. Bounded Waiting<ul>
<li>Once a process starts trying to enter its critical section, there is a bound on the number of times other processes can enter theirs.</li>
</ul>
</li>
<li>Requirement #3. Progress <ul>
<li>Say no process currently in critical section.</li>
<li>One of the processes trying to enter will eventually get in</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Solution-Disabling-Interrupts"><a href="#Solution-Disabling-Interrupts" class="headerlink" title="Solution: Disabling Interrupts"></a>Solution: Disabling Interrupts</h3><p><img src="/2024/09/13/Operating-Systems/os506.png"></p>
<h2 id="Solution-Spin-based-Locks"><a href="#Solution-Spin-based-Locks" class="headerlink" title="Solution: Spin-based Locks"></a>Solution: Spin-based Locks</h2><h3 id="Overview-about-Locks"><a href="#Overview-about-Locks" class="headerlink" title="Overview about Locks"></a>Overview about Locks</h3><ul>
<li>Use yet another shared objects: locks<ul>
<li>What about race condition on lock? </li>
<li>Atomic instructions: instructions that cannot be “interrupted”, not even by instructions running on another core</li>
</ul>
</li>
<li>Spin-based locks<ul>
<li>Process synchronization<ul>
<li>Basic spinning using 1 shared variable</li>
<li>Peterson’s solution: Spin using 2 shared variables</li>
</ul>
</li>
<li>Thread synchronization: pthread_spin_lock</li>
</ul>
</li>
<li>Sleep-based locks<ul>
<li>Process synchronization: POSIX semaphore</li>
<li>Thread synchronization: pthread_mutex_lock</li>
</ul>
</li>
</ul>
<h3 id="Spin-based-lock"><a href="#Spin-based-lock" class="headerlink" title="Spin-based lock"></a>Spin-based lock</h3><p><img src="/2024/09/13/Operating-Systems/os507.png"></p>
<ul>
<li>Consider the following sequence:<ul>
<li>Process0 leaves <code>cs()</code>, set <code>turn=1</code></li>
<li>Process1 enters <code>cs()</code>, leaves <code>cs()</code>, set <code>turn=0</code>, work on remainder_section_slow</li>
<li>Process0 loops back and enters <code>cs()</code> again, leaves <code>cs()</code>, set <code>turn=1</code></li>
<li>Process0 finishes its <code>remainder_section()</code>, go back to top of the loop<ul>
<li>It can’t enter its <code>cs()</code> (as turn = 1)</li>
<li>That is, process0 gets blocked, but Process1 is outside its <code>cs()</code>,  it is at its <code>remainder_section_slow()</code></li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="/2024/09/13/Operating-Systems/os508.png"></p>
<h3 id="Improvement-Peterson’s-Solution"><a href="#Improvement-Peterson’s-Solution" class="headerlink" title="Improvement: Peterson’s Solution"></a>Improvement: Peterson’s Solution</h3><blockquote>
<p>引入了一个“兴趣”机制</p>
</blockquote>
<table>
<tr>
<td><img src="/2024/09/13/Operating-Systems/os509.png"></td>
<td><img src="/2024/09/13/Operating-Systems/os510.png"></td>
</tr>
</table>



<ul>
<li>Mutual exclusion<ul>
<li><code>interested[0] == interested[1] == true</code></li>
<li><code>turn == 0</code> or <code>turn == 1</code>, not both</li>
</ul>
</li>
<li>Progress<ul>
<li>If only $P_0$ to enter critical section<ul>
<li><code>interested[1] == false</code>, thus $P_0$ enters critical section</li>
</ul>
</li>
<li>If both $P_0$ and $P_1$ to enter critical section<ul>
<li><code>interested[0] == interested[1] == true</code> and (<code>turn == 0</code> or <code>turn == 1</code>)</li>
<li>One of $P_0$ and $P_1$ will be selected</li>
</ul>
</li>
</ul>
</li>
<li><font color="red">Bounded-waiting</font> <ul>
<li>If both $P_0$ and $P_1$ to enter critical section, and $P_0$ selected first</li>
<li>When $P_0$ exit, <code>interested[0] = false</code><ul>
<li>If $P_1$ runs fast: <code>interested[0] == false</code>, $P_1$ enters critical section</li>
<li>If $P_0$ runs fast: <code>interested[0] = true</code>, but <code>turn = 0</code>, $P_1$ enters critical section.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="Multi-Process-Mutual-Exclusion"><a href="#Multi-Process-Mutual-Exclusion" class="headerlink" title="Multi-Process Mutual Exclusion"></a>Multi-Process Mutual Exclusion</h4><blockquote>
<ul>
<li>初始化一个 waiting array 表示 n 个进程，<code>lock == TRUE</code></li>
<li>当一个进程（e.g. process <code>i</code>）离开 critical section 时，它会从 <code>i+1</code> 开始遍历整个 waiting array</li>
<li>第一个被扫描到 <code>waiting[j] == TRUE</code> 的进程将会进入critical section</li>
<li>实现 Bounded-waiting：所有进程最多经过 $n-1$ 次即可进入 critical section</li>
<li>当不再有进程进入 critical section 时，<code>lock == FALSE</code> </li>
</ul>
</blockquote>
<h4 id="Priority-Inversion"><a href="#Priority-Inversion" class="headerlink" title="Priority Inversion"></a>Priority Inversion</h4><p><img src="/2024/09/13/Operating-Systems/os511.png"></p>
<blockquote>
</blockquote>
<h2 id="Solution-Sleep-based-Locks"><a href="#Solution-Sleep-based-Locks" class="headerlink" title="Solution: Sleep-based Locks"></a>Solution: Sleep-based Locks</h2><ul>
<li>Semaphore is just a struct, which includes <ul>
<li>an integer that counts the # of resources available<ul>
<li>Can do more than solving mutual exclusion</li>
</ul>
</li>
<li>a wait-list</li>
</ul>
</li>
<li>The trick is still the section entry/exit function implementation<ul>
<li>Must involve kernel (for sleep)</li>
<li>Implement uninterruptable section entry/exit<ul>
<li>Disable interrupts (on single core)</li>
<li>Atomic instructions (on multiple cores)</li>
</ul>
</li>
</ul>
</li>
</ul>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// definition of sema&#x27;</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">  <span class="type">int</span> value;</span><br><span class="line">  <span class="built_in">list</span> process_id;</span><br><span class="line">&#125; semaphore;</span><br></pre></td></tr></table></figure>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// example of sema&#x27;</span></span><br><span class="line"><span class="comment">/* wait */</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">sem_wait</span><span class="params">(semaphore *s)</span>&#123;</span><br><span class="line">  s-&gt;value = s-&gt;value - <span class="number">1</span>;</span><br><span class="line">  <span class="keyword">if</span> ( s-&gt;value &lt; <span class="number">0</span> ) &#123;</span><br><span class="line">    sleep();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* post */</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">sem_post</span><span class="params">(semaphore *s)</span> &#123;</span><br><span class="line">  s-&gt;value = s-&gt;value + <span class="number">1</span>;    </span><br><span class="line">  <span class="keyword">if</span> ( s-&gt;value &lt;= <span class="number">0</span> ) wakeup();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>See an example 👇</li>
</ul>
<table>
<tr>
<td><img src="/2024/09/13/Operating-Systems/os512.png"></td>
<td><img src="/2024/09/13/Operating-Systems/os513.png"></td>
</tr>
<tr>
<td><img src="/2024/09/13/Operating-Systems/os514.png"></td>
<td><img src="/2024/09/13/Operating-Systems/os515.png"></td>
</tr>
</table>

<ul>
<li>Origin value of semaphore represent the capacity of preemptive processes (<code>init=1</code>, allowing at most $1$ process to take the resource)</li>
<li>Now process 1357 is running and take the resource (locked)</li>
<li>when process 1234 arrives, value of semaphore became $-1$, so process 1234 sleep and wait.</li>
<li>Process 1357 exit critical section and return the resource, calling wakeup to set value of semaphore to $0$, so that process 1234 can take the resource.</li>
</ul>
<h3 id="Problems-solved-by-semaphore"><a href="#Problems-solved-by-semaphore" class="headerlink" title="Problems solved by semaphore"></a>Problems solved by semaphore</h3><ul>
<li>Producer-Consumer Problem<ul>
<li>Two types of processes: producer<ul>
<li>At least one producer and one consumer.</li>
</ul>
</li>
</ul>
</li>
<li>Dining Philosopher Problem<ul>
<li>Only one type of process<ul>
<li>At least two processes.</li>
</ul>
</li>
</ul>
</li>
<li>Reader Writer Problem<ul>
<li>Multiple readers, one write</li>
</ul>
</li>
</ul>
<h4 id="Producer-Consumer-Problem"><a href="#Producer-Consumer-Problem" class="headerlink" title="Producer-Consumer Problem"></a>Producer-Consumer Problem</h4><p><img src="/2024/09/13/Operating-Systems/os516.png"></p>
<ul>
<li>Requirement #1: Producer wants to put a new item in the buffer, but the buffer is already full<ul>
<li>The producer should wait</li>
<li>The consumer should notify the producer after it has dequeued an item</li>
</ul>
</li>
<li>Requirement #2: Consumer wants to consume an item from the buffer, but the buffer is empty<ul>
<li>Then consumer should wait</li>
<li>The producer should notify the consumer after it has enqueued an item</li>
</ul>
</li>
</ul>
<blockquote>
<p>How to implement (solve) ?</p>
</blockquote>
<ul>
<li>The problem can be divided into two sub-problems.<ul>
<li><strong>Mutual exclusion</strong> with <strong>one binary semaphore</strong><ul>
<li>The buffer is a shared object.  </li>
</ul>
</li>
<li><strong>Synchronization</strong> with <strong>two counting semaphores</strong><ul>
<li>Notify  the producer to stop producing when the buffer is full<ul>
<li>In other words, notify the producer to produce when the buffer is NOT full</li>
</ul>
</li>
<li>Notify the consumer to stop eating when the buffer is empty<ul>
<li>In other words, notify the consumer to consume when the buffer is NOT empty</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="/2024/09/13/Operating-Systems/os517.png"></p>
<ul>
<li><strong>Q1:</strong> Can we only use <code>avail</code> and remove <code>fill</code> ?<ul>
<li>producer <code>avail--</code> by wait</li>
<li>consumer <code>avail++</code> by post</li>
</ul>
</li>
<li><strong>A1:</strong> No. If consumer get CPU first, it removes item from NULL [Error!].</li>
<li><strong>Q2:</strong> Can we switch line 6 and 7 in producer ? (wait for <code>mutex</code> first)</li>
<li><strong>A2:</strong> Consider such a case:<ul>
<li>The buffer is full.</li>
<li>Producer wait at line 7 (wait for consumer to remove items)</li>
<li>Context switch.</li>
<li>Consumer pass line 5 but wait at line 6 (wait for producer to post &amp;mutex)</li>
<li>Now both producer and consumer wait for each other</li>
</ul>
</li>
<li>This scenario is called a <strong>deadlock</strong></li>
</ul>
<h4 id="Dining-Philosopher-Problem"><a href="#Dining-Philosopher-Problem" class="headerlink" title="Dining Philosopher Problem"></a>Dining Philosopher Problem</h4><p><img src="/2024/09/13/Operating-Systems/os518.png"></p>
<blockquote>
<p>两个要求：</p>
<ol>
<li>不能偷筷子，且两人不能同时用一根筷子（mutual exclusion）</li>
<li>必须避免死锁（每个人都拿了一根筷子，都吃不了东西）</li>
</ol>
<p>初步实现：</p>
<ol>
<li>一个人拿起一根筷子，如果另一根无法拿起（被占），则放下全部筷子并休息（sleep），被唤醒后再尝试</li>
</ol>
<p>问题：可能导致全部人都重复这个操作，最后还是谁都吃不了东西</p>
<p>Final Solution: 👇</p>
</blockquote>
<p><img src="/2024/09/13/Operating-Systems/os519.png"></p>
<p>a case:</p>
<table>
<tr>
<td><img src="/2024/09/13/Operating-Systems/os520.png"></td>
<td><img src="/2024/09/13/Operating-Systems/os521.png"></td>
</tr>
<tr>
<td><img src="/2024/09/13/Operating-Systems/os522.png"></td>
<td><img src="/2024/09/13/Operating-Systems/os523.png"></td>
</tr>
<tr>
<td><img src="/2024/09/13/Operating-Systems/os524.png"></td>
<td><img src="/2024/09/13/Operating-Systems/os525.png"></td>
</tr>
</table>



<h1 id="Lec06-Address-Translation"><a href="#Lec06-Address-Translation" class="headerlink" title="Lec06. Address Translation"></a>Lec06. Address Translation</h1><h2 id="Outline-4"><a href="#Outline-4" class="headerlink" title="Outline"></a>Outline</h2><ul>
<li>Memory Virtualization</li>
<li>Base &amp; Bounds</li>
<li>Segmentation</li>
<li>Memory Allocation</li>
</ul>
<h2 id="Memory-Virtualization"><a href="#Memory-Virtualization" class="headerlink" title="Memory Virtualization"></a>Memory Virtualization</h2><blockquote>
<p>Multiprogramming with Memory Partition brings problems to physical memory</p>
</blockquote>
<h3 id="Address-Space"><a href="#Address-Space" class="headerlink" title="Address Space"></a>Address Space</h3><p><img src="/2024/09/13/Operating-Systems/os601.png"></p>
<p><img src="/2024/09/13/Operating-Systems/os602.png"></p>
<ul>
<li>A mechanism that virtualize memory should<ul>
<li>Be transparent<ul>
<li>Memory virtualization should be invisible to processes</li>
<li>Processes run as if on a single private memory</li>
</ul>
</li>
<li>Be efficient<ul>
<li>Time: translation is fast</li>
<li>Space: not too space consuming</li>
</ul>
</li>
<li>Provide protection<ul>
<li>Enable memory isolation</li>
<li>One process may not access memory of another process or the OS kernel</li>
<li>Isolation is a key principle in building reliable systems</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Address-Translation"><a href="#Address-Translation" class="headerlink" title="Address Translation"></a>Address Translation</h3><p><img src="/2024/09/13/Operating-Systems/os603.png"></p>
<h2 id="Base-amp-Bound"><a href="#Base-amp-Bound" class="headerlink" title="Base &amp; Bound"></a>Base &amp; Bound</h2><p><img src="/2024/09/13/Operating-Systems/os604.png"></p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">Hardware Support</th>
<th style="text-align:center">Explanation</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Privileged mode to update base/bounds</td>
<td style="text-align:center">Needed to prevent user-mode processes from executing privileged operations to update base/bounds</td>
</tr>
<tr>
<td style="text-align:center">Base/bounds registers</td>
<td style="text-align:center">Need pair of registers per CPU to support address translation and bounds checks</td>
</tr>
<tr>
<td style="text-align:center">Privileged instruction(s) to register exception handlers</td>
<td style="text-align:center">Need to allow OS, but not the processes, to tell hardware what exception handlers code to run if exception occurs</td>
</tr>
</tbody>
</table>
</div>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">OS Support</th>
<th style="text-align:center">Explanation</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Memory management</td>
<td style="text-align:center">Need to allocate memory for new processes; Reclaim memory from terminated processes; manage memory via free list</td>
</tr>
<tr>
<td style="text-align:center">Base/bounds management</td>
<td style="text-align:center">Must set base/bounds properly upon context switch</td>
</tr>
<tr>
<td style="text-align:center">Exception handling</td>
<td style="text-align:center">Code to run when exceptions arise; likely action is to terminate offending process</td>
</tr>
</tbody>
</table>
</div>
<h3 id="Limitation"><a href="#Limitation" class="headerlink" title="Limitation"></a>Limitation</h3><ul>
<li><font color="red">Internal fragmentation</font> .<ul>
<li>wasted memory between heap and stack </li>
</ul>
</li>
<li><font color="red">Cannot support larger address space</font> .<ul>
<li>Address space equals the allocated slot in memory </li>
<li><font color="blue">E.g. Process C’s address space is at most 64KB</font> .</li>
</ul>
</li>
<li><font color="red">Hard to do inter-process sharing</font> .<ul>
<li>Want to share code segments when possible </li>
<li>Want to share memory between processes </li>
<li><font color="blue">E.g. Process A &amp; C cannot share memory</font> .</li>
</ul>
</li>
</ul>
<h2 id="Segmentation-Generalized-Base-Bounds"><a href="#Segmentation-Generalized-Base-Bounds" class="headerlink" title="Segmentation: Generalized Base/Bounds"></a>Segmentation: Generalized Base/Bounds</h2><p><img src="/2024/09/13/Operating-Systems/os605.png"></p>
<h3 id="Implementation"><a href="#Implementation" class="headerlink" title="Implementation"></a>Implementation</h3><ul>
<li>Base/bounds registers organized as a table<ul>
<li>Segment ID used to index the base/bounds pair</li>
<li>Base added to offset (of virtual address) to generate physical address</li>
<li>Error check catches offset (of virtual address) out of range</li>
</ul>
</li>
<li>Use segments explicitly<ul>
<li>Segment addressed by top bits of virtual address</li>
</ul>
</li>
<li>Use segments implicitly<ul>
<li>e.g., code segment used for code fetching</li>
</ul>
</li>
</ul>
<p><img src="/2024/09/13/Operating-Systems/os606.png"></p>
<ul>
<li>Memory sharing with segmentation<ul>
<li>Code sharing on modern OS is very common</li>
<li>If multiple processes use the same program code or library code<ul>
<li>Their address space may overlap in the physical memory</li>
<li>The cooresponding segments have the same base/bounds</li>
</ul>
</li>
<li>Memory sharing needs memory protection</li>
</ul>
</li>
<li>Memory protection with segmentation<ul>
<li>Extend base/bounds register pair</li>
<li>Read/Write/Execute permission</li>
</ul>
</li>
</ul>
<p><strong>Problems with Segmentation</strong></p>
<ul>
<li>OS context switch must also save and restore all pairs of segment registers</li>
<li>A segment may grow, which may or may not be possible</li>
<li>Management of free spaces of physical memory with variable sized segments</li>
<li>External fragmentation: gaps between allocated segments<ul>
<li>Segmentation may also have internal fragmentation if more space allocated than needed. (一个 seg 内的 heap 和 stack 之间存在内部碎片，浪费了过多分配的空间)</li>
</ul>
</li>
</ul>
<h2 id="Memory-Allocation"><a href="#Memory-Allocation" class="headerlink" title="Memory Allocation"></a>Memory Allocation</h2><ul>
<li>OS needs to manage all free physical memory regions</li>
<li>A basic solution is to maintain a <strong>linked list</strong> of free slots</li>
<li>An ideal allocation algorithm is both <em>fast and minimizes fragmentation</em>. (sometimes need trade-off)</li>
</ul>
<p><img src="/2024/09/13/Operating-Systems/os607.png" style="zoom:40%"></p>
<h3 id="Some-Strategies"><a href="#Some-Strategies" class="headerlink" title="Some Strategies"></a>Some Strategies</h3><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">Strategy</th>
<th style="text-align:left">Idea</th>
<th style="text-align:left">Pros</th>
<th style="text-align:left">Cons</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Best fit</td>
<td style="text-align:left"><ul><li>search through the free list and find chunks of free memory that are as big or bigger than the requested size.</li><li>return the one that is the <b>smallest</b> in that group of candidates;</li></ul></td>
<td style="text-align:left">Satisfy the request with minimal external fragmentation</td>
<td style="text-align:left">exhaustive search is slow</td>
</tr>
<tr>
<td style="text-align:center">Worst fit</td>
<td style="text-align:left"><ul><li>search through the free list and find chunks of free memory that are as big or bigger than the requested size.</li><li>return the one that is the <b>largest</b> in that group of candidates;</li></ul></td>
<td style="text-align:left">Leaves larger “holes” in physical memory</td>
<td style="text-align:left"><ul><li>exhaustive search is slow</li><li>severe fragmentation in practice</li></ul></td>
</tr>
<tr>
<td style="text-align:center">First fit</td>
<td style="text-align:left">find the first block that is big enough and returns the requested size</td>
<td style="text-align:left">Fast</td>
<td style="text-align:left">pollutes the beginning of the free list with small chunks</td>
</tr>
</tbody>
</table>
</div>
<h1 id="Lec07-Paging"><a href="#Lec07-Paging" class="headerlink" title="Lec07. Paging"></a>Lec07. Paging</h1><h2 id="Outline-5"><a href="#Outline-5" class="headerlink" title="Outline"></a>Outline</h2><ul>
<li>Introduction to paging</li>
<li>Multi-level page tables</li>
<li>Other page table structures</li>
<li>Real-world paging schemes</li>
<li>Translation lookaside buffer (<strong>TLB</strong>)</li>
</ul>
<h2 id="Intro-to-Paging"><a href="#Intro-to-Paging" class="headerlink" title="Intro to Paging"></a>Intro to Paging</h2><blockquote>
<p><font color="green">Recall:</font> Solutions on segmentation</p>
</blockquote>
<ul>
<li>Physical memory conceptually divided into <font color="red">fixed size</font><ul>
<li>Each is a <font color="red">page frame</font><ul>
<li>Too big → internal fragmentation</li>
<li>Too small → page table too big</li>
</ul>
</li>
</ul>
</li>
<li>Virtual address space conceptually divided into the same size<ul>
<li>Each is a <font color="red">page</font></li>
</ul>
</li>
<li>Page mapped to page frame<ul>
<li>One-to-one mapping</li>
<li>Many-to-one mapping 👉 memory sharing</li>
</ul>
</li>
<li>One page table per process<ul>
<li>Resides in physical memory<ul>
<li>One entry for one virtual $\to$ physical translation</li>
</ul>
</li>
</ul>
</li>
</ul>
<table><tr>
<td><img src="/2024/09/13/Operating-Systems/os701.png" style="zoom:60%"></td>
<td><img src="/2024/09/13/Operating-Systems/os702.png" style="zoom:60%"></td></tr>
<tr><td><img src="/2024/09/13/Operating-Systems/os703.png" style="zoom:60%"></td>
<td><img src="/2024/09/13/Operating-Systems/os704.png" style="zoom:60%"></td>
</tr></table>

<ul>
<li><strong>Virtual Address and Paging</strong><ul>
<li>Length of virtual address determines size of address space </li>
<li>Length of offset determines size of a page / page frame</li>
<li>In case of m-bit virtual address and k-bit offset<ul>
<li>Size of address space: $2^m$ </li>
<li>Size of a page: $2^k$</li>
<li>e.g., 32-bit virtual address, 4KB page: $m = 32$, $k = 12$</li>
</ul>
</li>
</ul>
</li>
<li><strong>Page Table Entry</strong><ul>
<li>An entry in the page table is called a page table entry (<strong>PTE</strong>).</li>
<li>Besides <strong>PFN</strong> (Page Frame Number), <strong>PTE</strong> also contains a <font color="red">valid bit</font><ul>
<li>Virtual pages with no valid mapping: valid bit = 0</li>
<li>Important for sparse address space (e.g., $2^{64}$ bytes)</li>
</ul>
</li>
<li>PTE also contains <font color="red">protection bits</font><ul>
<li>Permission to read from or write, or execute code on this page</li>
</ul>
</li>
<li>PTE also contains <font color="red">an access bit, a dirty bit, a present bit</font><ul>
<li>Present bit: whether this page is in physical memory or on disk</li>
<li>Dirty bit: whether the page has been modified since it was brought into memory</li>
<li>Access bit: whether a page has been accessed</li>
</ul>
</li>
</ul>
</li>
</ul>
<table><tr>
<td><img src="/2024/09/13/Operating-Systems/os705.png" style="zoom:60%"></td>
<td><img src="/2024/09/13/Operating-Systems/os706.png" style="zoom:60%"></td>
</tr></table>



<h2 id="Multi-level-page-tables"><a href="#Multi-level-page-tables" class="headerlink" title="Multi-level page tables"></a>Multi-level page tables</h2><ul>
<li>Two level Page Tables<ul>
<li>in order to save space</li>
<li>using “Tree” instead of “List” to improve performance</li>
</ul>
</li>
</ul>
<p><img src="/2024/09/13/Operating-Systems/os707.png" style="zoom:60%"></p>
<blockquote>
<p>More detail about …</p>
</blockquote>
<p><img src="/2024/09/13/Operating-Systems/os708.png" style="zoom:60%"></p>
<h2 id="Other-Page-Table-Strctures"><a href="#Other-Page-Table-Strctures" class="headerlink" title="Other Page Table Strctures"></a>Other Page Table Strctures</h2><ul>
<li>Hierarchical page tables <ul>
<li>2-level page tables</li>
<li>3-level page tables</li>
<li>4-level page tables</li>
</ul>
</li>
<li>Hashed Page Tables </li>
<li>Inverted Page Tables</li>
</ul>
<h2 id="Real-world-Paging-Scheme"><a href="#Real-world-Paging-Scheme" class="headerlink" title="Real-world Paging Scheme"></a>Real-world Paging Scheme</h2><p><strong>I.</strong> RISC-V support multiple MMU</p>
<ul>
<li><code>RV32</code> : SV32</li>
<li><code>RV64</code> : SV39 &amp; SV48</li>
</ul>
<p><img src="/2024/09/13/Operating-Systems/os709.png"></p>
<p><strong>II.</strong> IA-32 (Intel’s 32-bit CPU) uses two stage address translation: segmentation + paging</p>
<p><strong>Issues of Paging</strong></p>
<ul>
<li>Time Complexity<ul>
<li>Extra memory references during address translation</li>
<li>Three-level page tables requires 3 additional memory reads</li>
</ul>
</li>
</ul>
<h2 id="Translation-Lookaside-Buffer"><a href="#Translation-Lookaside-Buffer" class="headerlink" title="Translation Lookaside Buffer"></a>Translation Lookaside Buffer</h2><ul>
<li>A <font color="red">translation lookaside buffer (TLB)</font> is a hardware cache that is part of the MMU (Memory Management Unit)<ul>
<li>A cache for the PTEs: holding a translation likely to be <strong>re-used</strong><ul>
<li>Replacement policy: <strong>LRU</strong> (Recall for “Computer Organization”), FIFO, random</li>
</ul>
</li>
<li>Each entry holds mapping of a virtual address to a physical address</li>
</ul>
</li>
<li>Before a virtual-to-physical address translation is to be performed, TLB is looked up using VPN<ul>
<li>TLB hit: VPN is found, and the PFN of the same entry used</li>
<li>TLB miss: VPN not found, page table walk</li>
</ul>
</li>
</ul>
<p><img src="/2024/09/13/Operating-Systems/os710.png" style="zoom:60%"></p>
<center>TLB hit</center>

<p><img src="/2024/09/13/Operating-Systems/os711.png" style="zoom:60%"></p>
<center>TLB miss</center>



<blockquote>
<p>Thought: can TLB be big?</p>
<p>No. If it’s too big, it cannot function as speed-up.</p>
</blockquote>
<ul>
<li><strong>Issues with Context Switch</strong><ul>
<li>Two process may use the same virtual address<ul>
<li>e.g. <code>P1: 100-&gt;170</code>, <code>P2: 100-&gt;110</code></li>
</ul>
</li>
<li>Solutions: <ul>
<li>Flush TLB upon context switch (Invalidate all entries: <code>V-&gt;I</code>)</li>
<li>Extending TLB with address space ID (No need to flush TLB)</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="Lec08-Demand-Paging"><a href="#Lec08-Demand-Paging" class="headerlink" title="Lec08. Demand Paging"></a>Lec08. Demand Paging</h1><h2 id="Outline-6"><a href="#Outline-6" class="headerlink" title="Outline"></a>Outline</h2><ul>
<li>Demand Paging Mechanisms</li>
<li>Page Replacement Policy</li>
<li>Page Frame Allocation</li>
</ul>
<h2 id="Demand-Paging-Mechanisms"><a href="#Demand-Paging-Mechanisms" class="headerlink" title="Demand Paging Mechanisms"></a>Demand Paging Mechanisms</h2><blockquote>
<p>Who is responsible for moving data?</p>
<p>For applications, it’s <strong>memory overlay</strong></p>
<ul>
<li>Application in charge of moving data between memory and disk</li>
<li>e.g., calling a function needs to make sure the code is in memory!</li>
</ul>
<p>For OS, it’s <strong>demand paging</strong></p>
<ul>
<li>OS configures page table entries</li>
<li>Virtual page maps to physical memory or files in disk</li>
<li>Process sees an abstraction of address space</li>
<li>OS determines where the data is stored</li>
</ul>
</blockquote>
<h3 id="Swap-Space"><a href="#Swap-Space" class="headerlink" title="Swap Space"></a>Swap Space</h3><ul>
<li>Swap space is a partition or a file stored on the disk<ul>
<li>OS swaps pages out of memory to it </li>
</ul>
</li>
<li>OS swaps pages from it into memory<ul>
<li>Swap space conceptually divided into page-sized units</li>
<li>OS maintains a disk address of each page-sized unit</li>
</ul>
</li>
</ul>
<p><img src="/2024/09/13/Operating-Systems/os801.png" style="zoom:60%"></p>
<h3 id="Demand-Paging"><a href="#Demand-Paging" class="headerlink" title="Demand Paging"></a>Demand Paging</h3><ul>
<li>Load pages from disk to memory only as they are needed <ul>
<li>Pages are loaded “on demand”</li>
</ul>
</li>
<li>Data transferred in the unit of pages</li>
<li>Two possible on-disk locations <ul>
<li>Swap space: <ul>
<li>created by OS for temporary storage of pages on disk</li>
<li>e.g., pages for stack and heap</li>
</ul>
</li>
<li>Program binary files:<ul>
<li>The code pages from this binary are only loaded into memory when they are executed</li>
<li>Read-only, thus never write back</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>Physical Memory as a Cache</strong></p>
<ul>
<li>Physical memory can be regarded as a cache of on-disk swap space</li>
<li>Block size of the cache?<ul>
<li>1 page (4KB)</li>
</ul>
</li>
<li>Cache organization (direct-mapped, set-associative, fully-associative)?<ul>
<li>Fully associative: any disk page maps to any page frame</li>
</ul>
</li>
<li>What is page replacement policy?<ul>
<li>LRU, Random, FIFO</li>
</ul>
</li>
<li>What happens on a miss?<ul>
<li>Go to lower level to fill page (i.e. disk)</li>
</ul>
</li>
<li>What happens on a write, write-through or write back?<ul>
<li>write-back: changes are written back to disk when page is evicted <font color="green">(Recall for Computer Organization)</font></li>
</ul>
</li>
</ul>
<p><img src="/2024/09/13/Operating-Systems/os802.png"></p>
<ul>
<li>Using a present bit to indicate whether a page is in physical memory</li>
</ul>
<h4 id="Page-Fault"><a href="#Page-Fault" class="headerlink" title="Page Fault"></a>Page Fault</h4><ul>
<li>Present bit = 0 raises a <strong>page fault</strong><ul>
<li>OS gets involved in address translation</li>
</ul>
</li>
<li>Page fault handler<ul>
<li>(1) Find free page frame in physical memory</li>
<li>(2) Fetch page from disk and store it in physical memory</li>
</ul>
</li>
<li>After page fault<ul>
<li>Return from page fault exception</li>
<li>CPU re-execute the instruction that accesses the virtual memory</li>
<li>No more page fault since present bit is set this time</li>
<li>TLB entry loaded from PTE</li>
</ul>
</li>
</ul>
<p><strong>(1) Find free page frame in physical memory</strong></p>
<ul>
<li>Find one free page frame from a free-page list</li>
<li>If no free page, trigger <font color="red">page replacement</font><ul>
<li>find a page frame to be replaced<ul>
<li><font color="red">Page replacement</font> policy decides which one to replace</li>
</ul>
</li>
<li>If page frame to be replaced is dirty, write it back to disk</li>
<li>Update all PTEs pointing to the page frame</li>
<li>Invalidate all TLB entries for these PTEs</li>
</ul>
</li>
</ul>
<p><strong>(2) Fetch page from disk</strong></p>
<ul>
<li>Determine the faulting virtual address from register</li>
<li>Locate the disk address of the page in PTE (where PFN should be stored)<ul>
<li>It is a very natural choice to make use of the space in PTE</li>
</ul>
</li>
<li>Issues a request to disk to fetch the page into memory</li>
<li>Wait …… (could be a very long time, context switch!)</li>
<li>When I/O completes, update page table entry: PFN, present bit</li>
</ul>
<blockquote>
<p><strong>Q: When to Trigger Page Replacement?</strong></p>
<ul>
<li>Proactive page replacement usually leads to better performance<ul>
<li>Page replacement even though no one needs free page frames (yet)</li>
<li>Always reserve some free page frames in the system</li>
</ul>
</li>
<li>Swap daemon<ul>
<li>background process for reclaiming page frames</li>
<li>Low watermark: a threshold to trigger swap deamon</li>
<li>High watermark: a threshold to stop reclaiming page frames</li>
</ul>
</li>
</ul>
</blockquote>
<p><img src="/2024/09/13/Operating-Systems/os803.png"></p>
<h2 id="Page-Replacement-Policy"><a href="#Page-Replacement-Policy" class="headerlink" title="Page Replacement Policy"></a>Page Replacement Policy</h2><h3 id="Effective-Access-Time-EAT"><a href="#Effective-Access-Time-EAT" class="headerlink" title="Effective Access Time (EAT)"></a>Effective Access Time (EAT)</h3><blockquote class="blockquote-center">
<p>$<br>EAT=\text{ Hit Rate }\times \text{ Hit Time }+ \text{ Miss Rate }\times \text{ Miss Penalty }<br>$</p>

</blockquote>
<p><strong>Three types of Cache Misses</strong></p>
<ul>
<li>Compulsory Misses: <ul>
<li>Cold-start miss: pages that have never been fetched into memory before</li>
<li>Prefetching: loading them into memory before needed</li>
</ul>
</li>
<li>Capacity Misses:<ul>
<li>Not enough memory: must somehow increase available memory size</li>
<li>One option: Increase amount of DRAM (not quick fix!)</li>
<li>Another option:  If multiple processes in memory: adjust percentage of memory allocated to each one!</li>
</ul>
</li>
<li>Conflict Misses:<ul>
<li>fully-associative cache (OS page cache) does not have conflict misses</li>
</ul>
</li>
</ul>
<h3 id="Page-Replacement-Policies"><a href="#Page-Replacement-Policies" class="headerlink" title="Page Replacement Policies"></a>Page Replacement Policies</h3><ul>
<li>Optimal (also called MIN): <ul>
<li>Replace page that will not be used for the longest time</li>
<li>Lead to minimum page faults in theory</li>
<li><font color="grey">But OS won’t know about the future</font>.</li>
</ul>
</li>
<li>FIFO (First In, First Out)<ul>
<li>Throw out oldest page first</li>
<li>May throw out heavily used pages instead of infrequently used</li>
</ul>
</li>
<li>RANDOM:<ul>
<li>Pick random page for every replacement</li>
<li>Pretty unpredictable – makes it hard to make real-time guarantees</li>
</ul>
</li>
<li>Least Recently Used (LRU):<ul>
<li>Replace page that has not been used for the longest time</li>
<li>Temporal locality of program</li>
<li>If a page has not been used for a while, it is unlikely to be used in the near future</li>
<li><font color="grey">Seem to be practical, huh</font>?</li>
</ul>
</li>
<li>Least Frequently Used (LFU)<ul>
<li>Replace page that has not been accessed many times</li>
<li>Spatial locality of program</li>
<li>if a page has been accessed many times, perhaps it should not be replaced as it clearly has some value. (Like LRU)</li>
</ul>
</li>
</ul>
<blockquote>
<p><strong>Bélády’s Anomaly</strong></p>
<p>When you add memory the miss rate drops in LRU and MIN, but not necessarily for <strong>FIFO</strong> !</p>
</blockquote>
<h3 id="LRU-Impl"><a href="#LRU-Impl" class="headerlink" title="LRU Impl"></a>LRU Impl</h3><ul>
<li>Hardware support is necessary<ul>
<li>Update a data structure in OS upon every memory access</li>
<li>E.g., a timestamp counter for each page frame</li>
</ul>
</li>
<li>Overhead (LRU 实现需要考虑以下负载)<ul>
<li>One additional memory write for each memory access<ul>
<li>TLB hit does not save the extra memory access</li>
</ul>
</li>
<li>Scan the entire memory to find the LRU one<ul>
<li>4GB physical memory has 1 million page frames</li>
<li>sorting is time consuming</li>
</ul>
</li>
</ul>
</li>
<li>LRU Approximation with Reference Bit:<ul>
<li>Reference bit<ul>
<li>One reference bit per page frame</li>
<li>All bits are cleared to 0 initially</li>
<li>The first time a page is referenced, the reference bit is set by CPU (Can be integrated with page table walk)</li>
<li>The order of page accesses approximated by two clusters: used and unused pages</li>
</ul>
</li>
<li>E.g. Clock algorithm(second-chance algorithm), enhanced clock algorithm with dirty bits</li>
</ul>
</li>
</ul>
<h3 id="Clock-Algorithm"><a href="#Clock-Algorithm" class="headerlink" title="Clock Algorithm"></a>Clock Algorithm</h3><p><img src="/2024/09/13/Operating-Systems/os804.png"></p>
<blockquote>
<p>提供了一次“避免被替换”的机会</p>
</blockquote>
<ul>
<li>Clock Algorithm with Dirty Bit<ul>
<li>dirty bit = 1: the page has recently been modified</li>
</ul>
</li>
<li>CPU sets dirty bit to 1 upon <strong>write</strong> access</li>
<li>When a replacement occurs, OS checks <code>(ref bit, dirty bit)</code>, and selects a candidate page in decreasing order<ul>
<li><code>(0, 0)</code> neither recently used nor modified — best page to replace </li>
<li><code>(0, 1)</code> not recently used but modified — not quite as good, because the page will need to be written out before replacement </li>
<li><code>(1, 0)</code> recently used but clean — probably will be used again soon </li>
<li><code>(1, 1)</code> recently used and modified — probably will be used again soon, and the page will be need to be written out to secondary storage before it can be replaced</li>
</ul>
</li>
<li><font color="red"><b>Renew:</b></font> LRU Approximation with Reference Bit and Counter<ul>
<li>Reference bit indicate recent access<ul>
<li><font color="red">set by CPU hardware, cleared by OS</font>.</li>
</ul>
</li>
<li>Counter records history of accesses<ul>
<li>Maintained by OS</li>
</ul>
</li>
<li>Two counter example 👇</li>
</ul>
</li>
</ul>
<p><img src="/2024/09/13/Operating-Systems/os805.png"></p>
<h2 id="Page-Frame-Allocation"><a href="#Page-Frame-Allocation" class="headerlink" title="Page Frame Allocation"></a>Page Frame Allocation</h2><ul>
<li>How do we allocate memory among different processes?<ul>
<li>Does every process get the same fraction of memory?  Different fractions?</li>
<li>Should we completely swap some processes out of memory?</li>
</ul>
</li>
<li>Minimum number of pages per process<ul>
<li>Depends on the computer architecture</li>
<li>How many pages would one instruction use at one time<ul>
<li>x86 only allows data movement between memory and register and no indirect reference</li>
<li>needs at least one instruction page, one data page, and some page table pages</li>
</ul>
</li>
</ul>
</li>
<li>Maximum number of pages per process<ul>
<li>Depends on available physical memory</li>
</ul>
</li>
</ul>
<p><strong>Global vs. Local Allocation</strong></p>
<ul>
<li>Global replacement: One process can take a frame from another process</li>
<li>Local replacement: Each process selects from only its own set of allocated frames</li>
</ul>
<h3 id="Allocation-Algorithms"><a href="#Allocation-Algorithms" class="headerlink" title="Allocation Algorithms"></a>Allocation Algorithms</h3><ul>
<li>Equal allocation: <ul>
<li>Every process gets same amount of memory</li>
<li>Example: 100 frames, 5 processes $\to$ each process gets 20 frames</li>
</ul>
</li>
<li>Proportional allocation<ul>
<li>Number of page frames proportional to the size of process</li>
<li>$s_i =$ size of process $p_i$ and $m =$ total number of frame</li>
<li>$a_i =$ allocation for $p_i =m\times \frac{s_i}{\sum{s_j}}$</li>
</ul>
</li>
<li>Priority Allocation:<ul>
<li>Number of page frames proportional to the priority of process</li>
<li>Possible behavior: If process $p_i$ generates a page fault, select for replacement a frame from a process with lower priority number</li>
</ul>
</li>
</ul>
<blockquote>
<p>Thrashing</p>
<p>The memory demands of the set of running processes simply exceeds the available physical memory</p>
<p>Early OS: pages used actively of a process, and reduce # of process</p>
<p>Modern OS: Out-of-memory killer when memory is oversubscribed (need reboot)</p>
</blockquote>
<h1 id="Lec09-Linux-Memory-Management"><a href="#Lec09-Linux-Memory-Management" class="headerlink" title="Lec09. Linux Memory Management"></a>Lec09. Linux Memory Management</h1><h2 id="Outline-7"><a href="#Outline-7" class="headerlink" title="Outline"></a>Outline</h2><h2 id="Address-Space-in-Linux"><a href="#Address-Space-in-Linux" class="headerlink" title="Address Space in Linux"></a>Address Space in Linux</h2><p><img src="/2024/09/13/Operating-Systems/os901.png"></p>
<ul>
<li>Each page split into 3:1 (alike) portions, e.g., 3/4 for user mode and 1/4 for kernel space.</li>
</ul>
<blockquote>
<p>Q: Why is kernel memory mapped into the address space of each process?</p>
<ul>
<li>No need to change page table (i.e., switch CR3) when trapped into the kernel (no TLB flush)</li>
<li>Kernel code may access user memory when needed</li>
</ul>
</blockquote>
<p>Aware! —— The kernel memory in each address space is <font color="red">the same</font></p>
<p><img src="/2024/09/13/Operating-Systems/os902.png" style="zoom:70%"></p>
<ul>
<li>Linux adds supports to huge page (Linux term)<ul>
<li>Fewer TLB misses</li>
<li>Applications may need physically continuous physical memory</li>
<li>Leads to internal fragmentation</li>
</ul>
</li>
</ul>
<h2 id="Slab-Allocator"><a href="#Slab-Allocator" class="headerlink" title="Slab Allocator"></a>Slab Allocator</h2><p><img src="/2024/09/13/Operating-Systems/os908.png"></p>
<ul>
<li>When a slab is allocated to a cache, objects are initialized and marked as free</li>
<li>A slab can be in one of the following states:<ul>
<li>empty: all objects are free</li>
<li>partial: some objects are free</li>
<li>full: all objects are used</li>
</ul>
</li>
<li>A request is first served by a partial slab, then empty slab, then a new slab can be allocated from buddy system (buddy system 会介绍如何被分配到一个全新的 slab 中)</li>
<li>No memory is wasted due to <strong>fragmentation</strong><ul>
<li>when an object is requested, the slab allocator returns the exact amount of memory required to represent the object </li>
<li>Objects are packed tightly in the slab</li>
</ul>
</li>
<li>Memory requests can be satisfied <strong>quickly</strong><ul>
<li>Objects are created and initiated in advance </li>
<li>Freed object is marked as free and immediately available for subsequent requests </li>
</ul>
</li>
<li>Later Linux kernel also introduces <em>Slub allocator</em> and <em>Slob allocators</em>.</li>
</ul>
<h2 id="Buddy-System"><a href="#Buddy-System" class="headerlink" title="Buddy System"></a>Buddy System</h2><ul>
<li>Free physical memory is considered big space of size $2^N$ pages</li>
<li><strong>Allocation:</strong> the free space is divided by two until a block that is big enough to accommodate the request is found<ul>
<li>a further split would result in a space that is too small</li>
</ul>
</li>
<li><strong>Free:</strong> the freed block is recursively merged with its buddy<ul>
<li>Two <strong>buddy blocks</strong> have physical addresses that differ only in <strong>1 bit</strong></li>
<li>e.g. following example: page size = 4 KB</li>
</ul>
</li>
</ul>
<table>
<tr>
    <td><img src="/2024/09/13/Operating-Systems/os903.png"></td>
    <td><img src="/2024/09/13/Operating-Systems/os904.png"></td>
</tr>
<tr>
    <td><img src="/2024/09/13/Operating-Systems/os905.png"></td>
    <td><img src="/2024/09/13/Operating-Systems/os906.png"></td>
</tr>
<tr>
    <td><img src="/2024/09/13/Operating-Systems/os907.png"></td>
    <td>Note that two <b>buddy system</b> differ at bit i (where they separate, e.g., A and B at the lowest bit) on their <b>PFN</b></td>
</tr>
</table>



<h1 id="Lec10-I-O"><a href="#Lec10-I-O" class="headerlink" title="Lec10. I/O"></a>Lec10. I/O</h1><h2 id="Outline-8"><a href="#Outline-8" class="headerlink" title="Outline"></a>Outline</h2><ul>
<li>I/O Management &amp; View of Device</li>
<li>Basic I/O: Polling</li>
<li>Efficient I/O: Interrupts</li>
<li>Data Movement</li>
<li>Device Driver</li>
</ul>
<h2 id="I-O-Management-amp-View-of-Device"><a href="#I-O-Management-amp-View-of-Device" class="headerlink" title="I/O Management &amp; View of Device"></a>I/O Management &amp; View of Device</h2><ul>
<li>Challenges of I/O management<ul>
<li>Diverse devices: each device is slightly different<ul>
<li>How can we standardize the interfaces to these devices?</li>
</ul>
</li>
<li>Unreliable device: media failures and transmission errors<ul>
<li>How can we make them reliable?</li>
</ul>
</li>
<li>Unpredictable and slow devices<ul>
<li>How can we manage them if we do not know what they will do or how they will perform?</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="/2024/09/13/Operating-Systems/os1001.png" style="zoom:70%"></p>
<p><strong>A Canonical View of Devices</strong></p>
<ul>
<li>Interface<ul>
<li>The hardware interface a device present to the rest of the system</li>
<li><strong>Status registers</strong>: check the current status of the device</li>
<li><strong>Command register</strong>: tell the device to perform a certain task</li>
<li><strong>Data register</strong>: pass data to the device or get data from the device. </li>
</ul>
</li>
<li>Internal structures<ul>
<li>Implementation of the abstract of the device</li>
</ul>
</li>
</ul>
<p><img src="/2024/09/13/Operating-Systems/os1002.png" style="zoom:70%"></p>
<h2 id="Basic-I-O-Polling"><a href="#Basic-I-O-Polling" class="headerlink" title="Basic I/O: Polling"></a>Basic I/O: Polling</h2><ol>
<li>OS waits until the device is ready to receive a command by <strong>repeatedly reading</strong> the status register;</li>
<li>OS sends some data down to the data register;</li>
<li>OS writes a command to the command register;</li>
<li>OS waits for the device to finish by <strong>again polling</strong> it in a loop, waiting to see if it is finished.</li>
</ol>
<ul>
<li>Issues<ul>
<li>frequent checking the status of I/O devices</li>
<li>inefficient and inconvenient<ul>
<li>Polling wastes CPU time waiting for slow devices to complete its activity </li>
<li>If CPU switches to other tasks, data may be overwritten (CPU 内数据改变，导致写入设备的数据出错)</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="Efficient-I-O-Interrupts"><a href="#Efficient-I-O-Interrupts" class="headerlink" title="Efficient I/O: Interrupts"></a>Efficient I/O: Interrupts</h2><ul>
<li>Idea<ul>
<li>Put the calling process to sleep, and context switch to another task.</li>
<li>When the device is finally finished with the operation, it will <strong>raise a hardware interrupt</strong>, causing the CPU to jump into the OS at a <strong>predetermined interrupt handler</strong></li>
</ul>
</li>
</ul>
<p><img src="/2024/09/13/Operating-Systems/os1003.png"></p>
<ul>
<li>Comparison<ul>
<li>Polling works better for fast devices<ul>
<li>Data fetched with first poll</li>
</ul>
</li>
<li>Interrupt works better for slow devices<ul>
<li>Context switch is expensive</li>
</ul>
</li>
</ul>
</li>
<li>Hybird approach if speed of the device is not known or unstable<ul>
<li>Polls for a while</li>
<li>Then use interrupts</li>
</ul>
</li>
</ul>
<p><img src="/2024/09/13/Operating-Systems/os1004.png"></p>
<blockquote>
<p>Others related to <strong>Interrupt</strong>:</p>
<p>System call is made by executing a special instruction called software interrupts to trigger kernel to execute request</p>
<p>Multi-CPU systems can process interrupts concurrently</p>
</blockquote>
<h2 id="Data-Movement"><a href="#Data-Movement" class="headerlink" title="Data Movement"></a>Data Movement</h2><h3 id="Programmed-I-O"><a href="#Programmed-I-O" class="headerlink" title="Programmed I/O"></a>Programmed I/O</h3><ul>
<li>Explicit I/O instructions<ul>
<li>in/out instructions on x86: <code>out 0x21,AL</code></li>
<li>I/O instructions are privileged instructions</li>
</ul>
</li>
<li>Memory-mapped I/O<ul>
<li>Registers/memory appear in physical address space</li>
<li>I/O accomplished with load and store instructions</li>
<li>I/O protection with address translation</li>
</ul>
</li>
</ul>
<p><img src="/2024/09/13/Operating-Systems/os1005.png"></p>
<h3 id="DMA"><a href="#DMA" class="headerlink" title="DMA"></a>DMA</h3><p><strong>Def.</strong> Direct Memory Access</p>
<ul>
<li>DMA is used to avoid programmed I/O for large data movement <ul>
<li>Programmed I/O (PIO): when CPU is involved in data movement</li>
<li>PIO consumes CPU time</li>
<li>bypasses CPU to transfer data directly between I/O device and memory </li>
</ul>
</li>
<li>OS writes DMA command block into memory <ul>
<li>Source and destination addresses</li>
<li>Read or write mode</li>
<li>Count of bytes</li>
<li>Writes location to DMA controller</li>
<li>Bus mastering of DMA controller – grabs bus from CPU<ul>
<li><strong>Cycle stealing</strong> from CPU but still much more efficient</li>
</ul>
</li>
<li>When done, interrupts to signal completion</li>
</ul>
</li>
</ul>
<p><img src="/2024/09/13/Operating-Systems/os1006.png"></p>
<h2 id="Device-Driver"><a href="#Device-Driver" class="headerlink" title="Device Driver"></a>Device Driver</h2><p><strong>Def.</strong> Device-specific <font color="red">code in the kernel</font> that interacts directly with the device hardware, which support a standard, internal interface.</p>
<p>Special device-specific configuration supported with the <code>ioctl()</code> system call</p>
<ul>
<li>Two pieces of Device Driver:<ul>
<li><strong>Top half:</strong> accessed in call path from system calls <ul>
<li>implements a set of standard, cross-device calls like <code>open()</code>, <code>close()</code>, <code>read()</code>, <code>write()</code>, <code>ioctl()</code>, <code>strategy()</code>.</li>
<li>This is the kernel’s interface to the device driver</li>
<li>Top half will start I/O to device, may put thread to sleep until finished</li>
</ul>
</li>
<li><strong>Bottom half:</strong> run as interrupt routine<ul>
<li>Gets input or transfers next block of output</li>
<li>May wake sleeping threads if I/O now complete</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Life-Cycle-of-an-I-O-Request"><a href="#Life-Cycle-of-an-I-O-Request" class="headerlink" title="Life Cycle of an I/O Request"></a>Life Cycle of an I/O Request</h3><p><img src="/2024/09/13/Operating-Systems/os1007.png"></p>
<h3 id="Different-types-of-device"><a href="#Different-types-of-device" class="headerlink" title="Different types of device"></a>Different types of device</h3><table><tr>
    <td><img src="/2024/09/13/Operating-Systems/os1008.png"></td>
    <td><img src="/2024/09/13/Operating-Systems/os1009.png"></td>
</tr></table>




<h1 id="Lec11-Storage"><a href="#Lec11-Storage" class="headerlink" title="Lec11. Storage"></a>Lec11. Storage</h1><h2 id="Outline-9"><a href="#Outline-9" class="headerlink" title="Outline"></a>Outline</h2><ul>
<li>Storage Devices</li>
<li>Disk Scheduling</li>
</ul>
<h2 id="Storage-Devices"><a href="#Storage-Devices" class="headerlink" title="Storage Devices"></a>Storage Devices</h2><ul>
<li>Magnetic disks<ul>
<li>Storage that rarely becomes corrupted</li>
<li>Large capacity at low cost</li>
<li>Block level random access</li>
<li>Poor performance for random access</li>
<li>Better performance for <strong>sequential access</strong></li>
</ul>
</li>
<li>Flash memory<ul>
<li>Storage that rarely becomes corrupted</li>
<li>Capacity at intermediate cost (5-20x disk)</li>
<li>Block level random access</li>
<li>Good performance for <strong>reads</strong>; worse for random writes</li>
</ul>
</li>
</ul>
<h3 id="Concepts-for-Magnetic-Disk"><a href="#Concepts-for-Magnetic-Disk" class="headerlink" title="Concepts for Magnetic Disk"></a>Concepts for Magnetic Disk</h3><ul>
<li>Sector: Unit of Transfer<ul>
<li>Ring of sectors form a track</li>
<li>Stack of tracks form a cylinder (disk)</li>
<li>Heads (磁头) position on cylinders (to read data)</li>
</ul>
</li>
<li>Disk Tracks $\approx 1\mu m$ wide</li>
<li>Separated by unused guard regions<ul>
<li>avoid corrupted in writes</li>
</ul>
</li>
</ul>
<h3 id="Calculation-Time-of-read-write"><a href="#Calculation-Time-of-read-write" class="headerlink" title="Calculation: Time of read/write"></a>Calculation: Time of read/write</h3><p><strong>Three types of delay</strong></p>
<ul>
<li><strong>Seek time:</strong> position the head/arm over the proper track</li>
<li><strong>Rotational latency:</strong> wait for desired sector to rotate under r/w head</li>
<li><p><strong>Transfer time:</strong> transfer a block of bits (sector) under r/w head</p>
</li>
<li><p>Assumptions:</p>
<ul>
<li>Ignoring queuing and controller times for now</li>
<li>Avg seek time of 5ms, </li>
<li>7200RPM $\Rightarrow$ Time for rotation: 60000 (ms/minute) / 7200(rev/min) $\cong$ 8ms</li>
<li>Transfer rate 4MByte/s, sector size 1 Kbyte $\Rightarrow$ 1024 bytes / 4 $\times 10^{6}$(bytes/s) $=$256 $\times 10^{-6}$ sec $=$ 0.256 ms</li>
</ul>
</li>
<li>Read from random place of disk: use avg rot. latency:<ul>
<li>Seek (5ms) + Rot. Delay (4ms) + Transfer (0.26ms) $\approx 10ms$ for a sector</li>
</ul>
</li>
</ul>
<blockquote>
<p>Now Magnetic  Disks are gradually replaced by SSDs(Solid State Disks)</p>
</blockquote>
<h2 id="Disk-Scheduling"><a href="#Disk-Scheduling" class="headerlink" title="Disk Scheduling"></a>Disk Scheduling</h2><blockquote>
<p>OS should think how to use hardware efficiently?</p>
<p>Try to reduce <strong>seek time</strong> !</p>
<p>How to minimize the total head movement distance?</p>
<ul>
<li>Given a sequence of access cylinders in the HDD<ul>
<li>98, 183, 37, 122, 14, 124, 65, 67</li>
<li>Head point: 53</li>
<li>Pages: 0 ~ 199</li>
</ul>
</li>
</ul>
<p>See how different scheduling algorithms work.</p>
</blockquote>
<table>
<tr>
    <td><img src="/2024/09/13/Operating-Systems/os1101.png"><br>FIFO (First in First out)</td>
    <td><img src="/2024/09/13/Operating-Systems/os1102.png"><br>SSTF (Shortest Seek Time First)</td>
</tr>
<tr>
    <td><img src="/2024/09/13/Operating-Systems/os1103.png"><br>SCAN (elevator algo')</td>
    <td><img src="/2024/09/13/Operating-Systems/os1104.png"><br>C-SCAN</td>
</tr>
<tr>
    <td><img src="/2024/09/13/Operating-Systems/os1105.png"><br>LOOK, C-LOOK</td>
</tr>
</table>

<ul>
<li>Explanations<ul>
<li>In C-SCAN, when the head move to one end (e.g. 199), it immediately turn to another end (e.g. 0), and won’t cost the seek time (no 199 - 0)</li>
<li>The LOOK scheduling is improvement based on SCAN, and C-LOOK based on LOOK and C-SCAN. Both of the LOOK scheduling cost extra “look” time, but they have better performance (the head no need to go to the end)</li>
<li>C-LOOK only have one-direction service request, but it have best performance among these schedulings.</li>
</ul>
</li>
</ul>
<h1 id="Lec12-File-System"><a href="#Lec12-File-System" class="headerlink" title="Lec12. File System"></a>Lec12. File System</h1><h2 id="Outline-10"><a href="#Outline-10" class="headerlink" title="Outline"></a>Outline</h2><ul>
<li>File System Basic</li>
<li>Contiguous Allocation</li>
<li>Linked Allocation</li>
<li>iNode Allocation</li>
<li>Ext 2/3/4</li>
</ul>
<h2 id="File-System-Basic"><a href="#File-System-Basic" class="headerlink" title="File System Basic"></a>File System Basic</h2><p><strong>Def.</strong> Layer of OS that transforms block interface of disks (or other block devices) into Files, Directories, etc.</p>
<ul>
<li>File System Components<ul>
<li><strong>Naming</strong>: Interface to find files by name, not by blocks</li>
<li><strong>Disk Management</strong>: collecting disk blocks into files</li>
<li><strong>Protection</strong>: Layers to keep data secure</li>
<li><strong>Reliability/Durability</strong>: Keeping of files durable despite crashes, media failures, attacks, etc.</li>
</ul>
</li>
<li>Directory<ul>
<li><font color="red">A hierarchical structure</font>.</li>
<li>Each DIR’ entry is a collection of <ul>
<li>Files</li>
<li>Directories<ul>
<li>a link to another entry</li>
</ul>
</li>
</ul>
</li>
<li>Each has a name and attributes<ul>
<li>files have data</li>
</ul>
</li>
<li>Links (hard links, 类似快捷方式) make it a DAG (有向无环图), not just a tree<ul>
<li>Softlinks (类似副本) are another name for an entry</li>
</ul>
</li>
</ul>
</li>
<li>File<ul>
<li><font color="red">Named permanent storage</font>.</li>
<li>Contains<ul>
<li>Data</li>
<li>Metadata (Attributes)</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="Contiguous-Allocation"><a href="#Contiguous-Allocation" class="headerlink" title="Contiguous Allocation"></a>Contiguous Allocation</h2><blockquote>
<p>Easy to understand.</p>
</blockquote>
<p><img src="/2024/09/13/Operating-Systems/os1201.png"></p>
<ul>
<li>Good for locate file and delete file</li>
<li><font color="red">Bad for create</font>!<ul>
<li>External Fragmentation take response for it.</li>
<li>Defragmentation process may help, but it’s expensive (data movement on disk)!</li>
</ul>
</li>
</ul>
<table>
<tr>
    <td><img src="/2024/09/13/Operating-Systems/os1202.png"><br>Before</td>
</tr><tr>
    <td><img src="/2024/09/13/Operating-Systems/os1203.png"><br>After</td>
</tr>
</table>

<ul>
<li>Usage today<ul>
<li>ISO 9660 (光盘映射文件)</li>
<li>CV-ROM (no writing)</li>
</ul>
</li>
</ul>
<h2 id="Linked-Allocation"><a href="#Linked-Allocation" class="headerlink" title="Linked Allocation"></a>Linked Allocation</h2><p><strong>Step (1).</strong> Chop the storage device and data into <font color="red">equal sized blocks</font>.</p>
<p><strong>Step (2).</strong> Fill the empty space in a <font color="red">block-by-block manner</font>.</p>
<p><strong>Step (3).</strong> Leave 4 bytes from each block as “pointer” to next block of the same file. But still keep the file size in root directory table (facilitates <code>ls -l</code> etc. which lists file size)</p>
<p><img src="/2024/09/13/Operating-Systems/os1204.png"></p>
<h3 id="Comparison-to-contiguous-allocation"><a href="#Comparison-to-contiguous-allocation" class="headerlink" title="Comparison to contiguous allocation"></a>Comparison to contiguous allocation</h3><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center">Contiguous alloc</th>
<th style="text-align:center">Linekd alloc</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Fragmentation</td>
<td style="text-align:center">External Fragmentation</td>
<td style="text-align:center">Internal Fragmentation (not all files are multiple of block size)</td>
</tr>
<tr>
<td style="text-align:center">Random access</td>
<td style="text-align:center">good performance</td>
<td style="text-align:center">Bad performance(e.g. if I want 900th block, I have to go through previous 899.)</td>
</tr>
</tbody>
</table>
</div>
<h3 id="FAT"><a href="#FAT" class="headerlink" title="FAT"></a>FAT</h3><ul>
<li>Solution to the Poor performance of random access:<ul>
<li>File Allocation Table (<strong>FAT</strong>)</li>
<li>Turning the 4 bytes at the head of each block to a table besides Root Directory<ul>
<li>can only search for the table to get random access.</li>
</ul>
</li>
</ul>
</li>
<li>In DOS, a block is called a “cluster”.<ul>
<li>The cluster address length equals to the block address</li>
<li>Calculation: Given block size (e.g. 32 KB) and block address (e.g. 28 bits), we can know about the <strong>File System size</strong><ul>
<li>$fss=32\times 2^{10} \times 2^{28}=2^{43}\text{ Bytes}=8\text{ TB}$</li>
</ul>
</li>
</ul>
</li>
<li>What is more complex 👇</li>
</ul>
<p><img src="/2024/09/13/Operating-Systems/os1205.png"></p>
<h4 id="Header-of-file-name"><a href="#Header-of-file-name" class="headerlink" title="Header of file name"></a>Header of file name</h4><ul>
<li>Compare format difference from Normal DIR entry and LFN (Long File Name) entry</li>
</ul>
<p><img src="/2024/09/13/Operating-Systems/os1206.png"></p>
<blockquote>
<p>How does LFN really work when a long file name occur ? 👇</p>
</blockquote>
<p><img src="/2024/09/13/Operating-Systems/os1207.png" style="zoom:50%"></p>
<h4 id="About-FAT-reading-appending-and-deleting-files"><a href="#About-FAT-reading-appending-and-deleting-files" class="headerlink" title="About FAT reading, appending and deleting files"></a>About FAT reading, appending and deleting files</h4><p>I. Reading</p>
<table>
<tr>
    <td><img src="/2024/09/13/Operating-Systems/os1208.png"></td>
    <td><img src="/2024/09/13/Operating-Systems/os1209.png"></td>
</tr>
</table>

<p>II. Appending data</p>
<table>
<tr>
    <td><img src="/2024/09/13/Operating-Systems/os1210.png"></td>
    <td><img src="/2024/09/13/Operating-Systems/os1211.png"></td>
</tr>
<tr>
    <td><img src="/2024/09/13/Operating-Systems/os1212.png"></td>
    <td><img src="/2024/09/13/Operating-Systems/os1213.png"></td>
</tr>
</table>

<p>III. Deleting files</p>
<table>
<tr>
    <td><img src="/2024/09/13/Operating-Systems/os1214.png"></td>
    <td><img src="/2024/09/13/Operating-Systems/os1215.png"></td>
</tr>
</table>

<ul>
<li>Lazy delete<ul>
<li>“Deleted data” persists until the de-allocated clusters are reused.</li>
<li>Efficient but insecure (in multi-user system).</li>
</ul>
</li>
</ul>
<h2 id="iNode"><a href="#iNode" class="headerlink" title="iNode"></a>iNode</h2><ul>
<li>Original iNode format appeared in BSD 4.1<ul>
<li>Berkeley Standard Distribution Unix</li>
<li>Similar structure for Linux Ext2/3</li>
</ul>
</li>
<li>File Number is index of iNode arrays</li>
<li>Multi-level index structure<ul>
<li>Great for little and large files</li>
<li>Unbalanced tree with fixed sized blocks</li>
</ul>
</li>
<li>Metadata associated with the file<ul>
<li>Rather than in the directory that points to it</li>
</ul>
</li>
<li>Scalable directory structure</li>
</ul>
<blockquote>
<p>不同于 FAT 将所有文件指针放在一起，iNode 的单位是文件/文件夹。每个文件（夹）对应一个 iNode。（格式见下图）</p>
</blockquote>
<p><img src="/2024/09/13/Operating-Systems/os1217.png"></p>
<blockquote>
<p>而索引（存储）方式则是用一个 iNode array 进行存储</p>
<p>而指针采用非平衡树状数据结构（如下图）</p>
</blockquote>
<p><img src="/2024/09/13/Operating-Systems/os1216.png"></p>
<blockquote>
<p>Also see how to calculate File size based on given info.</p>
</blockquote>
<p><img src="/2024/09/13/Operating-Systems/os1218.png"></p>
<h2 id="Ext-2-3-4"><a href="#Ext-2-3-4" class="headerlink" title="Ext 2 / 3 / 4"></a>Ext 2 / 3 / 4</h2><blockquote>
<p>The latest default FS for Linux distribution is the Fourth <font color="blue">Extended File System</font>, Ext4 for short.</p>
</blockquote>
<h3 id="Ext-2-3"><a href="#Ext-2-3" class="headerlink" title="Ext 2/3"></a>Ext 2/3</h3><ul>
<li>For Ext 2/3:<ul>
<li>Block size: 1024, 2048, 4096 bytes</li>
<li>Block address size: 4 bytes $\Rightarrow$ # of block addresses $=2^{32}$</li>
</ul>
</li>
<li>So their File System Size = 4 TB, 8 TB and 16 TB</li>
<li><strong>Structure</strong><ul>
<li>divided into <strong>block groups</strong> (each block group like this 👇)</li>
</ul>
</li>
</ul>
<p><img src="/2024/09/13/Operating-Systems/os1219.png"></p>
<ul>
<li>Block Bitmap tells which data block is allocated</li>
<li>iNode Bitmap tells if an iNode is allocated</li>
</ul>
<table>
<tr>
    <td><img src="/2024/09/13/Operating-Systems/os1220.png"></td>
    <td><img src="/2024/09/13/Operating-Systems/os1221.png"></td>
</tr>
</table>

<blockquote>
<p>File deletion is just an update of the “entry length” of the previous entry.</p>
</blockquote>
<h3 id="Hard-amp-Soft-link"><a href="#Hard-amp-Soft-link" class="headerlink" title="Hard &amp; Soft link"></a>Hard &amp; Soft link</h3><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">Properties</th>
<th style="text-align:center">Hard Link</th>
<th style="text-align:center">Symbolic Link</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Creation</td>
<td style="text-align:center">Link to the same iNode (may have different file name)</td>
<td style="text-align:center">create a new iNode</td>
</tr>
<tr>
<td style="text-align:center">when link is deleted</td>
<td style="text-align:center">Reference counter decrease(target delete at 0)</td>
<td style="text-align:center">Target unchanged</td>
</tr>
<tr>
<td style="text-align:center">when target is moved</td>
<td style="text-align:center">remain valid</td>
<td style="text-align:center">link invalid</td>
</tr>
<tr>
<td style="text-align:center">Relative path</td>
<td style="text-align:center">N/A</td>
<td style="text-align:center">less than 60 characters(12 direct block and 3 indirect) is allowed</td>
</tr>
<tr>
<td style="text-align:center">Crossing filesystem boundaries</td>
<td style="text-align:center">Not supported(target must be on same filesystem)</td>
<td style="text-align:center">Supported</td>
</tr>
</tbody>
</table>
</div>
<h1 id="Lec13-Deadlock"><a href="#Lec13-Deadlock" class="headerlink" title="Lec13. Deadlock"></a>Lec13. Deadlock</h1><h2 id="Outline-11"><a href="#Outline-11" class="headerlink" title="Outline"></a>Outline</h2><h2 id="Deadlock-Basic"><a href="#Deadlock-Basic" class="headerlink" title="Deadlock Basic"></a>Deadlock Basic</h2><p><img src="/2024/09/13/Operating-Systems/os1301.png"></p>
<ul>
<li>4 Requirements for Deadlock<ul>
<li>Mutual exclusion<ul>
<li>Only one thread at a time can use a resource.</li>
</ul>
</li>
<li>Hold and wait<ul>
<li>Thread holding at least one resource is waiting to acquire additional resources held by other threads</li>
</ul>
</li>
<li>No preemption<ul>
<li>Resources are released only voluntarily by the thread holding the resource, after thread is finished with it</li>
</ul>
</li>
<li>Circular wait<ul>
<li>There exists a set $\{T_1, …, T_n \}$ of waiting threads</li>
<li>$T_1$ is waiting for a resource that is held by $T_2$</li>
<li>$T_2$ is waiting for a resource that is held by $T_3$</li>
<li>…</li>
<li>$T_n$ is waiting for a resource that is held by $T_1$</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="Two-ways-to-handle-deadlock"><a href="#Two-ways-to-handle-deadlock" class="headerlink" title="Two ways to handle deadlock"></a>Two ways to handle deadlock</h2><blockquote>
<p>Of course you can directly ignore it (like UNIX), but we are going to talk about 2 methods which truly handle it.</p>
</blockquote>
<h3 id="Deadlock-detection-with-Resource-Allocation-Graphs"><a href="#Deadlock-detection-with-Resource-Allocation-Graphs" class="headerlink" title="Deadlock detection with Resource Allocation Graphs"></a>Deadlock detection with Resource Allocation Graphs</h3><ol>
<li>If there is only one type of resource, go searching for cycle.</li>
<li>If there are multiple types of resource, we have to firstly represent the resource:<ul>
<li><strong>Available</strong>: A vector of length $m$ indicates the number of available resources of each type.</li>
<li><strong>Allocation</strong>: An $n \times m$ matrix defines the number of resources of each type currently allocated to each process.</li>
<li><strong>Request</strong>: An $n \times m$ matrix indicates the current request  of each process.  If Request $[i_j] = k$, then process $P_i$ is requesting $k$ more instances of resource type $R_j$. (Request-based)</li>
</ul>
</li>
</ol>
<blockquote>
<p>Suppose m and n are number of resources and processes</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/* Step 1 */</span><br><span class="line">init Work[m], Finish[n]</span><br><span class="line">init Work &lt;- Available</span><br><span class="line">for 1..n:</span><br><span class="line">  if Alloc[i] != 0: Finish[i] = false</span><br><span class="line">  else Finish[i] = true</span><br><span class="line"></span><br><span class="line">/* Step 2 */</span><br><span class="line">find i where</span><br><span class="line">  Finish[i] == false and Request[i] &lt;= Work[i]</span><br><span class="line">  jump Step 4</span><br><span class="line">else: jump Step 3</span><br><span class="line"></span><br><span class="line">/* Step 3 */</span><br><span class="line">Work = Work + Allocation[i]</span><br><span class="line">Finish[i] = true</span><br><span class="line">jump Step 2</span><br><span class="line"></span><br><span class="line">/* Step 4 */</span><br><span class="line">if Finish[i] == false:</span><br><span class="line">  P[i] is in deadlock /* process i&#x27;s deadlock detected */</span><br></pre></td></tr></table></figure>
<table>
<tr>
    <td><img src="/2024/09/13/Operating-Systems/os1302.png"></td>
    <td><img src="/2024/09/13/Operating-Systems/os1303.png"></td>
</tr>
</table>

<blockquote>
<p>Explanation: 经过进程 0，0 完成并释放一个资源 B，然而其他进程都无法得到相应资源，进入死锁</p>
</blockquote>
<p><strong>What if Deadlock Detected?</strong></p>
<ul>
<li>Terminate process, force it to give up resources<ul>
<li>Shoot a dining philosopher !?</li>
<li>But, not always possible</li>
</ul>
</li>
<li>Preempt resources without killing off process <ul>
<li>Take away resources from process temporarily</li>
<li>Does not always fit with semantics of computation</li>
</ul>
</li>
<li>Roll back actions of deadlocked process <ul>
<li>Common technique in databases (transactions)</li>
<li>Of course, deadlock may happen once again</li>
</ul>
</li>
</ul>
<h3 id="Deadlock-Prevention"><a href="#Deadlock-Prevention" class="headerlink" title="Deadlock Prevention"></a>Deadlock Prevention</h3><blockquote>
<p>Try to ensure at least one of the requirements of deadlock cannot hold</p>
</blockquote>
<ul>
<li>Remove “Mutual Exclusion” ? impossible for non-sharable resource.</li>
<li>Remove “Hold and Wait” ? low resource utilization or starvation</li>
<li>Remove “Preemption” ?<ul>
<li>If a process that is holding some resources requests another resource that cannot be immediately allocated to it, then all resources currently being held are released 👉 may cause starvation</li>
<li>Process will be restarted only when it can regain its old resources, as well as the new ones that it is requesting</li>
</ul>
</li>
<li>Remove “Circular Wait”<ul>
<li>impose a total ordering of all resource types, and require that each process requests resources in an increasing order of enumeration: $R= \{ R_1, R_2, \cdots , R_m \}$</li>
<li>One to one function $F:R\to N$</li>
<li>If a process request a resource $R_i$, it can request another resource $R_j$ if and only if $F(R_i) \lt F(R_j)$</li>
<li>Or, it must first release all resource $R_i$ such that $F(R_i) \ge F(R_j)$ </li>
</ul>
</li>
</ul>
<p><strong>Some concept go first</strong></p>
<ul>
<li>Deadlock Avoidance<ul>
<li>The deadlock-avoidance algorithm dynamically examines the resource-allocation state to ensure that there can never be a <strong>circular-wait condition</strong></li>
<li>Resource-allocation state is defined by the number of available and allocated resources, and the maximum demands of the processes</li>
</ul>
</li>
<li>Safe State<ul>
<li>System is in safe state if there exists a sequence $<P_1, p_2, \cdots , p_n>$ of <strong>ALL</strong> the processes in the systems such that for each $P_i$, the resources that $P_i$ can still request can be satisfied by currently available resources + resources held by all the $P_j$, with $j &lt; i$</P_1,></li>
</ul>
</li>
</ul>
<p><img src="/2024/09/13/Operating-Systems/os1304.png"></p>
<h4 id="Bankerʼs-Algorithm"><a href="#Bankerʼs-Algorithm" class="headerlink" title="Bankerʼs Algorithm"></a>Bankerʼs Algorithm</h4><p><strong>Idea</strong></p>
<ul>
<li>Multiple instances of each resource type</li>
<li>Each process must a priori claim maximum use</li>
<li>When a process requests a resource it may have to wait </li>
<li>When a process gets all its resources it must return them in a finite amount of time</li>
</ul>
<p><strong>Setting</strong></p>
<ul>
<li><strong>Available</strong>: Vector of length m.</li>
<li><strong>Max</strong>: $n \times m$ matrix. (<code>Max[i, j] = k</code> represent process i can request at most k instances of resource j)</li>
<li><strong>Allocation</strong>: $n \times m$ matrix.</li>
<li><strong>Need</strong>: $n \times m$ matrix.<ul>
<li><code>Need[i,j] = Max[i,j] - Alloc[i,j]</code></li>
</ul>
</li>
</ul>
<p><strong>Pseudo code</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/* Check safe function */</span><br><span class="line">/* 1 */</span><br><span class="line">Init Work = Available, Finish[i] = false for 0..(n-1)</span><br><span class="line">/* 2 */</span><br><span class="line">find i where (Finish[i] is false) and (Need[i][k] &lt;= Work[k] for all k)</span><br><span class="line">if no such i, goto 4</span><br><span class="line">/* 3 */</span><br><span class="line">Work = Work + Alloc[i]</span><br><span class="line">Finish[i] = true</span><br><span class="line">/* 4 */</span><br><span class="line">If Finish[i] == true for all i, then system is in safe state</span><br></pre></td></tr></table></figure>
<p><strong>Resource-Request Algorithm</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/* Request Resource of Process[i] */</span><br><span class="line">/* 1 */</span><br><span class="line">if Request[j] &lt;= Need[j] for all j then goto 2</span><br><span class="line">else raise exception /* process has exceeded its maximum claim */</span><br><span class="line">/* 2 */</span><br><span class="line">if Request[j] &lt;= Avail[j] for all j then goto 3</span><br><span class="line">else wait() /* Process i cannot get enough resource */</span><br><span class="line">/* 3 */</span><br><span class="line">&#123; /* state update */</span><br><span class="line">  Avail = Avail - Request</span><br><span class="line">  Alloc[i] = Alloc[i] + Request</span><br><span class="line">  Need = Need - Request</span><br><span class="line">  if checksafe():  /* define above */</span><br><span class="line">    update()       /* truly alloc  */</span><br><span class="line">  else:</span><br><span class="line">    rollback()     /* undo update  */</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="Lec14-Security-and-Protection"><a href="#Lec14-Security-and-Protection" class="headerlink" title="Lec14. Security and Protection"></a>Lec14. Security and Protection</h1><h2 id="Outline-12"><a href="#Outline-12" class="headerlink" title="Outline"></a>Outline</h2><ul>
<li>Access Matrix</li>
<li>Security</li>
<li>Cryptography</li>
</ul>
<h2 id="Access-Matrix"><a href="#Access-Matrix" class="headerlink" title="Access Matrix"></a>Access Matrix</h2><h3 id="Principles-of-Protection"><a href="#Principles-of-Protection" class="headerlink" title="Principles of Protection"></a>Principles of Protection</h3><ul>
<li>Programs, users and systems should be given <strong>just enough</strong> privileges to perform their tasks</li>
<li>Limits damage if entity has a bug, gets abused</li>
<li>Can be static (during life of system, during life of process)</li>
<li>Or dynamic (changed by process as needed)</li>
</ul>
<h3 id="Access-Matrix-1"><a href="#Access-Matrix-1" class="headerlink" title="Access Matrix"></a>Access Matrix</h3><ul>
<li>View protection as a matrix (access matrix)</li>
<li>Rows represent domains (e.g. users or processes)</li>
<li>Columns represent objects</li>
<li><code>Access(i, j)</code> is the set of operations that a process executing in Domain i can invoke on Object j (as the following pic shown)</li>
</ul>
<p><img src="/2024/09/13/Operating-Systems/os1305.png"></p>
<ul>
<li><strong>Access matrix</strong> design separates mechanism from policy<ul>
<li>Mechanism <ul>
<li>Operating system provides access-matrix + rules</li>
<li>It ensures that the matrix is only manipulated by authorized agents and that rules are strictly enforced</li>
</ul>
</li>
<li>Policy<ul>
<li>User dictates policy</li>
<li>Who can access what object and in what mode</li>
<li><font color="red">User who creates object can define access column for that object</font>.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Implementation-of-Access-Matrix"><a href="#Implementation-of-Access-Matrix" class="headerlink" title="Implementation of Access Matrix"></a>Implementation of Access Matrix</h3><p>Option 1 —— Global table</p>
<ul>
<li>Store ordered triples <code>&lt;domain, object, rights-set&gt;</code> in table</li>
<li>Problems<ul>
<li>too large to fit in main memory</li>
<li>difficult to group objects (consider an object that all domains can read)</li>
</ul>
</li>
</ul>
<p>Option 2 —— Access-control lists for objects</p>
<ul>
<li>per-object list consists of ordered pairs <code>&lt;domain, rights-set&gt;</code> defining all domains with non-empty set of access rights for the object</li>
</ul>
<p>Option 3 —— Capability list for domains</p>
<ul>
<li>Domain based lists</li>
<li><font color="blue">Capability list</font> for domain is list of objects together with operations allows on them</li>
<li>Object represented by its name or address, called a <font color="blue">capability</font>.</li>
</ul>
<p><strong>Last Solution: Combine Access-control lists and Capability lists.</strong></p>
<h2 id="Security"><a href="#Security" class="headerlink" title="Security"></a>Security</h2><ul>
<li>Concept<ul>
<li>Threat is potential security violation<ul>
<li>Breach of confidentiality: Unauthorized reading of data</li>
<li>Breach of integrity: Unauthorized modification of data</li>
<li>Breach of availability: Unauthorized destruction of data</li>
<li>Theft of service: Unauthorized use of resources</li>
<li>Denial of service (DoS): Prevention of legitimate use</li>
</ul>
</li>
<li>Attack is attempt to breach security</li>
</ul>
</li>
<li>Security must occur at four levels to be effective:<ul>
<li>Physical<ul>
<li>Data centers, servers, connected terminals</li>
</ul>
</li>
<li>Human<ul>
<li>Avoid social engineering, phishing, dumpster diving</li>
</ul>
</li>
<li>Operating System<ul>
<li>Protection mechanisms, debugging</li>
</ul>
</li>
<li>Network<ul>
<li>Intercepted communications, interruption, DoS</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Implementation-of-Security-Defenses"><a href="#Implementation-of-Security-Defenses" class="headerlink" title="Implementation of Security Defenses"></a>Implementation of Security Defenses</h3><ul>
<li>Intrusion detection endeavors to detect attempted or successful intrusions<ul>
<li>Signature-based detection spots known bad patterns</li>
<li>Anomaly detection spots differences from normal behavior</li>
<li>Can detect zero-day attacks</li>
<li>False-positives and false-negatives a problem</li>
</ul>
</li>
<li>Virus protection<ul>
<li>Searching all programs or programs at execution for known virus patterns</li>
<li>Or run in sandbox so can’t damage system</li>
</ul>
</li>
</ul>
<h3 id="Firewalling-to-Protect-Systems-and-Networks"><a href="#Firewalling-to-Protect-Systems-and-Networks" class="headerlink" title="Firewalling to Protect Systems and Networks"></a>Firewalling to Protect Systems and Networks</h3><ul>
<li>A network firewall is placed between trusted and untrusted hosts<ul>
<li>The firewall limits network access between these two security domains</li>
</ul>
</li>
<li>Can be tunneled or spoofed<ul>
<li>Tunneling allows disallowed protocol to travel within allowed protocol (i.e., telnet inside of HTTP)</li>
<li>Firewall rules typically based on host name or IP address which can be spoofed</li>
</ul>
</li>
<li>Personal firewall is software layer on given host<ul>
<li>Can monitor / limit traffic to and from the host</li>
</ul>
</li>
<li>Application proxy firewall understands application protocol and can control them (i.e., SMTP)</li>
<li>System-call firewall monitors all important system calls and apply rules to them (i.e., this program can execute that system call)</li>
</ul>
<p>…</p>
<h2 id="Cryptography"><a href="#Cryptography" class="headerlink" title="Cryptography"></a>Cryptography</h2><h3 id="Encryption"><a href="#Encryption" class="headerlink" title="Encryption"></a>Encryption</h3><ul>
<li>Set $K$ as keys</li>
<li>Set $M$ as messages</li>
<li>Set $C$ as ciphertexts</li>
<li>A function $E:K\to (M\to C)$, where for $k\in K$, $E_k$ is function for generating ciphertexts from messages</li>
<li>A function $D:K\to (C\to M)$, where for $k\in K$, $D_k$ is function for generating ciphertexts from messages</li>
</ul>
<blockquote>
<p>Users who get the <strong>keys</strong> are able to decrypte the ciphertext</p>
</blockquote>
<ul>
<li>Symmetric Encryption vs. Asymmetric Encryption</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">Symmetric</th>
<th style="text-align:center">Asymmetric</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Same key for encrypt and decrypt</td>
<td style="text-align:center">public key for encrypt but private key for decrypt</td>
</tr>
<tr>
<td style="text-align:center">Block cipher / Stream cipher</td>
<td style="text-align:center">Using an reliable encryption scheme</td>
</tr>
<tr>
<td style="text-align:center">DES, Advanced Encryption Standard (AES), RC4(Stream)</td>
<td style="text-align:center">RSA</td>
</tr>
</tbody>
</table>
</div>
<h3 id="Authentication"><a href="#Authentication" class="headerlink" title="Authentication"></a>Authentication</h3><blockquote>
<p>Algorithm alike encrypt, but no decrypt 👉 function $K \to (M\times A\to \{ true,false \})$ to verify auth</p>
</blockquote>
<ul>
<li>Usage<ul>
<li>Message-authentication code (MAC) authentication algorithm<ul>
<li>symm based</li>
</ul>
</li>
<li>Digital signatures authentication algorithm<ul>
<li>asym based</li>
<li><strong>anyone</strong> can verify authenticity of a message using the public key</li>
</ul>
</li>
</ul>
</li>
<li>Key Distribution<ul>
<li>Delivery of symmetric key is huge challenge<ul>
<li>Sometimes done out-of-band (?)</li>
</ul>
</li>
<li>Asymmetric keys distribution – public key<ul>
<li>Even asymmetric key distribution needs care – man-in-the-middle attack</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Certification-in-Network"><a href="#Certification-in-Network" class="headerlink" title="Certification in Network"></a>Certification in Network</h3><ul>
<li>Used between web servers and browsers for secure communication (credit card numbers)</li>
<li>The server is verified with a <strong>certificate</strong> assuring client is talking to correct server</li>
<li>Asymmetric cryptography used to establish a secure <strong>session key</strong> (symmetric encryption) for bulk of communication during session</li>
<li>Communication between each computer then uses symmetric key cryptography</li>
</ul>
<h1 id="Lec15-Virtualization"><a href="#Lec15-Virtualization" class="headerlink" title="Lec15. Virtualization"></a>Lec15. Virtualization</h1><h2 id="Outline-13"><a href="#Outline-13" class="headerlink" title="Outline"></a>Outline</h2><h2 id="About-Virtualization"><a href="#About-Virtualization" class="headerlink" title="About Virtualization"></a>About Virtualization</h2><ul>
<li>Virtualization leverages a software component (i.e., the hypervisor) and some hardware support to create an abstraction layer over computer hardware </li>
<li>It enables the hardware resources of a single computer (processors, memory, storage) to be multiplexed by multiple virtual machines (VMs). </li>
<li>VMs run their own operating systems (OS) and operate as if they are independent computers, though they are using only a portion of the underlying computer hardware. </li>
</ul>
<p><strong>Types of Virtualization</strong></p>
<ul>
<li>Type-I hypervisor: run directly on the host’s physical hardware</li>
<li>Type-II hypervisor: installed on existing OSs, and rely on them for virtualization and resource managemen</li>
</ul>
<p>…</p>
]]></content>
      <categories>
        <category>2024 Fall</category>
      </categories>
      <tags>
        <tag>CSE Learning</tag>
        <tag>Rust</tag>
      </tags>
  </entry>
  <entry>
    <title>CS303 人工智能</title>
    <url>/2025/01/01/Artificial-Intelligence/</url>
    <content><![CDATA[<h1 id="Contents"><a href="#Contents" class="headerlink" title="Contents"></a>Contents</h1><p><strong>AI Search</strong></p>
<ul>
<li>Lecture 1. AI as Search</li>
<li>Lecture 2. Beyond Classical Search</li>
<li>Lecture 3. Problem-Specific Search</li>
</ul>
<p><strong>Machine Learning</strong></p>
<ul>
<li>Lecture 4. Principles of Machine Learning</li>
<li>Lecture 5. Supervised Learning</li>
<li>Lecture 6. Performance Evaluation for Machine Learning</li>
<li>Lecture 7. Unsupervised Learning</li>
<li>Lecture 8. Recommender System</li>
<li>Lecture 9. Automated Machine Learning</li>
</ul>
<p><strong>Knowledge and Reasoning</strong></p>
<ul>
<li>Lecture 10. Logical Agents</li>
<li>Lecture 11. First Order Logic</li>
<li>Lecture 12. Representing and Inference with Uncertainty</li>
<li>Lecture 13. Knowledge Graph</li>
</ul>
<h1 id="Lecture-1-AI-as-Search"><a href="#Lecture-1-AI-as-Search" class="headerlink" title="Lecture 1. AI as Search"></a>Lecture 1. AI as Search</h1><h2 id="Outline"><a href="#Outline" class="headerlink" title="Outline"></a>Outline</h2><ul>
<li>From searching to search tree</li>
<li>Uninformed Search Methods </li>
<li><font color="red">Heuristic (informed) Search</font> 



</li>
</ul>
<h2 id="Search-in-a-Tree"><a href="#Search-in-a-Tree" class="headerlink" title="Search in a Tree ?"></a>Search in a Tree ?</h2><blockquote>
<p><strong>概念：最短路径选择，搜索树</strong></p>
<p>通过将所有“图”中的路径展开，可以得到一个搜索树。对树进行全局搜索必然可以得到最短路径。</p>
<p>但是，当图变得复杂时（如一个省的地图，or a state），搜索量极大，全局搜索及其低能。</p>
</blockquote>
<ul>
<li><font color="red">Q:</font> What is A Good Search Method?<ul>
<li><font color="green">Completeness</font>: Does it always find a solution if it exists?</li>
<li><font color="green">Optimality</font>: Does it always find the least-cost solution?</li>
<li><font color="green">Time complexity</font>: # nodes generated/expanded.</li>
<li><font color="green">Space complexity</font>: maximum # nodes in memory.</li>
</ul>
</li>
<li>In general, time and space complexity depend on:<ul>
<li>$b$ 👉 maximum # successors of any node in search tree. [枝]</li>
<li>$d$ 👉 depth of the least-cost solution. </li>
<li>$m$ 👉 maximum length of any path in the state space.</li>
</ul>
</li>
</ul>
<h2 id="Un-informed-Search-Methods"><a href="#Un-informed-Search-Methods" class="headerlink" title="Un-informed Search Methods"></a>Un-informed Search Methods</h2><blockquote>
<p>How to define “un-informed” ?</p>
</blockquote>
<ul>
<li>Use only the information available in the problem definition.</li>
<li>Use <strong>NO</strong> problem-specific knowledge.</li>
</ul>
<blockquote>
<p>As some algorithms have been learnt in course Algorithm Design and Analysis, we skip them.</p>
</blockquote>
<h3 id="BFS"><a href="#BFS" class="headerlink" title="BFS"></a>BFS</h3><ul>
<li><font color="DodgerBlue">Completeness?</font> Yes (Suppose $b$ is finite)</li>
<li><font color="DodgerBlue">Optimality?</font> Yes (Suppose all edge values are <strong>non-negative</strong>)</li>
<li><font color="DodgerBlue">Time &amp; Space?</font> Both $O(b^{d+1})$</li>
</ul>
<h3 id="UCS-Uniform-Cost-Search"><a href="#UCS-Uniform-Cost-Search" class="headerlink" title="UCS (Uniform-Cost Search)"></a>UCS (Uniform-Cost Search)</h3><ul>
<li>Idea<ul>
<li>Expand the cheapest unexpanded node.</li>
<li>Implementation: a queue ordered by path cost, lowest first.</li>
</ul>
</li>
</ul>
<p><img src="/2025/01/01/Artificial-Intelligence/ai101.png" style="zoom:60%"></p>
<ul>
<li><font color="DodgerBlue">Completeness?</font> Yes (Suppose every step costs $\ge \epsilon$)</li>
<li><font color="DodgerBlue">Optimality?</font> Yes (Suppose all edge values are <strong>non-negative</strong>)</li>
<li><font color="DodgerBlue">Time &amp; Space?</font>  $O(b^{1+\lfloor C^{*}/\epsilon\rfloor})$<ul>
<li>$C^{*}$ : the cost of the optimal solution.</li>
<li>every action costs at least $\epsilon$.</li>
<li>Only if all step costs are equal, time/space $=O(b^{d+1})$</li>
</ul>
</li>
</ul>
<h3 id="DFS"><a href="#DFS" class="headerlink" title="DFS"></a>DFS</h3><ul>
<li><font color="DodgerBlue">Completeness?</font> No (fail in infinite-depth space and space with loops.)</li>
<li><font color="DodgerBlue">Optimality?</font> No</li>
<li><font color="DodgerBlue">Time?</font> $O(b^m)$<ul>
<li>Terrible if $m$ is much larger than $d$.</li>
</ul>
</li>
<li><font color="DodgerBlue">Space?</font> $O(bm)$ - linear!</li>
</ul>
<h3 id="DLS-Depth-Limit-Search"><a href="#DLS-Depth-Limit-Search" class="headerlink" title="DLS (Depth-Limit Search)"></a>DLS (Depth-Limit Search)</h3><ul>
<li>A variant of DFS: node at depth $l$ has no sucessors.</li>
<li><font color="DodgerBlue">Completeness?</font> No</li>
<li><font color="DodgerBlue">Optimality?</font> No</li>
<li><font color="DodgerBlue">Time?</font> $O(b^l)$</li>
<li><font color="DodgerBlue">Space?</font> $O(bl)$</li>
</ul>
<h3 id="IDS-Iterative-Deepening-Search"><a href="#IDS-Iterative-Deepening-Search" class="headerlink" title="IDS (Iterative Deepening Search)"></a>IDS (Iterative Deepening Search)</h3><ul>
<li>Idea<ul>
<li>Apply <strong>DLS</strong> with increasing limits</li>
<li>Combine benefit of <strong>BFS</strong> and <strong>DFS</strong></li>
</ul>
</li>
<li><font color="DodgerBlue">Completeness?</font> Yes</li>
<li><font color="DodgerBlue">Optimality?</font> Yes (Suppose costs of edges are non-negative)</li>
<li><font color="DodgerBlue">Time?</font> $O(b^d)$<ul>
<li>$(d+1)b^{0}+ db^{1}+(d-1)b^{2}+\cdots +b^d=O(b^{d})$</li>
</ul>
</li>
<li><font color="DodgerBlue">Space?</font> $O(bd)$</li>
</ul>
<blockquote>
<p>Preference when <strong>search space</strong> is large and <strong>depth</strong> of solution is unknown.</p>
</blockquote>
<h3 id="Bi-directional-Search"><a href="#Bi-directional-Search" class="headerlink" title="Bi-directional Search"></a>Bi-directional Search</h3><ul>
<li>Idea: simultaneous<ul>
<li>Replace single search tree with two smaller sub trees.</li>
<li>Forward tree: forward search from source to goal.</li>
<li>Backward tree: backward search from goal to source.</li>
</ul>
</li>
<li><font color="DodgerBlue">Completeness &amp; Optimality?</font> Like BFS (if BFS used in both trees)</li>
<li><font color="DodgerBlue">Time &amp; Space?</font> $O(b^{d/2})$</li>
<li>Cons: not always applicable<ul>
<li>Reversible actions? [是否可以“由果溯因”？]</li>
<li>Explicitly stated goal state? [叶子节点代表“结局”，所有结局是否已知？]</li>
</ul>
</li>
</ul>
<h2 id="Heuristic-informed-Search"><a href="#Heuristic-informed-Search" class="headerlink" title="Heuristic (informed) Search"></a><font color="red">Heuristic (informed) Search</font></h2><blockquote>
<p><font color="red">Q:</font> What is “Heuristic” ?</p>
<p><font color="green">A:</font> Based on algorithm design, it searches the trees with intelligence, making use of <strong>domain knowledge</strong>.</p>
<p><font color="red">Q:</font> How to Design the Evaluation Function?</p>
<p><font color="green">A:</font> It depends (but some advice). Use heuristic function $f(x)$ to estimates the cheapest cost from $x$ to the goal state.</p>
<ol>
<li>$h(x)=0$ if $x$ is the goal state</li>
<li>non-negative</li>
<li><strong>problem-specific</strong></li>
</ol>
</blockquote>
<h3 id="Greedy-Best-first-Search"><a href="#Greedy-Best-first-Search" class="headerlink" title="Greedy Best-first Search"></a>Greedy Best-first Search</h3><ul>
<li>A simple example to describe heuristic function: let’s say $f(x)=h_{SLD}(x)$ , where $h_{SLD}(x)$ is physical distance between two nodes (cities)</li>
</ul>
<p><img src="/2025/01/01/Artificial-Intelligence/ai102.png" style="zoom:60%"></p>
<ul>
<li><font color="DodgerBlue">Completeness?</font> Yes (finite space + repeated-state checking)</li>
<li><font color="DodgerBlue">Optimality?</font> No</li>
<li><font color="DodgerBlue">Time?</font> $O(b^m)$ (In practice, good heuristic gives drastic improvement)</li>
<li><font color="DodgerBlue">Space?</font> $O(b^m)$</li>
</ul>
<h3 id="A-Search"><a href="#A-Search" class="headerlink" title="A* Search"></a>A* Search</h3><ul>
<li>Idea: avoid expanding paths that are already expensive.<ul>
<li>Expand the node $x$ that has minimal $f(x)=h(x)+g(x)$<ul>
<li>$g(x)$ : cost so far to reach $x$</li>
<li>$h(x)$ : estimated cost from $x$ to goal</li>
<li>$f(x)$ : total cost</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>PF(performance) Metrics</strong></p>
<ul>
<li><font color="DodgerBlue">Completeness?</font> Yes</li>
<li><font color="DodgerBlue">Optimality?</font> Yes, if $h$ is <strong>admissible</strong> [取决于启发式算法]</li>
<li><font color="DodgerBlue">Time?</font> $O(b^d)$</li>
<li><font color="DodgerBlue">Space?</font> $O(b^d)$</li>
</ul>
<p><strong>Admissible heuristic</strong></p>
<ul>
<li><strong>Def.</strong> Heuristic function $h$ is admissible if $\forall x \to h(x)\ge h’(x)$, where $h’(x)$ is the <strong>true</strong> cost from $x$ to goal.</li>
<li>Search Efficiency of Admissible Heuristic<ul>
<li>For admissible $h_1$ and $h_2$, if $h_2(x)\ge h_1(x)$ for all $n$, then $h_2$ <strong>deminates</strong> $h_1$ and is more efficient for search.</li>
</ul>
</li>
</ul>
<blockquote>
<p>A* 算法可以认为是学习 AI 的第一基础算法。它明确了 AI 需要具有的首要特性：学习。A* 算法是树/图搜索算法中第一个可以利用“知识”进行决策的算法，不再是像遍历这样“机械、随机”的算法。</p>
</blockquote>
<h1 id="Lecture-2-Beyond-Classical-Search"><a href="#Lecture-2-Beyond-Classical-Search" class="headerlink" title="Lecture 2. Beyond Classical Search"></a>Lecture 2. Beyond Classical Search</h1><h2 id="Outline-1"><a href="#Outline-1" class="headerlink" title="Outline"></a>Outline</h2><ul>
<li>More representations</li>
<li>General Search Frameworks</li>
<li>Summary</li>
</ul>
<h2 id="More-representations"><a href="#More-representations" class="headerlink" title="More representations"></a>More representations</h2><blockquote>
<p>Last lecture, we solve the search problem by Searching Tree.</p>
<p>But is there any more efficient data structure in some specific tasks ?</p>
</blockquote>
<h3 id="Direct-Search-in-the-Solution-Space"><a href="#Direct-Search-in-the-Solution-Space" class="headerlink" title="Direct Search in the Solution Space"></a>Direct Search in the Solution Space</h3><ul>
<li>Consider that the solution space is continuous, like $\mathbb{R}^{2}$.</li>
<li>Then if we generate a tree to describe each step, that’s silly.</li>
</ul>
<hr>
<ul>
<li>Representations of a solution space can be roughly categorized as:<ul>
<li>Continuous</li>
<li>Discrete: Binary, Integer, Permutation, etc.</li>
</ul>
</li>
<li>Different representations may favor different search methods, but most of them share a <strong>common framework</strong>.</li>
</ul>
<h2 id="General-Search-Frameworks"><a href="#General-Search-Frameworks" class="headerlink" title="General Search Frameworks"></a>General Search Frameworks</h2><p><img src="/2025/01/01/Artificial-Intelligence/ai201.png"></p>
<ul>
<li>Typical Frameworks:<ul>
<li>Local Search</li>
<li>Simulated Annealing</li>
<li>Tabu Search</li>
<li>Population-based search</li>
</ul>
</li>
<li>Two basic issues (differs over concrete search methods): <ul>
<li>search operator (how to generate a new candidate solution)</li>
<li>evaluation criterion (or replacement strategy)</li>
</ul>
</li>
</ul>
<h3 id="Typical-Search-Operators"><a href="#Typical-Search-Operators" class="headerlink" title="Typical Search Operators"></a>Typical Search Operators</h3><ul>
<li>A Search Operator generate a new solution based on previous ones.</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\phi : x\to x’,\forall x,x’ \in \mathcal{X}<br>$</p>

</blockquote>
<blockquote>
<p>Now we use continuous case as an example.</p>
</blockquote>
<h3 id="Greedy-Local-Search-Framework"><a href="#Greedy-Local-Search-Framework" class="headerlink" title="Greedy Local Search Framework"></a>Greedy Local Search Framework</h3><ul>
<li>Given a predefined Local Search Operator</li>
<li>Iteratively generate new solutions</li>
<li>Always pick the best solution so far, sometimes also known as <font color="DodgerBlue">Hill Climbing</font>.</li>
</ul>
<p><img src="/2025/01/01/Artificial-Intelligence/ai202.png"></p>
<blockquote>
<p>but sometimes trapped in local optimum</p>
</blockquote>
<h3 id="SA-Tabu-and-Bayesian-Optimizations"><a href="#SA-Tabu-and-Bayesian-Optimizations" class="headerlink" title="SA, Tabu and Bayesian Optimizations"></a>SA, Tabu and Bayesian Optimizations</h3><h4 id="Simulated-Annealing"><a href="#Simulated-Annealing" class="headerlink" title="Simulated Annealing"></a>Simulated Annealing</h4><blockquote>
<p>概念：温度，下降率</p>
<p>模拟退火是基于物理退火现象的一种对于贪心策略的优化方法。目的是在一定概率上帮助跳出局部最优的局面。（随机）</p>
<p>该优化方法需要根据实际情况调整超参数：初始温度 $T_0$，结束温度 $T_t$，和温度下降率 $\alpha$。</p>
</blockquote>
<blockquote class="blockquote-center">
<p>$<br>p=\left\{<br>\begin{array}{cl}<br>&amp;1 &amp;\text{if } f(x_i) \lt f(x_i’) \\<br>&amp;\exp{-\frac{f(x_i)-f(x_i’)}{T}} &amp;\text{if } f(x_i) \lt f(x_i’)<br>\end{array}\right.<br>$</p>

</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="type">Set</span> T(<span class="number">0</span>), T(t), alpha</span><br><span class="line">init x(<span class="number">0</span>), T(i) = T(<span class="number">0</span>)</span><br><span class="line"><span class="keyword">while</span> T(i) &lt; T(t):</span><br><span class="line">  generate x‘ based on x(i)</span><br><span class="line">  calc f(x‘)</span><br><span class="line">  calc p</span><br><span class="line">  <span class="keyword">if</span> c = random[<span class="number">0</span>,<span class="number">1</span>] &lt; p: x(i+<span class="number">1</span>) = x‘</span><br><span class="line">  <span class="keyword">else</span>: x(i+<span class="number">1</span>) = x(i)</span><br><span class="line">  i += <span class="number">1</span></span><br><span class="line">  Update T(i) = T(i) * alpha</span><br><span class="line">end</span><br><span class="line"><span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<h4 id="Tabu"><a href="#Tabu" class="headerlink" title="Tabu"></a>Tabu</h4><p><strong>Hill climbing → Tabu Search</strong></p>
<ul>
<li>Key idea: Don’t visit the sample candidate solution twice.</li>
<li>Challenge: How to define the Tabu list?</li>
<li>Concept:<ul>
<li>Tabu List [禁忌表]</li>
<li>Tabu Object: items in TL, e.g., in Traveling Salesman Problem (TSP), we can set cities as TO (can be some attributes involved to $f(x)$)</li>
<li>Tabu Tenure: “Time” that TO stay in TL. 👉 to avoid short loop(TT↓) or low PF(TT↑)</li>
<li>Aspiration Criteria: to choose TO with best PF, and pop it out from TL.</li>
</ul>
</li>
</ul>
<blockquote>
<p>通过维持一个禁忌表的方式，在一定程度上接收比当前最优解要差的结果，从而跳出局部最优</p>
</blockquote>
<h4 id="Bayesian-Optimizations"><a href="#Bayesian-Optimizations" class="headerlink" title="Bayesian Optimizations"></a>Bayesian Optimizations</h4><p><strong>Hill climbing → Bayesian Optimizations</strong></p>
<ul>
<li>Key idea: Build a model to ”guess” which solution is good.</li>
<li>Challenge: <ul>
<li>model building is non-trivial</li>
<li>may need lots of data to build the model, limited to low-dimensional problem</li>
</ul>
</li>
</ul>
<blockquote>
<p>涉及机器学习内容</p>
</blockquote>
<h3 id="Population-based-Search"><a href="#Population-based-Search" class="headerlink" title="Population-based Search"></a>Population-based Search</h3><ul>
<li>Idea: Since we sample from a probability distribution, why 1 at a time?</li>
<li><font color="red">Evolutionary Algorithm</font>:</li>
</ul>
<p><img src="/2025/01/01/Artificial-Intelligence/ai203.png"></p>
<ul>
<li>Seeking a good distribution: maximize the following “objective function”:</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\mathcal{J}=\int f(x)p(x|\theta_{1}) dx<br>$</p>

</blockquote>
<ul>
<li>where $p(x|\theta_{1})$ is prob density function parameterized by $\theta_{1}$</li>
<li>Using “Population” help making objective function “smooth”</li>
</ul>
<p><img src="/2025/01/01/Artificial-Intelligence/ai204.png"></p>
<ul>
<li>Suppose we now converge to some (global or local) optimum</li>
<li>If run the algorithm again, we hope the algorithm (i.e., the distribution corresponding to the final population) <font color="red">converge to a different optimum</font> (and thus a different PDF).</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\mathcal{J}= \sum_{i=1}^{\lambda} \int f(x)p(x|\theta_{i}) dx - \sum_{i=1}^{\lambda} \sum_{j=1}^{\lambda} C(\theta_{i}, \theta_{j})<br>$</p>

</blockquote>
<ul>
<li>where $C(\theta_{i},\theta_{j})$ is similarity of the two PDFs [概率密度分布]</li>
</ul>
<p><strong>EA Applications</strong></p>
<ul>
<li>N-Queen Problems [通过“杂交”操作生成新组合，每次进行多个组合计算]</li>
<li>鸟巢设计，动车车头设计等</li>
</ul>
<h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><ul>
<li>This lecture is talking about <font color="red">general-purpose search frameworks</font>, rather than search algorithm.</li>
<li>When addressing a specific problem, heuristics derived from domain knowledge needs to be incorporated in forms of search operators to obtain the best performance.</li>
<li>For some problem of great importance, mature <font color="red">application-specific optimization approaches</font> have been developed such that algorithm design from scratch is not needed.</li>
</ul>
<blockquote>
<p>Therefore, next lecture will talk about some problem-specific search algorithms.</p>
</blockquote>
<h1 id="Lecture-3-Problem-Specific-Search"><a href="#Lecture-3-Problem-Specific-Search" class="headerlink" title="Lecture 3. Problem-Specific Search"></a>Lecture 3. Problem-Specific Search</h1><h2 id="Outline-2"><a href="#Outline-2" class="headerlink" title="Outline"></a>Outline</h2><ul>
<li>Make Search Algorithms Less General</li>
<li>Gradient-based Methods for Numerical Optimization</li>
<li>Quadratic Programming Problems</li>
<li>Constraint Satisfaction Problems</li>
<li>Adversarial Search</li>
</ul>
<h2 id="Make-Search-Algorithms-Less-General"><a href="#Make-Search-Algorithms-Less-General" class="headerlink" title="Make Search Algorithms Less General"></a>Make Search Algorithms Less General</h2><blockquote>
<p>Why we need problem-specific search ?</p>
</blockquote>
<ul>
<li>When designing an algorithm for a problem (class), taking the problem characteristics into account usually helps us get the desired solution by <font color="red">searching only a part of the search/state space</font>, making the search more efficient.</li>
</ul>
<font color="green"><b>Recall</b></font>

<ul>
<li>consider the ubiquitous (普遍的) optimization problems:</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{ll}<br>&amp;\text{maximize} &amp;f(x) \\<br>&amp;\text{subject to:} &amp;g_i(x)\le 0,\ i=1\cdots m \\<br>&amp; &amp;h_j(x)=0,\ j=1\cdots p<br>\end{array}<br>$</p>

</blockquote>
<ul>
<li>What is “problem characteristic”? Most basically:<ul>
<li>What is $x$ ?</li>
<li>What is $f$ ?</li>
<li>Does $f$ fulfill some properties that would lead to a more efficient search?</li>
</ul>
</li>
</ul>
<h2 id="Gradient-based-Methods-for-Numerical-Optimization"><a href="#Gradient-based-Methods-for-Numerical-Optimization" class="headerlink" title="Gradient-based Methods for Numerical Optimization"></a>Gradient-based Methods for Numerical Optimization</h2><ul>
<li>Suppose the objective function $f(x_1 , y_1, x_2, y_2, x_3, y_3)$ is continuous and differentiable (thus the gradient could be calculated)</li>
<li>Compute:</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\nabla f=\left( \large{\frac{\partial f}{\partial x_1}, \frac{\partial f}{\partial y_1}, \frac{\partial f}{\partial x_2}, \frac{\partial f}{\partial y_2}, \frac{\partial f}{\partial x_3}, \frac{\partial f}{\partial y_3}} \right)<br>$</p>

</blockquote>
<ul>
<li>to increase/reduce $f$, e.g., by $x \leftarrow x + \alpha \nabla f(x)$ [梯度下降]</li>
</ul>
<h2 id="Quadratic-Programming-Problems"><a href="#Quadratic-Programming-Problems" class="headerlink" title="Quadratic Programming Problems"></a>Quadratic Programming Problems</h2><ul>
<li>The objective function is a <font color="red">quadratic(二次) function</font> of $x$</li>
<li>The constraints are linear functions of $x$</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{ll}<br>&amp; &amp;\min f(x)=q^{T}x + \frac{1}{2}x^{T}Qx \\<br>&amp;\text{s.t.} &amp; Ax = a,\ Bx \le b,\ x\ge 0 \\<br>\end{array}<br>$</p>

</blockquote>
<ul>
<li>When there is <strong>no constraint</strong>, we can solve this problem by differenctiation. ($f’(x)=0$)</li>
<li>But when there are constraints, search is still needed (<font color="green">Recall:</font> Lagrange multiplier)</li>
</ul>
<blockquote>
<p>引出接下来的问题：CSP</p>
</blockquote>
<h2 id="Constraint-Satisfaction-Problems-CSP"><a href="#Constraint-Satisfaction-Problems-CSP" class="headerlink" title="Constraint Satisfaction Problems (CSP)"></a><font color="red">Constraint Satisfaction Problems (CSP)</font></h2><ul>
<li>Standard Search Problem<ul>
<li><strong>state</strong> is a “black box” 👉 any old data structure that supports goal test, eval, successors</li>
</ul>
</li>
<li>CSP<ul>
<li><strong>state</strong> is defined by variable $X_i$ with values from domain $D_i$</li>
<li><strong>goal test</strong> is a set of constraints specifying allowable combinations of values for subsets of variables</li>
</ul>
</li>
</ul>
<blockquote>
<p>例：地图上色问题。限制：相邻区块不能上同一颜色。</p>
<p>假设两个区块 $X=\{A,B\}$，四种颜色 $D=\{R, G, B, Y\}$，原本可以有 16 种组合，但是由于限制条件只有 12 种。</p>
</blockquote>
<h3 id="Characteristics-of-CSPs"><a href="#Characteristics-of-CSPs" class="headerlink" title="Characteristics of CSPs"></a>Characteristics of CSPs</h3><h4 id="Real-world-CSPs"><a href="#Real-world-CSPs" class="headerlink" title="Real-world CSPs"></a>Real-world CSPs</h4><ul>
<li>Assignment problems</li>
<li>Timetabling problems</li>
<li>Hardware configuration</li>
<li>Floorplanning</li>
<li>Factory scheduling</li>
<li>……</li>
</ul>
<h4 id="Commutativity"><a href="#Commutativity" class="headerlink" title="Commutativity"></a>Commutativity</h4><blockquote>
<p>First character</p>
</blockquote>
<ul>
<li>Commutativity help us formulate the search tree (only 1 variable needs to be considered at each node in the search tree).</li>
</ul>
<p><img src="/2025/01/01/Artificial-Intelligence/ai301.png"></p>
<h4 id="Constraint-Graph"><a href="#Constraint-Graph" class="headerlink" title="Constraint Graph"></a>Constraint Graph</h4><blockquote>
<p>Second</p>
</blockquote>
<p><img src="/2025/01/01/Artificial-Intelligence/ai302.png"></p>
<h4 id="Inference"><a href="#Inference" class="headerlink" title="Inference"></a>Inference</h4><ul>
<li>A constraint graph allows the agent to do <font color="red">inference</font> in addition to search. </li>
<li>Inference basically means <font color="red">checking local consistency</font> (or detecting inconsistency) <ul>
<li>Node consistency</li>
<li>Arc Consistency</li>
<li>Path Consistency</li>
<li>K-consistency</li>
<li>Global consistency</li>
</ul>
</li>
<li>Inference helps <font color="red">prune</font> the search tree, either before or during the search.</li>
</ul>
<h3 id="Backtracking-Search-for-CSP"><a href="#Backtracking-Search-for-CSP" class="headerlink" title="Backtracking Search for CSP"></a>Backtracking Search for CSP</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">backtracking_search</span>(<span class="params">csp</span>) -&gt; (solution/failure):</span><br><span class="line">  <span class="keyword">return</span> recursive_backtracking(&#123;&#125;, csp)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">recursive_backtracking</span>(<span class="params">&#123;&#125;, csp</span>) -&gt; (result/failure):</span><br><span class="line">  <span class="keyword">if</span> assignment <span class="keyword">is</span> complete then <span class="keyword">return</span> assignment</span><br><span class="line">  var &lt;- Select_Unassigned_Variable(Variable[csp], assignment, csp)</span><br><span class="line">  <span class="keyword">for</span> value <span class="keyword">in</span> Order_Domain_Value(var, assignment, csp) do</span><br><span class="line">    <span class="keyword">if</span> value <span class="keyword">is</span> consistent <span class="keyword">with</span> assignment given constraint[csp] then</span><br><span class="line">      add &#123;var = value&#125; to assignment</span><br><span class="line">      result &lt;- recursive_backtracking(assignment, csp)</span><br><span class="line">      <span class="keyword">if</span> result != failure then <span class="keyword">return</span> result</span><br><span class="line">      remove &#123;var = value&#125; <span class="keyword">from</span> assignment</span><br><span class="line">  <span class="keyword">return</span> failure</span><br></pre></td></tr></table></figure>
<ul>
<li>More improvement can be done:<ul>
<li>E.g. in <code>Select_Unassigned_Variable</code>, design some strategies to choose the optimal variable</li>
<li>E.g. maintain a conflict set, etc.</li>
</ul>
</li>
</ul>
<h2 id="Adversarial-对抗性-Search"><a href="#Adversarial-对抗性-Search" class="headerlink" title="Adversarial(对抗性) Search"></a>Adversarial(对抗性) Search</h2><blockquote>
<p>以一个游戏为例：</p>
</blockquote>
<p><img src="/2025/01/01/Artificial-Intelligence/ai303.png"></p>
<p><strong>Algorithm.</strong> Minimax Algorithm</p>
<ul>
<li>Idea<ul>
<li>Assume the game is deterministic and perfect information is available</li>
<li>For player “MAX”, choose the move to position the <font color="dodgerblue">highest minimax value</font></li>
</ul>
</li>
</ul>
<p><img src="/2025/01/01/Artificial-Intelligence/ai304.png"></p>
<ul>
<li>Perform a <strong>complete</strong>(later we will optimize this) depth-first search of the game tree.</li>
<li><strong>Recursively</strong> compute the minimax values of each successor state.</li>
<li>Maximize the worst-case outcome for MAX.</li>
</ul>
<h3 id="Alpha-Beta-Pruning"><a href="#Alpha-Beta-Pruning" class="headerlink" title="Alpha-Beta Pruning"></a>Alpha-Beta Pruning</h3><ul>
<li>Idea: Remove (unneeded) part of the minimax tree from consideration.</li>
</ul>
<p><img src="/2025/01/01/Artificial-Intelligence/ai305.png"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># AB Search</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">alpha_beta_search</span>(<span class="params">state</span>):</span><br><span class="line">  <span class="keyword">return</span> max_value(state, -INF, INF)</span><br><span class="line"></span><br><span class="line"><span class="comment"># MAX search</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">max_value</span>(<span class="params">state, alpha, beta</span>):</span><br><span class="line">  <span class="keyword">if</span> <span class="keyword">is</span> terminal state:</span><br><span class="line">    <span class="keyword">return</span> util(state)</span><br><span class="line">  v &lt;- (-INF)</span><br><span class="line">  <span class="keyword">for</span> a <span class="keyword">in</span> action(state):</span><br><span class="line">    v &lt;- <span class="built_in">max</span>(v, min_value(result(s, a), alpha, beta))</span><br><span class="line">    <span class="keyword">if</span> v &gt;= beta:  <span class="comment"># pruning</span></span><br><span class="line">      <span class="keyword">return</span> v</span><br><span class="line">    alpha &lt;- <span class="built_in">max</span>(alpha, v)</span><br><span class="line">  <span class="keyword">return</span> v</span><br><span class="line"></span><br><span class="line"><span class="comment"># MIN search</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">min_value</span>(<span class="params">state, alpha, beta</span>):</span><br><span class="line">  <span class="keyword">if</span> <span class="keyword">is</span> terminal state:</span><br><span class="line">    <span class="keyword">return</span> util(state)</span><br><span class="line">  v &lt;- INF</span><br><span class="line">  <span class="keyword">for</span> a <span class="keyword">in</span> action(state):</span><br><span class="line">    v &lt;- <span class="built_in">min</span>(v, max_value(result(s, a), alpha, beta))</span><br><span class="line">    <span class="keyword">if</span> v &lt;= alpha:  <span class="comment"># pruning</span></span><br><span class="line">      <span class="keyword">return</span> v</span><br><span class="line">    beta &lt;- <span class="built_in">min</span>(beta, v)</span><br><span class="line">  <span class="keyword">return</span> v</span><br></pre></td></tr></table></figure>
<ul>
<li>Explanation:<ul>
<li>when we search maximum for “MAX”, we first suppose “MAX” choose action a, and “MIN” make perfect action (minimum in “MAX” view), assuming that value is 3.</li>
<li>Then “MAX” will focus on range $[3, \infty]$.</li>
<li>We then suppose “MAX” choose action b, and “MIN” make a choice for an action value 2.</li>
<li>We’re sure that “MIN” ultimately will make a choice having value $\le 2$ (optimal for “MIN”). However, “MAX” only accept actions value $\ge 3$, so action b won’t be accepted.</li>
<li>Therefore, we can stop “MIN” from searching the other actions.</li>
</ul>
</li>
<li>So we found that Alpha-Beta Pruning have limitation:<ul>
<li>games with more than 2 players ?</li>
<li>2-players game that is not zero-sum ? [非敌对？]</li>
<li>Minimax or Alpha-Beta Pruning don’t apply ?</li>
</ul>
</li>
<li>And sometimes the <strong>order</strong> of “actions” affects the PF.</li>
</ul>
<h2 id="Summary-on-Search"><a href="#Summary-on-Search" class="headerlink" title="Summary on Search"></a>Summary on Search</h2><ul>
<li>How to <font color="red">represent</font> the search space?<ul>
<li>Search Tree (state space)</li>
<li>Solution space</li>
</ul>
</li>
<li>What is the <font color="red">objective function and constraint</font>, and algorithm in textbook already good enough? </li>
<li>Which <font color="red">algorithmic framework</font> to choose?<ul>
<li>Tree search, e.g., Un-informed Search, Heuristic Search (A*…)</li>
<li>Direct search in the solution space, e.g., Hill Climbing, Simulated Annealing, Genetic Algorithm… </li>
</ul>
</li>
<li>How to define <font color="red">concrete components</font> of the algorithm framework? <ul>
<li>General-purpose operators in literature</li>
<li>Problem-specific operators, designed based on domain knowledge</li>
</ul>
</li>
</ul>
<blockquote>
<p>Always <strong>trade-off</strong> among solution quality, efficiency, and your domain knowledge</p>
</blockquote>
<h1 id="Lecture-4-Principles-of-Machine-Learning"><a href="#Lecture-4-Principles-of-Machine-Learning" class="headerlink" title="Lecture 4. Principles of Machine Learning"></a>Lecture 4. Principles of Machine Learning</h1><h2 id="Outline-3"><a href="#Outline-3" class="headerlink" title="Outline"></a>Outline</h2><ul>
<li>What is Learning</li>
<li>Key Questions for Learning</li>
<li>Learning Paradigms and Principles</li>
</ul>
<h2 id="What-is-Learning"><a href="#What-is-Learning" class="headerlink" title="What is Learning?"></a>What is Learning?</h2><ul>
<li><strong>Machine Learning</strong>: Given some observations (data) from the environment, how could an agent improve its agent function?</li>
<li>Intuitive assumptions<ul>
<li>the data share something in common</li>
<li>“something” could be obtained by an algorithm/program</li>
</ul>
</li>
</ul>
<h3 id="Two-simple-methods"><a href="#Two-simple-methods" class="headerlink" title="Two simple methods"></a>Two simple methods</h3><p><strong>A Naive Parametric Method —— Bayesian Formula</strong></p>
<ul>
<li>Classify a data to the class with the highest posterior probability</li>
<li><font color="dodgerblue">Assumption:</font> data follows independent identically distribution</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{c}<br>&amp;P(w_j|x)=\frac{p(x|w_j)p(w_j)}{p(x)} \\<br>&amp;P(w_2|x)\gt P(w_1|x) \Leftrightarrow \ln{p(x|w_2)}+\ln{p(w_2)} \gt \ln{p(x|w_1)}+\ln{p(w_1)} \\<br>\end{array}<br>$</p>

</blockquote>
<ul>
<li><strong>“Parametric”</strong>: the assumption on the probability density function (PDF).</li>
<li>Parametric methods usually do not involve parameters to fine-tune, while Nonparametric methods usually do.</li>
</ul>
<p><strong>A Linear Function</strong></p>
<ul>
<li>Find a straight line/hyper-plane to separate data from different classes.</li>
</ul>
<p><a name="ai401"><img src="/2025/01/01/Artificial-Intelligence/ai401.png"></a></p>
<h2 id="Key-Questions-for-Machine-Learning"><a href="#Key-Questions-for-Machine-Learning" class="headerlink" title="Key Questions for Machine Learning"></a>Key Questions for Machine Learning</h2><ul>
<li>What is the format of the data? (data representation)</li>
<li>What does the agent function look like? (model representation)</li>
<li>How to measure the “improvement”? (objective function)</li>
<li>What is the learning algorithm? (to get a good agent function)</li>
</ul>
<center><b>Representation + Algorithm + Evaluation = Agent function/Model</b></center>



<h2 id="Learning-Paradigms-and-Principles"><a href="#Learning-Paradigms-and-Principles" class="headerlink" title="Learning Paradigms and Principles"></a>Learning Paradigms and Principles</h2><ul>
<li>Learning Principles: <font color="magenta">Generalization!</font><ul>
<li>the learned agent function is expected to be able to handle previously unseen situations.</li>
</ul>
</li>
<li>Learning Paradigms (范式)<ul>
<li>A Machine Learning process typically involves two phases<ul>
<li>Training: build the agent function</li>
<li>Testing/Inference: test the agent function/deploy the agent function in real use.</li>
</ul>
</li>
<li>Different ML techniques may use different training/learning paradigms<ul>
<li><font color="red">Supervised Learning:</font> the correct answer is available to the learning algorithm.</li>
<li><font color="red">Reinforcement Learning:</font> the only feedback is the reward of an output, e.g., the output is correct or not (the correct answer is not given).</li>
<li><font color="red">Unsupervised Learning:</font> no correct answer is available</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="Lecture-5-Supervised-Learning"><a href="#Lecture-5-Supervised-Learning" class="headerlink" title="Lecture 5. Supervised Learning"></a>Lecture 5. Supervised Learning</h1><blockquote>
<p>注意：以下内容部分与课程 MA234 大数据导论与实践相重合！</p>
</blockquote>
<h2 id="Outline-4"><a href="#Outline-4" class="headerlink" title="Outline"></a>Outline</h2><ul>
<li>LDA</li>
<li>SVM</li>
<li>ANN (NN)</li>
<li>DT</li>
</ul>
<h2 id="Linear-Discriminant-Analysis"><a href="#Linear-Discriminant-Analysis" class="headerlink" title="Linear Discriminant Analysis"></a>Linear Discriminant Analysis</h2><ul>
<li>Idea: Viewing each datum to lie in a Euclidean space, find a straight line (a linear function) in the space (recall the <a href="#ai401">example</a> used in the last lecture), where the data projection on this line/plane can be well separate according to their label.</li>
<li>Let’s learn some Maths:<ul>
<li>Given dataset $D=\{ (\mathbf{x}_i, y_i) \}^{m}_{i=1}$, $y_i \in \{0,1\}$</li>
<li>Suppose $X_i$ is the data subset with label $i\in \{0,1\}$, $\mathbf{\mu_i}$ is the mean vector, $\Sigma_i$ is the Covariance Matrix</li>
</ul>
</li>
</ul>
<p><img src="/2025/01/01/Artificial-Intelligence/ai501.png" style="zoom:50%"></p>
<ul>
<li>Then the projection of samples in two classes are $w^T \mu_0$, $w^T \mu_1$</li>
<li>And the covariance within two classes are $w^T\Sigma_0 w$, $w^T\Sigma_1 w$</li>
<li>Trying to make projections of data in the same class closer, and in different classes farther, we describe the objective function $J$ in this way:</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{rcl}<br>\text{define within-class scatter matrix:} &amp;\mathbf{S_w}&amp;=\mathbf{\Sigma_0}+\mathbf{\Sigma_1} \\<br>&amp;&amp;=\sum_{x\in X_0}(\mathbf{x}-\mathbf{\mu_0})^T+\sum_{x\in X_1}(\mathbf{x}-\mathbf{\mu_1})^T \\<br>\text{define between-class scatter matrix:}&amp;\mathbf{S_b}&amp;=(\mathbf{\mu_0}-\mathbf{\mu_1})(\mathbf{\mu_0}-\mathbf{\mu_1})^T \\<br>\text{Then we get objective function:}&amp;J&amp;=\large\frac{|| w^T\mathbf{\mu_0}-w^T\mathbf{\mu_1} ||^{2}_{2}}{w^T\Sigma_0 w+w^T\Sigma_1 w} \\<br>&amp;&amp;=\large\frac{w^T (\mathbf{\mu_0}-\mathbf{\mu_1})(\mathbf{\mu_0}-\mathbf{\mu_1})^T w}{w^T (\Sigma_0+\Sigma_1)w} \\<br>&amp;&amp;=\large\frac{w^T \mathbf{S_b} w}{w^T \mathbf{S_w} w}<br>\end{array}<br>$</p>

</blockquote>
<ul>
<li>So we get what LDA wants to maximize (also called <strong>generalized Rayleigh quotient</strong>)</li>
<li>then we’re going to optimize this function to obtain an easy form:</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{rl}<br>&amp;\min_{\mathbf{w}} -\mathbf{w}^T\mathbf{S_b} \mathbf{w} \\<br>&amp;s.t.\ \mathbf{w}^T\mathbf{S_w} \mathbf{w}=1 \\<br>\text{use Langrange Multiplexer: }&amp;\mathbf{S_b}\mathbf{w}=\lambda\mathbf{S_w}\mathbf{w} \\<br>\text{Aware that } &amp;\mathbf{S_b}\mathbf{w} \text{ always has same direnction as } (\mathbf{\mu_0}-\mathbf{\mu_1}) \\<br>\text{Let }&amp;\mathbf{S_b}\mathbf{w} = \lambda (\mathbf{\mu_0}-\mathbf{\mu_1}) \\<br>\therefore&amp;\mathbf{w}=\mathbf{S_w}^{-1} (\mathbf{\mu_0}-\mathbf{\mu_1})<br>\end{array}<br>$</p>

</blockquote>
<blockquote>
<p>In practice, it’s more likely to represent $\mathbf{S_w}$ as form of Singularity Decomposition: $\mathbf{U}\mathbf{\Sigma}\mathbf{V}^T$.</p>
<p>So that we can get $\mathbf{S_w}^{-1}$ by computing $\mathbf{S_w}^{-1}= \mathbf{V}\mathbf{\Sigma}^{-1}\mathbf{U}^T$</p>
</blockquote>
<ul>
<li>This method is also practical in multi-classification task<ul>
<li>by computing $\mathbf{W}\in \mathbb{R}^{d\times (N-1)}$</li>
<li>Objective function: $\max_{W} \large\frac{tr(W^T S_b W)}{tr(W^T S_w W)}$</li>
</ul>
</li>
</ul>
<h2 id="Support-Vector-Machine"><a href="#Support-Vector-Machine" class="headerlink" title="Support Vector Machine"></a>Support Vector Machine</h2><ul>
<li>Basic idea: margin maximization<ul>
<li>the <font color="red">minimum</font> distance between a data point to the decision boundary is <font color="red">maximized</font>.</li>
<li>intuitively, the safest and most robust</li>
<li><font color="red">support vectors:</font> datapoints the margin pushes up</li>
</ul>
</li>
</ul>
<p><img src="/2025/01/01/Artificial-Intelligence/ai502.png" style="zoom:50%"></p>
<ul>
<li>decision boundary: $&lt;\mathbf{w}, \mathbf{x}&gt; +b = 0$</li>
</ul>
<p><img src="/2025/01/01/Artificial-Intelligence/ai503.png"></p>
<ul>
<li>Kernel SVM: for non-linearlity<ul>
<li>RBF</li>
<li>Polynomial</li>
<li>Sigmoid</li>
</ul>
</li>
<li>Soft Margin SVM<ul>
<li>Even with kernel trick, it is hardly to guarantee that the training data are linearly separable, thus a soft margin rather than hard margin is used in practice.</li>
</ul>
</li>
</ul>
<p><img src="/2025/01/01/Artificial-Intelligence/ai504.png"></p>
<h2 id="Artificial-Neural-Networks"><a href="#Artificial-Neural-Networks" class="headerlink" title="Artificial Neural Networks"></a>Artificial Neural Networks</h2><ul>
<li>A highly nonlinear function that mimic the structure of biological NN.</li>
</ul>
<p><img src="/2025/01/01/Artificial-Intelligence/ai505.png"></p>
<h3 id="Training-NN"><a href="#Training-NN" class="headerlink" title="Training NN"></a>Training NN</h3><ul>
<li>Optimize weights to minimize the Loss function</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>J(w)=\frac{1}{2} \sum_{k=1}^{c}(y_k-z_k)^2=\frac{1}{2} ||\mathbf{y}-\mathbf{z} ||^{2}<br>$</p>

</blockquote>
<ul>
<li>Training algorithm: gradient descent, with Back Propagation(BP) algorithm as a representative example.</li>
</ul>
<p><strong>BP</strong></p>
<ul>
<li>Update weights between output and hidden layers</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\nabla w_{ji}=-\eta\frac{\partial{J}}{ \partial{w_{ji}}}<br>$</p>

</blockquote>
<ul>
<li>Update weights between input and hidden layers</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\frac{\partial{J}}{ \partial{w_{ki}}}=\frac{\partial{J}}{ \partial{net_{k}}} \cdot \frac{ \partial{net_{k}}}{ \partial{w_{ki}}} = -\delta_{k}\frac{ \partial{net_{k}}}{ \partial{w_{ki}}}<br>$</p>

</blockquote>
<ul>
<li>Apply in BP algorithm<ul>
<li>initial $D=\{ (\mathbf{x_1},y_1), \cdots, (\mathbf{x_m}, y_m) \}$ and learning rate $\eta$</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">while</span> Optimality conditions are <span class="keyword">not</span> satisfied:</span><br><span class="line">  <span class="keyword">for</span> (x, y) <span class="keyword">in</span> D:</span><br><span class="line">    calc current output by current param</span><br><span class="line">    calc grad <span class="keyword">for</span> output-layer neurons</span><br><span class="line">    calc grad <span class="keyword">for</span> hidden-layer neurons</span><br><span class="line">    update weight <span class="keyword">and</span> thresholds</span><br><span class="line">end</span><br></pre></td></tr></table></figure>
<h3 id="Some-issues"><a href="#Some-issues" class="headerlink" title="Some issues"></a>Some issues</h3><ul>
<li>Universal Approximation Theory</li>
<li>Fully connected NN (MLP) with more than 1 hidden layer is very difficult to train</li>
<li>etc.</li>
</ul>
<h2 id="Decision-Tree"><a href="#Decision-Tree" class="headerlink" title="Decision Tree"></a>Decision Tree</h2><ul>
<li>A natural way to handle nonmetric data (also applicable to real-valued data).</li>
<li>Tree searching metrics<ul>
<li>Entropy: $i(N) = -\sum_{i}p(w_i)\log{p(w_i)}$</li>
<li>Variance: $i(N) = 1 - \sum_{i}p^2(w_i)$</li>
<li>Misclassification rate: $i(N) = 1 - \max_{i}p(w_i)$</li>
</ul>
</li>
</ul>
<blockquote>
<p>How to contruct a DT ?</p>
</blockquote>
<ol>
<li>Start from the root, keep searching for a rule to branch a node.</li>
<li>At each node, select the rule that leads to the most significant decrease in <strong>impurity</strong> (similar to gradient descent).<ul>
<li>$\Delta i(N) = i(N) - p_L i(N_L) - (1-p_L)i(N_R)$ </li>
</ul>
</li>
<li>When the process terminates, assign class label to the leaf nodes. <ul>
<li>label a leaf node with the label of majority instances that fall into it.</li>
</ul>
</li>
</ol>
<blockquote>
<p>How to control the complexity ?</p>
</blockquote>
<ul>
<li>Setting the maximum height of the tree (early stopping)</li>
<li>Introduce the tree height (or any other complexity measure as a penalty)</li>
<li>Fully grow the tree first, and then prune it (post processing)</li>
</ul>
<h1 id="Lecture-6-Performance-Evaluation-for-Machine-Learning"><a href="#Lecture-6-Performance-Evaluation-for-Machine-Learning" class="headerlink" title="Lecture 6. Performance Evaluation for Machine Learning"></a>Lecture 6. Performance Evaluation for Machine Learning</h1><h2 id="Outline-5"><a href="#Outline-5" class="headerlink" title="Outline"></a>Outline</h2><ul>
<li>Brief view</li>
<li>Performance Metrics</li>
<li>Estimating the Generalization</li>
</ul>
<h2 id="Brief-view"><a href="#Brief-view" class="headerlink" title="Brief view"></a>Brief view</h2><ul>
<li>Be careful when choosing your objective function, two principles:<ul>
<li>Consistent with the user requirements?</li>
<li>Existing easy-to-use algorithm to optimize it (to train the model)?</li>
</ul>
</li>
<li>Do internal tests as much as possible<ul>
<li>estimate the generalization performance as accurate as possible.</li>
</ul>
</li>
<li>Can only reduce rather than remove risk. There is no guarantee in life.</li>
</ul>
<h2 id="Performance-Metrics"><a href="#Performance-Metrics" class="headerlink" title="Performance Metrics"></a>Performance Metrics</h2><blockquote>
<p>Review MA234.</p>
</blockquote>
<ul>
<li>T &amp; F : represents truth of label (标签是否真实)</li>
<li>P &amp; N : represents aspect of label (标签的正反两面)</li>
<li>And there’re 4 cases: TP, TN, FP, FN</li>
<li>Several metrics:<ul>
<li>accuracy 👉 bad when samples are imbalanced</li>
<li>precision</li>
<li>Recall</li>
<li>F-measure ($F_1$) $=\large\frac{2\times \text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}$</li>
</ul>
</li>
</ul>
<blockquote>
<p>细节请参考大数据导论与实践（二）</p>
</blockquote>
<ul>
<li>ROC 👉 TPR / FPR</li>
<li>AUC : slope of ROC, good PF when $AUC\gt 0.75$</li>
</ul>
<h2 id="Estimating-the-Generalization"><a href="#Estimating-the-Generalization" class="headerlink" title="Estimating the Generalization"></a>Estimating the Generalization</h2><ul>
<li>Generalization performance is a random variable. </li>
<li>Split the data in hand into training and testing subsets.<ul>
<li>Random Split</li>
<li>Cross-validation</li>
<li>Bootstrap</li>
</ul>
</li>
<li>Collecting the test performance for many times, calculate the average and standard deviation. </li>
<li>Do statistical tests (check your textbook on statistics)</li>
</ul>
<h1 id="Lecture-7-Unsupervised-Learning"><a href="#Lecture-7-Unsupervised-Learning" class="headerlink" title="Lecture 7. Unsupervised Learning"></a>Lecture 7. Unsupervised Learning</h1><h2 id="Outline-6"><a href="#Outline-6" class="headerlink" title="Outline"></a>Outline</h2><ul>
<li>Why Unsupervised ?</li>
<li>Clustering</li>
<li>K-Means</li>
<li>Dimensionality Reduction</li>
</ul>
<h2 id="Why-Unsupervised"><a href="#Why-Unsupervised" class="headerlink" title="Why Unsupervised ?"></a>Why Unsupervised ?</h2><ul>
<li>In practice, it might neither be tractable to collect sufficient labelled data</li>
<li>Instead, it is relatively easy to accumulate large amount of unlabeled data.</li>
</ul>
<p><strong>Supervised vs. Unsupervised</strong></p>
<ul>
<li>Share the same key factors, i.e., representation + algorithm + evaluation</li>
<li>For supervised learning, since ground-truth is available for the training data, the evaluation (objective function) can be said as <font color="red">objective</font>.</li>
<li>For unsupervised learning, the evaluation is usually less specific and <font color="red">more subjective</font>.</li>
<li>It is more likely that an unsupervised learning problem is ill-defined and the learning output deviate from our intuition.</li>
</ul>
<h2 id="Clustering"><a href="#Clustering" class="headerlink" title="Clustering"></a>Clustering</h2><ul>
<li><strong>Def.</strong> a typical ill-defined problem as there is no unique definition of the similarity between clusters.</li>
<li>Idea: gathering similar data into one class<ul>
<li>e.g. Objective Function (to minimize distance)</li>
</ul>
</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\begin{array}{}<br>J= \underset{i=1}{\overset{k}{\sum}} \underset{x \in D_i }{\sum} || \mathbf{x} - \mathbf{m_i} ||^2 \\<br>i.e. J = \frac{1}{2} \underset{i=1}{\overset{k}{\sum}} n_i \underset{x,x’ \in D_i }{\sum} || \mathbf{x}-\mathbf{x’} ||^2<br>\end{array}<br>$</p>

</blockquote>
<p><strong>Naive Approach</strong></p>
<ul>
<li><font color="dodgerblue">Top-down:</font> following the decision tree idea to split the data recursively. </li>
<li><font color="dodgerblue">Bottom-up:</font> recursively put two instances (or “meta-instances”) into the same group</li>
<li>Basically you need to define <font color="red">similarity metric</font> (e.g., Euclidean distance) first.</li>
</ul>
<blockquote>
<p>层次聚类？</p>
</blockquote>
<h2 id="K-Means"><a href="#K-Means" class="headerlink" title="K-Means"></a>K-Means</h2><h3 id="Algorithm"><a href="#Algorithm" class="headerlink" title="Algorithm"></a>Algorithm</h3><ul>
<li>Given a predefined $K$<ol>
<li>Randomly initialize $K$ cluster centers</li>
<li>Assign each instance to the nearest center</li>
<li>Update the each center as the mean of all the instances in the cluster</li>
<li>Repeat Step 1-3 until the centers do not change any more</li>
</ol>
</li>
</ul>
<blockquote>
<p>Not only similarity metric, but also needs calculating of the average.</p>
</blockquote>
<h3 id="Application-Clustering-for-Graph-Data"><a href="#Application-Clustering-for-Graph-Data" class="headerlink" title="Application: Clustering for Graph Data"></a>Application: Clustering for Graph Data</h3><p><img src="/2025/01/01/Artificial-Intelligence/ai701.png"></p>
<h2 id="Dimensionality-Reduction"><a href="#Dimensionality-Reduction" class="headerlink" title="Dimensionality Reduction"></a>Dimensionality Reduction</h2><h3 id="Principle-Component-Analysis"><a href="#Principle-Component-Analysis" class="headerlink" title="Principle Component Analysis"></a>Principle Component Analysis</h3><ul>
<li>Given a n-by-d data set, can we map it into a lower dimensional space with a <font color="red">linear</font> transformation, while only introduce the minimum information loss?</li>
<li>Suppose we want to reduce data dimension from $n$ to $k$<ol>
<li>Init a dataset: $X=\{x_1, x_2, \cdots , x_m\}$</li>
<li>Calculate the mean value and minus it (decentralize)</li>
<li>Calculate the covariance matrix by $C= \frac{1}{n}XX^T$</li>
<li>Calculate the eigenvalues and corresponding eigenvectors</li>
<li>Sort the eigenvectors by eigenvalues (large to small) and select the top $k$ as eigenvector matrix $P$</li>
<li>$Y=PX$ to get new data.</li>
</ol>
</li>
</ul>
<h3 id="Locally-Linear-Embedding"><a href="#Locally-Linear-Embedding" class="headerlink" title="Locally Linear Embedding"></a>Locally Linear Embedding</h3><p><img src="/2025/01/01/Artificial-Intelligence/ai702.png"></p>
<ul>
<li>Idea flow:<ol>
<li>Identify nearest neighbors for each instance</li>
<li>Calculate the linear weights for each instances to be reconstructed by its neighbors<ul>
<li>$\varepsilon(W)=\underset{i}{\sum}|X_i-\underset{j}{\sum} W_{ij} X_j|^2$</li>
</ul>
</li>
<li>Use W as the local structure information to be preserved (i.e., fix $W$), find the optimal values (say $Y$) for $X$ in the lower dimensional space.<ul>
<li>$\Phi (Y)=\underset{i}{\sum} |Y_i - \underset{j}{\sum} W_{ij} Y_j|^2$</li>
</ul>
</li>
</ol>
</li>
</ul>
<h1 id="Lecture-8-Recommender-System"><a href="#Lecture-8-Recommender-System" class="headerlink" title="Lecture 8. Recommender System"></a>Lecture 8. Recommender System</h1><h2 id="Outline-7"><a href="#Outline-7" class="headerlink" title="Outline"></a>Outline</h2><ul>
<li>Overview of recommender system (RS)</li>
<li>How does RS do recommendation?</li>
<li>How to build a RS?</li>
</ul>
<h2 id="Overview-of-recommender-system-RS"><a href="#Overview-of-recommender-system-RS" class="headerlink" title="Overview of recommender system (RS)"></a>Overview of recommender system (RS)</h2><ul>
<li>Recommender System recommend new items to its user.</li>
<li>Based on ?<ul>
<li>The items that the user has been interacted. [根据相似物品]</li>
<li>The users who have been interacted with same items which this user also been interacted. [根据相似用户]</li>
</ul>
</li>
<li>The recommendation is <font color="red">personalized</font>. </li>
<li>The key of Recommender System is a <font color="red">score function</font>.<ul>
<li>Input: a user and an item.</li>
<li>Return value: a score, indicating how likely the user would be interested in the item.</li>
</ul>
</li>
</ul>
<h2 id="How-does-RS-do-recommendation"><a href="#How-does-RS-do-recommendation" class="headerlink" title="How does RS do recommendation?"></a>How does RS do recommendation?</h2><p><img src="/2025/01/01/Artificial-Intelligence/ai801.png"></p>
<ul>
<li>RS basically estimate the probability of interaction between a user and an item, </li>
<li>The score function is essentially a <fotn color="red">model trained with data&lt;/font&gt;.</fotn></li>
<li>In practice, the score function could be very complicated since<ul>
<li>The RS needs to be efficient (make recommendations in seconds)</li>
<li>In many applications, we may have millions of users and items</li>
<li>There is always a trade-off between efficiency and accuracy</li>
</ul>
</li>
</ul>
<h2 id="How-to-build-a-RS"><a href="#How-to-build-a-RS" class="headerlink" title="How to build a RS?"></a>How to build a RS?</h2><h3 id="Problem-Formulation"><a href="#Problem-Formulation" class="headerlink" title="Problem Formulation"></a>Problem Formulation</h3><ul>
<li><strong>Input:</strong> Historical user-item interaction records or additional side information (e.g. user’s social relations, item’s knowledge, etc.)</li>
<li><strong>Output:</strong> The score function</li>
</ul>
<p><img src="/2025/01/01/Artificial-Intelligence/ai802.png"></p>
<h3 id="Typical-methods"><a href="#Typical-methods" class="headerlink" title="Typical methods"></a>Typical methods</h3><ul>
<li><strong>Content-based method</strong>:<ul>
<li>The very basic idea: build a regression/classification model for each user<ul>
<li>Focusing on the side information of the items (i.e., attributes, features of items)</li>
<li>Suggesting items by comparing their features to a user’s past behaviors</li>
</ul>
</li>
</ul>
</li>
<li><strong>Collaborative Filtering method</strong>: <ul>
<li>Predicting user preferences based on the behaviors of other users. </li>
<li>Based on the historical user-item interaction data </li>
</ul>
</li>
<li><strong>Hybrid method</strong>: Combination of CF-based and Content-based method</li>
</ul>
<h3 id="CF-based-method"><a href="#CF-based-method" class="headerlink" title="CF-based method"></a>CF-based method</h3><ul>
<li>Attributes/features of users and items are not available, <ul>
<li>How to build the regression/classification model (as the score function)?</li>
<li>Learning representation of users and items</li>
</ul>
</li>
</ul>
<p><img src="/2025/01/01/Artificial-Intelligence/ai803.png"></p>
<h3 id="Represented-by-correlation"><a href="#Represented-by-correlation" class="headerlink" title="Represented by correlation"></a>Represented by correlation</h3><ul>
<li>Represent the user/item by its correlation with the other users/items.<ul>
<li>Users with similar historical interactions are likely to have the same preferences.</li>
<li>Items that are interacted by similar users are likely to have hidden commonalities (共性).</li>
</ul>
</li>
<li>A user/item is represented by a vector that consists of all the correlation between itself and all the users/items.</li>
</ul>
<blockquote>
<font color="red">Q: How to define the correlation between 2 users or items?</font>
<br>
<font color="green">A: Pearson Correlation Coefficient, a normalized measurement of the covariance</font>

</blockquote>
<blockquote class="blockquote-center">
<p>$<br>c_{u_1u_2}=\large\frac{\underset{i\in M}{\sum} (r_{u_1,i} - \bar{r}_{u_1}) (r_{u_2,i} - \bar{r}_{u_2}) }{\sqrt{\underset{i\in M}{\sum} (r_{u_1,i} - \bar{r}_{u_1})^2} \sqrt{\underset{i\in M}{\sum} (r_{u_2,i} - \bar{r}_{u_2})^2}}<br>$</p>

</blockquote>
<ul>
<li>An example of user’s Pearson Correlation Coefficient</li>
<li>$M$: The item set</li>
<li>$r_{u,i}$: Interaction record between user $u$ and item $i$</li>
<li>$\bar{r}_u$: Mean value of all the interaction records of user $u$</li>
</ul>
<p><img src="/2025/01/01/Artificial-Intelligence/ai804.png"></p>
<ul>
<li><strong>Advantage</strong>: high interpretability<ul>
<li>It is easy to explain why the system recommend the item to the user.</li>
</ul>
</li>
<li><strong>Disadvantage</strong>: low scalability<ul>
<li>What if there are millions of users and millions of items?</li>
<li>High-dimensional, sparse feature representation</li>
</ul>
</li>
</ul>
<h3 id="Represent-by-matrix-factorization"><a href="#Represent-by-matrix-factorization" class="headerlink" title="Represent by matrix factorization"></a>Represent by matrix factorization</h3><ul>
<li>A matrix $R\in \mathbb{R}^{n\times m}$ approximate to the product of two matrix:</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>R\approx PQ^T ,\ P\in \mathbb{R}^{n\times d},\ Q\in \mathbb{R}^{m\times d}<br>$</p>

</blockquote>
<ul>
<li>Representing the user and item as a $d$-dimension vector</li>
<li>Matrix $P$, $Q$ consist of the representation vectors of all the users and items.</li>
<li>The low-dimension vector representation is also called as <strong>embedding vector</strong>.</li>
</ul>
<blockquote class="blockquote-center">
<p>$<br>\underset{P,Q}{\min} \underset{r_{u,i} \in R’}{\sum} ||r_{u,i} - r’_{u,i} ||,\ \text{where } r’_{u,i} = P_u Q_i^T<br>$</p>

</blockquote>
<ul>
<li>In this “objective function”, $P_u$ is user $u$’s embedding vector, $Q_i$ is item $i$’s embedding vector<ul>
<li>$r’_{u,i} = f(P_u, Q_i) = P_uQ_i^T$ is a simple example for this function.</li>
</ul>
</li>
<li>If we replace the matrix multiplication with a complex model $M$, such as MLP<ul>
<li>objective function will be : $\large\underset{P,Q,M}{\min} \underset{r_{u,i}\in R’}{\sum} ||r_{u,i}-f(P_u, Q_i, M)||$</li>
<li>The model with higher complexity may have better prediction performance in <strong>big data scenario</strong> (as an optimization)</li>
</ul>
</li>
</ul>
<h1 id="Lecture-9-Automated-Machine-Learning"><a href="#Lecture-9-Automated-Machine-Learning" class="headerlink" title="Lecture 9. Automated Machine Learning"></a>Lecture 9. Automated Machine Learning</h1><h2 id="Tuning-Hyper-parameters"><a href="#Tuning-Hyper-parameters" class="headerlink" title="Tuning Hyper-parameters"></a>Tuning Hyper-parameters</h2><blockquote>
<p>How to tune the hyper-parameters?</p>
</blockquote>
<p><img src="/2025/01/01/Artificial-Intelligence/ai901.png"></p>
<ul>
<li>Grid Search<ul>
<li>Too costly</li>
</ul>
</li>
<li>More efficient ways?<ul>
<li>Use heuristic Search (e.g., using Black-Box optimization algorithms)</li>
<li>Sometimes, good surrogate of generalization is available to accelerate the evaluation</li>
</ul>
</li>
</ul>
<blockquote>
<p>Too short ? Sorry, my lecture slides is only 6 pages.</p>
</blockquote>
<h1 id="Lecture-10-Logical-Agents"><a href="#Lecture-10-Logical-Agents" class="headerlink" title="Lecture 10. Logical Agents"></a>Lecture 10. Logical Agents</h1><h2 id="Outline-8"><a href="#Outline-8" class="headerlink" title="Outline"></a>Outline</h2><ul>
<li>Knowledge-based Agents</li>
<li>Represent Knowledge with Logic</li>
<li>(Propositional) Logic</li>
<li>Inference with Propositional Logic</li>
</ul>
<h2 id="Knowledge-based-Agents"><a href="#Knowledge-based-Agents" class="headerlink" title="Knowledge-based Agents"></a>Knowledge-based Agents</h2><p><strong>Agent Components</strong></p>
<ul>
<li>Intelligent agents need <font color="red">knowledge</font> about the world to choose good actions/decisions.</li>
<li>Knowledge = {sentences} in a knowledge representation language (formal language).</li>
<li>A sentence is an assertion about the world.</li>
<li>A knowledge-based agent is composed of:<ol>
<li><font color="dodgerblue">Knowledge base</font>: domain-specific content.</li>
<li><font color="dodgerblue">Inference mechanism</font>: domain-independent algorithms.</li>
</ol>
</li>
</ul>
<p><strong>Agent Requirements</strong></p>
<ul>
<li>Represent states, actions, etc.</li>
<li>Incorporate new percepts</li>
<li>Update internal representations of the world</li>
<li>Deduce hidden properties of the world</li>
<li>Deduce appropriate actions</li>
</ul>
<p><strong>Declarative approach to building an agent</strong></p>
<ul>
<li>Add new sentences: <em>Tell</em> it what it needs to know</li>
<li>Query what is known: <em>Ask</em> itself what to do - answers should follow from the KB</li>
</ul>
<blockquote>
<p>Use a game as an example:</p>
</blockquote>
<p><img src="/2025/01/01/Artificial-Intelligence/ai1001.png" style="zoom:60%"></p>
<ul>
<li>Actuators:<ul>
<li>Left turn, Right turn, Forward, Grab, Release, Shoot </li>
</ul>
</li>
<li>Sensors:<ul>
<li>Stench, Breeze, Glitter, Bump, Scream</li>
<li>Represented as a 5-element list</li>
<li>Example: [Stench, Breeze, None, None, None]</li>
</ul>
</li>
</ul>
<h2 id="Represent-Knowledge-with-Logic"><a href="#Represent-Knowledge-with-Logic" class="headerlink" title="Represent Knowledge with Logic"></a>Represent Knowledge with Logic</h2><ul>
<li><font color="dodgerblue">Knowledge base</font>: a set of sentences in a formal representation</li>
<li><font color="dodgerblue">Syntax</font>: defines well-formed sentences in the language</li>
<li><font color="dodgerblue">Semantic</font>: defines the truth or meaning of sentences in a world</li>
<li><font color="dodgerblue">Inference</font>: a procedure to derive a new sentence from other ones.</li>
</ul>
<table>
<tr>
    <td><img src="/2025/01/01/Artificial-Intelligence/ai1002.png"></td>
    <td><img src="/2025/01/01/Artificial-Intelligence/ai1003.png"></td>
</tr>
</table>

<h3 id="Inference-1"><a href="#Inference-1" class="headerlink" title="Inference"></a>Inference</h3><ul>
<li>Inference: the procedure of deriving a sentence from another sentence</li>
<li><font color="red">Model Checking</font>: A basic (and general) idea to inference</li>
</ul>
<p><img src="/2025/01/01/Artificial-Intelligence/ai1004.png" style="zoom:50%"></p>
<h2 id="Propositional-Logic"><a href="#Propositional-Logic" class="headerlink" title="Propositional Logic"></a>Propositional Logic</h2><blockquote>
<p>Most have been learnt in CS201 Discrete Mathemetics</p>
</blockquote>
<p><strong>Def.</strong> A proposition is a declarative statement that’s either True or False.</p>
<ul>
<li><font color="green">Recall:</font><ul>
<li>Negation</li>
<li>AND</li>
<li>OR</li>
<li>Implication</li>
<li>Biconditional, etc.</li>
</ul>
</li>
</ul>
<h2 id="Inference-with-Propositional-Logic"><a href="#Inference-with-Propositional-Logic" class="headerlink" title="Inference with Propositional Logic"></a>Inference with Propositional Logic</h2><ul>
<li>Our inference algorithm target:</li>
<li><strong>Sound</strong>: oes not infer false formulas, that is, derives only entailed sentences.<ul>
<li>$\{ \alpha | KB \vdash \alpha \} \subseteq \{ \alpha | KB \models \alpha \}$</li>
</ul>
</li>
<li><strong>Complete</strong>: derives ALL entailed sentences.<ul>
<li>$\{ \alpha | KB \vdash \alpha \} \supseteq \{ \alpha | KB \models \alpha \}$</li>
</ul>
</li>
<li>That is, we want a <strong>Logical Equivalent</strong>: $p\equiv q$</li>
</ul>
<blockquote>
<p>Go review some Inferences instance:</p>
<p>e.g. Modus Ponens, Modus Tollens, etc.</p>
</blockquote>
<h3 id="Inference-as-a-search-problem"><a href="#Inference-as-a-search-problem" class="headerlink" title="Inference as a search problem"></a>Inference as a search problem</h3><ul>
<li><font color="red">Initial state:</font> The initial KB</li>
<li><font color="red">Actions:</font> all inference rules applied to all sentences that match the top of the inference rule</li>
<li><font color="red">Results:</font> add the sentence in the bottom half of the inference rule</li>
<li><font color="red">Goal:</font> a state containing the sentence we are trying to prove.</li>
<li><font color="dodgerblue">Completeness Issue:</font> if the inference rules to use are not sufficient, the goal can not be obtained.</li>
</ul>
<blockquote>
<p>How to ensure soundness ?</p>
</blockquote>
<ul>
<li>The <strong>idea of inference</strong> is to repeat applying inference rules to the KB.</li>
<li>Inference can be applied whenever suitable premises are found in the KB.</li>
</ul>
<blockquote>
<p>What aboud completeness ?</p>
</blockquote>
<ul>
<li>Two ways to ensure completeness:<ul>
<li><strong>Proof by resolution</strong>: use powerful inference rules (resolution rule)</li>
<li><strong>Forward or Backward chaining</strong>: use of modus ponens on a restricted form of propositions (Horn clauses)</li>
</ul>
</li>
</ul>
<h3 id="Proof-by-resolution"><a href="#Proof-by-resolution" class="headerlink" title="Proof by resolution"></a>Proof by resolution</h3><p><img src="/2025/01/01/Artificial-Intelligence/ai1005.png" style="zoom:60%"></p>
<ul>
<li>Two cases to end loop:<ul>
<li>there are no new clauses that can be added, in which case $KB$ doesn’t ential $\alpha$; or,</li>
<li>two clauses resolve to yield the empty clause, in which case $KB$ entails $\alpha$</li>
</ul>
</li>
</ul>
<h3 id="Forward-chaining"><a href="#Forward-chaining" class="headerlink" title="Forward chaining"></a>Forward chaining</h3><p><img src="/2025/01/01/Artificial-Intelligence/ai1006.png" style="zoom:60%"></p>
<ul>
<li><strong>Idea</strong>: Find any rule whose premises are satisfied in the $KB$, add its conclusion to the KB, until query is found</li>
</ul>
<table>
<tr>
    <td><img src="/2025/01/01/Artificial-Intelligence/ai1007.png"></td>
    <td><img src="/2025/01/01/Artificial-Intelligence/ai1008.png"></td>
    <td><img src="/2025/01/01/Artificial-Intelligence/ai1009.png"></td>
    <td><img src="/2025/01/01/Artificial-Intelligence/ai1010.png"></td>
</tr>
<tr>
    <td><img src="/2025/01/01/Artificial-Intelligence/ai1011.png"></td>
    <td><img src="/2025/01/01/Artificial-Intelligence/ai1012.png"></td>
    <td><img src="/2025/01/01/Artificial-Intelligence/ai1013.png"></td>
    <td><img src="/2025/01/01/Artificial-Intelligence/ai1014.png"></td>
</tr>
</table>

<h3 id="Backward-chaining"><a href="#Backward-chaining" class="headerlink" title="Backward chaining"></a>Backward chaining</h3><ul>
<li><strong>Idea:</strong> Works backwards from the query $q$</li>
<li>To prove $q$ by Backward Chaining:<ul>
<li>Check if $q$ is known already, or</li>
<li>Prove by Backward Chaining all premises of some rule concluding $q$.</li>
</ul>
</li>
<li>Avoid loops: check if new subgoal is already on the goal stack</li>
<li>Avoid repeated work: check if new subgoal<ul>
<li>has already been proved true, or</li>
<li>has already failed</li>
</ul>
</li>
</ul>
<table>
<tr>
    <td><img src="/2025/01/01/Artificial-Intelligence/ai1015.png"></td>
    <td><img src="/2025/01/01/Artificial-Intelligence/ai1016.png"></td>
    <td><img src="/2025/01/01/Artificial-Intelligence/ai1017.png"></td>
    <td><img src="/2025/01/01/Artificial-Intelligence/ai1018.png"></td>
    <td><img src="/2025/01/01/Artificial-Intelligence/ai1019.png"></td>
</tr>
<tr>
    <td><img src="/2025/01/01/Artificial-Intelligence/ai1020.png"></td>
    <td><img src="/2025/01/01/Artificial-Intelligence/ai1021.png"></td>
    <td><img src="/2025/01/01/Artificial-Intelligence/ai1022.png"></td>
    <td><img src="/2025/01/01/Artificial-Intelligence/ai1023.png"></td>
    <td><img src="/2025/01/01/Artificial-Intelligence/ai1024.png"></td>
</tr>
</table>

<ul>
<li>Explanation:<ul>
<li>start from query $Q$, and $A$, $B$ has been known.</li>
<li>check recursively each node that “should be proved right”</li>
<li>for one node:<ul>
<li>if its “successors” wait to be proved (e.g. L 👈 <strong>P</strong>, A)</li>
<li>or it’s unknown (neither “green” nor “red”), then avoid it</li>
</ul>
</li>
<li>else this node is proved (turn “red”)</li>
</ul>
</li>
<li>Suppose: B is unknown<ul>
<li>then step 5 (want to prove L 👈 A, <strong>B</strong>) failed</li>
<li>and L cannot be proved, and query $Q$ failed immediately too.</li>
</ul>
</li>
</ul>
<blockquote>
<p><strong>Forward vs. Backward</strong></p>
</blockquote>
<ul>
<li>Forward chaining:<ul>
<li>Data-driven, automatic, unconscious processing,</li>
<li>May do lots of work that is irrelevant to the goal</li>
</ul>
</li>
<li>Backward chaining:<ul>
<li>Goal-driven, appropriate for problem-solving,</li>
<li>Complexity of BC can be much less than linear in size of KB</li>
</ul>
</li>
</ul>
<h3 id="DPLL"><a href="#DPLL" class="headerlink" title="DPLL"></a>DPLL</h3><blockquote>
<p>The <strong>DPLL algorithm</strong> is similar to <strong>Backtracking</strong> for CSP, but using various problem dependent information/heuristics, such as Early Termination, Pure symbol heuristic and Unit clause heuristic.</p>
</blockquote>
<p><img src="/2025/01/01/Artificial-Intelligence/ai1025.png" style="zoom:60%"></p>
<blockquote>
<p>概念介绍：如下的式子被称为合取范式（CNF），式子中只包含逻辑与，逻辑或和逻辑非，且每个部分由<strong>逻辑与</strong>连接</p>
<p>$(a\vee b\vee \neg c)\wedge \cdots \wedge (a\vee d \vee \neg d)$</p>
<ul>
<li>括号部分为该公式的<strong>子句(clause)</strong>，每个子句中的变量或变量的否定为<strong>文字(literal/symbol)</strong></li>
<li>要使整个公式为 True，则每个子句都必须为 True，也就是说，每个子句中至少有一个文字为 True</li>
<li>DPLL 算法简化步骤实际上就是<font color="hotpink">移除所有在赋值后值为 True 的子句，以及所有在赋值后值为 False 的文字</font>。<ul>
<li>简化步骤分两步：孤立文字消去（Pure Symbol）和单位子句传播（Unit Clause）</li>
</ul>
</li>
</ul>
</blockquote>
<ul>
<li>In <strong>pure symbol elimination</strong>, we try to find <font color="red">symbols</font> that only appear <font color="red">once in all clauses</font>.<ul>
<li>If the symbol is in form $a$ (positive), then it’s assigned to <font color="limegreen">True</font> ;</li>
<li>If the symbol is in form $\neg a$ (negative), then it’s assigned to <font color="orangered">False</font> ;</li>
<li>then we check the clause containing this symbol if it’s true or false. <em>(try to eliminate)</em></li>
</ul>
</li>
<li>In <strong>unit clause propagation</strong>, we try to find <font color="red">clauses with only one literal</font>, or <font color="red">clauses with one literal that is unknown</font> (and it must cause the whole clause unknown).<ul>
<li>E.g. $(a\vee b\vee c\vee \neg d)\wedge (\neg a\vee c)\wedge (\neg c\vee d)\wedge (a)$<ul>
<li>find $a$ as unit clause, then we say $a$ must be <font color="limegreen">True</font>, and reduce the sentence $\to (c)\wedge (\neg c\vee d)\wedge (a)$ ;</li>
<li>then find $c$ as unit clause, same process $\to (c)\wedge(d)\wedge(a)$ ;</li>
</ul>
</li>
</ul>
</li>
<li>At last, we got a <code>model</code> with some assigned literal. That’s the solution we want.</li>
</ul>
<h3 id="Summary-1"><a href="#Summary-1" class="headerlink" title="Summary"></a>Summary</h3><ul>
<li><strong>Inference with Propositional Logic</strong> 👉 we want an inference algorithm that is:<ul>
<li>sound (does not infer false formulas), and</li>
<li>ideally, complete too (derives all true formulas).</li>
</ul>
</li>
<li>Limits ?<ul>
<li>PL is not expressive enough to describe all the world around us. It can’t express information about different object and the relation between objects.</li>
<li>PL is not compact. It can’t express a fact for a set of objects without enumerating all of them which is sometimes <strong>impossible</strong>.</li>
</ul>
</li>
</ul>
<blockquote>
<p>Review: First Order Logic (learnt in Discrete Mathematics)</p>
<ul>
<li>Concept of Syntax, Semantics, Entailment(necessary truth of one sentence given another), etc.</li>
<li><p>Forward, backward chaining are linear in time, complete for horn clauses. Resolution is complete for propositional logic.</p>
</li>
<li><p>Pros</p>
<ul>
<li>Intelligibility of models: models are encoded explicitly</li>
</ul>
</li>
<li>Cons<ul>
<li>Do not handle uncertainty</li>
<li>Rule-based and do not use data (Machine Learning)</li>
<li>It is hard to model every aspect of the world</li>
</ul>
</li>
</ul>
</blockquote>
<h1 id="Lecture-11-First-Order-Logic"><a href="#Lecture-11-First-Order-Logic" class="headerlink" title="Lecture 11. First Order Logic"></a>Lecture 11. First Order Logic</h1><h2 id="Inference-with-FOL"><a href="#Inference-with-FOL" class="headerlink" title="Inference with FOL"></a>Inference with FOL</h2><blockquote>
<p><strong>Basic concept of FOL</strong></p>
<p>Three basic component: Objects, Relations, Functions</p>
</blockquote>
<p><img src="/2025/01/01/Artificial-Intelligence/ai1101.png" style="zoom:60%"></p>
<ul>
<li><font color="green">Recall</font>:<ul>
<li>Universal Instantiation, Existential Instantiation, etc.</li>
<li>Reduce FOL to simple format</li>
</ul>
</li>
<li>Better Ideas to Inference with FOL: Unification<ul>
<li>Resolution</li>
<li>Chaining Algorithms (In lec 10.)</li>
</ul>
</li>
</ul>
<h1 id="Lecture-12-Representing-and-Inference-with-Uncertainty"><a href="#Lecture-12-Representing-and-Inference-with-Uncertainty" class="headerlink" title="Lecture 12. Representing and Inference with Uncertainty"></a>Lecture 12. Representing and Inference with Uncertainty</h1><h2 id="Outline-9"><a href="#Outline-9" class="headerlink" title="Outline"></a>Outline</h2><ul>
<li>Uncertainty and Rational Decisions</li>
</ul>
<h2 id="Uncertainty-and-Rational-Decisions"><a href="#Uncertainty-and-Rational-Decisions" class="headerlink" title="Uncertainty and Rational Decisions"></a>Uncertainty and Rational Decisions</h2><ul>
<li>Alternative to Logic<ul>
<li>Utility theory: Assign utility to each state/actions</li>
<li>Probability theory: Summarize the uncertainty associated with each state</li>
<li>Rational Decisions: Maximize the expected utility (Probability + Utility) </li>
<li>Thus we need to represent states in the language of probability</li>
</ul>
</li>
<li><font color="red">In a word, use probability to replace logic.</font>



</li>
</ul>
<h2 id="Basic-Probability-Theory-and-Usage"><a href="#Basic-Probability-Theory-and-Usage" class="headerlink" title="Basic Probability Theory and Usage"></a>Basic Probability Theory and Usage</h2><table>
<tr>
    <td><img src="/2025/01/01/Artificial-Intelligence/ai1201.png"></td>
    <td><img src="/2025/01/01/Artificial-Intelligence/ai1202.png"></td>
</tr>
</table>

<blockquote>
<p><font color="green">Recall:</font> MA212 概率论与数理统计</p>
<p>贝叶斯公式，条件概率，联合概率等</p>
</blockquote>
<h2 id="Bayesian-Networks"><a href="#Bayesian-Networks" class="headerlink" title="Bayesian Networks"></a>Bayesian Networks</h2><ul>
<li>What is a BN ?<ul>
<li>A Directed Acyclic Graph (DAG).</li>
<li>Each node is a random variable, associated with conditional distribution. </li>
<li>Each arc (link) represent <font color="red">direct influence</font> of a parent node to a child node.</li>
</ul>
</li>
</ul>
<p><img src="/2025/01/01/Artificial-Intelligence/ai1203.png" style="zoom:60%"></p>
<ul>
<li>In the above exmaple, a Conditional Probability Table (CPT) is construct for each node<ul>
<li>Easier to utilize independence and conditional dependence relations to define the joint distribution.</li>
</ul>
</li>
<li>How to construct a <strong>CPT for BN</strong>?</li>
</ul>
<p><img src="/2025/01/01/Artificial-Intelligence/ai1204.png" style="zoom:60%"></p>
<h3 id="Inference-with-BN"><a href="#Inference-with-BN" class="headerlink" title="Inference with BN"></a>Inference with BN</h3><ul>
<li>Given a Bayesian Network, and an (or some) observed events, which specifies the value for <font color="red">evidence variables</font>, we want to know the probability distribution of one (or several) <font color="red">query variables</font> $\color{red}X$, i.e. $P(X | \text{events})$</li>
<li>First we try enumeration (calc all possible cases)</li>
</ul>
<p><img src="/2025/01/01/Artificial-Intelligence/ai1205.png" style="zoom:70%"></p>
<ul>
<li>and it’s time consuming.</li>
<li>A way to simplify: Enumeration by Variable Elimination</li>
</ul>
<p><img src="/2025/01/01/Artificial-Intelligence/ai1206.png" style="zoom:70%"></p>
<h3 id="Approximate-Inference-with-BN"><a href="#Approximate-Inference-with-BN" class="headerlink" title="Approximate Inference with BN"></a>Approximate Inference with BN</h3><ul>
<li>Basic Idea:<ol>
<li>Draw N samples from a sampling distribution $S$</li>
<li>Compute an approximate posterior probability (后验概率) $\hat{P}$</li>
<li>Show this converge to the true probability $P$</li>
</ol>
</li>
<li>Outline<ul>
<li>Sampling from an empty network</li>
<li>Rejection sampling: reject samples disagreeing with evidence</li>
<li>Likelihood weighting: use evidenve to weight samples</li>
<li>Markov Chain Monte Carlo (MCMC): sample from a stochastic process (随机过程) whose stationary distribution is the true posterior.</li>
</ul>
</li>
</ul>
<h4 id="Sampling-from-an-empty-network"><a href="#Sampling-from-an-empty-network" class="headerlink" title="Sampling from an empty network"></a>Sampling from an empty network</h4><p><img src="/2025/01/01/Artificial-Intelligence/ai1207.png" style="zoom:60%"></p>
<h4 id="Rejection-Sampling"><a href="#Rejection-Sampling" class="headerlink" title="Rejection Sampling"></a>Rejection Sampling</h4><p><img src="/2025/01/01/Artificial-Intelligence/ai1208.png" style="zoom:80%"></p>
<h4 id="Likelihood-Weighting"><a href="#Likelihood-Weighting" class="headerlink" title="Likelihood Weighting"></a>Likelihood Weighting</h4><p><img src="/2025/01/01/Artificial-Intelligence/ai1209.png" style="zoom:80%"></p>
<h4 id="MCMC"><a href="#MCMC" class="headerlink" title="MCMC"></a>MCMC</h4><p><img src="/2025/01/01/Artificial-Intelligence/ai1210.png" style="zoom:70%"></p>
<h3 id="How-to-construct-a-BN-or-KB-in-general"><a href="#How-to-construct-a-BN-or-KB-in-general" class="headerlink" title="How to construct a BN (or KB in general) ?"></a>How to construct a BN (or KB in general) ?</h3><ul>
<li>Challenge<ul>
<li>Big Data</li>
</ul>
</li>
<li>Methods<ul>
<li>Structural Learning</li>
<li>Parameter Estimation</li>
</ul>
</li>
<li>Similar to Neural Networks<ul>
<li>Structural Learning: Identify the network structure</li>
<li>Parameter Estimation: find VALUEs for parameters associated with an edge<ul>
<li>Depending on how you define the relationship between events/nodes<ul>
<li>values in a CPT</li>
<li>parameters of a probability density function</li>
</ul>
</li>
</ul>
</li>
<li>A machine learning or search problem again.</li>
</ul>
</li>
</ul>
<h1 id="Lecture-13-Knowledge-Graph"><a href="#Lecture-13-Knowledge-Graph" class="headerlink" title="Lecture 13. Knowledge Graph"></a>Lecture 13. Knowledge Graph</h1><h2 id="Overview-of-Knowledge-Graph-KG"><a href="#Overview-of-Knowledge-Graph-KG" class="headerlink" title="Overview of Knowledge Graph (KG)"></a>Overview of Knowledge Graph (KG)</h2><blockquote>
<p>What is Knowledge Graph?</p>
</blockquote>
<ul>
<li>To make a knowledge base (KB) of <strong>practical significance</strong>, we need to:<ul>
<li>Set a proper boundary for “knowledge”, which means:<ul>
<li>bound the scope of the KB (and thus its representation)</li>
<li>bound the utility (application) of the KB</li>
</ul>
</li>
</ul>
</li>
<li>The idea of KG stems from <strong>Semantic Network</strong>.<ul>
<li>Knowledge Graph: Large-scale semantic network</li>
</ul>
</li>
<li>SN/KG uses vertexes and edges to represent knowledge graphically.<ul>
<li><strong>Vertexes</strong>: entities and concepts</li>
<li><strong>Edges</strong>: relations and properties</li>
</ul>
</li>
</ul>
<p><img src="/2025/01/01/Artificial-Intelligence/ai1301.png" style="zoom:90%"></p>
<h2 id="How-to-construct-Knowledge-Graph？"><a href="#How-to-construct-Knowledge-Graph？" class="headerlink" title="How to construct Knowledge Graph？"></a>How to construct Knowledge Graph？</h2><ul>
<li>Heterogeneous directed graphs.<ul>
<li>The KG can be represented as a graph $\mathcal{G}=(V,E)$ , $V$ is vertex set (entities set), $E$ is the edge set (relations set).</li>
</ul>
</li>
<li>RDF：Resource Description Framework, an XML Document standard from W3C<ul>
<li>use relation triplet <code>&lt;head entity, relation type, tail entity&gt;</code> to describe a relation.</li>
<li><strong>Head entity</strong>: the subject of this relation</li>
<li><strong>Relation type</strong>: the category of this relation</li>
<li><strong>Tail entity</strong>: the object of this relation</li>
</ul>
</li>
</ul>
<p><strong>The General (Semi-)Automatic Viewpoint</strong></p>
<p><img src="/2025/01/01/Artificial-Intelligence/ai1302.png" style="zoom:60%"></p>
<h3 id="Automatic-Entity-Recognition"><a href="#Automatic-Entity-Recognition" class="headerlink" title="Automatic Entity Recognition"></a>Automatic Entity Recognition</h3><ul>
<li>Identify meaningful entities based on the statistical metrics of vocabulary across various texts.<ul>
<li>Input: Documents (text)</li>
<li>Output: A set of entities</li>
</ul>
</li>
<li><strong>TF-IDF</strong> (Term Frequency–Inverse Document Frequency):<ul>
<li><font color="dodgerblue">Idea:</font> If a word appears frequently in one document but infrequently in others, it is more likely to be a meaningful entity.</li>
<li>For a corpus of documents:<ul>
<li>Term Frequency (TF): $P(w|d)$</li>
<li>Inverse Document Frequency (IDF): $\log{\left(\frac{|D|}{|\{ d\in D|w\in d \}|}\right)}$</li>
<li>TF-IDF: TF $\times$ IDF</li>
</ul>
</li>
</ul>
</li>
<li><strong>Entropy</strong> :<ul>
<li><font color="dodgerblue">Idea:</font> If a word has a rich variety of <font color="red">neighboring words</font>, it is likely be a meaningful entity<ul>
<li>$H(u) = - \sum_{x\in \mathcal{X}} p(x) \log{p(x)}$</li>
<li>$p(x)$ is the probability of a certain left neighbor (right neighbor) word, $\mathcal{X}$ is the set of all left neighbor (right neighbor) characters of $u$.</li>
<li>The larger $H(u)$ is, more abundant the set of $u$’s neighbors is.</li>
</ul>
</li>
</ul>
</li>
</ul>
<blockquote>
<p>Also, some ML techniques can solve the NER(Name Entity Recognition) tasks. Considering <strong>input</strong> is a sentence, <strong>output</strong> is the label of each word in the sentence.</p>
</blockquote>
<p><img src="/2025/01/01/Artificial-Intelligence/ai1303.png" style="zoom:80%"></p>
<h3 id="Automatic-Relation-Extraction"><a href="#Automatic-Relation-Extraction" class="headerlink" title="Automatic Relation Extraction"></a>Automatic Relation Extraction</h3><blockquote>
<p>By recognizing entities, now AI should “learn” about relations.</p>
</blockquote>
<ul>
<li>Using machine learning techniques, model the Relation Extraction process as a Text Classification Problem.<ul>
<li>It’s also a supervised learning task.</li>
</ul>
</li>
<li>Input is a sentence that contains 2 entities. Output is the category of the relation that the sentence express.<ul>
<li>Input: <font color="red">Zihan Zhang</font> will join the <font color="green">ICPC</font>.</li>
<li>Output: participate in</li>
</ul>
</li>
<li><strong>Relation extraction task</strong> can be solved by the following technologies:<ul>
<li>RNN, Transformers, …</li>
</ul>
</li>
</ul>
<h3 id="Knowledge-Graph-Completion"><a href="#Knowledge-Graph-Completion" class="headerlink" title="Knowledge Graph Completion"></a>Knowledge Graph Completion</h3><p><img src="/2025/01/01/Artificial-Intelligence/ai1304.png" style="zoom:80%"></p>
<ul>
<li>2 ways for completion task<ul>
<li>Path-based method</li>
<li>Embedding-based method</li>
</ul>
</li>
</ul>
<ul>
<li>Path-based is interpretable, so we skip it.</li>
<li>Embedding-based methods represent the entities and relation types in the KG as a <strong>low-dimensional real value vector</strong> (also called embedding).<ul>
<li>Design a score function $\mathcal{g}(h,r,t)$. Get suitable embedding for entities and relation types.<ul>
<li>$h$, $r$, and $t$ are embeddings of head entity $h$, relation type $r$, and tail entity $t$ respectively.</li>
<li>Higher $\mathcal{g}(h,r,t)$ means that the relation is more possible to be true.</li>
</ul>
</li>
</ul>
</li>
<li>How to get suitable embedding for entities and relation types?<ul>
<li>Consider: All the relations in the KG should have higher score than any relation that is not in the KG.</li>
<li>Objective Function: $\min \underset{(h,r,t)\in \mathcal{g}}{\sum} \underset{(h’,r’,t’)\notin \mathcal{g}}{\sum} \left[\mathcal{g}(h’,r’,t’) - \mathcal{g}(h,r,t)\right]_{+}$</li>
<li>Get suitable embedding by <strong>gradient descent</strong>.</li>
</ul>
</li>
</ul>
<h2 id="KG-Based-Recommender-System"><a href="#KG-Based-Recommender-System" class="headerlink" title="KG-Based Recommender System"></a>KG-Based Recommender System</h2><p><img src="/2025/01/01/Artificial-Intelligence/ai1305.png" style="zoom:80%"><br><img src="/2025/01/01/Artificial-Intelligence/ai1306.png" style="zoom:80%"><br><img src="/2025/01/01/Artificial-Intelligence/ai1307.png" style="zoom:80%"><br><img src="/2025/01/01/Artificial-Intelligence/ai1308.png" style="zoom:80%"></p>
<ul>
<li>We can get the <strong>feature of the user and item</strong> from the new graph that is mixed by KG and interaction records.</li>
<li>A typical method is GNN (Graph Neural Network):<ul>
<li>There is an initial embedding for each node in the graph.</li>
<li>The final embedding of each node is calculated by the embeddings of its neighborhood.</li>
<li>Result of $f(u,w)$ is calculated according to the final embeddings of user<br>$u$ and item $w$ by a model $M$, such as MLP or matrix multiplication.</li>
</ul>
</li>
</ul>
<h1 id="Review-and-Semester-Summary"><a href="#Review-and-Semester-Summary" class="headerlink" title="Review and Semester Summary"></a>Review and Semester Summary</h1><blockquote>
<p>I can build a knowledge base here to tell you what we’ve learnt in AI course. 😂 </p>
<p>Just a framework.</p>
</blockquote>
<ul>
<li>Problem-solving<ul>
<li>Classical search</li>
<li>Beyondclassical search</li>
<li>Problem-Specific Search</li>
</ul>
</li>
<li>MachineLearning<ul>
<li>Supervised Learning</li>
<li>Performance Evaluation</li>
<li>Unsupervised Learning</li>
<li>Automated Machine Learning</li>
</ul>
</li>
<li>Knowledge and Reasoning <ul>
<li>Representing and Inference with logic</li>
<li>Representing and Inference with Uncertainty </li>
<li>Knowledge Graph andRecommender System </li>
</ul>
</li>
</ul>
<h2 id="Connection-with-Previous-Courses"><a href="#Connection-with-Previous-Courses" class="headerlink" title="Connection with Previous Courses"></a>Connection with Previous Courses</h2><ul>
<li>In searching module, we use algorithm of graph, which we’ve learnt in <strong>DSAA</strong>.</li>
<li>In ML module, we use knowledge in <strong>Big Data</strong> Course.<ul>
<li>Also we talked about FOL … which is in <strong>Discrete Mathemetic</strong>.</li>
</ul>
</li>
<li>In KG-RS module, we use knowledge in <strong>Probability Theory and Mathemetic Statistics</strong>.</li>
<li>And the whole AI Course has strong connection to <strong>Calculus</strong> and <strong>Linear Algebra</strong>.</li>
</ul>
<blockquote>
<p>Therefore, if you want to learn AI well, these courses should be premises.</p>
<p>(Also said to me, a foolish student …)</p>
</blockquote>
]]></content>
      <categories>
        <category>2024 Fall</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>CSE Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>Traps that I&#39;m in —— `Next.js` App-dev</title>
    <url>/2025/03/30/Traps-that-I-m-in-%E2%80%94%E2%80%94-Next-js-App-dev/</url>
    <content><![CDATA[<h1 id="Before"><a href="#Before" class="headerlink" title="Before"></a>Before</h1><ul>
<li>A note for project development of Software Engineering</li>
<li>Recording the trap I’ve been in when I was coding by <code>React/Next.js</code></li>
<li>I was responsible for front-end. Although my team use framework <code>Springboot + React</code>, this note will only includes contents of <code>Next.js</code></li>
</ul>
<h1 id="1-Using-State-amp-Using-Effect"><a href="#1-Using-State-amp-Using-Effect" class="headerlink" title="1. Using State &amp; Using Effect"></a>1. Using State &amp; Using Effect</h1>]]></content>
      <categories>
        <category>2025 Spring</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>React</tag>
        <tag>Next.js</tag>
      </tags>
  </entry>
</search>
